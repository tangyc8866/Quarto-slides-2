<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; 基于逆高斯过程的统计建模 – 随机退化过程与统计建模</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/05-ED.html" rel="next">
<link href="../chapters/03-Gamma.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-678afd9922eebfa9ca7f5014aecbca52.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-1b5c5d9af6a8c471bfa7390881d2a26e.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>
<!-- This is what works with Quarto -->
<script>
  MathJax = {
      tex: {
          tags: 'ams',  // should be 'ams', 'none', or 'all'
          inlineMath: [                 // start/end delimiter pairs for in-line math
              ['$', '$'],
              ['\\(', '\\)'],
          ],
          displayMath: [                // start/end delimiter pairs for display math
              ['$$', '$$'],
              ['\\[', '\\]']
          ],
          processEscapes: true,
          macros: {
              bm: ["\\boldsymbol{#1}", 1],  
              diff: ["\\mathrm{d}"],  
          },
      }
  };
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">随机退化过程与统计建模</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="搜索"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="切换导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://xu-ancha.github.io/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="切换深色模式"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="切换阅读器模式">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/04-IG.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">基于逆高斯过程的统计建模</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">前言</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">引言</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-Wiener.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">基于维纳过程的统计建模</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-Gamma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">基于伽马过程的统计建模</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-IG.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">基于逆高斯过程的统计建模</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-ED.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">基于指数分散过程的统计建模</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-Conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">总结与展望</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">参考文献</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#sec-IG" id="toc-sec-IG" class="nav-link active" data-scroll-target="#sec-IG"><span class="header-section-number">4.1</span> 逆高斯过程</a></li>
  <li><a href="#sec-Hetero-IG" id="toc-sec-Hetero-IG" class="nav-link" data-scroll-target="#sec-Hetero-IG"><span class="header-section-number">4.2</span> 子总体异质性下的逆高斯过程</a>
  <ul class="collapse">
  <li><a href="#sec-AMM2020-s2" id="toc-sec-AMM2020-s2" class="nav-link" data-scroll-target="#sec-AMM2020-s2"><span class="header-section-number">4.2.1</span> 模型构建</a></li>
  <li><a href="#sec-AMM2020-s3" id="toc-sec-AMM2020-s3" class="nav-link" data-scroll-target="#sec-AMM2020-s3"><span class="header-section-number">4.2.2</span> 统计推断</a></li>
  <li><a href="#sec-AMM2020-s4" id="toc-sec-AMM2020-s4" class="nav-link" data-scroll-target="#sec-AMM2020-s4"><span class="header-section-number">4.2.3</span> 模拟实验</a></li>
  <li><a href="#sec-AMM2020-s5" id="toc-sec-AMM2020-s5" class="nav-link" data-scroll-target="#sec-AMM2020-s5"><span class="header-section-number">4.2.4</span> 实例分析</a></li>
  <li><a href="#sec-Append-4B" id="toc-sec-Append-4B" class="nav-link" data-scroll-target="#sec-Append-4B"><span class="header-section-number">4.2.5</span> 附录</a></li>
  </ul></li>
  <li><a href="#sec-tp-IG" id="toc-sec-tp-IG" class="nav-link" data-scroll-target="#sec-tp-IG"><span class="header-section-number">4.3</span> 二阶段逆高斯过程</a>
  <ul class="collapse">
  <li><a href="#sec-tp-s1" id="toc-sec-tp-s1" class="nav-link" data-scroll-target="#sec-tp-s1"><span class="header-section-number">4.3.1</span> 研究背景</a></li>
  <li><a href="#sec-tp-s2" id="toc-sec-tp-s2" class="nav-link" data-scroll-target="#sec-tp-s2"><span class="header-section-number">4.3.2</span> 模型构建</a></li>
  <li><a href="#sec-tp-s3" id="toc-sec-tp-s3" class="nav-link" data-scroll-target="#sec-tp-s3"><span class="header-section-number">4.3.3</span> 统计推断</a></li>
  <li><a href="#sec-tp-s5" id="toc-sec-tp-s5" class="nav-link" data-scroll-target="#sec-tp-s5"><span class="header-section-number">4.3.4</span> 模拟实验</a></li>
  <li><a href="#sec-tp-s6" id="toc-sec-tp-s6" class="nav-link" data-scroll-target="#sec-tp-s6"><span class="header-section-number">4.3.5</span> 实例分析</a></li>
  <li><a href="#附录" id="toc-附录" class="nav-link" data-scroll-target="#附录"><span class="header-section-number">4.3.6</span> 附录</a></li>
  </ul></li>
  <li><a href="#sec-Online-IG" id="toc-sec-Online-IG" class="nav-link" data-scroll-target="#sec-Online-IG"><span class="header-section-number">4.4</span> 在线估计与RUL预测</a>
  <ul class="collapse">
  <li><a href="#sec-igintro" id="toc-sec-igintro" class="nav-link" data-scroll-target="#sec-igintro"><span class="header-section-number">4.4.1</span> 模型设定</a></li>
  <li><a href="#sec-igsimple" id="toc-sec-igsimple" class="nav-link" data-scroll-target="#sec-igsimple"><span class="header-section-number">4.4.2</span> 在线估计</a></li>
  <li><a href="#sec-igre" id="toc-sec-igre" class="nav-link" data-scroll-target="#sec-igre"><span class="header-section-number">4.4.3</span> 考虑随机效应的在线估计</a></li>
  <li><a href="#sec-simulation" id="toc-sec-simulation" class="nav-link" data-scroll-target="#sec-simulation"><span class="header-section-number">4.4.4</span> 模拟实验</a></li>
  <li><a href="#sec-case" id="toc-sec-case" class="nav-link" data-scroll-target="#sec-case"><span class="header-section-number">4.4.5</span> 实例分析</a></li>
  <li><a href="#sec-Append-4C" id="toc-sec-Append-4C" class="nav-link" data-scroll-target="#sec-Append-4C"><span class="header-section-number">4.4.6</span> 附录</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-04-IG" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">基于逆高斯过程的统计建模</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> 代码</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="sec-IG" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-IG"><span class="header-section-number">4.1</span> 逆高斯过程</h2>
<p>尽管维纳过程和伽马过程在退化建模领域得到了广泛应用, 但在处理复杂退化数据时, 其拟合能力可能受到一定限制. 尤其是当退化路径存在显著异质性或动态变化特征时, 传统方法可能难以精准刻画系统的退化规律. 相比之下, 逆高斯(Inverse Gaussian, IG)过程凭借其灵活的分布形式和参数结构, 能够更有效地捕捉退化数据中的异质性和动态演化特征. 其在单调退化建模场景中的适用性已在多个研究中得到验证, 并展现出优越的拟合能力和预测性能 <span class="citation" data-cites="wang2010inverse ye2014inverse peng2014inverse">(<a href="references.html#ref-peng2014inverse" role="doc-biblioref">Peng 等, 2014</a>; <a href="references.html#ref-wang2010inverse" role="doc-biblioref">Wang 等, 2010</a>; <a href="references.html#ref-ye2014inverse" role="doc-biblioref">Ye 等, 2014</a>)</span>.</p>
<p>若随机过程 <span class="math inline">\(\{Y(t), t \ge 0\}\)</span> 满足以下性质:</p>
<ol type="i">
<li><p><span class="math inline">\(Y(0)=0\)</span>, 概率为1;</p></li>
<li><p>对于 <span class="math inline">\(t&gt;s&gt;u\)</span>, 增量<span class="math inline">\(Y(t)-Y(s)\)</span> 与 <span class="math inline">\(Y(s)-Y(u)\)</span> 相互独立;</p></li>
<li><p>对于 <span class="math inline">\(t&gt;s \geq 0\)</span>, 增量 <span class="math inline">\(Y(t)-Y(s)\)</span> 服从 IG 分布 <span class="math inline">\(\textrm{IG}\left(\alpha (t-s), \lambda(t-s)^2\right)\)</span>. 其PDF为 <span class="math display">\[
f_{\textrm{IG}}(y; \alpha, \lambda)=\sqrt{\frac{\lambda t^2}{2\pi y^3}} \exp\left\{-\frac{\lambda}{2y} \left( \frac{y}{\alpha} - t \right)^2\right\}.
\]</span> 则称该过程为{过程, 记作 <span class="math inline">\(\{Y(t), t \ge 0\} \sim \textrm{\textrm{IG}}(\alpha t, \lambda t^2)\)</span>.</p></li>
</ol>
<p>IG过程的均值和方差分别为<span class="math inline">\(\mathbb{E}[Y(t)]=\alpha t\)</span>和<span class="math inline">\(\mathbb{Var}[Y(t)]=\alpha^3 t/\lambda\)</span>. 从其数学表达形式可以看出, IG过程在刻画产品性能退化规律时具有清晰的物理解释. 其中, 参数 <span class="math inline">\(\alpha\)</span> 表示退化速率, 直接反映系统性能随时间推移的衰减速度, 而参数 <span class="math inline">\(\lambda\)</span> 作为扩散系数, 衡量退化过程的波动程度, 表征退化路径的随机性和不确定性. 假设产品失效阈值为 <span class="math inline">\(\omega\)</span>, 则产品寿命定义为 <span class="math inline">\(T= \inf \{t \mid Y(t) \geq \omega\}\)</span>. 此时, 产品寿命 <span class="math inline">\(T\)</span> 的CDF为 <span class="math display">\[\begin{align}
F(t) &amp;=P(T \leq t)=P(Y(t)&gt;\omega)\nonumber\\
%=1-F_{I G}\left(\omega ; \alpha t, \lambda t^2\right) \nonumber\\
&amp;=\Phi\left[ \sqrt{\frac{\lambda}{\omega}}(t - \frac{\omega}{\alpha})
\right] - \exp\left({\frac{2 \lambda t}{\alpha}}\right) \Phi\left[-\sqrt{\frac{\lambda}{\omega}}(\frac{\omega}{\alpha} +t)\right],
\end{align}\]</span> 其中 <span class="math inline">\(\Phi(\cdot)\)</span> 为标准正态分布的CDF.</p>
<p>在退化建模中, IG过程 <span class="math inline">\(\mathcal{IG}(\alpha t, \lambda t^2)\)</span> 假设了线性的平均退化路径. 然而, 实际退化数据通常表现为非线性特征, 并且存在显著的异质性, 即不同产品或系统的退化行为存在差异. 为了克服这些局限性, 本章对经典 IG 模型进行了扩展: 首先, 引入了子群体异质性(详见第 <a href="#sec-Hetero-IG" class="quarto-xref"><span> 4.2</span></a> 节), 以便更精准地刻画不同群体之间的异质性, 从而提高模型在复杂数据中的适应性. 其次, 针对某些产品在退化过程中存在明显的阶段性变化, 提出一类新的两阶段重参数化IG过程(详见第 <a href="#sec-tp-IG" class="quarto-xref"><span> 4.3</span></a> 节), 并基于RUL分布给出了一种自适应替换策略; 最后, 针对非线性退化和带随机效应的IG过程, 介绍一种高效的在线算法, 实现动态更新参数估计并RUL分布的预测 (详见 <a href="#sec-Online-IG" class="quarto-xref"><span> 4.4</span></a> 节).</p>
</section>
<section id="sec-Hetero-IG" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-Hetero-IG"><span class="header-section-number">4.2</span> 子总体异质性下的逆高斯过程</h2>
<p>退化数据通常因不可观测的内生因素（如原材料的初始缺陷）和外部因素（如使用模式）表现出显著的群体内异质性 <span class="citation" data-cites="ye2013heterogeneities">(<a href="references.html#ref-ye2013heterogeneities" role="doc-biblioref">Ye 等, 2013</a>)</span>. 随机效应模型通过引入服从特定分布（如正态分布 <span class="citation" data-cites="Si2012">(<a href="references.html#ref-Si2012" role="doc-biblioref">Si 等, 2012</a>)</span>、截断正态分布 <span class="citation" data-cites="ye2014inverse">(<a href="references.html#ref-ye2014inverse" role="doc-biblioref">Ye 等, 2014</a>)</span>、伽马分布 <span class="citation" data-cites="peng2014inverse peng2017bayesian">(<a href="references.html#ref-peng2014inverse" role="doc-biblioref">Peng 等, 2014</a>, <a href="references.html#ref-peng2017bayesian" role="doc-biblioref">2017</a>)</span>）的随机参数来表征单元间的差异. 然而, 这些模型通常仅适用于描述同一群体内的异质性, 难以处理多个子群体的情况. 在实际应用中, 多子群体共存的现象非常普遍. 例如, 制造过程中的高度变异可能导致微机电系统设备的失效时间呈现多峰分布 <span class="citation" data-cites="hartzell2011lifetime yuan2012reliability">(<a href="references.html#ref-hartzell2011lifetime" role="doc-biblioref">Hartzell 等, 2011</a>; <a href="references.html#ref-yuan2012reliability" role="doc-biblioref">Yuan 等, 2012</a>)</span>, 或者在激光单元数据中, 假设多个子群体的模型优于同质群体模型 <span class="citation" data-cites="yuan2015hierarchical">(<a href="references.html#ref-yuan2015hierarchical" role="doc-biblioref">Yuan 等, 2015</a>)</span>. 类似情况也出现在口腔冲洗器 <span class="citation" data-cites="ericsouglu2011mixture">(<a href="references.html#ref-ericsouglu2011mixture" role="doc-biblioref">Erişoğlu 等, 2011</a>)</span> 和汽车铅酸电池 <span class="citation" data-cites="kontar2017remaining">(<a href="references.html#ref-kontar2017remaining" role="doc-biblioref">Kontar 等, 2017</a>)</span> 的研究中. 为处理这种子群体异质性, 研究者广泛采用混合分布随机效应模型 <span class="citation" data-cites="ericsouglu2011mixture al1989failure li2017nonparametric">(<a href="references.html#ref-al1989failure" role="doc-biblioref">Al-Hussaini 等, 1989</a>; <a href="references.html#ref-ericsouglu2011mixture" role="doc-biblioref">Erişoğlu 等, 2011</a>; <a href="references.html#ref-li2017nonparametric" role="doc-biblioref">Li 等, 2017</a>)</span>. 然而, 由于此类数据通常较为稀缺, 这些方法在高可靠性产品的失效数据建模中效果有限. 随着传感器技术的进步, 退化数据的可用性显著提高, 但如何建模来自异质群体且具有子群体结构的退化数据, 现有研究仍显不足. 例如, 基于混合高斯模型的广义路径模型 <span class="citation" data-cites="yuan2015hierarchical">(<a href="references.html#ref-yuan2015hierarchical" role="doc-biblioref">Yuan 等, 2015</a>)</span> 虽然能够表征单元间的变异性, 但仅适用于环境随机性较小的情况; 而基于混合正态分布参数的维纳退化过程 <span class="citation" data-cites="zhang2017stochastic">(<a href="references.html#ref-zhang2017stochastic" role="doc-biblioref">Zhang 等, 2017</a>)</span> 则无法有效建模单调退化过程. 因此, 针对子群体异质性退化数据的建模方法仍存在较大局限性, 需进一步研究和改进.</p>
<p>基于上述讨论, 本节提出了一种基于IG过程的新模型, 用于建模存在子群体异质性的退化数据. 该模型引入混合高斯分布作为随机效应分布, 能够近似任意形式的分布 <span class="citation" data-cites="lesaffre1991multivariate komarek2008generalized">(<a href="references.html#ref-komarek2008generalized" role="doc-biblioref">Komárek 等, 2008</a>; <a href="references.html#ref-lesaffre1991multivariate" role="doc-biblioref">Lesaffre 等, 1991</a>)</span>, 同时利用IG过程来有效建模单调退化过程. 针对模型参数增多时对初始值敏感的问题<span class="citation" data-cites="lindbate1988">(<a href="references.html#ref-lindbate1988" role="doc-biblioref">Lindstrom 等, 1988</a>)</span>, 提出一种高效的EM算法, 通过边际化方法实现稳健的参数估计, 并结合偏差修正的百分位数自助法进行区间估计. 本节的结构如下: 第 <a href="#sec-AMM2020-s2" class="quarto-xref"><span> 4.2.1</span></a> 节介绍带有混合高斯分布随机效应的IG过程; 第 <a href="#sec-AMM2020-s3" class="quarto-xref"><span> 4.2.2</span></a> 节详细介绍了统计推断方法; 第 <a href="#sec-AMM2020-s4" class="quarto-xref"><span> 4.2.3</span></a> 节通过模拟研究验证模型与算法的性能; 第 <a href="#sec-AMM2020-s5" class="quarto-xref"><span> 4.2.4</span></a> 节通过两个案例研究展示模型与算法的实际效果. <!-- 第 @sec-AMM2020-s6 节总结了本文并提出了一些未来的研究方向.  --></p>
<section id="sec-AMM2020-s2" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-AMM2020-s2"><span class="header-section-number">4.2.1</span> 模型构建</h3>
<p>本小节首先将第 <a href="#sec-IG" class="quarto-xref"><span> 4.1</span></a> 节中定义的IG过程扩展到非线性退化路径的情形. 令 <span class="math inline">\(\Lambda(t, \beta)\)</span> 为时间尺度变换函数, 用于描述退化路径的非线性特征, 其中 <span class="math inline">\(\Lambda(0, \beta) = 0\)</span>. 与上一节中定义的IG过程不同, 本节中的增量 <span class="math inline">\(Y(t + \Delta t) - Y(t)\)</span> 服从 <span class="math inline">\(IG(\alpha \Delta \Lambda(t, \beta), \lambda \Delta \Lambda(t, \beta)^2)\)</span>, 其中 <span class="math inline">\(\Delta \Lambda(t, \beta) = \Lambda(t + \Delta t, \beta) - \Lambda(t, \beta)\)</span>. 为了同时刻画单元与子总体的异质性, 定义 <span class="math inline">\(\nu = 1/\alpha\)</span> 为随机效应, 并假设其服从混合高斯分布. 在这种设置下, <span class="math inline">\(\nu\)</span> 同时影响退化过程的均值和方差, 从而刻画了单元间的变异性, 并灵活地将总体划分为多个子总体. 设第 <span class="math inline">\(k\)</span> 个高斯分布的均值和方差分别为 <span class="math inline">\(\mu_k\)</span> 和 <span class="math inline">\(\sigma_k^2 / \lambda\)</span>, 则具有子总体异质性的 IG 退化模型为 <span class="math display">\[\begin{equation}\label{mnd}
    \begin{split}
    Y(t) \mid \nu &amp;\sim \textrm{\textrm{IG}}(\Lambda(t,\beta)/\nu, \lambda\Lambda(t,\beta)^2),\\
    \nu &amp;\sim \sum\limits_{k=1}^Kp_k{N}(\mu_k,\sigma_k^2/\lambda),
    \end{split}
\end{equation}\]</span> 其中 <span class="math inline">\(p_k\)</span> 为第 <span class="math inline">\(k\)</span> 个子总体的比例, <span class="math inline">\({N}(\cdot)\)</span> 表示高斯分布, <span class="math inline">\(K\)</span> 为子群体总数.</p>
<p><strong>注2</strong>: 模型<span class="math inline">\(\eqref{mnd}\)</span>中子总体的方差设定为<span class="math inline">\(\sigma_k^2/\lambda\)</span>, 目的是为了 简化数学推导. 实际上, 从模型的角度来看, 这一设定等同于假设 <span class="math inline">\(\nu \sim \sum\limits_{k=1}^K p_k N(\mu_k, \delta_k^2)\)</span>. 通过参数变换 <span class="math inline">\(\delta_k^2 = \sigma_k^2 / \lambda\)</span>可知两者是等价的. 然而, 模型 <span class="math inline">\(\eqref{mnd}\)</span> 的设定在数学表达和后续统计推断中会更加简洁和方便.</p>
<p>基于模型<span class="math inline">\(\eqref{mnd}\)</span>, 定义产品寿命<span class="math inline">\(T= \inf \{t \mid Y(t) \geq \omega\}\)</span>. 则<span class="math inline">\(T\)</span>的分布可由以下定理给出.</p>
<div id="thm-AMM2020-1" class="theorem">
<p><span class="theorem-title"><strong>定理 4.1</strong></span> 在模型<span class="math inline">\(\eqref{mnd}\)</span>下, 产品寿命<span class="math inline">\(T\)</span>的CDF为<br>
<span class="math display">\[\begin{align}\label{cdf}
    F_T(t)&amp;=\int_{-\infty}^{\infty}[1-P(Y(t)\le \omega \mid \nu)]f(\nu)\text{d}\nu\nonumber\\
    &amp;=\sum\limits_{k=1}^Kp_k\Phi\left(\dfrac{\sqrt{\lambda}(\Lambda(t,\beta)-\omega\mu_k) }{\sqrt{\omega(1+\omega\sigma_k^2)}}\right)\nonumber\\
    &amp;\quad -\sum\limits_{k=1}^Kp_k\exp\left[2\lambda\Lambda(t,\beta)(\sigma_k^2\Lambda(t,\beta)+\mu_k)\right]\nonumber\\
    &amp;\quad\times\Phi\left( -\dfrac{\sqrt{\lambda}[(1+2\omega\sigma_k^2)\Lambda(t,\beta)+\omega\mu_k] }{\sqrt{\omega(1+\omega\sigma_k^2)}}\right).
\end{align}\]</span></p>
</div>
<p>根据定理 <a href="#thm-AMM2020-1" class="quarto-xref"><span>4.1</span></a> 可知, 当 <span class="math inline">\(K = 1\)</span> 时, 式 <span class="math inline">\(\eqref{cdf}\)</span> 就简化为 <span class="citation" data-cites="peng2015inverse">Peng (<a href="references.html#ref-peng2015inverse" role="doc-biblioref">2015</a>)</span> 的结果, 表示所有单元来自同一总体; 当 <span class="math inline">\(K &gt; 1\)</span> 时, 则刻画了包含 <span class="math inline">\(K\)</span> 个子总体的一般情况.</p>
</section>
<section id="sec-AMM2020-s3" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-AMM2020-s3"><span class="header-section-number">4.2.2</span> 统计推断</h3>
<p>假设在退化试验中有 <span class="math inline">\(n\)</span> 个样品. 设 <span class="math inline">\(y_{ij}\)</span> 为第 <span class="math inline">\(i\)</span> 个样品在测量时间 <span class="math inline">\(t_{ij}\)</span> (<span class="math inline">\(j=1,\dots,m_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>) 时所观测到的退化值. 令 <span class="math inline">\(\Delta \bm{y_i}=(\Delta y_{i1},\dots,\Delta y_{im_i})^{'}\)</span>, 其中 <span class="math inline">\(\Delta y_{i1}=y_{i1}\)</span>, 且 <span class="math inline">\(\Delta y_{ij} = y_{ij}-y_{i(j-1)}\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, <span class="math inline">\(\bm y=(\Delta \bm y_{1},\dots, \Delta \bm y_{n})^{'}\)</span>. 设 <span class="math inline">\(h_{ij}(\beta)=\Lambda(t_{ij},\beta)-\Lambda(t_{i(j-1)},\beta)\)</span>, 并且 <span class="math inline">\(t_{i0}=0\)</span>, <span class="math inline">\(j=1,\dots,m_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>. 假设样品性能的退化过程服从模型 <span class="math inline">\(\eqref{mnd}\)</span>, 则基于第 <span class="math inline">\(i\)</span> 个样品的退化数据, 给定 <span class="math inline">\(\nu_i\)</span>, 对任意的 <span class="math inline">\(j\)</span>, 有<span class="math inline">\(\Delta y_{ij} \sim IG(h_{ij}(\beta)/\nu_i, \lambda h_{ij}(\beta)^2)\)</span>, 且 <span class="math inline">\(\nu_i \sim \sum_{k=1}^K p_k N(\mu_k, \sigma_k^2/\lambda)\)</span>. 令 <span class="math inline">\(\bm \Theta=(\lambda,\beta,p_k,\mu_k,\sigma_k^2,k=1,\dots,K)\)</span>. 对于第 <span class="math inline">\(i\)</span> 个退化路径的完整数据 <span class="math inline">\((\Delta \bm y_{i},\nu_i)\)</span>, 其似然函数为 <span class="math display">\[\begin{align}
    L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)&amp;=\prod\limits_{j=1}^{m_i}
    \sqrt{\dfrac{\lambda h_{ij}(\beta)^2}{2\pi \Delta y_{ij}^3}}\exp\left\{-\dfrac{\lambda}{2\Delta y_{ij}}\left(\nu_i\Delta y_{ij}-h_{ij}(\beta)\right)^2\right\}\nonumber\\
    &amp;\quad \times \sum\limits_{k=1}^K p_k\sqrt{\frac{\lambda}{2\pi\sigma_k^2}}\exp\left\{-\dfrac{\lambda(\nu_i-\mu_k)^2}{2\sigma_k^2}\right\}.\label{compdata}
\end{align}\]</span> 基于 <span class="math inline">\(\prod_{i=1}^n L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)\)</span> 求解参数 <span class="math inline">\(\bm \Theta\)</span> 的估计通常有两种方法:</p>
<ol type="1">
<li>EM算法: <span class="citation" data-cites="wangschda2007">Wang 等 (<a href="references.html#ref-wangschda2007" role="doc-biblioref">2007</a>)</span> 提出了一类EM算法, 用于求非线性随机效应混合模型的参数估计. 然而, 该方法在数学推导上较为复杂, 难以求解, 并且需要处理两类潜在变量, 这显著降低了计算效率.</li>
<li>贝叶斯分析: 引入潜在变量简化 <span class="math inline">\(\eqref{compdata}\)</span> 中的求和结构, 并为参数 <span class="math inline">\(\bm{\Theta}\)</span> 指定先验分布, 结合 MCMC 算法生成后验样本, 从而估计 <span class="math inline">\(\bm \Theta\)</span>. 然而, 在实际实施过程中, 后验抽样可能面临一些挑战. 特别是参数 <span class="math inline">\(\sigma_k^2\)</span> 的先验分布难以确定, 一些弱信息先验（如均匀分布或逆伽马分布）在特定情况下可能导致后验分布不存在, 相关问题已在文献中得到详细讨论 <span class="citation" data-cites="gelman2006 polsco2012">(<a href="references.html#ref-gelman2006" role="doc-biblioref">Gelman, 2006</a>; <a href="references.html#ref-polsco2012" role="doc-biblioref">Polson 等, 2012</a>)</span>.</li>
</ol>
<p>基于以上分析, 本小节提出一种新的EM算法: 首先对<span class="math inline">\(\nu_i\)</span>做边际化处理, 然后构造EM算法来实现参数估计.</p>
<section id="sec-AMM2020-s3-1" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="sec-AMM2020-s3-1"><span class="header-section-number">4.2.2.1</span> EM 算法</h4>
<p>由于 <span class="math inline">\(\nu_i\)</span> 不可观测, 对 <span class="math inline">\(L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)\)</span> 中的 <span class="math inline">\(\nu_i\)</span> 进行积分后, 基于第 <span class="math inline">\(i\)</span> 个样品退化数据的似然函数为 <span class="math display">\[\begin{align}\label{margi}
    L_i(\Delta \bm y_{i} \mid \bm \Theta)&amp;=\int_{-\infty}^\infty L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)\text{d}\nu_i \nonumber\\
    &amp;=(2\pi\lambda)^{m_i/2-1}y_{im_i}^{-1/2}\prod\limits_{j=1}^{m_i}\dfrac{h_{ij}(\beta)}{\Delta y_{ij}^{3/2}}\nonumber\\
    &amp;\ \ \ \times\exp\left\{-\dfrac{\lambda}{2}\left[\sum\limits_{j=1}^{m_i}h_{ij}(\beta)^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta)^2/y_{im_i} \right]\right\}\nonumber\\
    &amp;\quad\times\sum\limits_{k=1}^K \dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}
    \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}\nonumber\\
    &amp;=G_i(\Delta \bm y_{i},\beta,\lambda)\sum\limits_{k=1}^K \dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}\nonumber\\
    &amp;\quad \times\exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\},
\end{align}\]</span> 其中 <span class="math display">\[\begin{equation*}
  \begin{split}
  G_i(\Delta \bm y_{i},&amp;\beta,\lambda)=(2\pi\lambda)^{m_i/2-1}y_{im_i}^{-1/2}\\
  &amp;\times \prod\limits_{j=1}^{m_i}\dfrac{h_{ij}(\beta)}{\Delta y_{ij}^{3/2}}\exp\left\{-\dfrac{\lambda}{2}\left[\sum\limits_{j=1}^{m_i}h_{ij}(\beta)^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta)^2/y_{im_i} \right]\right\}.
  \end{split}
\end{equation*}\]</span> 为简化式 <span class="math inline">\(\eqref{margi}\)</span>, 引入潜在变量 <span class="math inline">\(\bm Z_i=(Z_{i1},\dots,Z_{iK})^{'}\)</span> 表示第 <span class="math inline">\(i\)</span> 个样品对应的子总体标签. <span class="math inline">\(\bm Z_i\)</span> 为多项分布变量, 当 <span class="math inline">\(Z_{ik}=1\)</span> 且 <span class="math inline">\(Z_{ij}=0, \forall j \neq k\)</span> 时, 第 <span class="math inline">\(i\)</span> 个样品属于第 <span class="math inline">\(k\)</span> 个子总体. 给定 <span class="math inline">\(Z_{ik}=1\)</span> 时, 似然函数为<br>
<span class="math display">\[\begin{equation*}
  \begin{split}
    L_i(\Delta \bm y_{i} \mid &amp;Z_{ik}=1,\bm \Theta)=G_i(\Delta \bm y_{i},\bm \beta,\lambda) \\
    &amp;\times \dfrac{\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}
    \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}.
  \end{split}
\end{equation*}\]</span> 因此, 给定第 <span class="math inline">\(i\)</span> 个样品的完整数据 <span class="math inline">\((\Delta \bm y_{i}, \bm Z_i)\)</span>, 似然函数可表示为<br>
<span class="math display">\[\begin{equation*}
\begin{split}
  L_i(\Delta \bm y_{i},&amp;\bm Z_i \mid \bm \Theta) = G_i(\Delta \bm y_{i},\beta,\lambda)\\
  &amp;\times \prod\limits_{k=1}^K \left[\dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}} \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}\right]^{Z_{ik}}.
\end{split}
\end{equation*}\]</span> 对于所有样品的完整数据 <span class="math inline">\((\Delta \bm y, \bm Z)\)</span>, 参数 <span class="math inline">\(\bm \Theta\)</span> 的对数似然函数为 <span class="math display">\[\begin{align}\label{lf}
    l(\Delta \bm y, \bm Z \mid \bm \Theta)&amp;=\sum\limits_{i=1}^n\log(L_i(\Delta \bm y_{i},\bm Z_i \mid \bm \Theta))\nonumber\\
    &amp;=C+\dfrac{1}{2}\sum\limits_{i=1}^nm_i\log(\lambda)+\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i}\log h_{ij}(\beta)\nonumber\\
    &amp;\quad -\dfrac{\lambda}{2}\left[\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}-\sum\limits_{i=1}^n\Lambda(t_{im_i},\beta)^2/y_{im_i}\right]\nonumber\\
    &amp;\quad +\sum\limits_{i=1}^n\sum\limits_{k=1}^{K} Z_{ik}\Bigg[\log p_k-\dfrac{1}{2}\log(1/y_{im_i}+\sigma_k^2)\nonumber\\
    &amp;\quad -
    \dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)}  \Bigg],
\end{align}\]</span> 其中 <span class="math display">\[C = -\sum_{i=1}^n \left[ m_i \log(2\pi) + \log(y_{im_i}) + 3 \sum_{j=1}^{m_i} \log(\Delta y_{ij}) \right] / 2.
\]</span> EM 算法是一个迭代算法, 包含E步和M步. E 步的计算是在观测数据 <span class="math inline">\(\Delta \bm y\)</span> 和上次迭代参数值 <span class="math inline">\(\bm \Theta^{(s)}\)</span> 条件下, 对 <span class="math inline">\(\bm Z\)</span> 的对数似然函数的期望. 可知<span class="math inline">\(\bm Z_i\)</span> 的条件分布为多项分布: <span class="math inline">\(\bm Z_i \mid \Delta \bm y_{i},\bm \Theta\sim \mathcal{MN}(1;w_{i1}(\bm \Theta),\dots,w_{iK}(\bm \Theta))\)</span>, 其中 <span class="math display">\[\begin{equation*}
  w_{ik}(\bm \Theta)=\dfrac{ p_k(1/y_{im_i}+\sigma_k^2)^{-1}
        \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}}
    {\sum\limits_{k=1}^K p_k(1/y_{im_i}+\sigma_k^2)^{-1}
        \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}},
\end{equation*}\]</span> 表示第 <span class="math inline">\(i\)</span> 个样品属于第 <span class="math inline">\(k\)</span> 个子总体的概率. 在 E 步中, 结合<span class="math inline">\(\bm Z_i\)</span> 的条件分布, 对<span class="math inline">\(l(\Delta \bm y,\bm Z \mid \bm \Theta)\)</span> 关于 <span class="math inline">\(\bm Z\)</span>求期望可得 <span class="math display">\[\begin{equation*}\label{fcdata}
    \begin{split}
    Q (\bm \Theta,\bm \Theta^{(s)})
        %=\text{E}\left(l(\Delta \bm y, \bm Z \mid \bm \Theta) \mid \Delta\bm  y, \bm \Theta^{(s)}\right)\\
        =\  &amp; C+\dfrac{1}{2}\sum\limits_{i=1}^nm_i\log(\lambda)+\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i}\log h_{ij}(\beta)\\
        &amp;-\dfrac{\lambda}{2}\left[\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}-\sum\limits_{i=1}^n\Lambda(t_{im_i},\beta)^2/y_{im_i}\right]\\
        &amp;+\sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\Bigg[\log p_k-\dfrac{1}{2}\log(1/y_{im_i}+\sigma_k^2)\nonumber\\
        &amp;\qquad -\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)}  \Bigg],
    \end{split}
\end{equation*}\]</span> 其中 <span class="math inline">\(w_{ik}^{(s)}=w_{ik}(\bm \Theta^{(s)})\)</span>. 在 M 步中通过最大化<span class="math inline">\(Q(\bm \Theta,\bm \Theta^{(s)})\)</span>得到 <span class="math inline">\(\bm \Theta^{(s+1)}\)</span>. 具体更新公式见式 <span class="math inline">\(\eqref{wiener-RESS2021-arg}\)</span>, 详细推导见本节附录 <a href="#sec-Append-4B" class="quarto-xref"><span> 4.2.5</span></a>. EM 算法的实施过程与 <a href="02-Wiener.html#sec-RESS2021-s3-1" class="quarto-xref"><span> 2.2.2.1</span></a> 节类似, 这里不再重复介绍.</p>
<!-- - **步骤 1**. 设置参数 $\bm \Theta^{(0)}$ 的初始值和容忍误差 $\epsilon$.  -->
<!-- - **步骤 2**. 给定第 $s$ 次迭代的参数估计 $\bm \Theta^{(s)}$, 通过 \eqref{pmulam}-\eqref{betas} 更新第 $(s+1)$ 次迭代的参数估计 $\bm \Theta^{(s+1)}$.  -->
<!-- - **步骤 3**. 重复步骤 2, 直到满足 $|\sum_{i=1}^n[\log L_i(\bm \Delta y_i|\bm \Theta^{(s+1)})-\log L_i(\bm \Delta y_i|\bm \Theta^{(s)})]|<\epsilon$ 或 $|\bm \Theta^{(s+1)} - \bm \Theta^{(s)}| < \epsilon$.  -->
<!-- - **步骤 4**. 得到 $\bm \Theta$ 的ML估计为 $\bm{\hat\Theta}=\bm\Theta^{(s+1)}$.  -->
<p><strong>注3</strong>: 混合模型存在识别问题, 即交换子总体标签不会影响似然函数 <span class="math inline">\(\prod_{i=1}^n L_i(\Delta \bm y_i \mid \bm \Theta)\)</span> 的值 <span class="citation" data-cites="celeux2000computational">(<a href="references.html#ref-celeux2000computational" role="doc-biblioref">Celeux 等, 2000</a>)</span>. 为确保参数可识别性, 在计算过程中可对子总体均值 <span class="math inline">\(\mu_k\)</span> 按递增顺序排列.</p>
<p><strong>注4</strong>: 所提出的 EM 算法基于给定的子总体数 <span class="math inline">\(K\)</span> 进行计算. <span class="math inline">\(K\)</span> 的选择属于模型选择问题, 本节通过 AIC 来确定最优的 <span class="math inline">\(K\)</span>. AIC 定义为 <span class="math display">\[{\rm AIC} = -2\sum_{i=1}^n \log L_i(\Delta \bm y_i \mid \bm{\hat{\Theta}}) + 2 \times (3K + 1).\]</span> 最小的 AIC 值对应最优的<span class="math inline">\(K\)</span>. 在实际操作中, 可预设一个最大值 <span class="math inline">\(K\)</span>, 该值取决于样本大小 <span class="math inline">\(n\)</span>, 确保 <span class="math inline">\(n\)</span> 大于模型参数个数, 以保证参数的可识别性.</p>
<p><strong>注5</strong>: 本节中样品的标签信息不可观测. 基于参数估计值 <span class="math inline">\(\hat{\Theta}\)</span>, 可通过后验概率 <span class="math inline">\(w_{ik}(\hat{\Theta})\)</span> 估计样品的标签. 若 <span class="math inline">\(w_{ij}(\hat{\Theta}) = \max\{w_{ik}(\hat{\Theta}), k=1,\dots,K\}\)</span>, 则样品 <span class="math inline">\(i\)</span> 被归为第 <span class="math inline">\(j\)</span> 个子总体. 因此, EM 算法的实施过程同时也是样品聚类的学习过程.</p>
</section>
<section id="sec-AMM2020-s3-2" class="level4" data-number="4.2.2.2">
<h4 data-number="4.2.2.2" class="anchored" data-anchor-id="sec-AMM2020-s3-2"><span class="header-section-number">4.2.2.2</span> 收敛速率</h4>
<p>EM算法通过迭代不断优化参数估计. 根据 <span class="citation" data-cites="wu1983">Wu (<a href="references.html#ref-wu1983" role="doc-biblioref">1983</a>)</span> 的定理1, 该算法能够使对数似然函数收敛到一个稳定点或局部极大值. 为实现该算法, 需要随机初始化参数值, 通过多次迭代寻找最优解. 最终, 选取使似然函数值达到最大的点作为参数估计.</p>
<p>对于混合高斯分布, <span class="citation" data-cites="xujor1996">Xu 等 (<a href="references.html#ref-xujor1996" role="doc-biblioref">1996</a>)</span> 的定理1表明, EM算法本质上是一种梯度上升算法, 且收敛速度与对数似然函数的Hessian矩阵的条件数有关. 在本模型中, Hessian矩阵 <span class="math inline">\(H(\bm{\Theta})\)</span> 可由对数似然函数 <span class="math inline">\(l(\bm{\Theta}) = \sum_{i=1}^n \log L_i(\Delta \bm{y}_i \mid \bm{\Theta})\)</span> 求得, 具体为 <span class="math inline">\(H(\bm\Theta)=\dfrac{\partial^2 l(\bm\Theta)}{\partial\bm\Theta\partial\bm\Theta^{'}}.\)</span> 在参数更新中, 使用牛顿法求解 <span class="math inline">\(\sigma_k^2\)</span> 和 <span class="math inline">\(\beta\)</span> (见式 <span class="math inline">\(\eqref{sigmas}\)</span> 和 <span class="math inline">\(\eqref{betas}\)</span>) . 因此, 所提的EM算法也可视为一种梯度上升算法.</p>
<div id="thm-AMM2020-2" class="theorem">
<p><span class="theorem-title"><strong>定理 4.2</strong></span> 在EM算法的每次迭代中有 <span class="math display">\[\begin{eqnarray*}
   P^{(s+1)}-P^{(s)}&amp;=&amp;G_P^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}},\\
  \mu_k^{(s+1)}-\mu_k^{(s)}&amp;=&amp;G_{\mu_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}},\\
   \lambda^{(s+1)}-\lambda^{(s)}&amp;=&amp;G_{\lambda}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}},\\
    (\sigma_k^2)^{(s+1)}-(\sigma_k^2)^{(s)}&amp;=&amp;G_{\sigma_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \sigma_k^2}\Big|_{\bm\Theta=\bm\Theta^{(s)}},\\
\beta^{(s+1)}-\beta^{(s)}&amp;=&amp;G_{\beta}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \beta}\Big|_{\bm\Theta=\bm\Theta^{(s)}},
\end{eqnarray*}\]</span> 其中 <span class="math inline">\(P=(p_1,\dots,p_K)^{'}\)</span>, <span class="math display">\[\begin{align*}
h_{ij}&amp;=h_{ij}(\beta^{(s)}), h^{'}_{ij}=h^{'}_{ij}(\beta^{(s)}), h^{''}_{ij}=h^{''}_{ij}(\beta^{(s)}),\\ \Lambda_i&amp;=\Lambda(t_{im_i},\beta^{(s)}), \Lambda_i^{'}=\Lambda^{'}(t_{im_i},\beta^{(s)}), \Lambda_i^{''}=\Lambda^{''}(t_{im_i},\beta^{(s)}),\\
G_P^{(s)}&amp;=\dfrac{1}{n}\left[\textrm{diag}\{p_1^{(s)},\dots,p_K^{(s)}\}-P^{(s)}\left(P^{(s)}\right)^{'}\right],\\
    G_{\mu_k}^{(s)}&amp;=\left[\sum_{i=1}^{n}\lambda^{(s)}w_{ik}^{(s)}/\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)\right]^{-1},\\
    G_{\lambda}^{(s)}&amp;=2\lambda^{(s)}
    \left\{\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} \dfrac{h_{ij}^2}{\Delta y_{ij}}-\dfrac{\Lambda_i^2}{y_{im_i}}+
    \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right] \right\}^{-1},\\
        G_{\sigma_k}^{(s)}&amp;=-\left\{
        \sum\limits_{i=1}^nw_{ik}^{(s)}\left[\dfrac{\lambda^{(s)}(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^3}-\dfrac{1}{2\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^2}\right] \right\}^{-1},\\
    G_{\beta}^{(s)}&amp;=-\Bigg\{\sum_{i=1}^{n}\Bigg[\sum_{j=1}^{m_i}\dfrac{h_{ij}^{''}h_{ij}-(h_{ij}^{'})^2}{h_{ij}^2}\\
    &amp;-\lambda^{(s)}\left(\sum_{j=1}^{m_i}\dfrac{h_{ij}^{''}h_{ij}+(h_{ij}^{'})^2}{\Delta y_{ij}}-\dfrac{\Lambda_{i}^{''}\Lambda_{i}-(\Lambda_{i}^{'})^2}{y_{im_i}}\right)\Bigg]\\
    &amp;-\sum_{i=1}^{n}\sum_{j=1}^{m_i}\dfrac{\lambda^{(s)}w_{ik}^{(s)}}{1+y_{im_i}(\sigma_k^2)^{(s)}}\left(\dfrac{\Lambda_{i}^{''}\Lambda_{i}^2+2(\Lambda_{i}^{'})^2\Lambda_i}{y_{im_i}}
    -\mu_k^{(s)}\left(\Lambda_{i}^{''}\Lambda_{i}+(\Lambda_{i}^{'})^2\right)\right) \Bigg\}^{-1}.    
\end{align*}\]</span></p>
</div>
<p>定理 <a href="#thm-AMM2020-2" class="quarto-xref"><span>4.2</span></a> 的证明见本节附录 <a href="#sec-Append-4B" class="quarto-xref"><span> 4.2.5</span></a>. <span class="citation" data-cites="xujor1996">Xu 等 (<a href="references.html#ref-xujor1996" role="doc-biblioref">1996</a>)</span> 表明, 在约束条件 <span class="math inline">\(\sum_{k=1}^{K} p_k^{(s)} = 1\)</span> 且 <span class="math inline">\(p_k^{(s)} \ge 0\)</span> (对所有 <span class="math inline">\(k\)</span>) 的情况下, <span class="math inline">\(G_P^{(s)}\)</span> 是正定矩阵, <span class="math inline">\(G_{\mu_k}^{(s)}\)</span> 和 <span class="math inline">\(G_{\lambda}^{(s)}\)</span> 是正值, 这一点易于验证. 在定理 <a href="#thm-AMM2020-2" class="quarto-xref"><span>4.2</span></a> 的证明中, <span class="math inline">\(G_{\sigma_k}^{(s)}\)</span> 和 <span class="math inline">\(G_{\beta}^{(s)}\)</span> 分别为 <span class="math display">\[G_{\sigma_k}^{(s)} = - \frac{\partial^2 l(\bm{\Theta})}{\partial \sigma_k^2 \partial \sigma_k^2} \Big|{\bm{\Theta}=\bm{\Theta}^{(s)}} \quad \text{和} \quad G_{\beta}^{(s)} = - \frac{\partial^2 l(\bm{\Theta})}{\partial \beta \partial \beta} \Big|_{\bm{\Theta}=\bm{\Theta}^{(s)}},\]</span> 对于足够大的 <span class="math inline">\(n\)</span>, 这些值均为正. 定义 <span class="math display">\[\mathcal{G}(\bm\Theta)=\textrm{diag}\{G_{\lambda},~G_{\beta},~G_P,~ G_{\mu_1},~\dots,~G_{\mu_K},~G_{\sigma_1},~\dots,~G_{\sigma_K} \},\]</span> 这是一个正定矩阵. 根据定理 <a href="#thm-AMM2020-2" class="quarto-xref"><span>4.2</span></a> 可写为 <span class="math display">\[\begin{equation}
\bm\Theta^{(s+1)}=\bm\Theta^{(s)}+\mathcal{G}(\bm\Theta^{(s)})~\dfrac{\partial l(\bm\Theta)}{\partial \bm\Theta}\Big|_{\bm\Theta=\bm\Theta^{(s)}}.
\end{equation}\]</span> 因此, 在每次EM算法迭代中, 搜索方向 <span class="math inline">\(\bm{\Theta}^{(s+1)} - \bm{\Theta}^{(s)}\)</span> 在对数似然函数梯度上具有正投影. 令 <span class="math inline">\(\mathcal{E} = \{\mathcal{E}_1, \dots, \mathcal{E}_d\}\)</span> 为一组独立的单位基向量, 覆盖 <span class="math inline">\(\bm{\Theta}\)</span> 的参数空间. 令 <span class="math inline">\(\gamma_{s+1} = \frac{|\bm{\Theta}^{(s+1)} - \bm{\Theta}^{\ast}|}{|\bm{\Theta}^{(s)} - \bm{\Theta}^{\ast}|}\)</span>, 其中 <span class="math inline">\(\bm{\Theta}^{\ast}\)</span> 是 <span class="math inline">\(\bm{\Theta}\)</span> 的真实值. 根据 <span class="citation" data-cites="xujor1996">Xu 等 (<a href="references.html#ref-xujor1996" role="doc-biblioref">1996</a>)</span> 的式(16), EM算法的收敛速度由以下不等式界定: <span class="math display">\[\begin{equation}\label{crate}
\gamma_{s+1}\le\sqrt{1+\kappa_M^2\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]-2\kappa_m\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]},
\end{equation}\]</span> 其中 <span class="math inline">\(\kappa_m[A]\)</span> 和 <span class="math inline">\(\kappa_M[A]\)</span> 分别表示矩阵 <span class="math inline">\(A\)</span> 的最小和最大特征值. EM算法的收敛速度依赖于矩阵 <span class="math inline">\(\mathcal{E}' \mathcal{G}(\bm{\Theta}^{\ast}) H(\bm{\Theta}^{\ast}) \mathcal{E}\)</span> 的条件数, 定义为<br>
<span class="math display">\[\begin{equation}\label{condnum}
\mathcal{C}=\kappa_M\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]/\kappa_m\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right].
\end{equation}\]</span> 较大的 <span class="math inline">\(\mathcal{C}\)</span> 会导致较慢的收敛速度. 当 <span class="math inline">\(\mathcal{C}=1\)</span> 且 <span class="math inline">\(\kappa_M[\mathcal{E}' \mathcal{G}(\bm{\Theta}^{\ast}) H(\bm{\Theta}^{\ast}) \mathcal{E}] = 1\)</span> 时, 式<span class="math inline">\(\eqref{crate}\)</span>中的上界收敛至 <span class="math inline">\(0\)</span>, 实现超线性收敛速度. <!-- 我们有 $$\sqrt{1+\kappa_M^2\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]-2\kappa_m\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]}=0,$$ --> 在算法实施中, 用每次迭代的估计值代替 <span class="math inline">\(\eqref{condnum}\)</span> 中的 <span class="math inline">\(\bm{\Theta}^\ast\)</span>, 以监控条件数 <span class="math inline">\(\mathcal{C}\)</span> 的变化, 从而评估不同算法的收敛速度.</p>
</section>
<section id="sec-AMM2020-s3-3" class="level4" data-number="4.2.2.3">
<h4 data-number="4.2.2.3" class="anchored" data-anchor-id="sec-AMM2020-s3-3"><span class="header-section-number">4.2.2.3</span> 自助法计算区间</h4>
<p><span class="citation" data-cites="louis1982">Louis (<a href="references.html#ref-louis1982" role="doc-biblioref">1982</a>)</span> 提出了推导参数 Fisher 信息矩阵的方法. 但该模型获得其解析形式较为困难. 因此, 可采用偏差校正百分位自助法计算参数的区间估计 <span class="citation" data-cites="Johnson1993">(<a href="references.html#ref-Johnson1993" role="doc-biblioref">Efron 等, 1993</a>)</span>. 对于参数的任意函数 <span class="math inline">\(\eta = g(\bm{\Theta})\)</span>, 具体实施步骤如下:</p>
</section>
</section>
<section id="sec-AMM2020-s4" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-AMM2020-s4"><span class="header-section-number">4.2.3</span> 模拟实验</h3>
<p>本节将通过蒙特卡洛仿真来验证EM算法的有效性. 设定总体包含两个子群体 (<span class="math inline">\(K=2\)</span>), 异质性参数为 <span class="math inline">\(p_1=0.4\)</span>、<span class="math inline">\(p_2=0.6\)</span>、<span class="math inline">\(\mu_1=2\)</span>、<span class="math inline">\(\mu_2=4\)</span>、<span class="math inline">\(\sigma_1^2=0.2\)</span>、<span class="math inline">\(\sigma_2^2=0.5\)</span>. 模型的其他参数包括 <span class="math inline">\(\Lambda(t,\beta) = t^{1.5}\)</span> 和 <span class="math inline">\(\lambda = 1\)</span>, 测量时间点设置为 <span class="math inline">\((t_1,t_2,\dots,t_m) = (2,4,\dots,2m)\)</span>. 样本大小和测量次数分别选取 <span class="math inline">\(n=50,100\)</span> 和 <span class="math inline">\(m=10,20\)</span>. 为评估不同 <span class="math inline">\((n,m)\)</span> 组合对估计结果的影响, 每个组合重复模拟2000次, EM算法的容忍误差设为 <span class="math inline">\(\epsilon = 10^{-5}\)</span>.</p>
<p>表 <span class="math inline">\(\ref{tbl-simu1}\)</span> 列出了基于2000次模拟的模型参数估计结果. 可发现:</p>
<ol type="1">
<li><p>在固定 <span class="math inline">\(m\)</span> 的情况下, 随着样本量 <span class="math inline">\(n\)</span> 增加, 参数估计的偏差和RMSE显著降低.</p></li>
<li><p>在固定 <span class="math inline">\(n\)</span> 的情况下, 随着测量次数 <span class="math inline">\(m\)</span> 增加, 参数 <span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\beta\)</span> 的RMSE明显减少, 而其他模型参数的 RMSE 几乎保持不变. 这是因为异质性的信息主要由样本量决定, 而参数 <span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\beta\)</span> 的估计精度依赖于总测量次数<span class="math inline">\(n \times m\)</span>. 例如, 当 <span class="math inline">\((n,m) = (50,20)\)</span> 和 <span class="math inline">\((100,10)\)</span> 时, 两者总测量次数均为1000, 对应的 <span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\beta\)</span> 的估计RMSE非常接近.</p></li>
</ol>
<p>假设阈值为 <span class="math inline">\(\omega=10\)</span>, 根据式 <span class="math inline">\(\eqref{cdf}\)</span> 绘制产品失效时间的分布函数. 图 <a href="#fig-fig:meancdf" class="quarto-xref"><span>4.1</span></a> 展示了基于估计的分布函数, 其中实线为真实分布函数, 虚线为表 <span class="math inline">\(\ref{tbl-simu1}\)</span> 中平均估计得到的分布函数, 灰色虚线为每个数据集的估计结果 (仅绘制前100条以便说明) . 从图中可以看出, 随着样本量增加, 分布函数的估计精度逐步提高. 对于固定样本量, 不同 <span class="math inline">\(m\)</span> 的分布函数估计结果相似, 这与表 <span class="math inline">\(\ref{tbl-simu1}\)</span> 的分析一致.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:meancdf" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:meancdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/mean.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:meancdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.1: 不同<span class="math inline">\((n,m)\)</span>条件下失效时间的CDF估计值.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-AMM2020-s5" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="sec-AMM2020-s5"><span class="header-section-number">4.2.4</span> 实例分析</h3>
<p>本节应用所提模型分析两个实际数据集. 第 <a href="#sec-AMM2020-s5-1" class="quarto-xref"><span> 4.2.4.1</span></a> 节展示模型可准确识别子总体数量, 并对每个样品实现分类. 第 <a href="#sec-AMM2020-s5-2" class="quarto-xref"><span> 4.2.4.2</span></a> 节通过与其他两种考虑子总体的现有模型进行 AIC 比较, 验证模型有效性, 同时评估 EM 算法的计算效率.</p>
<section id="sec-AMM2020-s5-1" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="sec-AMM2020-s5-1"><span class="header-section-number">4.2.4.1</span> 集成电路器件退化数据</h4>
<!-- 数据表明, 集成电路器件的功率随时间下降. 它们在三种温度条件下进行测试: $150^\circ C$、$195^\circ C$ 和 $237^\circ C$. 在这三种温度下的样本量分别为 7、12 和 15.  -->
<p>为验证模型的有效性, 选取了一个集成电路器件退化数据的实际案例进行分析 (详见图 <a href="01-intro.html#fig-fig:deviceB" class="quarto-xref"><span>1.6</span></a>). 根据测试条件, 设备被分为三个子总体, 且每个设备的子总体归属已知. 图 <a href="#fig-fig:newcl" class="quarto-xref"><span>4.2</span></a>-(a) 显示了设备分类结果, 不同颜色代表不同子总体. 采用第 <a href="#sec-AMM2020-s3-1" class="quarto-xref"><span> 4.2.2.1</span></a> 节的方法, 通过AIC确定子总体数量, 并在算法运行后估计设备标签. 由于真实数据已知, 可直接评估模型和算法的分类准确性.</p>
<p>数据采用线性退化路径 <span class="math inline">\(\Lambda(t,\beta) = t\)</span> 进行拟合. 表 <span class="math inline">\(\ref{tbl-laserpar}\)</span> 列出了不同子总体数量 <span class="math inline">\(K=1, 2, 3, 4\)</span> 时的参数估计和AIC值. 结果显示, <span class="math inline">\(K=3\)</span>对应最小的AIC值, 表明数据中存在三个子群体, 与实际情况相符. 图 <a href="#fig-fig:newcl" class="quarto-xref"><span>4.2</span></a>-(b) 展示了基于 <span class="math inline">\(K=3\)</span> 的分类结果. 此外, 本方法与广义路径模型 <span class="citation" data-cites="yuan2015hierarchical">(<a href="references.html#ref-yuan2015hierarchical" role="doc-biblioref">Yuan 等, 2015</a>)</span> (图 <a href="#fig-fig:newcl" class="quarto-xref"><span>4.2</span></a>-(c)) 和维纳过程模型 <span class="citation" data-cites="zhang2017stochastic">(<a href="references.html#ref-zhang2017stochastic" role="doc-biblioref">Zhang 等, 2017</a>)</span> (图 <a href="#fig-fig:newcl" class="quarto-xref"><span>4.2</span></a>-(d)) 进行了比较. 在本方法中, 仅有一个 <span class="math inline">\(237^\circ C\)</span> 组的样品被错误分类为 <span class="math inline">\(195^\circ C\)</span> (用粗长虚线标出) , 分类准确率达到 <span class="math inline">\(97.06%\)</span>. 相比之下, 其他两种模型各有三个样品分类错误, 表明本方法分类效果更佳. 值得注意的是, <span class="citation" data-cites="wangschda2007">Wang 等 (<a href="references.html#ref-wangschda2007" role="doc-biblioref">2007</a>)</span> 提出的EM算法不适用于此例, 其复杂的数学表达式使得推导困难. 同样, 基于MCMC的贝叶斯分析也不适用, 因为在没有先验信息的情况下指定九个参数的先验分布可能导致不适当的后验分布 <span class="citation" data-cites="gelman2006 polsco2012">(<a href="references.html#ref-gelman2006" role="doc-biblioref">Gelman, 2006</a>; <a href="references.html#ref-polsco2012" role="doc-biblioref">Polson 等, 2012</a>)</span>, 且MCMC算法计算负担重, 收敛时间长. 这些结果进一步证实了模型和算法在确定子总体数量和准确分类方面的有效性.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:newcl" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:newcl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/rclus.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:newcl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.2: (a) 图为原始数据, (b)-(d) 分别展示了所提模型与其他模型的分类结果.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-AMM2020-s5-2" class="level4" data-number="4.2.4.2">
<h4 data-number="4.2.4.2" class="anchored" data-anchor-id="sec-AMM2020-s5-2"><span class="header-section-number">4.2.4.2</span> 铝合金裂纹退化数据</h4>
<!-- 铝合金裂纹退化数据来自2024-T351铝合金的寿命实验, 相关数据可以在[@Wu2003A] 的表1中找到. 实验中使用了30个抛光铝合金样本, 在室温下使用相同的测量设备进行测试. 时间单位为10,000个循环, 范围从1到4, 步长为0.5. 当单个样本的裂纹长度超过15mm时, 视为报废, 记录的循环数即为该单元的寿命.  -->
<p>本小节以铝合金裂纹退化数据为例 (详见图 <a href="01-intro.html#fig-fig:crack" class="quarto-xref"><span>1.7</span></a>), 考虑非线性退化路径函数 <span class="math inline">\(\Lambda(t,\beta)=t^\beta\)</span> 和 <span class="math inline">\(\Lambda(t,\beta)=\exp{(\beta t)}-1\)</span>, 并分别设置 <span class="math inline">\(K=1,2,3,4\)</span>. 各模型的点估计结果和 AIC 值列于表 <span class="math inline">\(\ref{tbl-crackesti}\)</span>. 结果显示, <span class="math inline">\(\Lambda(t,\beta)=\exp{(\beta t)}-1\)</span> 的模型在 AIC 值上显著优于其他模型. 为方便表述, 本小节后续将直接以“模型”代指“使用 <span class="math inline">\(\Lambda(t,\beta)=\exp{(\beta t)}-1\)</span> 的模型”. 在子总体数量的选择上, <span class="math inline">\(K=2\)</span> 的模型 AIC 值最小, 其次是 <span class="math inline">\(K=3\)</span> 的模型, 两者 AIC 值非常接近.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:crackci4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:crackci4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/crackci.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:crackci4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.3: 基于疲劳裂纹数据的不同 <span class="math inline">\(K\)</span> 的 CDF 估计.
</figcaption>
</figure>
</div>
</div>
</div>
<p>图 <a href="#fig-fig:crackci4" class="quarto-xref"><span>4.3</span></a> 展示了不同 <span class="math inline">\(K\)</span> 值下估计的失效时间分布, 其中黑点为拟合随机效应非线性模型的结果, 可视为“伪”失效时间点. 可以看出, <span class="math inline">\(K=3\)</span> 的模型拟合效果更好. 然而, AIC 综合考虑了拟合优度与模型复杂度, 表明 <span class="math inline">\(K=2\)</span> 的模型更合适. 这可能是因为 <span class="math inline">\(K=3\)</span> 的模型存在过拟合现象. 表 <span class="math inline">\(\ref{tbl-crackci5}\)</span> 列出了 <span class="math inline">\(K=2\)</span> 和 <span class="math inline">\(K=3\)</span> 模型参数的 95% 自助法置信区间, 图 <a href="#fig-fig:crackci4" class="quarto-xref"><span>4.3</span></a> 同时展示了 <span class="math inline">\(K=2\)</span> 模型的 95% 点估计自助法置信区间. 似然比检验结果显示: 原假设为<span class="math inline">\(K=1\)</span>对备择假设<span class="math inline">\(K=2\)</span> 的 检验P值为 0.021, 而原假设为 <span class="math inline">\(K=2\)</span>对 备择假设<span class="math inline">\(K=3\)</span> 的检验P值为 0.12. 这表明在显著性水平 0.05 下, 30 个样本中存在两个子总体. 对于 <span class="math inline">\(K=2\)</span> 的情况, 广义路径模型 <span class="citation" data-cites="yuan2015hierarchical">(<a href="references.html#ref-yuan2015hierarchical" role="doc-biblioref">Yuan 等, 2015</a>)</span> 和维纳过程模型 <span class="citation" data-cites="zhang2017stochastic">(<a href="references.html#ref-zhang2017stochastic" role="doc-biblioref">Zhang 等, 2017</a>)</span> 的 AIC 值分别为 -105.69 和 -117.83, 而该模型的 AIC 值更低, 显示了更优的性能. 这可能是因为广义路径模型未能捕捉时间变化的退化波动, 而维纳过程更适合非单调退化路径. 需要注意的是, 混合高斯分布可能导致负值, 与单调递增退化路径的假设冲突, 但根据估计参数, <span class="math inline">\(\nu\)</span> 为负的概率仅为 <span class="math inline">\(2.031 \times 10^{-6}\)</span>, 可忽略不计.</p>
<div id="fig-fig:cdede" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:cdede-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fig:cdede" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-fig:logvalue" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fig:logvalue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/loglikeli.pdf" class="img-fluid" data-ref-parent="fig-fig:cdede">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fig:logvalue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 对数似然函数值
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fig:cdede" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-fig:fcond" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fig:fcond-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/condnum.pdf" class="img-fluid" data-ref-parent="fig-fig:cdede">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fig:fcond-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) 每次迭代条件数
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:cdede-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.4: 所提算法迭代效果.
</figcaption>
</figure>
</div>
<p>通过监测对数似然函数值评估所提 EM 算法的收敛性, 容差设定为 <span class="math inline">\(\epsilon=1 \times 10^{-5}\)</span>. 图 <a href="#fig-fig:logvalue" class="quarto-xref"><span>4.4 (a)</span></a> 显示了每次迭代中对数似然函数的变化, 当 <span class="math inline">\(|\sum_{i=1}^n[\log L_i(\bm\Delta y_i|\bm\Theta^{(s+1)})-\log L_i(\bm\Delta y_i|\bm\Theta^{(s)})]|&lt;\epsilon\)</span> 时, 算法停止. 在本例中, 收敛在第 45 次迭代后实现.<br>
图 <a href="#fig-fig:fcond" class="quarto-xref"><span>4.4 (b)</span></a> 对比了所提 EM 算法与简单梯度上升算法每次迭代的条件数, 其中简单梯度上升算法基于矩阵 <span class="math inline">\(H(\bm\Theta)\)</span> 计算条件数. 从图中可以看出, 所提 EM 算法的条件数更小, 表明其收敛速度更快. 图 <a href="#fig-fig:parite" class="quarto-xref"><span>4.5</span></a> 显示了每次迭代的模型参数估计值变化. 可以看到, 所提 EM 算法的参数估计值收敛非常迅速, 计算时间仅为 0.5 秒 (测试环境: Windows 7 系统, Intel Core 2 Duo 处理器, 2.4 GHz, 4 GB 内存). 相比之下, <span class="citation" data-cites="wangschda2007">(<a href="references.html#ref-wangschda2007" role="doc-biblioref">Wang 等, 2007</a>)</span> 的 EM 算法也需 45 次迭代, 但计算时间为 1.63 秒; 而基于 MCMC 方法 (<span class="citation" data-cites="matin2005">Marin 等 (<a href="references.html#ref-matin2005" role="doc-biblioref">2005</a>)</span> 的第 4.3 节) 的算法需要 20,000 次迭代, 计算时间达 23.15 秒. 三种方法的参数估计结果列于表 <span class="math inline">\(\ref{tbl-comptime}\)</span>. 图 <a href="#fig-fig:crackg2" class="quarto-xref"><span>4.6</span></a> 展示了在假设存在两个子群体时, 30 个单元的聚类情况. 结果显示, 第 1 组样品的性能退化速度明显快于第 2 组.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:parite" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:parite-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/parites.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:parite-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.5: 模型参数估迭代图.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:crackg2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:crackg2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/AMM2020/crackgroup2.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:crackg2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.6: 当 <span class="math inline">\(K=2\)</span> 时, 疲劳裂纹数据的单元聚类.
</figcaption>
</figure>
</div>
</div>
</div>
<!-- ### 总结  {#sec-AMM2020-s6} -->
<!-- 本研究针对具有子群体异质性的退化数据提出了一种新型随机效应模型. 具体而言, 提出了一个 IG 过程, 其参数之一服从混合高斯分布. 基于所提出的模型, 我们开发了一种计算效率高的 EM 算法来估计参数. 此外, 采用偏差校正百分位数引导法计算模型参数的置信区间\index{置信区间}. 通过模拟研究和具有子群体的真实数据集验证了所提模型的能力和有效性. 我们还将所提出的模型和相应的 EM 算法应用于经典数据集. 结果表明, 所提出的模型和 EM 算法在 AIC\index{AIC} 和收敛速度方面分别优于现有的模型和算法. 所提模型的优点是它灵活且能够适用于任意数量的子群体, 甚至适用于无子群体的情况 (即 $K=1$) . 值得一提的是, 当子种群数量很大时, 所需的样本量应该足够大, 以便确定精确的值 $K$. 所提模型中的随机效应由参数 $\alpha$ 反映. 然而, 分散参数 $\lambda$ 也可能是随机的, 并遵循混合分布, 例如混合伽马分布\index{伽马分布}. 此外, 这两个参数都服从混合分布. 这两种情况的统计推断也可以通过所提出的 EM 算法进行, 只需稍加修改.  -->
<!-- 未来有一些可能的研究方向. 首先, 本研究通过基于 AIC\index{AIC} 的计数来确定子种群的数量. 一种更有效的确定适当数量的方法很重要, 值得研究, 例如可逆跳跃. 此外, 将所提出的模型集成到故障\index{故障}预测和预防性维护决策中具有重要意义, 需要付出大量努力.-->
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="sec-Append-4B" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="sec-Append-4B"><span class="header-section-number">4.2.5</span> 附录</h3>
<section id="em-算法技术细节" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="em-算法技术细节">EM 算法技术细节</h4>
<p>M 步可以通过求解以下方程实现. <span class="math display">\[\begin{align*}
        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial p_k}&amp;=\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}}{p_k}=0,  \\
        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \mu_k}&amp;=
        \sum\limits_{i=1}^n w_{ik}^{(s)}\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)/(1/y_{im_i}+\sigma_k^2)=0,\\
        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \sigma_k^2}&amp; =-\dfrac{1}{2} \sum\limits_{i=1}^n \left[\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2} - \dfrac{w_{ik}^{(s)}\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{(1/y_{im_i}+\sigma_k^2)^2}\right]=0, \\
        &amp; \qquad k=1,\dots,K,\\
        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \lambda}&amp;=
        \dfrac{1}{2}\sum\limits_{i=1}^n\left[ m_i/\lambda- \sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}+\Lambda(t_{im_i},\beta)^2/y_{im_i} \right. \\
        &amp;\quad \left. - \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right]=0,\\
        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \beta}&amp;=
        \sum\limits_{i=1}^n \left[ \sum\limits_{j=1}^{m_i}\dfrac{h^{'}_{ij}(\beta)}{h_{ij}(\beta)}-
        \lambda\left(\sum\limits_{i=1}^{m_i}h^{'}_{ij}(\beta)h_{ij}(\beta)/\Delta y_{ij}-\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)/y_{im_i}\right) \right]\\
        &amp;- \sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\lambda\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)/(1+y_{im_i}\sigma_k^2)=0.
\end{align*}\]</span> 通过求解上述方程, 可求得第 <span class="math inline">\((s+1)\)</span> 次迭代的参数估计值 <span class="math inline">\(\bm \Theta^{(s+1)}\)</span>, 如下所示 <span class="math display">\[\begin{eqnarray}
  p_k^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}}{n},\nonumber\\
  \mu_k^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}\Lambda(t_{im_i},\beta^{(s)})/(y_{im_i}/(\sigma_k^2)^{(s)}+1)}
        {\sum\limits_{i=1}^nw_{ik}^{(s)}/(1/y_{im_i}+(\sigma_k^2)^{(s)})},\nonumber\\
        \lambda^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nm_i}{\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} h_{ij}(\beta^{(s)})^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta^{(s)})^2/y_{im_i}+
            \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right] },\nonumber
\end{eqnarray}\]</span> <span class="math inline">\((\sigma_k^2)^{(s+1)}\)</span> 可以通过求解以下方程得到. <span class="math display">\[\begin{equation}\label{sigmas}
    \sum\limits_{i=1}^n \left[\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2}- \dfrac{w_{ik}^{(s)}\lambda^{(s)}(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2}{(1/y_{im_i}+\sigma_k^2)^2}\right]=0,
\end{equation}\]</span> <span class="math inline">\(\beta^{(s+1)}\)</span> 可以通过求解以下方程得到. <span class="math display">\[\begin{align}\label{betas}
    &amp;\sum\limits_{i=1}^n \left[\sum\limits_{j=1}^{m_i}\dfrac{h^{'}_{ij}(\beta)}{h_{ij}(\beta)}-
    \lambda^{(s)}\left(\sum\limits_{i=1}^{m_i}h^{'}_{ij}(\beta)h_{ij}(\beta)/\Delta y_{ij}-\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)/y_{im_i}\right) \right]\nonumber\\
    &amp;- \sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\lambda^{(s)}\Lambda^{'}(t_{im_i},\beta)
    \Lambda(t_{im_i},\beta)\dfrac{\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k^{(s)}}{1+y_{im_i}(\sigma_k^2)^{(s)}}=0.
\end{align}\]</span> 通过使用 <em>R</em> 软件中的 <em>uniroot()</em> 函数, 求解式 <span class="math inline">\(\eqref{sigmas}\)</span> 和 <span class="math inline">\(\eqref{betas}\)</span> 的零点.</p>
</section>
<section id="定理-thm-amm2020-2-的证明" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="定理-thm-amm2020-2-的证明">定理 <a href="#thm-AMM2020-2" class="quarto-xref"><span>4.2</span></a> 的证明</h4>
<p>对数似然函数定义为 <span class="math inline">\(l(\bm\Theta)=\sum_{i=1}^n \log L_i(\Delta \bm y_{i} \mid \bm \Theta)\)</span>, 其中 <span class="math inline">\(L_i(\Delta \bm y_{i}|\bm \Theta)\)</span> 的表达式如式 <span class="math inline">\(\eqref{margi}\)</span> 所示. 定义 <span class="math display">\[H_{ik}(\bm\Theta)=\dfrac{\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}
    \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}.\]</span> 则对 <span class="math inline">\(P\)</span> 的一阶导数为 <span class="math display">\[\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=
\sum_{i=1}^{n}\dfrac{(H_{i1}(\bm\Theta^{(s)}),\dots,H_{iK}(\bm\Theta^{(s)}))^{'}}
    {\sum_{k=1}^{K}p_k^{(s)}H_{ik}(\bm\Theta^{(s)})}, \]</span> 进一步计算得到:<br>
<span class="math display">\[\begin{equation*}
    \begin{split}
    G_P^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}}&amp;=
    \dfrac{1}{n}\sum_{i=1}^{n}\dfrac{(p_1^{(s)}H_{i1}(\bm\Theta^{(s)}),\dots,p_K^{(s)}H_{iK}(\bm\Theta^{(s)}))^{'}}
    {\sum_{k=1}^{K}p_k^{(s)}H_{ik}(\bm\Theta^{(s)})}-P^{(s)}\\
    &amp;=\dfrac{1}{n}\sum_{i=1}^{n}\left(w_{i1}^{(s)},\dots,w_{iK}^{(s)}\right)^{'}-P^{(s)}\\
    &amp;=P^{(s+1)}-P^{(s)}.
    \end{split}
    \end{equation*}\]</span> 类似地, 对 <span class="math inline">\(\mu_k\)</span> 的一阶导数为 <span class="math display">\[\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=\sum_{i=1}^{n}\lambda^{(s)}w_{ik}^{(s)}\dfrac{\Lambda_{i}/y_{im_i}-\mu_k^{(s)}}{1/y_{im_i}+(\sigma_k^2)^{(s)}}
.\]</span> 因此 <span class="math display">\[\begin{equation*}
    \begin{split}
    G_{\mu_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=
    {\mu_k}^{(s+1)}-{\mu_k}^{(s)}.
    \end{split}
\end{equation*}\]</span> 对 <span class="math inline">\(\lambda\)</span> 进行一阶导数, 并将 <span class="math inline">\(\lambda=\lambda^{(s)}\)</span> 代入, 得到 <span class="math display">\[\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=
\dfrac{\sum_{i=1}^{n}m_i}{2\lambda^{(s)}}-\dfrac{1}{2}
\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} \dfrac{h_{ij}^2}{\Delta y_{ij}}-\dfrac{\Lambda_i^2}{y_{im_i}}+
\sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right].
\]</span> 因此 <span class="math display">\[G_{\lambda}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}}
=\lambda^{(s+1)}-\lambda^{(s)}.\]</span> 令 <span class="math display">\[g_k(\sigma_k)=-\dfrac{1}{2}\sum\limits_{i=1}^n \left[\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2}- \dfrac{w_{ik}^{(s)}\lambda^{(s)}(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2} {(1/y_{im_i}+\sigma_k^2)^2}\right],\]</span> 则 <span class="math display">\[\dfrac{\partial l(\bm\Theta)}{\partial \sigma_k^2}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=
g_k(\sigma_k^{(s)}).\]</span> <span class="math inline">\(\sigma_k^2\)</span> 的 EM 更新通过牛顿法计算: <span class="math display">\[  (\sigma_k^2)^{(s+1)}-(\sigma_k^2)^{(s)}=-\dfrac{g_k(\sigma_k^{(s)})}{g_k^{'}(\sigma_k^{(s)})},\]</span> 其中 <span class="math display">\[g_k^{'}(\sigma_k^{(s)})=  \sum\limits_{i=1}^nw_{ik}^{(s)}\left[\dfrac{\lambda^{(s)}(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^3}-\dfrac{1}{2\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^2}\right].\]</span> 设 <span class="math inline">\(G_{\sigma_k}^{(s)} = -1 / g_k'(\sigma_k^{(s)})\)</span>, 则结果成立. 对 <span class="math inline">\(\beta\)</span> 的推导与 <span class="math inline">\(\sigma_k^2\)</span> 类似, 这里省略.</p>
</section>
</section>
</section>
<section id="sec-tp-IG" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-tp-IG"><span class="header-section-number">4.3</span> 二阶段逆高斯过程</h2>
<section id="sec-tp-s1" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="sec-tp-s1"><span class="header-section-number">4.3.1</span> 研究背景</h3>
<p>在 <a href="02-Wiener.html#sec-Two-Phase-Wiener" class="quarto-xref"><span> 2.3</span></a> 节中，介绍了两阶段维纳过程模型, 其用来描述产品性能呈现两个不同退化的规律. 由维纳过程的性质可知, 这类模型对非单调退化数据的拟合有显著效果. 然而, 对于单调退化数据, 例如钢铝合金金属的疲劳裂纹扩展 <span class="citation" data-cites="lawless2004covariates">(<a href="references.html#ref-lawless2004covariates" role="doc-biblioref">Lawless 等, 2004</a>)</span>、碳膜电阻器的电阻变化 <span class="citation" data-cites="park2006stochastic">(<a href="references.html#ref-park2006stochastic" role="doc-biblioref">Park 等, 2006</a>)</span> 以及LED的退化 <span class="citation" data-cites="Zhai2018">(<a href="references.html#ref-Zhai2018" role="doc-biblioref">Zhai, Ye, 2018</a>)</span>, 伽马过程和IG过程可能会更合适. 这两类随机过程能够有效刻画单调退化模式, 并为系统剩余寿命的准确估计提供有力支持. 对于伽马过程, <span class="citation" data-cites="linngtsu2019">Ling 等 (<a href="references.html#ref-linngtsu2019" role="doc-biblioref">2019</a>)</span> 提出了一种两阶段伽马退化过程模型, 并使用ML方法和贝叶斯方法估计未知参数. 同样, <span class="citation" data-cites="Lin2021b">Lin 等 (<a href="references.html#ref-Lin2021b" role="doc-biblioref">2021</a>)</span> 提出了一个固定变点的两阶段伽马退化过程模型, 用于分析恒定电流下电池老化的电压-放电曲线. 而对于IG过程, <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 研究了一类两阶段 IG 退化过程模型, 但其工作存在以下局限:</p>
<ol type="1">
<li><p>变点位置的约束: 在两阶段退化模型中 (如图 <a href="#fig-tp-fig:ig" class="quarto-xref"><span>4.7 (a)</span></a> 所示), <span class="math inline">\(Y(t)\)</span>在时间<span class="math inline">\(\tau\)</span>之前服从IG过程<span class="math inline">\(\mathcal{IG}(\alpha_1t, \lambda t^2)\)</span>, 在<span class="math inline">\(\tau\)</span>之后则过渡到另一个IG过程<span class="math inline">\(\mathcal{IG}(\alpha_2t, \lambda t^2)\)</span>. 假设<span class="math inline">\(t_j &lt; \tau &lt; t_{j+1}\)</span>, 表示<span class="math inline">\(Y_j\)</span>、<span class="math inline">\(Y_\tau\)</span>和<span class="math inline">\(Y_{j+1}\)</span>分别为时间<span class="math inline">\(t_j\)</span>、<span class="math inline">\(\tau\)</span>和<span class="math inline">\(t_{j+1}\)</span>的退化值. 退化增量<span class="math inline">\(Y_{j+1} - Y_j\)</span>可分解为<span class="math inline">\(Y_{j+1} - Y_\tau\)</span>和<span class="math inline">\(Y_\tau - Y_j\)</span>两个子增量, 且已知<span class="math inline">\(Y_{j+1} - Y_\tau \sim IG(a, b)\)</span>和<span class="math inline">\(Y_\tau - Y_j \sim IG(c, d)\)</span>, 其中: <span class="math inline">\(a=\alpha_2(t_{j+1}-\tau)\)</span>, <span class="math inline">\(b=\lambda(t_{j+1}-\tau)^2\)</span>, <span class="math inline">\(c=\alpha_1(\tau-t_j)\)</span>, <span class="math inline">\(d=\lambda(\tau-t_j)^2\)</span>. 然而, 由于 IG 分布的可加性在此问题中不适用, 即便<span class="math inline">\(\alpha_1 = \alpha_2\)</span>, 推导<span class="math inline">\(Y_{j+1} - Y_j\)</span>的分布仍具有挑战性. 为简化问题, <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 假设变点<span class="math inline">\(\tau\)</span>与测量时间点重合, 即<span class="math inline">\(\tau = t_j\)</span>或<span class="math inline">\(\tau = t_{j+1}\)</span>. 尽管这种假设在理论上可行, 但实际情况下变点通常是随机的, 这一约束可能导致参数估计偏差、RUL预测不准确, 进而影响维修决策.</p></li>
<li><p>寿命分布推导的局限: <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 假设变点对应的退化状态为固定值, 并在此基础上推导失效时间的分布. 然而, 变点位置的估计本质上依赖于样本信息, 其不确定性将直接影响退化状态的估计结果. 因此, 有必要进一步考虑变点的随机性, 并推导失效时间的边际分布. 此外, <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 仅聚焦于统计推断问题, 尚未充分探讨RUL估计及其对后续维修策略制定的潜在影响.</p></li>
<li><p><strong>忽略估计中的不确定性</strong>: <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 采用ML法对模型参数进行点估计, 未考虑参数估计的不确定性. 在中小样本情形下, 参数估计方差可能较大, 而MTTF、可靠性及分位寿命等关键指标一般为参数的函数, 其估计方差也会较大, 从而影响对产品可靠性的准确评估. 因此, 引入区间估计方法以量化参数不确定性尤为关键. 这不仅有助于全面反映估计量的波动, 也为后续的维修决策提供更具参考价值的信息 <span class="citation" data-cites="wu2022interval">(<a href="references.html#ref-wu2022interval" role="doc-biblioref">Wu 等, 2023</a>)</span>.</p></li>
</ol>
<div id="fig-tp-ig_rig" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-ig_rig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-ig_rig" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-tp-fig:ig" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-tp-fig:ig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/IG.pdf" class="img-fluid" data-ref-parent="fig-tp-ig_rig">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-tp-fig:ig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) IG过程
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-ig_rig" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-tp-fig:rig" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-tp-fig:rig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/rIG.pdf" class="img-fluid" data-ref-parent="fig-tp-ig_rig">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-tp-fig:rig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) rIG过程
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-ig_rig-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.7: 两种类型的两阶段随机过程.
</figcaption>
</figure>
</div>
<p>为更好地解决这些问题, 本节首先介绍一类新的两阶段重参数化IG (reparameterized IG, rIG) 过程模型, 并在此基础上考虑变点的异质性以及基于RUL 的维修决策问题. 具体包括以下三个方面:</p>
<ol type="1">
<li><p><strong>提出新的两阶段rIG退化模型</strong>. 为克服传统两阶段IG退化模型中涉及的非可加问题, 引入一种新的两阶段rIG退化模型. 如图 <a href="#fig-tp-fig:rig" class="quarto-xref"><span>4.7 (b)</span></a> 所示, 当变点位于时间间隔<span class="math inline">\((t_j, t_{j+1})\)</span>内时, 通过两个子增量<span class="math inline">\(Y_{j+1} - Y_{\tau}\)</span>和<span class="math inline">\(Y_{\tau} - Y_{j}\)</span>的分布, 推导出退化增量<span class="math inline">\(Y_{j+1} - Y_{j}\)</span>的分布. 具体而言, 若<span class="math inline">\(Y_{j+1} - Y_{\tau} \sim rIG(a, b)\)</span>且<span class="math inline">\(Y_{\tau} - Y_{j} \sim rIG(c, b)\)</span>, 则<span class="math inline">\(Y_{j+1} - Y_{j} \sim rIG(a+c, b)\)</span>. 该模型允许变点发生在任意时刻, 而不局限于特定的测量时间, 从而显著提升模型的灵活性和准确性, 使其能够更全面地刻画复杂退化模式.</p></li>
<li><p><strong>引入系统特定的</strong>变点和参数以刻画系统间的异质性. 通过为每个系统设定独立的变点和模型参数, 反映设备之间的差异性, 并充分考虑变点处退化状态的不确定性. 在此基础上, 推导每个系统的故障时间分布及 RUL 分布. 为实现精准推断, 提供两种统计推断方法: i) 基于ML方法的参数估计, 通过自助法获得区间估计. ii) 采用自适应拒绝抽样 (Adaptive Rejection Metropolis Sampling, ARMS) 结合Gibbs抽样生成后验样本, 构建可信区间. 这些区间量化了参数估计和RUL预测中的不确定性, 为工程应用提供全面的信息支持.</p></li>
<li><p><strong>提出基于RUL分布的</strong>自适应替换策略. 针对两阶段或多阶段退化的维修策略, 尽管已有研究 <span class="citation" data-cites="zhang2024condition yang2017condition zhang2016optimal">(<a href="references.html#ref-yang2017condition" role="doc-biblioref">Yang 等, 2017</a>; <a href="references.html#ref-zhang2016optimal" role="doc-biblioref">Zhang 等, 2016</a>; <a href="references.html#ref-zhang2024condition" role="doc-biblioref">Zhang 等, 2024</a>)</span> 基于固定变点考虑了成本最优化决策, 但对未知参数和变点的动态检测关注较少. 文献 <span class="citation" data-cites="fouladirad2011 fouladirad2008use grall2008maintenance">(<a href="references.html#ref-fouladirad2008use" role="doc-biblioref">Fouladirad 等, 2008</a>, <a href="references.html#ref-fouladirad2011" role="doc-biblioref">2011</a>; <a href="references.html#ref-grall2008maintenance" role="doc-biblioref">Grall 等, 2008</a>)</span> 考虑了已知模型参数情况下的变点检测问题. 相较之下, 本节假设参数和变点位置未知, 通过连续获取的观测数据动态更新参数估计, 并以此制定自适应 替换策略. 这种自适应策略更贴近实际应用, 可以显著提升系统动态演化背景下的维修决策效果.</p></li>
</ol>
<p>本节内容安排如下: 第 <a href="#sec-tp-s2" class="quarto-xref"><span> 4.3.2</span></a> 节介绍两阶段rIG退化模型, 推导出相应的失效时间和剩余寿命分布, 并提出基于RUL的自适应替换策略. 第 <a href="#sec-tp-s3" class="quarto-xref"><span> 4.3.3</span></a> 节描述用于估计模型未知参数的两种方法: EM方法和贝叶斯方法. 第 <a href="#sec-tp-s5" class="quarto-xref"><span> 4.3.4</span></a> 节通过模拟研究比较不同方法的统计推断性能. 第 <a href="#sec-tp-s6" class="quarto-xref"><span> 4.3.5</span></a> 节进行案例研究, 用于验证所提方法的适用性.</p>
</section>
<section id="sec-tp-s2" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="sec-tp-s2"><span class="header-section-number">4.3.2</span> 模型构建</h3>
<section id="sec-EJOR2024-s2-1" class="level4" data-number="4.3.2.1">
<h4 data-number="4.3.2.1" class="anchored" data-anchor-id="sec-EJOR2024-s2-1"><span class="header-section-number">4.3.2.1</span> rIG 过程</h4>
<p>传统的 IG 过程广泛用于刻画产品性能的退化规律 <span class="citation" data-cites="fan2023complete hao2019degradation pan2016remaining">(<a href="references.html#ref-fan2023complete" role="doc-biblioref">Fan 等, 2024</a>; <a href="references.html#ref-hao2019degradation" role="doc-biblioref">Hao 等, 2019</a>; <a href="references.html#ref-pan2016remaining" role="doc-biblioref">Pan 等, 2016</a>)</span>. 然而, 当性能退化呈现多个阶段时, 传统 IG 过程对不同阶段退化的可加性质将不满足, 这限制了其应用. 为解决这一问题, 本节首先引入 rIG 分布 <span class="math inline">\(rIG(\delta, \gamma)\)</span>, 为相关的 rIG 过程提供数学基础. <span class="math inline">\(rIG(\delta, \gamma)\)</span> 与传统的 IG 分布 <span class="math inline">\(IG(a, b)\)</span> 之间的参数关系为 <span class="math inline">\(a=\delta/\gamma\)</span> 和 <span class="math inline">\(b = \delta^2\)</span> <span class="citation" data-cites="Barndorff1998">(<a href="references.html#ref-Barndorff1998" role="doc-biblioref">Barndorff-Nielsen 等, 1998</a>)</span>. <span class="math inline">\(rIG(\delta, \gamma)\)</span> 的 PDF 表达式为: <span class="math display">\[\begin{equation}
f_{rIG}(y| \delta, \gamma)=\frac{\delta}{\sqrt{2 \pi}} e^{\delta \gamma} y^{-3 / 2} e^{-\left(\delta^2 y^{-1}+\gamma^2 y\right) / 2}, ~ y&gt;0,\delta&gt;0,\gamma&gt;0.
\end{equation}\]</span> 对应的CDF 为: <span class="math display">\[\begin{equation}\label{pdf}
\begin{aligned}
    F_{rIG}(y | \delta, \gamma)&amp;= \Phi\left[\sqrt{y}\gamma - \frac{\delta}{\sqrt{y}}\right]+e^{2 \delta \gamma} \Phi\left[-\sqrt{y}\gamma - \frac{\delta}{\sqrt{y}} \right],
\end{aligned}
\end{equation}\]</span> 其中 <span class="math inline">\(\Phi(\cdot)\)</span> 是标准正态分布的CDF. 若随机变量 <span class="math inline">\(Y\)</span> 服从 rIG 分布 <span class="math inline">\(rIG(\delta,\gamma)\)</span>, 则其矩母函数 (moment-generating function, MGF) 为 <span class="math display">\[\begin{equation}\label{mfg0}
M_Y(t) = \mathbb{E}(e^{ty}) = e^{\delta \gamma \left( 1 - \sqrt{1-\frac{2t}{\gamma^2} } \right)}.
\end{equation}\]</span> 根据 <span class="math inline">\(\eqref{mfg0}\)</span> 的表达式, 可知 rIG 分布具有可加性质, 即, 若两个独立随机变量 <span class="math inline">\(Y_1\sim rIG\left(\delta_1, \gamma\right)\)</span> 和 <span class="math inline">\(Y_2\sim rIG\left(\delta_2, \gamma\right)\)</span>, 则有 <span class="math inline">\(Y_1+Y_2\sim rIG\left(\delta_1+\delta_2, \gamma\right).\)</span></p>
<p>由此, 可定义一类 rIG 过程. 若随机过程 <span class="math inline">\({Z(t), t\ge0}\)</span> 满足以下条件, 则称其为 rIG 过程: i) <span class="math inline">\(Z(0)=0\)</span>, 概率为1; ii) 对于 <span class="math inline">\(t_2&gt;t_1 \geq s_2&gt;s_1 \geq 0\)</span>, <span class="math inline">\(Z\left(t_2\right)-Z\left(t_1\right)\)</span> 与 <span class="math inline">\(Z\left(s_2\right)-Z\left(s_1\right)\)</span> 相互独立; iii) 对于 <span class="math inline">\(t&gt;s \geq 0\)</span>, 增量 <span class="math inline">\(Z(t)-Z(s)\)</span> 服从 rIG 分布 <span class="math inline">\(rIG\left(\delta(\Lambda(t)-\Lambda(s)), \gamma\right)\)</span>, 其中 <span class="math inline">\(\Lambda(t)\)</span> 是单调增函数, 满足 <span class="math inline">\(\Lambda(0)=0\)</span>. 称该 rIG 过程为 <span class="math inline">\(r\mathcal{IG}\left(\delta\Lambda(t), \gamma\right)\)</span>, 其中 <span class="math inline">\(\delta\)</span> 是漂移参数, <span class="math inline">\(\gamma\)</span> 是扩散参数. 基于上述定义, 可以推导出 <span class="math inline">\(Z(t)\)</span> 的均值和方差分别为 <span class="math inline">\(\delta \Lambda(t) / \gamma\)</span> 和 <span class="math inline">\(\delta \Lambda(t)/ \gamma^3\)</span>.</p>
</section>
<section id="sec-tp-s2-2" class="level4" data-number="4.3.2.2">
<h4 data-number="4.3.2.2" class="anchored" data-anchor-id="sec-tp-s2-2"><span class="header-section-number">4.3.2.2</span> 两阶段rIG退化模型</h4>
<p>假设系统的退化过程由两个不同阶段组成, 并通过一个变点进行区分. 在这两个阶段中, 假定退化模式符合rIG过程, 每个阶段使用不同的漂移参数来描述变点前后的退化行为. 由于测试系统来自相同的总体, 可以推断这些系统的故障机制是一致的. 由于扩散参数<span class="math inline">\(\gamma\)</span>反映系统的故障机制, 进一步假定它在不同系统中保持一致. 令<span class="math inline">\(\Lambda(t) = t\)</span>来描述退化速率随时间线性增加的情形 <span class="citation" data-cites="Kong2017 Wang2018itr">(<a href="references.html#ref-Kong2017" role="doc-biblioref">Kong 等, 2017</a>; <a href="references.html#ref-Wang2018itr" role="doc-biblioref">Wang, Tang, Bae, 等, 2018</a>)</span>. 此外, 不同系统的变点可能不同. 为了刻画这种变异性, 将变点<span class="math inline">\(\tau\)</span>设为随机变量, 并假定其服从正态分布, 记其PDF为<span class="math inline">\(g_\tau(\cdot|\mu_\tau, \sigma_\tau^2)\)</span>. 这种处理方式既能刻画系统间的异质性, 又便于数学推导 (可以得到估计<span class="math inline">\(\mu_\tau\)</span>和<span class="math inline">\(\sigma_\tau^2\)</span>的解析形式), 因此在退化建模领域被广泛采用 <span class="citation" data-cites="Lu2020 shen2018degradation">(<a href="references.html#ref-Lu2020" role="doc-biblioref">Lu 等, 2020</a>; <a href="references.html#ref-shen2018degradation" role="doc-biblioref">Shen 等, 2018</a>)</span>. 由此, 可考虑以下的两阶段rIG退化模型: <span class="math display">\[\begin{equation}\label{tp-model}
    \begin{aligned}
        &amp;   Y(t)|\tau\sim r\mathcal{IG}\left(m(t;\delta_1 ,\delta_2 ,\tau),\gamma\right),~\tau\sim N\left(\mu_\tau, \sigma_\tau^2\right),\\
        &amp;   m(t;\delta_1 ,\delta_2 ,\tau) = \begin{cases} \delta_1t, &amp; t \leq \tau, \\ \delta_2 \left(t-\tau\right)+\delta_1\tau, &amp; t&gt;\tau,\end{cases}
    \end{aligned}
\end{equation}\]</span> 其中 <span class="math inline">\(\delta_1\)</span> 和 <span class="math inline">\(\delta_2\)</span> 分别是 <span class="math inline">\(t \leq \tau\)</span> 和 <span class="math inline">\(t&gt;\tau\)</span> 时的漂移参数.</p>
</section>
<section id="sec-tp-s2-3" class="level4" data-number="4.3.2.3">
<h4 data-number="4.3.2.3" class="anchored" data-anchor-id="sec-tp-s2-3"><span class="header-section-number">4.3.2.3</span> 失效时间和 RUL分布</h4>
<p>基于两阶段 rIG 退化模型 <span class="math inline">\(\ref{tp-model}\)</span>, 接下来对系统的失效时间和RUL分布进行推导, 这对于维修决策和优化资源分配具有重要意义 <span class="citation" data-cites="zhang2018degradation">(<a href="references.html#ref-zhang2018degradation" role="doc-biblioref">Zhang 等, 2018</a>)</span>. 失效时间 <span class="math inline">\(T\)</span> 定义为系统的退化值 <span class="math inline">\(Y(t)\)</span> 首次超过失效阈值 <span class="math inline">\(\mathcal{D}\)</span> 的时间, 即 <span class="math inline">\(T=\inf \left\{t \mid Y(t) \geq \mathcal{D}\right\}\)</span>. <span class="math inline">\(T\)</span> 的可靠度函数和MTTF计算公式见定理 <a href="#thm-EJOR2024-thy-1" class="quarto-xref"><span>4.3</span></a>.</p>
<div id="thm-EJOR2024-thy-1" class="theorem">
<p><span class="theorem-title"><strong>定理 4.3</strong></span> 系统失效时间 <span class="math inline">\(T\)</span> 的可靠度函数为 <span class="math display">\[\begin{equation}
            \begin{aligned}
                R\left(t \right)    &amp; =P\left(Y(t)&lt;\mathcal{D}, \tau \geq t\right)+P\left(Y(t)&lt;\mathcal{D}, 0&lt;\tau&lt;t\right) \\
                &amp; =\bar{F}_1\left(t  \mid  \tau \right) \bar{G}_{\tau}(t)+\int_0^t g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_2\left(t  \mid  \tau\right) \mathrm{d} \tau, \\
            \end{aligned}
        \end{equation}\]</span> 其中 <span class="math inline">\(\bar{G}_{\tau}(t)\)</span> 是随机变量 <span class="math inline">\(\tau\)</span> 的生存函数, <span class="math inline">\(\bar{F}_{1}(t|\tau)=P(T&gt;t \mid \tau \geq t)\)</span>, <span class="math inline">\(\bar{F}_{2}(t|\tau)=P(T&gt;t \mid \tau &lt; t)\)</span>. 给定可靠性函数, MTTF 为 <span class="math display">\[\begin{equation}\label{tp-mttf}
            \text{MTTF} =  \mathbb{E}(T) = \int_{0}^{\infty} R(t) \mathrm{d} t.
        \end{equation}\]</span></p>
</div>
<p>对于工程师来讲, 可能更关注系统在时刻 <span class="math inline">\(t\)</span>未失效时, 还能继续正常工作多长时间. 令 <span class="math inline">\(y_t\)</span> 为时刻 <span class="math inline">\(t\)</span> 系统性能退化的观测值. 系统在 <span class="math inline">\(t\)</span>时刻 的 RUL 定义为: <span class="math inline">\(S_{t}=\inf \left\{x; Y\left(t+x\right) \geq \mathcal{D} \mid Y_t &lt; \mathcal{D}\right\}\)</span>.</p>
<div id="thm-EJOR2024-thy-2" class="theorem">
<p><span class="theorem-title"><strong>定理 4.4</strong></span> RUL 的可靠度函数为 <span class="math display">\[\begin{equation}
    \begin{aligned}
      R_{S_t}(x) =&amp; \bar{F}_{S_t,1}\left(x \mid  \tau \right)    \bar{G}_{\tau}(x+t) + \int_{t}^{x+t} g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_{S_t,2}\left(x \mid  \tau\right) \mathrm{d} \tau \\
      &amp;+ \int_{0}^{t} g_{\tau}(\tau) \bar{F}_{S_t,3}\left(x \mid  \tau\right) \mathrm{d} \tau,
    \end{aligned}
\end{equation}\]</span> 其中, <span class="math inline">\(\bar{F}_{S_t,i}\)</span> (<span class="math inline">\(i=1,2,3\)</span>) 为 <span class="math inline">\(S_t\)</span> 的条件可靠度函数, 由时间 <span class="math inline">\(t\)</span>、<span class="math inline">\(t+x\)</span> 和变点 <span class="math inline">\(\tau\)</span> 的关系定义. RUL 的PDF为: <span class="math display">\[\begin{equation}\label{tp-rul_pdf}
  f_{S_t}(x) = -\frac{\partial R_{S_t}(x)}{\partial x}.
\end{equation}\]</span> 在时刻 <span class="math inline">\(t\)</span> 的平均剩余寿命 (Mean Residual Life, MRL) 为: <span class="math display">\[\begin{equation}
  \text{MRL} =  \mathbb{E}(S_t) = \int_{0}^{\infty} R_{S_t}(x) \mathrm{d} x.
\end{equation}\]</span></p>
</div>
<p>定理 <a href="#thm-EJOR2024-thy-1" class="quarto-xref"><span>4.3</span></a> 和 <a href="#thm-EJOR2024-thy-2" class="quarto-xref"><span>4.4</span></a> 的证明见本节附录A.</p>
</section>
<section id="sec-tp-s2-4" class="level4" data-number="4.3.2.4">
<h4 data-number="4.3.2.4" class="anchored" data-anchor-id="sec-tp-s2-4"><span class="header-section-number">4.3.2.4</span> 自适应替换策略</h4>
<p>本节将详细阐述自适应替换策略, 并建立了一个基于单周期准则的维修成本模型 <span class="citation" data-cites="Lu2022 sheu2019optimal">(<a href="references.html#ref-Lu2022" role="doc-biblioref">Lu 等, 2022</a>; <a href="references.html#ref-sheu2019optimal" role="doc-biblioref">Sheu 等, 2019</a>)</span>. 假设工程师在确定的检测时间点上对第 <span class="math inline">\(i\)</span> 个系统的性能退化进行观测. 令<span class="math inline">\(0 = t_{i,0} &lt; t_{i,1} &lt; \dots &lt; t_{i,j} &lt; \dots &lt; t_{i,n_i}\)</span>表示检测时间点, 且 <span class="math inline">\(y_{i,j}\)</span> 表示在时间点<span class="math inline">\(t_{i,j}\)</span> 所观测到的退化值. 记<span class="math inline">\(y_{i,1:j} = \{y_{i,1}, y_{i,2}, \dots, y_{i,j}\}\)</span>. 为了充分利用每次新增的观测数据, 可采用动态更新的方式, 通过更新模型参数的估计值 (将在第 <a href="#sec-tp-s3" class="quarto-xref"><span> 4.3.3</span></a> 节中详细介绍) 给出RUL分布预测, 并记在<span class="math inline">\(t_{i,j}\)</span>时刻系统的RUL分布为 <span class="math inline">\(f_{S_t}(x|y_{i,1:j})\)</span>. 在动态维修决策中, 需要在每个检测时间点重新评估候选维修操作, 并结合新收集的数据, 确定最优的预定备件方案和维修策略. 通过这种序贯更新过程, 企业可以实时获取系统状态信息, 动态优化维修决策, 从而实现主动预防系统失效.</p>
<p>假设系统的失效只能通过定期检测来发现, 每次检测的成本为 <span class="math inline">\(c_i\)</span>. 当系统发生失效并进行维修时, 工程师会将其更换为全新的同型号备件. 这种维修方式称为完美维修, 即系统在维修后被完全恢复至初始状态. 为了保障系统的可靠运行, 通常需提前准备备件. 在实际维修开始前, 还需完成一系列维修前的准备工作, 以避免操作失误或不必要的延误. 这些准备工作包括但不限于: 工具与设备的配置、技术人员的调配以及系统的关闭等. 将准备所需的时间记为 <span class="math inline">\(\varpi\)</span>.</p>
<p>在替换策略中, 决策者可选择纠正性替换或预防性替换两种策略. 设系统在<span class="math inline">\(t_{i,j}\)</span>时刻正常运行, 当预测其即将发生故障时, 决策者可选择执行预防性替换, 以避免突发性故障带来的损失. 预防性替换的成本记为 <span class="math inline">\(c_p\)</span>, 且替换操作需在指定的准备时间 <span class="math inline">\(\varpi\)</span> 后完成. 相反, 若在检测时发现系统已发生故障, 则必须执行纠正性替换, 对应的成本为 <span class="math inline">\(c_c\)</span>. 此外, 在系统失效后, 维修准备期间的停机将会产生额外成本, 记停机成本为 <span class="math inline">\(c_b\)</span>. 因此, 对于每个系统, 其在特定时刻 <span class="math inline">\(t_{i,j}\)</span> 的最优替换时间 <span class="math inline">\(\mathcal{T}_{i,j}\)</span> 可通过最小化期望成本来确定: <span class="math display">\[\begin{equation}\label{tp-min}
    \begin{aligned}
        \mathcal{T}_{i,j} = \underset{T_{i,j}}{\inf} \left\lbrace \int_0^{T_{i,j}-t_{i,j}} \frac{c_c + c_i \lfloor x + t_{i,j} \rfloor + c_b}{x + t_{i,j} + \varpi} f_{S_{t}}(x|y_{i,1:j}) \mathrm{d} x \right. \\
+ \left. \int_{T_{i,j}-t_{i,j}}^{+\infty} f_{S_{t}}(x|y_{i,1:j}) \frac{c_p + c_i \lfloor T_{i,j}-\varpi \rfloor}{T_{i,j}} \mathrm{d} x  \right\rbrace,
    \end{aligned}
\end{equation}\]</span> 其中, <span class="math inline">\(\lfloor \psi \rfloor = \max \{h \in \mathbb{Z} \mid t_{i,h} \leq \psi \}\)</span> 表示在时间 <span class="math inline">\(\psi\)</span> 之前已完成的检测次数. 这种决策过程在预防性替换的即时成本与等待下一次检测所可能带来的风险及相关成本之间实现了权衡. 需要注意的是, <span class="math inline">\(\mathcal{T}_{i,j}\)</span> 被视为候选的替换时间点. 这是因为在较长的时间跨度内, RUL的预测精度可能较低. 然而, 随着检测次数的增加和观测数据的累积, 基于RUL的自适应替换策略将随着时间推移不断提升预测准确性. 由此, 能够实施更为可靠的维修策略, 从而优化系统的整体运行效率和安全性.</p>
<p>具体而言, 随着 <span class="math inline">\(\mathcal{T}_{i,j}\)</span> 的动态更新, 应在首次满足条件 <span class="math inline">\(\mathcal{T}_{i,j} - t_{i,j} \leq \varpi\)</span>时, 确定最佳的准备时间点. 一旦该条件成立, 即可启动相应的准备工作, 并在准备工作完成后立即执行替换操作. 换言之, 最佳的准备时间和替换时间可通过以下公式来确定: <span class="math display">\[\begin{equation}\label{tp-final}
    \mathcal{T}^\prime_i =  \underset{t_{i,j}}{\inf} \{\mathcal{T}_{i,j}  - t_{i,j} \leq  \varpi\}, \quad  \text{和} \quad \mathcal{T}^*_i = \mathcal{T}^\prime_i + \varpi.
\end{equation}\]</span> 替换完成后, 新安装的部件将投入运行, 并开启新的维修决策周期.</p>
<p>上述内容描述了所提自适应替换策略的基本原理, 接下来将重点评估该策略的实际性能. 设有 <span class="math inline">\(I\)</span> 个系统, 每个系统只运行一个维修周期. 定义 <span class="math inline">\(\mathbb{X}_i = \min\{ \mathcal{T}^{*}_{i}, \mathcal{T}^{\text{f}}_{i} \}\)</span>, 其中 <span class="math inline">\(\mathcal{T}^{*}_{i}\)</span> 表示预测的最优替换时间, <span class="math inline">\(\mathcal{T}^{\text{f}}_{i}\)</span>表示系统的实际失效时间. 此时, 第 <span class="math inline">\(i\)</span> 个系统的实际成本率可通过以下公式计算: <span class="math display">\[\begin{equation}\label{cr}
    \textit{CR}_{i}=\left\{\begin{array}{l}
        \dfrac{c_{p} + c_i \lfloor \mathbb{X}_i -\varpi \rfloor}{\mathcal{T}^{*}_{i}},  ~\mathbb{X}_i = \mathcal{T}^{*}_{i}, \\
        \dfrac{c_{c} + c_i \lfloor \mathbb{X}_i \rfloor + c_b}{ \mathcal{T}^{\text{f}}_{i} + \varpi}, ~\mathbb{X}_i = \mathcal{T}^{\text{f}}_{i}. % + c_i \mathbb{X}_i
    \end{array}\right.
\end{equation}\]</span> 因此, 可定义所有系统的平均成本率为: <span class="math display">\[\begin{equation}\label{cr_everage}
    \overline{\textit{CR}}= \frac{\sum_{i = 1}^{I}\textit{CR}_{i}}{I}.
\end{equation}\]</span> 算法 <span class="math inline">\(\ref{tp-alg4}\)</span> 给出了所提出的动态自适应替换决策过程. 在实际应用中可采用贝叶斯方法进行统计推断分析. 第 <a href="#sec-tp-s5" class="quarto-xref"><span> 4.3.4</span></a> 节的仿真结果表明, 相较于ML方法, 贝叶斯方法在预测准确性与不确定性量化方面表现更优. 为进一步验证基于RUL的自适应替换策略的有效性, 本节将其与以下两种基准维修策略进行了对比: i). 经典替换策略 ( Classical Replacement Policy, CRP): 基于历史可靠性数据确定预防性维修时间，通常以系统的MTTF为准. 在该策略下, 第 <span class="math inline">\(i\)</span> 个系统的成本率形式与式 <span class="math inline">\(\eqref{cr}\)</span> 类似，但将 <span class="math inline">\(\mathcal{T}^{*}_{i}\)</span> 替换为 <span class="math inline">\(\bar{\mathcal{T}}^{F}\)</span>，且不计入检测成本. ii). 理想替换策略 (Ideal Replacement Policy, IRP): 假设可准确预测失效时间<span class="math inline">\(\mathcal{T}^{P}_{i}\)</span>. 在这种策略下, 第 <span class="math inline">\(i\)</span> 个系统的成本率为 <span class="math inline">\(c_p / \mathcal{T}^{P}_{i}\)</span>. 最终, 基于式 <span class="math inline">\(\eqref{cr_everage}\)</span>, 计算三种策略下所有系统的平均成本率, 以评估所提方法的相对优势.</p>
</section>
</section>
<section id="sec-tp-s3" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="sec-tp-s3"><span class="header-section-number">4.3.3</span> 统计推断</h3>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-data_dis" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-data_dis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/IG/EJOR2024/3frame.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-data_dis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.8: 变点与检测时间之间的三种关系.
</figcaption>
</figure>
</div>
</div>
</div>
<!-- ::: {#fig-tp-data_dis layout-ncol="2"} -->
<!-- ![$\tau_i \geq t_{i, j}$](figures/IG/EJOR2024/dat1.pdf){#fig-tp-fig:data1} -->
<!-- ![$t_{i, j-1} \leq \tau_i<t_{i, j}$](figures/IG/EJOR2024/dat2.pdf){#fig-tp-fig:data2} -->
<!-- ![$\tau_i<t_{i, j-1}$](figures/IG/EJOR2024/dat3.pdf){#fig-tp-fig:data3} -->
<!-- 两种类型的两阶段随机过程. -->
<!-- ::: -->
<p>假设在退化试验中共有 <span class="math inline">\(I\)</span> 个系统. 每个系统的性能退化过程在某个特定时刻 <span class="math inline">\(\tau_i\)</span> 发生明显变化, 即, <span class="math inline">\(\tau_i\)</span>为第 <span class="math inline">\(i\)</span> 个系统的性能退化变点. 假设系统的性能退化规律服从两阶段 rIG 退化模型 <span class="math inline">\(\ref{tp-model}\)</span>. 记 <span class="math inline">\(Y_{i, j}\)</span> 表示在测量时间 <span class="math inline">\(t_{i, j}\)</span> 处观测到的退化值, 其中 <span class="math inline">\(i=1, \dots, I\)</span> 且 <span class="math inline">\(j=1, \dots, n_i\)</span>, 满足 <span class="math inline">\(0 &lt; t_{i, 1} &lt; \ldots &lt; t_{i, n_i}\)</span>. 定义退化增量 <span class="math inline">\(\Delta y_{i, j}=Y_{i, j}-Y_{i, j-1}\)</span>, 其中 <span class="math inline">\(Y_{i, 0}=0\)</span>. 进一步定义 <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}_i=\left(\Delta y_{i, 1}, \ldots, \Delta y_{i, n_i}\right)^{\top}\)</span>, <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}=\left(\boldsymbol{\Delta} \boldsymbol{Y}_1^{\top}, \cdots, \boldsymbol{\Delta} \boldsymbol{Y}_I^{\top}\right)^{\top}\)</span>. 变点 <span class="math inline">\(\tau_i\)</span> 决定了各时刻下退化增量 <span class="math inline">\(\Delta y_{i, j}\)</span> 的分布形式. 如图 <a href="#fig-tp-data_dis" class="quarto-xref"><span>4.8</span></a> 所示, 变点 <span class="math inline">\(\tau_i\)</span> 与测量时间点存在三种潜在关系: <span class="math inline">\(k=1\)</span>, 对应于 <span class="math inline">\(\tau_i \geq t_{i, j}\)</span>; <span class="math inline">\(k=2\)</span>, 对应于 <span class="math inline">\(t_{i, j-1} \leq \tau_i &lt; t_{i, j}\)</span>; <span class="math inline">\(k=3\)</span>, 对应于 <span class="math inline">\(\tau_i &lt; t_{i, j-1}\)</span>. 因此, 对于每个观测点, 退化增量<span class="math inline">\(\Delta y_{i, j}\)</span> 的分布可统一表示为 <span class="math inline">\(rIG\left(\Delta m_{i, j}^{(k)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right),\gamma\right)\)</span>, 其中 <span class="math display">\[\begin{equation*}
        \Delta m_{i, j}^{(k)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)= \begin{cases}\delta_{1,i} \Delta t_{i, j} &amp; k=1, \\ \left(\delta_{1,i}-\delta_{2,i}\right)  \tau_i+\delta_{2,i} t_{i, j} -\delta_{1,i}  t_{i, j-1}, &amp; k=2, \\
        \delta_{2,i}  \Delta t_{i, j}, &amp; k=3,\end{cases}
\end{equation*}\]</span> <span class="math inline">\(\Delta t_{i, j}=t_{i, j} - t_{i, j-1}\)</span> 且 <span class="math inline">\(t_{i,0}=0\)</span>, <span class="math inline">\(i=1\dots, I,~j=1, \dots, n_i\)</span>. 为简化表达, 令<span class="math inline">\(\lambda_{i, j}^{(1)}=\mathcal{I}\left(\tau_i \geq t_{i, j}\right), \lambda_{i, j}^{(2)}=\mathcal{I}\left(t_{i, j-1} \leq \tau_i&lt;t_{i, j}\right)\)</span>, 和 <span class="math inline">\(\lambda_{i, j}^{(3)}=\mathcal{I}\left(\tau_i&lt;t_{i, j-1}\right)\)</span>, 其中 <span class="math inline">\(\mathcal{I}(\cdot)\)</span> 为示性函数, 进一步可得: <span class="math display">\[\begin{equation*}
        \begin{aligned}
            \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = &amp; \Delta m_{i, j}^{(1)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)^{\lambda_{i, j}^{(1)}} \times \Delta m_{i, j}^{(2)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) ^{\lambda_{i, j}^{(2)}} \\
            &amp; \times\Delta m_{i, j}^{(3)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)^{\lambda_{i, j}^{(3)}}.
        \end{aligned}
    \end{equation*}\]</span> 因此, 给定变点 <span class="math inline">\(\tau_i\)</span>, <span class="math inline">\(\Delta y_{i, j}\)</span> 的条件PDF为: <span class="math display">\[\begin{equation}\label{tp-pdf_1}
        \begin{aligned}
            \begin{aligned}
                f_{i,j} \left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i}, \tau_i, \gamma\right)
                &amp;= \frac{\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)}{\sqrt{2 \pi}} \exp\left\lbrace{ \gamma \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) }\right\rbrace  \Delta y_{i, j}^{-3 / 2} \\
                &amp;~~~ \times \exp\left\lbrace {-\frac{\left[\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\right]^2 \Delta y_{i, j}^{-1}+\gamma^2 \Delta y_{i, j}}{2}}\right\rbrace.
            \end{aligned}
        \end{aligned}
    \end{equation}\]</span> 记 <span class="math inline">\(\boldsymbol{\delta}_1=\left(\delta_{1,1}, \ldots, \delta_{1,I}\right)^{\top}\)</span>, <span class="math inline">\(\boldsymbol{\delta}_2=\left(\delta_{2,1}, \ldots, \delta_{2,I}\right)^{\top}\)</span> 和 <span class="math inline">\(\boldsymbol{\tau}=\left(\tau_1, \ldots, \tau_I\right)^{\top}\)</span>. 定义 <span class="math inline">\(\boldsymbol{\eta}=\)</span> <span class="math inline">\(\left(\boldsymbol{\delta}_1^{\top}, \boldsymbol{\delta}_2^{\top}, \gamma\right)^{\top}\)</span>, <span class="math inline">\(\boldsymbol{\theta}_\tau=\left(\mu_\tau, \sigma_\tau^2\right)^{\top}\)</span> 和 <span class="math inline">\(\boldsymbol{\vartheta}=\left(\boldsymbol{\theta}_\tau^{\top}, \boldsymbol{\eta}^{\top}\right)^{\top}\)</span>. 给定观测数据 <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}\)</span>, 模型参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 的似然函数可表示为: <span class="math display">\[\begin{equation}\label{tp-likelihood}
        \begin{aligned}
            L_{o b s}(\boldsymbol{\Delta} \boldsymbol{Y}|\boldsymbol{\vartheta}) &amp; = \prod_{i=1}^I \int_{-\infty}^{\infty} \prod_{j=1}^{n_i} f_{i,j}\left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i}, \tau_i, \gamma \right)g_\tau(\tau_i| \boldsymbol{\theta}_\tau)  \mathrm{d}  \tau_i.
        \end{aligned}
    \end{equation}\]</span> 显然，该似然函数涉及对变点 <span class="math inline">\(\tau_i\)</span> 的积分，难以获得参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 的MLE的解析形式. 为此，将引入一种基于EM算法的迭代优化方法来估计参数。EM算法是一种处理含有潜在变量问题的经典方法，广泛应用于可靠性建模与统计推断中 <span class="citation" data-cites="xiao2023hybrid">(<a href="references.html#ref-xiao2023hybrid" role="doc-biblioref">Xiao 等, 2023</a>)</span>. 该算法通过在每次迭代中交替执行期望步 (E步) 和最大化步 (M步), 最终获得模型参数的估计值.</p>
<section id="sec-tp-s3-1" class="level4" data-number="4.3.3.1">
<h4 data-number="4.3.3.1" class="anchored" data-anchor-id="sec-tp-s3-1"><span class="header-section-number">4.3.3.1</span> EM 算法与自助法</h4>
<p>在 E 步中, 构建一个 Q 函数, 用于表示在当前参数估计值下, 完全数据 <span class="math inline">\((\boldsymbol{\Delta Y}, \boldsymbol{\tau})\)</span> 的对数似然函数的条件期望. 该期望值基于当前参数向量 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 和 <span class="math inline">\(\boldsymbol{\tau}\)</span> 的条件分布进行计算. 随后, 在M 步中, 通过最大化该 Q 函数以更新模型参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 的估计值. 上述 E 步与 M 步的迭代过程将持续进行, 直至参数更新的幅度小于设定的收敛阈值, 从而获得稳定的参数估计. 在该框架下, 完全数据的对数似然函数可表示为: <span class="math display">\[\begin{equation}\label{tp-com-log}
    l_c(\boldsymbol{\Delta Y}, \boldsymbol{\tau}|\boldsymbol{\vartheta})=\sum_{i=1}^I l_i\left(\boldsymbol{\theta}_\tau\right)+\sum_{i=1}^I \sum_{j=1}^{n_i} l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}),
\end{equation}\]</span> 其中, <span class="math display">\[\begin{equation*}
    \begin{aligned}
        l_i\left(\boldsymbol{\theta}_\tau\right)&amp;= \log g_\tau\left(\tau_i \mid \boldsymbol{\theta}_\tau\right) = -\log \sqrt{2\pi} \sigma_{\tau} - \frac{{(\tau_i - \mu_\tau)}^2}{2 \sigma_\tau^2},\\
        l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) &amp;=\log f_{i, j}\left(\Delta y_{i, j} \mid \boldsymbol{\eta}, \boldsymbol{\tau} \right) \\
        &amp; = - \log \sqrt{2\pi} + \log \Delta m_{i,j}  + \gamma \Delta m_{i,j} - \frac{3}{2} \log \Delta y_{i,j} - \frac{\Delta m_{i,j}^{2}}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},
    \end{aligned}
\end{equation*}\]</span> <span class="math inline">\(\Delta m_{i,j}= \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\)</span>. 假设在第 <span class="math inline">\(s\)</span> 次迭代中, M 步得到了参数估计的最优解 <span class="math inline">\(\boldsymbol{\vartheta}_{(s)}\)</span>, 则在第 <span class="math inline">\(s+1\)</span> 次迭代的 E 步中, 需计算如下形式的 Q 函数: <span class="math display">\[\begin{equation}\label{tp-e-step}
    \begin{aligned}
        \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})&amp;=   \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[l_c(\boldsymbol{\Delta Y}, \boldsymbol{\tau}|\boldsymbol{\vartheta})\right]\\
        &amp;=\sum_{i=1}^I  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]  +\sum_{i=1}^I \sum_{j=1}^{n_i}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[ l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right],
    \end{aligned}
\end{equation}\]</span> 其中, 公式右侧的两项分别为 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]\)</span> 和 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]\)</span>, 其详细推导见本节附录B. 一旦得到 Q 函数, 通过以下 M 步更新参数估计: <span class="math display">\[\begin{equation}\label{tp-arg}
    \boldsymbol{\vartheta}_{(s + 1)} =  \arg \max \boldsymbol{Q}_{(s)} (\boldsymbol{\vartheta}).
\end{equation}\]</span> 可利用数值优化算法 (如牛顿或拟牛顿算法) 获得<span class="math inline">\(\boldsymbol{\vartheta}_{(s + 1)}\)</span> <span class="citation" data-cites="jamshidian1997">(<a href="references.html#ref-jamshidian1997" role="doc-biblioref">Jamshidian 等, 1997</a>)</span>. 在此基础上, 模型参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 的MLE可通过迭代计算直至收敛, 变点 <span class="math inline">\(\tau_i\)</span> 可通过计算 <span class="math inline">\(E_{\boldsymbol{\hat{\vartheta}}}\left\{\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}\)</span>, <span class="math inline">\(i=1, \ldots, I\)</span> 获得. EM 算法的详细技术细节可见本节附录B.</p>
<p>除了点估计 <span class="math inline">\(\boldsymbol{\vartheta}\)</span>, 还需要为参数函数 <span class="math inline">\(h(\boldsymbol{\vartheta})\)</span> 构造置信区间. 通常的区间估计基于渐近理论. 然而, 考虑到所提出模型 Fisher 信息矩阵的复杂性, 采用参数化自助法 <span class="citation" data-cites="efron2012bayesian Zhai2023multivariate">(<a href="references.html#ref-efron2012bayesian" role="doc-biblioref">Efron, 2012</a>; <a href="references.html#ref-Zhai2023multivariate" role="doc-biblioref">Zhai 等, 2023</a>)</span> 作为替代方法以量化参数的不确定性. 自助法的实施步骤可见算法 <span class="math inline">\(\ref{tp-alg1}\)</span>. 在获得自助法估计 <span class="math inline">\(\left\lbrace \hat{\boldsymbol{\vartheta}}_1^{\ast}, \ldots, \hat{\boldsymbol{\vartheta}}_{\mathcal{B}}^{\ast} \right\rbrace\)</span> 后, 可为参数函数<span class="math inline">\(h(\boldsymbol{\vartheta})\)</span>构造近似 <span class="math inline">\(100 (1-\zeta)\%\)</span> 的自助置信区间, 形式如下: <span class="math display">\[\left[h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{(\zeta \mathcal{B} / 2)}, h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{((1-\zeta / 2) \mathcal{B})}\right],\]</span> 其中 <span class="math inline">\(h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{(b)}\)</span> 表示 <span class="math inline">\(\left\lbrace h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_1, \ldots, h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{\mathcal{B}}\right\rbrace\)</span> 中的第 <span class="math inline">\(b\)</span> 个统计量.</p>
</section>
<section id="sec-tp-s3-2" class="level4" data-number="4.3.3.2">
<h4 data-number="4.3.3.2" class="anchored" data-anchor-id="sec-tp-s3-2"><span class="header-section-number">4.3.3.2</span> 贝叶斯分析</h4>
<p>贝叶斯分析在PHM领域中具有重要地位, 因其能够有效融合先验知识并量化模型参数的不确定性, 受到广泛关注 <span class="citation" data-cites="zhou2023fast taylor2022bayesian zhu2022bayesian">(<a href="references.html#ref-taylor2022bayesian" role="doc-biblioref">Taylor 等, 2024</a>; <a href="references.html#ref-zhou2023fast" role="doc-biblioref">Zhou 等, 2023</a>; <a href="references.html#ref-zhu2022bayesian" role="doc-biblioref">Zhu 等, 2022</a>)</span>. 其显著优势之一在于通过先验分布整合已有信息, 这些先验分布体现了对参数的先验认知. 在结合观测数据后, 贝叶斯分析可提供更为稳健的参数估计与不确定性评估. 本节将采用贝叶斯方法对两阶段退化模型中的参数进行估计, 所考虑的模型框架如下: <span class="math display">\[\begin{align}
    &amp;Y_i(t|\tau_i) \sim r\mathcal{IG}\left(m(t;\delta_{1,i} ,\delta_{2,i} ,\tau_i),\gamma\right),~\tau_i\sim N\left(\mu_\tau, \sigma_\tau^2\right), ~i=1, \ldots, I, \label{tp-mod1} \\
    &amp;m(t;\delta_{1,i} ,\delta_{2,i} ,\tau_i) = \begin{cases} \delta_{1,i}t, &amp; t \leq \tau_i, \\ \delta_{2,i} \left(t-\tau_i\right)+\delta_{1,i}\tau_i, &amp; t&gt;\tau_i,\end{cases} \label{tp-mod2}\\
    &amp;\left(\mu_\tau, \sigma_\tau^2\right) \sim NIGa\left(\beta_\tau, \eta_\tau, v_\tau, \xi_\tau\right), \gamma \sim N(\omega, \kappa^2), \label{tp-fiprior} \\
    &amp;\delta_{1,i} \sim N\left(\mu_1, \sigma_1^2\right), \delta_{2,i}  \sim N\left(\mu_2, \sigma_2^2\right), \label{tp-fiprior1} \\
    &amp;\left(\mu_1, \sigma_1^2\right)\sim NIGa\left(\beta_1, \eta_1, v_1, \xi_1\right), \left(\mu_2, \sigma_2^2\right) \sim NIGa\left(\beta_2, \eta_2, v_2, \xi_2\right), \label{tp-sedprior}
\end{align}\]</span> 其中, <span class="math inline">\(NIGa(\cdot)\)</span>表示正态逆伽马分布. 式 <span class="math inline">\(\eqref{tp-mod1}\)</span> 和式 <span class="math inline">\(\eqref{tp-mod2}\)</span> 是与第 <a href="#sec-tp-s3-1" class="quarto-xref"><span> 4.3.3.1</span></a> 节的模型设定一致. 在式 <span class="math inline">\(\eqref{tp-fiprior}\)</span> 中, 模型的共享参数 (如 <span class="math inline">\(\tau_i\)</span>) 设定先验分布, 以整合样本间信息并提高 <span class="math inline">\(\tau_i\)</span> 的估计精度. 接下来, 为漂移参数设定先验分布. 由于不同系统的退化路径可能存在差异, 其漂移参数可能不同. 然而, 这些系统来自同一总体, 存在一定的共同特性. 因此, 引入分层先验方法, 在漂移参数中同时考虑总体层面的共同影响和个体层面的异质性. 这种分层建模方法首先通过式 <span class="math inline">\(\eqref{tp-fiprior1}\)</span> 描述漂移参数的个体特性, 然后在式 <span class="math inline">\(\eqref{tp-sedprior}\)</span> 中进一步引入整体先验, 以捕捉系统间的整体相关性. 这种方法能够更全面地描述系统退化模式的复杂性.</p>
<p><strong>注1</strong>: 在贝叶斯框架中, 本文为参数 <span class="math inline">\(\gamma\)</span>、<span class="math inline">\(\delta_{1,i}\)</span> 和 <span class="math inline">\(\delta_{2,i}\)</span> 指定正态先验分布. 虽然这些参数可能出现负值, 但需要注意的是, 当先验分布的标准差与均值之比足够小时, 这种情况的发生概率会变得极低 <span class="citation" data-cites="Chen2013 Wang2018ress">(<a href="references.html#ref-Chen2013" role="doc-biblioref">Chen 等, 2013</a>; <a href="references.html#ref-Wang2018ress" role="doc-biblioref">Wang, Tang, Joo Bae, 等, 2018</a>)</span>. 这一假设符合贝叶斯建模的标准做法, 即在精心构造的先验分布下, 罕见的极端值通常被赋予较低权重, 从而对后验推断的影响较小. 此外, 选择正态先验不仅具有数学上的便利性, 还适合为超参数构建分层结构. 正如 <span class="citation" data-cites="bernardo2009bayesian">(<a href="references.html#ref-bernardo2009bayesian" role="doc-biblioref">Bernardo 等, 2009</a>)</span> 所述, 正态逆伽马分布是正态分布的均值和方差参数的共轭先验, 这一特性极大地简化了推断过程, 使分析更高效且易于处理.</p>
<p>定义<span class="math inline">\(\boldsymbol{\theta}=\left(\boldsymbol{\vartheta}, \mu_1, \sigma_1^2, \mu_2, \sigma_2^2\right)^{\top}\)</span> 为两阶段贝叶斯模型的参数向量. 根据贝叶斯定理, 参数 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的联合后验分布可表示为: <span class="math display">\[\begin{equation}\label{tp-posterior}
    \begin{aligned}
        \pi(\boldsymbol{\theta} \mid \boldsymbol{\Delta Y}) &amp;\propto \pi\left(\mu_\tau, \sigma_\tau^2\right) \pi\left(\mu_1, \sigma_1^2\right) \pi\left(\mu_2, \sigma_2^2\right) \pi\left(\gamma \mid \omega, \kappa\right) \pi\left(\tau \mid \mu_\tau, \sigma_\tau^2\right) \\
        &amp; \quad \times \pi\left(\boldsymbol{\delta}_1 \mid \mu_1, \sigma_1^2\right) \pi\left(\boldsymbol{\delta}_2 \mid \mu_1, \sigma_1^2\right) f_{\Delta Y}\left(\boldsymbol{\Delta Y} \mid \boldsymbol{\delta}_1, \boldsymbol{\delta}_2, \boldsymbol{\tau}, \gamma\right).\\
    \end{aligned}
\end{equation}\]</span> 由于 <span class="math inline">\(\pi(\boldsymbol{\theta} \mid \boldsymbol{\Delta Y})\)</span> 形式复杂, 难以直接解析求解其贝叶斯估计. 为此, 采用MCMC算法 (见算法 <span class="math inline">\(\ref{tp-alg}\)</span>) 生成后验样本. 这里, <span class="math inline">\(\boldsymbol{\theta}_{\backslash \eta}\)</span> 表示从 <span class="math inline">\(\boldsymbol{\theta}\)</span> 中去除 <span class="math inline">\(\boldsymbol{\eta}\)</span> 后的剩余参数, 满条件后验分布的推导细节可以在本节附录C中找到. 需要注意的是, <span class="math inline">\(\boldsymbol{\theta}\)</span> 中除 <span class="math inline">\(\tau_i\)</span>、<span class="math inline">\(\delta_{1,i}\)</span> 和 <span class="math inline">\(\delta_{2,i}\)</span> 外的参数, 其完整条件后验分布是已知的, 因此这些参数的后验样本可直接通过统计软件生成. 而对于 <span class="math inline">\(\tau_i\)</span>、<span class="math inline">\(\delta_{1,i}\)</span> 和 <span class="math inline">\(\delta_{2,i}\)</span> (<span class="math inline">\(i=1, \ldots, I\)</span>), 需要采用ARMS算法 <span class="citation" data-cites="gilks1995">(<a href="references.html#ref-gilks1995" role="doc-biblioref">Gilks 等, 2022</a>)</span>.</p>
</section>
</section>
<section id="sec-tp-s5" class="level3" data-number="4.3.4">
<h3 data-number="4.3.4" class="anchored" data-anchor-id="sec-tp-s5"><span class="header-section-number">4.3.4</span> 模拟实验</h3>
<p>本节通过模拟研究对所提出的模型与参数推断方法的性能进行评估. 为此, 考虑三种不同的系统数量 <span class="math inline">\(I\)</span> 和观测点数量 <span class="math inline">\(n_i\)</span>: 情形 (I): <span class="math inline">\(I = 5\)</span>, <span class="math inline">\(n_i = 20\)</span>; 情形 (II): <span class="math inline">\(I = 5\)</span>, <span class="math inline">\(n_i = 40\)</span>; 情形 (III): <span class="math inline">\(I = 8\)</span>, <span class="math inline">\(n_i = 20\)</span>. 扩散参数<span class="math inline">\(\gamma\)</span>设定为2. 为体现系统间的异质性, 漂移参数和变点按照如下方式随机生成: 从<span class="math inline">\(N(4, 1)\)</span> 分布中生成 <span class="math inline">\(\delta_{1,1}, \dots, \delta_{1,I}\)</span>; 从 <span class="math inline">\(N(15, 1)\)</span> 分布中生成 <span class="math inline">\(\delta_{2,1}, \dots, \delta_{2,I}\)</span>; 从 <span class="math inline">\(N(10, 1)\)</span> 分布中生成变点 <span class="math inline">\(\tau_1, \dots, \tau_I\)</span>. 在给定变点 <span class="math inline">\(\tau_i\)</span> 的条件下, 每个系统的退化增量根据式 <span class="math inline">\(\eqref{tp-pdf_1}\)</span> 所定义的 rIG 分布模拟生成. 为降低随机抽样对结果的影响, 每种情形均重复模拟 500 组样本, 用于后续的统计分析与性能评估</p>
<section id="sec-tp-sec5-1" class="level4" data-number="4.3.4.1">
<h4 data-number="4.3.4.1" class="anchored" data-anchor-id="sec-tp-sec5-1"><span class="header-section-number">4.3.4.1</span> 参数估计的性能评估</h4>
<p>首先, 使用所提出的模型和方法对模拟数据进行拟合. 对于贝叶斯方法, 先验分布设定为无信息先验, 具体如下: <span class="math inline">\((\mu_\tau,\sigma_\tau^2) \sim NIGa(8,100,0.01,0.01)\)</span>, <span class="math inline">\((\mu_1,\sigma_1^2) \sim NIGa(1,100,0.01,0.01)\)</span>, <span class="math inline">\((\mu_2,\sigma_2^2) \sim NIGa(2,100,0.01,0.01)\)</span>, <span class="math inline">\(\gamma \sim N(5,100)\)</span>. 后验样本的生成采用第 <a href="#sec-tp-s3-2" class="quarto-xref"><span> 4.3.3.2</span></a> 节中介绍的 ARMS-Gibbs 算法. 设定烧蚀期样本长度为<span class="math inline">\(\mathcal{L} = 5000\)</span>, 进行 <span class="math inline">\(\mathcal{S} - \mathcal{L} = 5000\)</span> 次迭代以获得后验样本. 所有参数的贝叶斯点估计均取对应后验样本的均值. 对于 ML 方法, 使用上述贝叶斯估计结果作为 EM 算法的初始值. 参数的点估计通过第 <a href="#sec-tp-s3-1" class="quarto-xref"><span> 4.3.3.1</span></a> 节中描述的 EM 算法获得, 参数的区间估计则通过参数化自助法实现, 自助样本数量设为 <span class="math inline">\(\mathcal{B} = 500\)</span>. EM 算法的收敛标准为: <span class="math inline">\(\left | \boldsymbol{\vartheta}_{(s+1)}-\boldsymbol{\vartheta}_{(s)}\right | &lt; 10^{-3}\)</span>, 其中 <span class="math inline">\(|\cdot|\)</span> 表示 <span class="math inline">\(L_1\)</span> 距离.</p>
<p>表 <span class="math inline">\(\ref{tp-com}\)</span> 展示了两种推断方法的评估结果, 包括RB、RMSE 和95%区间估计的CP. 从点估计的角度来看, 贝叶斯方法与ML方法均表现出较小的相对偏差和合理的 RMSE, 表明两种方法在参数点估计方面均具备较好的性能. 需要指出的是, 在情形 I 与情形 II 中, 随着单个系统观测次数 <span class="math inline">\(n_i\)</span> 的增加, 两种方法的 RMSE 均显著降低, 说明增加观测频率有助于提升参数估计的准确性. 而在情形 III 中，由于试验中包含更多的系统数量, RMSE 有一定程度的下降, 进一步表明系统间信息的融合对估计精度具有积极影响. 然而， 在区间估计方面， 贝叶斯方法在所有情形下均表现出更优性能, 其覆盖概率更接近 0.95 的名义水平, 显示出较强的区间置信性. 相比之下, ML 方法在所有情形中的 CP 均明显低于 0.95, 表明其在不确定性量化方面存在一定不足. 综上所述, 建议在两阶段退化模型的参数估计中优先采用贝叶斯方法, 以获得更为准确的点估计和更具可靠性的区间估计.</p>
</section>
<section id="sec-tp-sec5-2" class="level4" data-number="4.3.4.2">
<h4 data-number="4.3.4.2" class="anchored" data-anchor-id="sec-tp-sec5-2"><span class="header-section-number">4.3.4.2</span> 可靠性估计的性能评估</h4>
<p>本小节进一步开展模拟研究, 以评估所提模型在可靠性估计中的优势. 选择情形 I 和情形 III, 假设系统故障均发生于第二阶段, 且失效阈值设定为 75. 为进行对比分析, 引入三种不考虑变点结构的基准模型, 包括: 1) 线性 rIG 模型, 退化路径设为<span class="math inline">\(\Lambda(t) = t\)</span>; 2) 幂律模型: <span class="math inline">\(\Lambda(t; \varsigma) = t^\varsigma\)</span>; 3) 指数模型: <span class="math inline">\(\Lambda(t; \varsigma) = \exp(\varsigma t) - 1\)</span>. 对于所有基准模型, 均采用贝叶斯方法进行推断, 并设参数 <span class="math inline">\(\varsigma\)</span>的先验为正态分布 <span class="math inline">\(N(5,100)\)</span>, 其中较大的方差表示参数 <span class="math inline">\(\varsigma\)</span>的先验信息较弱. 其余模型参数的先验分布与第 <a href="#sec-tp-sec5-1" class="quarto-xref"><span> 4.3.4.1</span></a> 节的设定一致. 图 <a href="#fig-tp-mttf-rmse" class="quarto-xref"><span>4.9</span></a> 给出了各模型对系统 MTTF估计上的RMSE对比结果. 从图中可以看出, 所提模型在贝叶斯方法下所得的RMSE显著低于其他基准模型. 这一结果表明, 所提模型在预测系统MTTF方面具有更高的精度, 从而验证了其在可靠性估计中的显著优势.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-mttf-rmse" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-mttf-rmse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/R_com2.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-mttf-rmse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.9: 基于不同模型的MTTF估计结果比较.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-tp-sec5-3" class="level4" data-number="4.3.4.3">
<h4 data-number="4.3.4.3" class="anchored" data-anchor-id="sec-tp-sec5-3"><span class="header-section-number">4.3.4.3</span> 变点估计的性能评估</h4>
<p>为进一步突出所提模型在实时环境下对变点检测的优势, 本研究基于情形 II (<span class="math inline">\(n_i = 40\)</span>) 进行模拟实验. 设退化数据为动态获取, 在每个阶段使用当前观测数据 <span class="math inline">\(y_{i,1:j}\)</span> 对模型参数进行更新估计, 并据此判断变点位置. 图 <a href="#fig-tp-tau_com" class="quarto-xref"><span>4.10</span></a> 展示了在 <span class="math inline">\(j=20, 30, 40\)</span>三个时间点下, 变点估计的平均RMSE. 结果表明, 随着可用观测数据量的增加, 变点估计的 RMSE 持续下降, 且两种方法在各阶段均保持较小的RMSE, 说明所提模型能够有效识别变点位置. 值得注意的是, 贝叶斯方法在变点检测方面表现出更高的精度, 其在所有阶段下的平均 RMSE 均显著低于ML方法. 该结果进一步验证了贝叶斯方法在动态监测退化过程中的鲁棒性与优越性</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-tau_com" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-tau_com-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/tau_com.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-tau_com-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.10: 不同时间点下变点估计的平均 RMSE.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-tp-s6" class="level3" data-number="4.3.5">
<h3 data-number="4.3.5" class="anchored" data-anchor-id="sec-tp-s6"><span class="header-section-number">4.3.5</span> 实例分析</h3>
<p>本小节采用锂离子电池退化数据集对所提方法的实际应用性能进行验证（见图 <span class="math inline">\(\ref{fig-tp-battery-data}\)</span>）. 锂离子电池广泛应用于手机、电动汽车等各类商业产品中, 其性能退化或故障可能导致设备效能下降, 甚至完全失效. 因此, 准确预测电池的RUL分布，并据此制定科学的维修与更换策略，对于提升设备运行的可靠性和降低维护成本具有重要意义 <span class="citation" data-cites="zhang2023joint peng2018joint">(<a href="references.html#ref-peng2018joint" role="doc-biblioref">Peng 等, 2018</a>; <a href="references.html#ref-zhang2023joint" role="doc-biblioref">Zhang 等, 2023</a>)</span>.</p>
<!-- 图 @fig-tp-battery-data 展示了六个电池容量随周期变化的退化数据. 从图中可以看出, 每个电池的容量退化呈现出两个阶段的特征: 初始阶段退化速率较低, 而后进入退化速率较高的阶段. 基于此数据集, 目标是利用所提模型拟合这些电池的退化路径, 并提供RUL的预测分布 (见第 @sec-tp-s6-1 节). 随后展示所提自适应替换\index{自适应替换}策略的维修决策效果 (见第 @sec-tp-s6-2 节). -->
<!-- ```{r} -->
<!-- #| label: fig-tp-battery-data -->
<!-- #| fig.align: 'center' -->
<!-- #| echo: FALSE -->
<!-- #| out.width: '70%' -->
<!-- #| fig.cap: '6个锂电池的容量退化数据.' -->
<!-- knitr::include_graphics("figures/IG/EJOR2024/battery-data.pdf") -->
<!-- ``` -->
<section id="sec-tp-s6-1" class="level4" data-number="4.3.5.1">
<h4 data-number="4.3.5.1" class="anchored" data-anchor-id="sec-tp-s6-1"><span class="header-section-number">4.3.5.1</span> 模型拟合与可靠性分析</h4>
<p>首先, 采用所提的两阶段 rIG 模型对退化数据进行拟合, 并分别通过贝叶斯方法和ML方法进行参数估计. 两种方法的设置与模拟实验中的保持一致. 为验证 EM 算法和 ARMS-Gibbs 采样算法的收敛性, 本节附录D展示了参数估计的迭代过程、后验样本的轨迹图以及遍历均值图. 结果表明, 两种算法均具有良好的收敛性, 表现出快速且稳定的收敛趋势. 表 <span class="math inline">\(\ref{tp-real-data-para}\)</span> 给出了模型参数和变点的估计结果. 以扩散参数 <span class="math inline">\(\gamma\)</span> 为例, 贝叶斯方法和 ML 方法的点估计分别为 2.930 和 3.001, 对应的 95% 可信区间（贝叶斯方法）与置信区间（ML 方法）分别为 (2.615, 3.556) 和 (2.804, 3.165). 这些结果表明，两种方法均能够提供稳定且可靠的参数估计</p>
<p>此外, 为评估所提模型的预测能力, 选取前 30 个数据点用于模型拟合, 并预测后续19 个充放电循环后的电池容量变化. 作为对比, 本文引入 <span class="citation" data-cites="Duan2017">Duan 等 (<a href="references.html#ref-Duan2017" role="doc-biblioref">2017</a>)</span> 提出的两阶段 IG 模型（以下简称 “Duan” 模型）, 该模型假设变点仅发生在观测时间点上. 模型中的未知参数通过ML方法估计，并借助 Schwarz 信息准则在拟合精度与模型复杂度之间进行权衡以确定变点位置. 需注意的是，“Duan” 模型的变点位置仅限定于离散的观测点上, 而所提模型则可在连续时间域中直接估计变点位置, 并允许其具备一定的不确定性.</p>
<p>表 <span class="math inline">\(\ref{tp-pre}\)</span> 汇总了五种模型在训练阶段、预测阶段及整体性能方面的RB与RMSE, 其中 “Proposed” 表示采用贝叶斯方法进行参数估计的所提模型. 从表中可以看出, 三种不考虑变点的基准模型在预测精度方面表现较差, RMSE 与 RB 值均显著偏高. 例如, 图 <a href="#fig-tp-5method-path" class="quarto-xref"><span>4.11</span></a> 展示了各模型对电池 #2 的拟合与预测路径. 可以观察到, 不包含变点机制的模型拟合能力不足, 导致其在未来退化路径的预测中存在较大误差. 相较之下, 两阶段模型能够有效识别退化过程中的变点, 从而生成与实际观测更为一致的预测结果. 与 “Duan” 模型相比, 所提模型在预测性能上表现更优, 体现为更低的 RMSE 与 RB 值. 这一优势主要得益于其对变点位置的更精准估计. 以电池 #2 为例, 图 <a href="#fig-tp-5method-path" class="quarto-xref"><span>4.11</span></a> 进一步对比了两种模型在变点检测方面的差异. 可以明显看出, 变点估计结果的差异直接影响了第二阶段退化速率的判断, 进而对RUL预测的准确性产生显著影响.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-5method-path" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-5method-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/5method-path5.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-5method-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.11: 使用不同方法对电池#2 进行退化路径训练和预测结果.
</figcaption>
</figure>
</div>
</div>
</div>
<p>基于所提模型的估计结果, 可推导每个电池的失效时间和RUL分布, 方法如第 <a href="#sec-tp-s2-3" class="quarto-xref"><span> 4.3.2.3</span></a> 节所述. 以贝叶斯估计为例, 使用前30个循环数据, 图 <a href="#fig-tp-failure-time-plot" class="quarto-xref"><span>4.12</span></a> 展示了每个电池失效时间的可靠度函数和PDF, 阈值为 <span class="math inline">\(\mathcal{D} = 20\%\)</span>. 根据式 <span class="math inline">\(\eqref{tp-mttf}\)</span>, 各电池的MTTF分别为 41.984、43.208、43.658、44.588、43.320 和 42.257. 图 <a href="#fig-tp-rul-plot" class="quarto-xref"><span>4.13</span></a> 展示了第30个循环时RUL的可靠度函数和PDF, 各电池的MRL分别为 9.352、13.375、14.354、15.111、13.180 和 11.925.</p>
<div id="fig-tp-failure-time-plot" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-failure-time-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-failure-time-plot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-failure-time-pdf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-failure-time-pdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/failure-time-R.pdf" class="img-fluid" data-ref-parent="fig-tp-failure-time-plot">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-failure-time-pdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 平均退化路径估计
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-failure-time-plot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-failure-time-R" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-failure-time-R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/failure-time-pdf.pdf" class="img-fluid" data-ref-parent="fig-tp-failure-time-plot">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-failure-time-R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) 寿命估计PDF
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-failure-time-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.12: 基于贝叶斯方法的可靠度和失效时间密度函数.
</figcaption>
</figure>
</div>
<div id="fig-tp-rul-plot" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-rul-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-rul-plot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rul-R" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rul-R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/rul_r.pdf" class="img-fluid" data-ref-parent="fig-tp-rul-plot">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rul-R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 平均退化路径估计
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-tp-rul-plot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rul-pdf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rul-pdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/rul_pdf.pdf" class="img-fluid" data-ref-parent="fig-tp-rul-plot">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rul-pdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) 寿命估计PDF
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-rul-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.13: 基于贝叶斯方法的 RUL 在第 30 个周期的可靠度和密度函数.
</figcaption>
</figure>
</div>
</section>
<section id="sec-tp-s6-2" class="level4" data-number="4.3.5.2">
<h4 data-number="4.3.5.2" class="anchored" data-anchor-id="sec-tp-s6-2"><span class="header-section-number">4.3.5.2</span> 自适应替换策略</h4>
<p>基于RUL预测结果, 可利用所提自适应替换策略确定每个电池的最佳替换时间. 为展示模型在实时场景中的适用性, 选取前30的数据点作为历史数据, 并随着时间推移逐步获取新数据. 在此过程中, 每当获取新的观测数据时, 模型参数和RUL分布的估计均会动态更新. 依据期望成本率式 <span class="math inline">\(\eqref{tp-min}\)</span>, 可以确定持续数据收集期间每个电池的候选替换时间. 为说明效果, 表 <span class="math inline">\(\ref{tp-optimal-PR}\)</span> 展示了电池 #2 和 #3 的候选替换时间, 其中各项成本设定为 <span class="math inline">\(c_i = 2, c_c = 600, c_p = 200, c_b = 100\)</span>, 维修准备时间<span class="math inline">\(\varpi = 1\)</span>. 此外, 表中还包括真实的RUL和预测的MRL. 从表中可以看出, 候选替换时间根据RUL预测结果进行动态调整. 电池 #2 和 #3 的最佳准备时间分别为42和43. 一旦准备完成, 最佳替换时间分别为43和44, 均与电池实际失效时间高度一致, 表明应在失效发生前进行预防性维修. 这一结果进一步验证了所提自适应替换策略在动态环境下的有效性与实用性.</p>
<p>为突出模型准确性对自适应维修策略的影响, 将所提两阶段模型的结果与其他模型进行比较. 需要注意, “Duan” 模型假设变点已知, 且未推导出 RUL 分布, 因此仅将所提模型与其他三个不考虑变点的模型 (线性、幂律和指数) 进行比较. 表 <span class="math inline">\(\ref{tp-6_battery}\)</span> 展示了不同模型下 6 个电池的最佳替换时间, 其中“FC” 表示电池的真实失效时间, “P” 和 “C” 分别对应预防性维修和纠正性维修. 从表中可见, 在自适应替换策略下, 除幂律模型对五个电池执行纠正性维修外, 其他模型中所有电池的最终确定的最佳替换时间均小于 FC, 即成功执行预防性维修.</p>
<p>图 <a href="#fig-tp-arc" class="quarto-xref"><span>4.14</span></a> 展示了每种策略的平均成本率, 其中 ARP 代表所提策略. 在 ARP 下, 使用两阶段 rIG 模型的策略称为 ARP-TP. 从图中可以看出, 除 ARP-Power 策略外, 其他基于 RUL 的 ARP 策略均明显优于 CRP. 此外, 值得注意的是, 与其他策略相比, ARP-TP 的表现最接近 IRP. 结合表 <span class="math inline">\(\ref{tp-6_battery}\)</span>, ARP-TP 提供了接近系统实际故障时间的准确 <span class="math inline">\(\mathcal{T}_i^*\)</span> 值, 而不会超过其实际寿命. ARP-TP 的平均成本率相对较低, 归因于所提两阶段模型的有效性, 该模型能够准确捕捉变更点的位置并拟合退化路径, 显著提升了预测和决策的精度.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-arc" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-arc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/ARC-prepare2.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-arc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.14: 每个策略的平均成本率.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="附录" class="level3" data-number="4.3.6">
<h3 data-number="4.3.6" class="anchored" data-anchor-id="附录"><span class="header-section-number">4.3.6</span> 附录</h3>
<section id="附录a-定理-thm-ejor2024-thy-1-和-thm-ejor2024-thy-2-证明" class="level4" data-number="4.3.6.1">
<h4 data-number="4.3.6.1" class="anchored" data-anchor-id="附录a-定理-thm-ejor2024-thy-1-和-thm-ejor2024-thy-2-证明"><span class="header-section-number">4.3.6.1</span> 附录A: 定理 <a href="#thm-EJOR2024-thy-1" class="quarto-xref"><span>4.3</span></a> 和 <a href="#thm-EJOR2024-thy-2" class="quarto-xref"><span>4.4</span></a> 证明</h4>
<p>首先证明定理 <a href="#thm-EJOR2024-thy-1" class="quarto-xref"><span>4.3</span></a> 的结果. 设<span class="math inline">\(Y_1(t)\)</span>和<span class="math inline">\(Y_2(t)\)</span>分别是变点<span class="math inline">\(\tau\)</span>之前和之后的退化过程. 那么有 <span class="math display">\[\begin{equation*}
    Y(t)=\left\{
    \begin{array}{ll}
        Y_1(t), &amp; t\le\tau, \\
        Y_1(\tau)+Y_2(t-\tau), &amp; t&gt;\tau.
    \end{array}
    \right.
\end{equation*}\]</span><br>
当<span class="math inline">\(0 \leq t \leq \tau\)</span>时, 在给定<span class="math inline">\(\tau\)</span>的条件下, <span class="math inline">\(T\)</span>的可靠度函数, 记作<span class="math inline">\(\bar{F}_{1}(t|\tau)\)</span>, 可以写为 <span class="math display">\[\begin{equation}\label{r1}
    \begin{aligned}
        \bar{F}_{1}(t  \mid  \tau)&amp; = P(T&gt;t \mid \tau \geq t) = P(Y_1(t) &lt; \mathcal{D} \mid  \tau \geq t) = F_{rIG}(\mathcal{D}| \delta_1 t, \gamma).
    \end{aligned}
\end{equation}\]</span> 当 <span class="math inline">\(t &gt;\tau\)</span> 时, 给定<span class="math inline">\(\tau\)</span>的<span class="math inline">\(T\)</span>的可靠度函数可以表示为 <span class="math display">\[\begin{equation}\label{r2}
    \begin{aligned}
        \bar{F}_{2} (t \mid \tau)=&amp;P\left(Y(t)&lt;\mathcal{D} \mid \tau &lt; t \right)
        =P\left(Y_{1}(\tau)+Y_{2}(t-\tau)&lt;\mathcal{D} \mid \tau &lt; t \right) \\
        =&amp;\int_0^{\mathcal{D}} P\left(Y_{2}(t-\tau)&lt; \mathcal{D} - y_{\tau} \mid  \tau&lt; t\right)  f_1(y_{\tau}\mid\tau)\mathrm{d} y_{\tau} \\
        =&amp;  \int_0^{\mathcal{D}} F_{rIG}(\mathcal{D} - y_{\tau}|  \delta_2  (t - \tau), \gamma)  f_1(y_{\tau}\mid\tau) \mathrm{d} y_{\tau},
    \end{aligned}
\end{equation}\]</span> 其中<span class="math inline">\(y_{\tau}\)</span>表示变点时间<span class="math inline">\(\tau\)</span>处的退化值, <span class="math inline">\(f_1(y\_{\tau}\mid\tau)\)</span>是<span class="math inline">\(y_{\tau}\)</span>的PDF. 根据 rIG 过程的性质可知, <span class="math inline">\(f_1(y_{\tau}\mid\tau) = f_{rIG}(y_\tau \mid \delta_1 \tau, \gamma)\)</span>. 由式 <span class="math inline">\(\eqref{r1}\)</span> 和式 <span class="math inline">\(\eqref{r2}\)</span> 得到<span class="math inline">\(T\)</span>的无条件可靠度函数为 <span class="math display">\[\begin{equation}
    \begin{aligned}
        R\left(t \right)   &amp; =P\left(Y(t)&lt;\mathcal{D}, \tau \geq t\right)+P\left(Y(t)&lt;\mathcal{D}, 0&lt;\tau&lt;t\right) \\
        &amp; =\bar{F}_1\left(t  \mid  \tau \right) \bar{G}_{\tau}(t)+\int_0^t g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_2\left(t  \mid  \tau\right) \mathrm{d} \tau, \\
    \end{aligned}
\end{equation}\]</span> 其中<span class="math inline">\(\bar{G}_{\tau}(t)\)</span>是随机变量<span class="math inline">\(\tau\)</span>的生存函数.</p>
<p>接下来, 证明定理 <a href="#thm-EJOR2024-thy-2" class="quarto-xref"><span>4.4</span></a> 的结果. 设<span class="math inline">\(y_t\)</span>是时间<span class="math inline">\(t\)</span>处观测到的退化值. 在时间<span class="math inline">\(t\)</span>处系统<span class="math inline">\(S_{t}\)</span>的RUL定义为<span class="math inline">\(S_{t}=\inf \left\{x; Y\left(t+x\right) \geq \mathcal{D} \mid y_t &lt; \mathcal{D}\right\}\)</span>, 表示在条件<span class="math inline">\(y_t &lt; \mathcal{D}\)</span>下系统继续正常运行的最短时间. 为了计算系统在时间<span class="math inline">\(t+x\)</span>处正常运行的概率, 需计算系统剩余使用寿命的可靠性. 考虑到时间<span class="math inline">\(t\)</span>、<span class="math inline">\(t+x\)</span>和<span class="math inline">\(\tau\)</span>之间的不同关系, 首先根据<span class="math inline">\(\tau\)</span>的条件得到了三种不同的可靠度.</p>
<ol type="i">
<li>当 <span class="math inline">\(x+t  \leq \tau\)</span> 时, <span class="math inline">\(S_t\)</span>的条件可靠度函数为 <span class="math display">\[\begin{equation}\label{rul1}
    \begin{aligned}
        \bar{F}_{S_{t},1}(x \mid  \tau)&amp;=  P(Y(t + x) &lt; \mathcal{D} \mid  y_t &lt; \mathcal{D}, x+t  \leq \tau)   \\
        &amp; =  P(Y(t + x) - y_t &lt; \mathcal{D} - y_t  \mid  y_t &lt; \mathcal{D}, x+t  \leq \tau)  \\
        &amp; = F_{r\mathcal{IG}}(\mathcal{D} - y_t| \delta_1 x, \gamma).
    \end{aligned}
\end{equation}\]</span></li>
<li>当 <span class="math inline">\(t &lt; \tau&lt;x+t\)</span> 时, <span class="math inline">\(S_t\)</span>的条件可靠度函数为 <span class="math display">\[\begin{equation}\label{rul2}
    \begin{aligned}
   \bar{F}&amp;_{S_{t},2}(x  \mid  \tau)=  P(Y(t + x) &lt; \mathcal{D} \mid  y_t &lt; \mathcal{D}, t &lt; \tau&lt;x+t)   \\
   &amp; =  P(Y_{2}(t + x- \tau ) + Y_{1}(\tau) &lt; \mathcal{D}   \mid  y_t &lt; \mathcal{D}, t &lt; \tau&lt;x+t)  \\
   &amp; =  \int_0^{\mathcal{D}} F_{r\mathcal{IG}}(\mathcal{D} - y_\tau| \delta_2 (t+x-\tau), \gamma)   f_1(y_\tau\mid\tau) {\rm d} y_{\tau}.
    \end{aligned}
\end{equation}\]</span></li>
<li>当 <span class="math inline">\(\tau \leq t\)</span> 时, <span class="math inline">\(S_t\)</span>的条件可靠度函数为 <span class="math display">\[\begin{equation}\label{rul3}
    \bar{F}_{S_{t},3}(x  \mid  \tau)= F_{r\mathcal{IG}}(\mathcal{D} - y_t | \delta_2 x, \gamma).
\end{equation}\]</span></li>
</ol>
<p>基于式 <span class="math inline">\(\eqref{rul1}\)</span> - 式 <span class="math inline">\(\eqref{rul3}\)</span>, RUL的无条件可靠度函数是 <span class="math display">\[\begin{equation}
  \begin{aligned}
    R_{S_t}(x) =&amp; P(Y(t + x) &lt; \mathcal{D}, t &lt; x+t \leq \tau) \\
      &amp;+ P(Y(t + x) &lt; \mathcal{D}, t \leq \tau &lt; x+t)  + P(Y(t + x) &lt; \mathcal{D}, t &gt; \tau) \\
      =&amp; \bar{F}_{S_t,1}\left(x \mid  \tau \right) \bar{G}_{\tau}(x+t) + \int_{t}^{x+t} g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_{S_t,2}\left(x \mid  \tau\right) {\rm d} \tau \\
      &amp; + \int_{0}^{t} g_{\tau}(\tau) \bar{F}_{S_t,3}\left(x \mid  \tau\right) {\rm d}\tau.\\
\end{aligned}
\end{equation}\]</span></p>
</section>
<section id="附录b-em算法技术细节" class="level4" data-number="4.3.6.2">
<h4 data-number="4.3.6.2" class="anchored" data-anchor-id="附录b-em算法技术细节"><span class="header-section-number">4.3.6.2</span> 附录B: EM算法技术细节</h4>
<p>为了进一步解释EM算法的技术细节, 首先定义一组符号. 对数似然函数 <span class="math inline">\(\eqref{tp-com-log}\)</span> 可以根据 <span class="math inline">\(\tau_i\)</span> 分为两部分, 即 <span class="math display">\[l_i(\boldsymbol{\theta_\tau})=\boldsymbol{v}_i^{\top}(\tau_i) \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right) \quad \text{和} \quad l_{i, j}(\boldsymbol{\eta},\tau_i) = \sum_{k=1}^{3}\lambda^{(k)}_{i,j} \boldsymbol{v}_{i, j}^{(k) \top}(\tau_i) \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta}),\]</span> 其中 <span class="math display">\[
\begin{aligned}
    \boldsymbol{v}_i\left(\tau_i\right)=&amp;\left(1, \tau_i, \tau_i^2\right)^{\top}, v_{i, j}^{(1)}\left(\tau_i\right)=1,\\
    \boldsymbol{v}_{i, j}^{(2)}\left(\tau_i\right) =&amp;\left(1, \log(\Delta A_{i,j} + \Delta B_i \tau_i), \tau_i, \tau_i^2\right)^{\top}, \\
    v_{i, j}^{(3)}\left(\tau_i\right)=&amp;1, \\
    \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)=&amp;\left(-\log \sqrt{2 \pi} \sigma_\tau-\frac{\mu_\tau^2}{2 \sigma_\tau^2}, \frac{\mu_\tau}{\sigma_\tau^2}, -\frac{1}{2 \sigma_\tau^2}\right)^{\top}, \\
\end{aligned}
\]</span> <span class="math display">\[\begin{aligned}
         w_{i, j}^{(1)}(\boldsymbol{\eta})=&amp;-\log \sqrt{2 \pi} + \log \delta_{1,i} \Delta t_{i,j}  + \gamma \delta_{1,i} \Delta t_{i,j} - \frac{3}{2} \log \Delta y_{i,j} \\
         &amp;- \frac{{\left( \delta_{1,i} \Delta t_{i,j}\right) }^2}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},\\
         \boldsymbol{w}_{i, j}^{(2)}(\boldsymbol{\eta}) =&amp; \left(
        -\log \sqrt{2 \pi} -\frac{3}{2} \log \Delta y_{i,j} - \frac{\gamma^2 \Delta y_{i,j}}{2} \right. \nonumber \\
        &amp;\left. + \gamma \Delta A_{i,j} - \frac{\Delta A_{i,j}^2}{2 \Delta y_{i,j}}, 1, \Delta B_i \gamma - \frac{\Delta A_{i,j} \Delta B_i}{\Delta y_{i,j}}, - \frac{\Delta B_i^2}{2 \Delta y_{i,j}}
        \right)^{\top},\\
        w_{i, j}^{(3)}(\boldsymbol{\eta})=&amp;-\log \sqrt{2 \pi} + \log \delta_{2,i}  \Delta t_{i,j}  + \gamma \delta_{2,i}  \Delta t_{i,j} - \frac{3}{2} \log \Delta y_{i,j} \\
        &amp; - \frac{{\left[ \delta_{2,i}  \Delta t_{i,j}\right] }^2}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},
\end{aligned}
\]</span> <span class="math inline">\(\Delta A_{i,j} = \delta_{2,i}  t_{i,j} -  \delta_{1,i} t_{i,j-1}\)</span> 和 <span class="math inline">\(\Delta B_i  = \delta_{1,i} - \delta_{2,i}\)</span>.</p>
<section id="附录b-1-e步中条件期望的推导" class="level5" data-number="4.3.6.2.1">
<h5 data-number="4.3.6.2.1" class="anchored" data-anchor-id="附录b-1-e步中条件期望的推导"><span class="header-section-number">4.3.6.2.1</span> 附录B-1: E步中条件期望的推导</h5>
<p>在E步中, 需要计算关于 <span class="math inline">\(p(\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i)\)</span> 的期望. 为简化说明, 省略对参数<span class="math inline">\(\boldsymbol{\vartheta}\)</span>的依赖. 根据退化增量的独立性, <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}_i\)</span> 和 <span class="math inline">\(\tau_i\)</span> 的联合PDF为 <span class="math display">\[\begin{equation}\label{joint}
    \begin{aligned}
        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i, \tau_i }\left(\boldsymbol{\Delta y}_i, \tau_i  \right) &amp; =
        \prod_{j=1}^{n_i}  f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i\right) g_\tau\left(\tau_i \mid  \boldsymbol{\theta}_\tau\right). \\
    \end{aligned}
\end{equation}\]</span> 从式 <span class="math inline">\(\eqref{joint}\)</span> 中积分掉 <span class="math inline">\(\tau_i\)</span> 后, <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}_i\)</span> 的边际PDF为 <span class="math display">\[\begin{equation}\label{e_y1}
    \begin{aligned}
        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i  }\left(\boldsymbol{\Delta y}_i  \right)= &amp; \int_{-\infty}^{+\infty}     \prod_{j=1}^{n_i}  
        f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i. \\
        %       = &amp; \int_{-\infty}^{t_{i, 0}} L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_{\tau}\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i \\
        %       &amp; +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} M_{i, j}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_\tau\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i \\
        %       &amp; +\int_{t_{i, n_i}}^{+\infty} R_i\left(\boldsymbol{\Delta y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_\tau\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i,
    \end{aligned}
\end{equation}\]</span> 在计算条件PDF时, 需考虑变点 <span class="math inline">\(\tau_i\)</span>、时间点 <span class="math inline">\(t_{i,j}\)</span> 以及 <span class="math inline">\(t_{i,j-1}\)</span> 之间的三种关系, 因为会得到不同形式的<span class="math inline">\(\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\)</span>. 为简化表示, 根据三种情形分别引入了不同的条件PDF. 具体来说, 当 <span class="math inline">\(\tau_i &lt; t_{i, 0}\)</span> 时, <span class="math inline">\(\Delta y_{i,j}\)</span> 的条件PDF为: <span class="math display">\[\begin{equation}
  \begin{aligned}
    f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;  =  \frac{\Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)}{\sqrt{2 \pi}} \exp\left\lbrace{ \gamma \Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) }\right\rbrace  \Delta y_{i, j}^{-3 / 2} \\
   &amp; \times \exp\left\lbrace {-\frac{\left[\Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\right]^2 \Delta y_{i, j}^{-1}+\gamma^2 \Delta y_{i, j}}{2}}\right\rbrace,
\end{aligned}
\end{equation}\]</span> 将 <span class="math inline">\(\Delta y_{i,j}\)</span> 的条件PDF记为 <span class="math inline">\(f_{i, j \mid(3)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)\)</span>, 其中 <span class="math inline">\(\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(3)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\)</span>. 类似地, 对于 <span class="math inline">\(t_{i, j-1} \leqslant \tau_i&lt;t_{i, j}\)</span> 和 <span class="math inline">\(\tau_i \geqslant t_{i, n_i}\)</span> 的情况, <span class="math inline">\(\Delta y_{i,j}\)</span> 的条件PDF分别记为 <span class="math inline">\(f_{i, j \mid(2)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)\)</span> 和 <span class="math inline">\(f_{i, j \mid(1)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)\)</span>, 其中 <span class="math display">\[\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(2)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right), \text{以及} \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(1)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right).\]</span></p>
<p>接下来, 将式 <span class="math inline">\(\eqref{e_y1}\)</span> 中的 <span class="math inline">\(\prod_{j=1}^{n_i} f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)\)</span> 分解为以下三种情况:</p>
<ol type="1">
<li>当 <span class="math inline">\(\tau_i&lt;t_{i, 0}\)</span>, <span class="math display">\[\begin{equation}
        \begin{aligned}
            \prod_{j=1}^{n_i}  
            f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;=\prod_{j=1}^{n_i} f_{i, j \mid(3)}\left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right), \\
            &amp;  \triangleq  L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid   \boldsymbol{\eta}, \tau_i \right).
            %           \prod_{j=1}^{n_i} f_{i, j \mid(3)} \left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)
        \end{aligned}
\end{equation}\]</span></li>
<li>当 <span class="math inline">\(t_{i, j-1} \leqslant \tau_i&lt;t_{i, j}, ~j = 1, \dots, n_i\)</span>, <span class="math display">\[\begin{equation}
        \begin{aligned}
            \prod_{j=1}^{n_i}  
            f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  &amp;=\left\{\prod_{j^{\prime}=1}^{j-1} f_{i, j^{\prime} \mid(1)}\left(\Delta y_{i, j^{\prime}}  \mid  \delta_{1,i},\gamma, \tau_i\right)\right\} \\
            &amp; ~~~\times f_{i, j\mid(2)}\left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i} ,\gamma, \tau_i\right), \\
            &amp;~~~ \times\left\{\prod_{j^{\prime}=j+1}^{n_i} f_{i, j^{\prime} \mid(3)}\left(\Delta y_{i, j^{\prime}}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)\right\} \\
            &amp;  \triangleq  M_{ij}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i \right).
            %           \prod_{j=1}^{n_i} f_{i, j \mid(3)} \left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)
        \end{aligned}
\end{equation}\]</span></li>
<li>当 <span class="math inline">\(\tau_i \geqslant t_{i, n_i}\)</span>, <span class="math display">\[\begin{equation}
        \begin{aligned}
            \prod_{j=1}^{n_i}  
            f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;  =\prod_{j=1}^{n_i} f_{i, j \mid(1)}\left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right), \\
            &amp;  \triangleq  R_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i \right).
        \end{aligned}
\end{equation}\]</span></li>
</ol>
<p>因此, 式 <span class="math inline">\(\eqref{e_y1}\)</span> 中的 <span class="math inline">\(\boldsymbol{\Delta} \boldsymbol{Y}_i\)</span> 的边际PDF可以重写为: <span class="math display">\[\begin{equation}\label{e_y2}
    \begin{aligned}
        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i } &amp;\left(\boldsymbol{\Delta y}_i  \right)=  \int_{-\infty}^{+\infty}     \prod_{j=1}^{n_i}  
        f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i \\
        = &amp; \int_{-\infty}^{t_{i, 0}} L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_{\tau}\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i
        +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} M_{i, j}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i \\
        &amp; +\int_{t_{i, n_i}}^{+\infty} R_i\left(\boldsymbol{\Delta y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i,
    \end{aligned}
\end{equation}\]</span> 根据贝叶斯定理, 可以计算条件PDF <span class="math inline">\(p(\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i)\)</span> 为: <span class="math display">\[\begin{equation}\label{con-1}
    \begin{aligned}
        p(\tau_i \mid  \boldsymbol{\Delta} \boldsymbol{y}_i) &amp;= \frac{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i, \tau_i }\left(\boldsymbol{\Delta} \boldsymbol{y}_i, \tau_i  \right)}{f_{\boldsymbol{\Delta}  \boldsymbol{Y}_i }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \right)}.
    \end{aligned}
\end{equation}\]</span> 然后, 可以推导出条件期望 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[\boldsymbol{v}_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right]\)</span> 和 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right]\)</span>. 对于 <span class="math inline">\(\boldsymbol{v}_i\)</span> 的条件期望, <span class="math inline">\(i=1, \ldots, I\)</span>, 可表示为: <span class="math display">\[\begin{equation}\label{e_v}
    \begin{aligned}
         \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}} &amp;\left\{\boldsymbol{v}_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}=  \frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \right)}\left(\int_{-\infty}^{t_{i, 0}} \boldsymbol{v}_i(\tau_i) L_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right. \\
        &amp; +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} \boldsymbol{v}_i(\tau_i) M_{i, j}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i \\
        &amp; \left.+\int_{t_{i, n_i}}^{\infty} \boldsymbol{v}_i(\tau_i) R_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right) .
    \end{aligned}
\end{equation}\]</span> <span class="math inline">\(\lambda_{i, j}^{(k)} v_{i, j}^{(k)}\)</span> 的条件期望, 其中 <span class="math inline">\(i=1, \ldots, I\)</span>, <span class="math inline">\(j=1, \ldots, n_i\)</span>, <span class="math inline">\(k=1,2,3\)</span>, 如下所示: 当 <span class="math inline">\(k=1\)</span>时: <span class="math display">\[\begin{equation}\label{e_k1}
    \begin{aligned}
        &amp; \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(1)} v_{i, j}^{(1)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\} \\
        &amp; = \frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)} \left(\sum_{j^{\prime}=j+1}^{n_i} \int_{t_{i, j^{\prime}-1}}^{t_{i, j^{\prime}}} v_{i, j^{\prime}}^{(1)}(\tau_i) M_{i, j^{\prime}}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right. \\
        &amp; \left.\quad+\int_{t_{i, n_i}}^{\infty} v_{i, j}^{(1)}(\tau_i) R_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i \mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right),
    \end{aligned}
\end{equation}\]</span> 当 <span class="math inline">\(k=2\)</span>时: <span class="math display">\[\begin{equation}\label{e_k2}
    \begin{aligned}
        &amp;\boldsymbol{ \mathbb{E}}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(2)} \boldsymbol{v}_{i, j}^{(2)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}\\
        &amp;=\frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i  }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)}  \left(\int_{t_{i, j-1}}^{t_{i, j}} \boldsymbol{v}_{i, j}^{(2)}(\tau_i) M_{i, j}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i\right),
    \end{aligned}
\end{equation}\]</span> 当 <span class="math inline">\(k=3\)</span>时: <span class="math display">\[\begin{equation}\label{e_k3}
    \begin{aligned}
        &amp; \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(3)} v_{i, j}^{(3)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}\\ &amp;=\frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)}\left(\int_{-\infty}^{t_{i, 0}} v_{i, j}^{(3)}(\tau_i) L_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i \mid \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i\right. \\
        &amp; \left.\quad+\sum_{j^{\prime}=1}^{j-1} \int_{t_{i, j^{\prime}-1}}^{t_{i, j^{\prime}}} v_{i, j^{\prime}}^{(3)}(\tau_i) M_{i, j^{\prime}}\left(\boldsymbol{\Delta} \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)},\tau_i\right) g_\tau\left(\tau_i\mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right).
    \end{aligned}
\end{equation}\]</span> 因此, E 步中的 Q 函数为: <span class="math display">\[\begin{equation}\label{e-step2}
    \begin{aligned}
        \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})
        =&amp; \sum_{i=1}^I  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\boldsymbol{v}_i \mid \boldsymbol{\Delta} y\right\}^{\top}  \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)\\
        &amp; +  \sum_{i=1}^I \sum_{j=1}^{n_i} \sum_{k=1}^3  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right\}^{\top}  \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta}).
    \end{aligned}
\end{equation}\]</span></p>
</section>
<section id="附录b-2-m步中关于boldsymbolvartheta的一阶偏导数" class="level5" data-number="4.3.6.2.2">
<h5 data-number="4.3.6.2.2" class="anchored" data-anchor-id="附录b-2-m步中关于boldsymbolvartheta的一阶偏导数"><span class="header-section-number">4.3.6.2.2</span> 附录B-2: M步中关于<span class="math inline">\(\boldsymbol{\vartheta}\)</span>的一阶偏导数</h5>
<p>对式 <span class="math inline">\(\eqref{e-step2}\)</span> 中的 Q 函数关于 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 求一阶偏导数, 并将导数设为零, 从而得到 <span class="math inline">\(\boldsymbol{\vartheta}_{(s+1)}\)</span> 的估计. <span class="math display">\[\begin{equation}\label{derivation}
    \begin{aligned}
        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial \boldsymbol{\theta}_\tau}= &amp; \sum_{i=1}^I \left[\frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}\right]^{\top}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\boldsymbol{v}_i \mid \boldsymbol{\Delta} y\right\} = \boldsymbol{0},\\
        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top }= &amp;  \sum_{j=1}^{n_i} \sum_{k=1}^3  \left[\frac{\partial \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top }\right]^{\top}
         \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right\} = \boldsymbol{0}, ~ i = 1,\dots,I, \\
        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial \gamma}= &amp; \sum_{i=1}^{I}  \sum_{j=1}^{n_i} \sum_{k=1}^3 \left[ \frac{\partial \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta})}{\partial \gamma  }\right]^{\top}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right\} = 0,
    \end{aligned}
\end{equation}\]</span> 其中 <span class="math display">\[\begin{equation*}
    \begin{aligned}
        \frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}  &amp; =
        \left(\begin{array}{ccc}-\frac{\mu_\tau}{\sigma_\tau^2}, &amp; -\frac{1}{2 \sigma_\tau^2}+\frac{\mu_\tau^2}{2 \sigma_\tau^4}\\
            \frac{1}{\sigma_\tau^2}, &amp; \frac{-\mu_\tau}{\sigma^4_\tau}\\ 0, &amp; \frac{1}{2 \sigma_\tau^4} \end{array}\right),\\
        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right)}^\top } &amp; = \left(\begin{array}{ccc} \left( \frac{1}{\delta_{1,i}}+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{1,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}},&amp; 0\end{array}\right),\\
                \frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}  &amp; =
        \left(\begin{array}{ccc}-\frac{\mu_\tau}{\sigma_\tau^2}, &amp; -\frac{1}{2 \sigma_\tau^2}+\frac{\mu_\tau^2}{2 \sigma_\tau^4}\\
            \frac{1}{\sigma_\tau^2}, &amp; \frac{-\mu_\tau}{\sigma^4_\tau}\\ 0, &amp; \frac{1}{2 \sigma_\tau^4} \end{array}\right),\\
        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right)}^\top } &amp; = \left(\begin{array}{ccc} \left( \frac{1}{\delta_{1,i}}+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{1,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}},&amp; 0\end{array}\right),\\
    \end{aligned}
\end{equation*}\]</span> <span class="math display">\[\begin{equation*}
    \begin{aligned}
        \frac{\partial \boldsymbol{w}_{i,j}^{(2)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top  } &amp; =
        \left(
        \begin{array}{ccc} -\gamma t_{i,j-1} + \frac{\Delta A_{i,j} t_{i,j-1}}{\Delta y_{i,j}},&amp; \gamma t_{i,j} -\frac{\Delta A_{i,j} t_{i,j}}{\Delta y_{i,j}}\\
            0, &amp;0\\
            \gamma+\frac{\Delta  B_i t_{i,j-1} - \Delta A_{i,j}}{\Delta y_{i,j}}, &amp;     - \gamma+\frac{\Delta A_{i,j}- \Delta B_i t_{i,j}}{\Delta y_{i,j}}\\
            \frac{\delta_{2,i} -\delta_{1,i} }{\Delta y_{i,j}}, &amp;  \frac{\delta_{1,i} -\delta_{2,i} }{\Delta y_{i,j}}
        \end{array}\right),\\
        \frac{\partial {w}_{i, j}^{(3)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right) }^\top } &amp; = \left(\begin{array}{ccc}
            0, &amp; \left( \frac{1}{\delta_{2,i} }+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{2,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}}
        \end{array}\right), \\
        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial \gamma} &amp; =  \delta_{1,i}  \Delta t_{i,j}-\gamma \Delta y_{i,j},\\
    \end{aligned}
\end{equation*}\]</span></p>
<span class="math display">\[\begin{equation*}
    \begin{aligned}
        \frac{\partial \boldsymbol{w}_{i,j}^{(2)}(\boldsymbol{\eta})}{\partial \gamma } &amp; =
        {\left(
            \begin{array}{ccc} -\gamma \Delta y_{i,j}+\Delta A_{i,j},~0,~\Delta B_i,~0\\
            \end{array}\right)}^\top,\\
        \frac{\partial {w}_{i, j}^{(3)}(\boldsymbol{\eta})}{\partial \gamma } &amp;= \delta_{2,i}  \Delta t_{i,j} - \gamma \Delta y_{i,j}.
    \end{aligned}
\end{equation*}\]</span>
</section>
<section id="附录b-3-em-算法的步骤" class="level5" data-number="4.3.6.2.3">
<h5 data-number="4.3.6.2.3" class="anchored" data-anchor-id="附录b-3-em-算法的步骤"><span class="header-section-number">4.3.6.2.3</span> 附录B-3: EM 算法的步骤</h5>
<p>EM 算法可以通过以下步骤实现:</p>
<ul>
<li><p><strong>步骤 1</strong>. 设定参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span>的初始值 <span class="math inline">\(\boldsymbol{\vartheta}_{(\mathbf{0})}\)</span>, 并设置容差误差 <span class="math inline">\(\epsilon\)</span>.</p></li>
<li><p><strong>步骤 2</strong>. 基于第 <span class="math inline">\(s\)</span> 次迭代的解 <span class="math inline">\(\boldsymbol{\vartheta}_{(s)}\)</span>, 计算 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{y}\right]\)</span> 和 <span class="math inline">\(\mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[ l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{y}\right]\)</span>.</p></li>
<li><p><strong>步骤 3</strong>. 根据式 <span class="math inline">\(\eqref{tp-arg}\)</span> 计算第 <span class="math inline">\((s+1)\)</span> 次迭代的解 <span class="math inline">\(\boldsymbol{\vartheta}_{(s+1)}\)</span>.</p></li>
<li><p><strong>步骤 4</strong>. 重复步骤 2 和步骤 3, 直到 <span class="math inline">\(\left | \boldsymbol{\vartheta}_{(s+1)}-\boldsymbol{\vartheta}_{(s)}\right | &lt;\epsilon\)</span>, 其中 <span class="math inline">\(|\cdot|\)</span> 是 <span class="math inline">\(L_1\)</span> 距离.</p></li>
<li><p><strong>步骤 5</strong>. 参数 <span class="math inline">\(\boldsymbol{\vartheta}\)</span> 的MLE可以通过 <span class="math inline">\(\hat{\boldsymbol{\vartheta}}=\boldsymbol{\vartheta}_{(s+1)}\)</span> 获得.</p></li>
</ul>
</section>
</section>
<section id="附录c-贝叶斯分析技术细节" class="level4" data-number="4.3.6.3">
<h4 data-number="4.3.6.3" class="anchored" data-anchor-id="附录c-贝叶斯分析技术细节"><span class="header-section-number">4.3.6.3</span> 附录C: 贝叶斯分析技术细节</h4>
<p>每个参数的满条件后验分布计算如下</p>
<ul>
<li><p>给定 <span class="math inline">\(\boldsymbol{\theta}_{\backslash\left(\mu_\tau, \sigma_\tau^2\right)}\)</span> 和 <span class="math inline">\(\boldsymbol{\Delta Y}\)</span>, <span class="math inline">\(\left(\mu_\tau, \sigma_\tau^2\right)\)</span> 的满条件后验分布是 <span class="math display">\[
  \begin{aligned}
      &amp; \left(\mu_\tau, \sigma_\tau^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_\tau, \sigma_\tau^2\right)}, \boldsymbol{\Delta Y} \sim NIG a\left(\beta_\tau^{\prime}, \eta_\tau^{\prime}, v_\tau^{\prime}, \xi_\tau^{\prime}\right),
  \end{aligned}
  \]</span> 其中 <span class="math inline">\(\beta_\tau^{\prime}=\beta_\tau+I, \eta_\tau^{\prime}=\left(\beta_\tau \eta_\tau+\sum_{i=1}^I \tau_i\right) /\left(\beta_\tau+I\right), v_\tau^{\prime}=I / 2+v_\tau\)</span>, 和 <span class="math inline">\(\xi_\tau^{\prime}=\xi_\tau+\beta_\tau \eta_\tau^2 / 2+\sum_{i=1}^I \tau_i^2 / 2-\left(\beta_\tau \eta_\tau+\sum_{i=1}^I \tau_i\right)^2 /\left(2\left(\beta_\tau+I\right)\right).\)</span></p></li>
<li><p>给定 <span class="math inline">\(\boldsymbol{\theta}_{\backslash\left(\mu_1, \sigma_1^2\right)}\)</span> 和 <span class="math inline">\(\boldsymbol{\Delta Y}\)</span>, <span class="math inline">\(\left(\mu_1, \sigma_1^2\right)\)</span> 的满条件后验分布是 <span class="math display">\[
  \begin{aligned}
      &amp; \left(\mu_1, \sigma_1^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_1, \sigma_1^2\right)}, \boldsymbol{\Delta Y} \sim NIGa\left(\beta_1^{\prime}, \eta_1^{\prime}, v_1^{\prime}, \xi_1^{\prime}\right),
  \end{aligned}
  \]</span> 其中<span class="math inline">\(\beta_1^{\prime}=\beta_1+I, \quad \eta_1^{\prime}=\left(\beta_1 \eta_1+\sum_{i=1}^I \delta_i^1\right) /\left(\beta_1+I\right)\)</span>, <span class="math inline">\(v_1^{\prime}=I / 2+v_1\)</span> 和 <span class="math inline">\(\xi_1^{\prime}=\xi_1+\beta_1 \eta_1^2 / 2+\sum_{i=1}^I \delta_{1,i}^{2} / 2- \left(\beta_1 \eta_1+\sum_{i=1}^I \delta_i^1\right)^2 /\left(2\left(\beta_1+I\right)\right)\)</span>.</p></li>
<li><p>给定 <span class="math inline">\(\boldsymbol{\theta}_{\backslash\left(\mu_2, \sigma_2^2\right)}\)</span> 和 <span class="math inline">\(\boldsymbol{\Delta Y}\)</span>, <span class="math inline">\(\left(\mu_2, \sigma_2^2\right)\)</span> 的满条件后验分布是 <span class="math display">\[\begin{aligned}
&amp; \left(\mu_2, \sigma_2^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_2, \sigma_2^2\right)}, \boldsymbol{\Delta Y} \sim NIGa\left(\beta_2^{\prime}, \eta_2^{\prime}, v_2^{\prime}, \xi_2^{\prime}\right),
  \end{aligned}\]</span> 其中 <span class="math inline">\(\beta_2^{\prime}=\beta_2+I\)</span>, <span class="math inline">\(\eta_2^{\prime}=\left(\beta_2 \eta_2+\sum_{i=1}^I \delta_{2,i} \right) /\left(\beta_2+I\right)\)</span>, <span class="math inline">\(v_2^{\prime}=I / 2+v_2\)</span> 和 <span class="math inline">\(\xi_2^{\prime}=\xi_2+\beta_2 \eta_2^2 / 2+\sum_{i=1}^I \delta_{2,i}^{2} / 2- \left(\beta_2 \eta_2+\sum_{i=1}^I \delta_{2,i} \right)^2 /\left(2\left(\beta_2+I\right)\right)\)</span>.</p></li>
<li><p>给定 <span class="math inline">\(\boldsymbol{\theta}_{\backslash\gamma}\)</span> 和 <span class="math inline">\(\boldsymbol{\Delta Y}\)</span>, <span class="math inline">\(\gamma\)</span> 的满条件后验分布是 <span class="math display">\[\gamma \mid \boldsymbol{\theta}_{\backslash \gamma}, \boldsymbol{\Delta Y} \sim
  N\left(\omega^\prime, \kappa^\prime \right).\]</span> 其中 <span class="math inline">\(\omega^\prime = \left( \omega + \kappa N \right) / \left(1 + \kappa N\right), \kappa^\prime = \kappa^2 / \left( 1 + \kappa^2 N\right)\)</span>和 <span class="math inline">\(N = \sum_{i=1}^{I}\sum_{j=1}^{n_i} \Delta y_{i,j}\)</span>.</p></li>
<li><p><span class="math inline">\(\delta_{1,i}, i=1, \ldots, I\)</span>的满条件后验分布为: <span class="math display">\[\begin{aligned}
      \pi &amp;\left( \delta_{1,i} \mid \boldsymbol{\theta}_{\backslash \delta_{1,i}}, \boldsymbol{\Delta Y} \right)  \propto \\
      &amp;   \exp \left\lbrace  \frac{ 2 \mu_1 \delta_{1,i} - \delta_{1,i}^2}{ 2 \sigma_1^2 } + \gamma     \sum_{j=1}^{n_i} \Delta \mathcal{M}_{1,i,j} -
      \sum_{i=1}^{I}\sum_{j=1}^{n_i}  \frac{  \Delta\mathcal{M}_{1,i,j}^2 }{2 \Delta y_{i,j}} \right\rbrace  \prod_{j=1}^{n_i} \Delta \mathcal{M}_{1,i,j},
  \end{aligned}\]</span> 其中<span class="math inline">\(\Delta \mathcal{M}_{1,i,j} = \delta_{1,i} t_{i,j}\lambda^{(1)}_{i,j} + \left[\left( \delta_{1,i} -  \delta_{2,i}  \right) \tau_i + \delta_{2,i}   t_{i,j+1}  - \delta_{1,i} t_{i,j} \right] \lambda^{(2)}_{i,j}\)</span>.</p></li>
<li><p><span class="math inline">\(\delta_{2,i}, i=1, \ldots, I\)</span> 的满条件后验分布为: <span class="math display">\[\begin{aligned}
          \pi &amp;\left(\delta_{2,i}  \mid \boldsymbol{\theta}_{\backslash \delta_{2,i} }, \boldsymbol{\Delta Y} \right)  \propto \\
          &amp; \exp \left\lbrace    \frac{2 \mu_2 \delta_{2,i}   -   \delta^2_{2,i} }{ 2 \sigma_2^2 } + \gamma      \sum_{j=1}^{n_i} \Delta \mathcal{M}_{2,i,j} -
          \sum_{i=1}^{I}  \sum_{j=1}^{n_i}    \frac{  {\Delta \mathcal{M}^2_{2,i,j}} }{2 \Delta y_{i,j}} \right\rbrace \prod_{j=1}^{n_i} \Delta \mathcal{M}_{2,i,j},
      \end{aligned}\]</span> 其中 <span class="math inline">\(\Delta \mathcal{M}_{2,i,j} =\left[\left(\delta_{1,i} - \delta_{2,i}  \right) \tau_i +\delta_{2,i} t_{i,j+1}  -\delta_{1,i}  t_{i,j} \right] \lambda^{(2)}_{i,j} + \delta_{2,i}  t_{i,j}\lambda^{(3)}_{i,j}\)</span>.</p></li>
<li><p>对于 <span class="math inline">\(\tau_i, i=1, \ldots, I\)</span>, 满条件后验分布如下: <span class="math display">\[ \begin{aligned}
          \pi  &amp; \left( \tau_i \mid \boldsymbol{\theta}_{\backslash \tau_i}, \boldsymbol{\Delta Y} \right)  \propto \\
          &amp;   \exp \left\lbrace \frac{ 2 \mu_\tau \tau_i - \tau_i^2}{ 2 \sigma_\tau^2 } + \gamma   \sum_{j=1}^{n_i} \Delta \mathcal{M}_{3,i,j} -
          \sum_{i=1}^{I}\sum_{j=1}^{n_i}  \frac{ \Delta \mathcal{M}_{3,i,j}^2 }{2 \Delta y_{i,j}} \right\rbrace   \prod_{j=1}^{n_i} \Delta \mathcal{M}_{3,i,j},
      \end{aligned}\]</span> 其中<span class="math inline">\(\Delta \mathcal{M}_{3,i,j} =  \left[\left(\delta_{1,i} - \delta_{2,i}  \right) \tau_i +\delta_{2,i}  t_{i,j+1}  -\delta_{1,i}  t_{i,j} \right] \lambda^{(2)}_{i,j}\)</span>.</p></li>
</ul>
</section>
<section id="附录d-案例研究附加结果" class="level4" data-number="4.3.6.4">
<h4 data-number="4.3.6.4" class="anchored" data-anchor-id="附录d-案例研究附加结果"><span class="header-section-number">4.3.6.4</span> 附录D: 案例研究附加结果</h4>
<p>对于贝叶斯方法, 通过轨迹图和遍历均值图来监控ARMS-Gibbs算法的收敛性, 见图 <a href="#fig-tp-fig:trace" class="quarto-xref"><span>4.15</span></a> 和图 <a href="#fig-tp-fig:erg_mean" class="quarto-xref"><span>4.16</span></a> . 通过这些图可以确认马尔科夫链已经收敛. 图 <a href="#fig-tp-fig:em" class="quarto-xref"><span>4.17</span></a> 则展示了基于EM算法的模型参数估计迭代过程. 从图中可以看出, 经过100次迭代后, 参数估计值已经收敛到一个相对稳定的状态.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-fig:trace" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-fig:trace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/trace_plot.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-fig:trace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.15: 模型参数后验样本轨迹图.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-fig:erg_mean" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-fig:erg_mean-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/erg_mean.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-fig:erg_mean-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.16: 模型参数后验样本遍历平均图.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tp-fig:em" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tp-fig:em-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/EJOR2024/EM-iter.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tp-fig:em-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.17: EM算法中各参数迭代过程.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="sec-Online-IG" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-Online-IG"><span class="header-section-number">4.4</span> 在线估计与RUL预测</h2>
<!-- 快速且可靠的RUL预测在工业资产的预测与健康管理中起着至关重要的作用. 随着数据采集技术的进步, 基于退化数据的RUL预测在过去十年中引起了广泛关注. 在文献中, 大多数研究集中于使用Wiener过程作为基础退化模型的RUL预测. 另一方面, 当退化路径是单调时, IG过程已被证明是Wiener过程的一个流行替代方案. 尽管IG过程在退化建模中具有重要性, 但基于IG过程的RUL预测研究仍然较为匮乏. 因此, 本研究的主要目的是对基于IG过程的RUL预测进行系统分析. 我们首先提出了一系列新的在线估计算法, 以便在每次获得新的退化测量数据时高效地更新模型参数. 随后推导出RUL的分布, 并且该分布也可以递归更新. 鉴于不同系统之间可能存在的异质性, 我们进一步将提出的在线算法扩展到IG随机效应模型. 数值研究和渐近分析表明, 所提出的算法能够高效且可靠地估计参数和RUL. 最后, 我们使用了两个实际退化数据集进行说明.-->
<!-- 关键词: 退化; IG过程; 一步估计器; 随机效应.-->
<!-- RUL 是指一个组件或系统在其预定用途下能够正常运行的剩余时间, 直到需要维修或更换. RUL在工业系统的预测与健康管理中起着关键作用, 它是维护活动规划、备件准备、缺陷识别以及运行效率优化的关键因素之一. 由于RUL预测对运营成本具有巨大的影响, 它在诸如导航系统[@si2013degradation]、电池工业[@hu2020joint]、航空应用[@lorton2013methodology]和高分子材料[@peng2019transformed]等多个领域得到了广泛关注. 传统的RUL估计方法基于寿命数据, RUL也被称为平均剩余寿命[@mercier2019stochastic; @liu2020steady; @xu2024ob]. 然而, 由于现代系统和产品的高可靠性, 失效时间数据通常难以获取, 甚至几乎不可能. 另一方面, 退化是另一个重要的可靠性信息来源, 失效通常被定义为退化水平首次达到预设阈值的时间. 在过去的几十年中, 基于退化数据的RUL预测引起了广泛的兴趣.  -->
<!-- 为了进行基于退化的RUL预测, 一个重要的任务是为退化数据开发适当的模型. 在文献中, Wiener过程、伽马过程\index{伽马过程}和IG过程是退化数据的三种常见随机模型, 因为它们具有良好的数学性质和明确的物理解释. Wiener过程适用于非单调的退化数据, 如LED光强度, 而伽马过程\index{伽马过程}和IG过程则更适用于需要单调性的情形. 在文献中, 有大量研究集中在基于这三种随机退化过程对参数和可靠性特征进行统计推断, 例如[@peng2015inverse; @hong2018interval; @hu2020joint; @chen2018uncertainty; @hong2020nonparametric; @hajiha2021degradation; @zhai2023multivariate]. 在RUL预测方面, 基于Wiener过程的研究引起了显著关注, 这主要是因为其数学性质和与传统统计方法的兼容性, 使得处理和分析变得更为简单; 相关示例可见[@si2013degradation; @zhai2017rul; @wang2019improved; @hu2020joint], 以及综述论文[@zhang2018degradation]中的参考文献. 另一方面, 尽管在过去十年中许多研究验证了伽马过程\index{伽马过程}和IG过程在退化建模中的重要性和实用性, 但它们在RUL预测中的关注度相对较低[@ye2014inverse; @chen2019pairwise; @fang2022inverse; @tung2023optimizing].  -->
<!-- 本研究的重点是基于IG过程的RUL预测. 目前关于IG过程的大多数研究假设所有退化数据均可获得 (例如, 通过退化试验获取) , 并且主要关注如何估计一些与总体相关的可靠性特征, 如寿命分布和寿命分位数[@wang2010inverse; @ye2014inverse; @peng2015inverse; @chen2018uncertainty]. 然而, 在实际操作中, 退化数据通常只可获得至当前时刻, 因此在每次数据到达时需要进行RUL预测, 以便为后续的预测与健康管理提供支持. [@pan2016remaining]的研究是一个出色的例外, 该研究讨论了基于IG过程的RUL预测. 在该文中, 研究考虑了一个平稳的IG过程, 假设平均退化水平是时间的线性函数. 此外, 通过假设IG过程中的一个参数是特定于个体并在不同个体之间变化, 考虑了单元之间的异质性. 在模型设置的基础上, 推导了在获得新的退化测量时RUL的概率分布, 并使用期望最大化 EM 算法估计未知参数. -->
<!-- @pan2016remaining 的开创性工作提出了一种可行的方法, 并突显了基于IG过程进行RUL预测的重要性. 然而, 其模型设置和估计方法存在一些局限性. 首先, 平稳性假设并非总是成立. 在大多数应用中, 退化是非平稳的, 并且退化水平随时间呈现非线性趋势. 如果退化数据被错误地建模为平稳的IG过程, 所预测的RUL可能会不准确, 从而误导操作人员. 其次, RUL预测仅基于一个系统的退化数据. 然而, 在实践中, 通常是同时监测多个系统, 其他系统的退化数据也包含了对目标系统RUL有价值的信息. 实际上, 如果只考虑一个系统, 随机效应模型的动机并不充分. 最后, 在估计RUL分布函数中的未知参数时, 所有历史退化数据都需要作为EM算法的输入. 这种非递归的过程在历史退化测量数据量巨大的情况下计算负担沉重, 而快速RUL预测在许多决策过程中至关重要.  -->
<!-- 本研究旨在通过关注IG过程, 尤其是结合非线性和随机效应, 填补上述RUL预测中的空白. 首先, 我们考虑基于时间尺度变换$\Lambda(t)$的非平稳IG过程的在线RUL预测, 这是退化建模中广泛采用的技术 [@hu2020predictive; @zhou2021generalized; @wang2021degradation]. $\Lambda(t)$的一些常见参数化形式包括幂变换, 即$\Lambda_\beta(t) = t^\beta$, 以及指数变换, 即$\Lambda_\beta(t) = 1-e^{-\beta t}$. 引入附加参数$\beta$使得RUL的在线预测更加复杂. 此外, 未知参数的离线估计和在线更新是基于来自多个具有异质性的系统的历史退化数据, 这使得估计变得更具挑战性. 这些挑战将在本研究中通过对$\beta$和其他参数的迭代估计来解决.  -->
<!-- 另一方面, 文献中常通过一些滤波技术来缓解计算需求, 从而使参数估计可以随着新观测数据的到来进行序贯更新. 例如, Wiener过程通常结合不同变体的粒子滤波器, 也称为序贯蒙特卡罗方法, 以实现在线RUL预测 [@si2013wiener; @zhai2017rul; @hu2020joint]. 因此, 将粒子滤波器引入IG过程以进行在线RUL预测可能是一个自然的想法. 然而, 众所周知, 粒子滤波器存在退化问题, 即粒子权重逐渐被少数粒子主导, 这显然会影响后验分布的近似精度. 尽管基于重采样的补救措施被提出以应对权重退化问题, 但其采样效率无法得到保证, 且可能会出现样本退化问题 [@givens2012computational]. 在本研究中, 我们提出了一种新的在线算法, 当获得新的退化测量数据时, 该算法能够高效地更新估计值. 其基本思想是为$\beta$的估计值开发一步近似方法, 并在此基础上构建其他未知参数的闭式递归公式. 我们将建立递归估计量的渐近性质. RUL的分布进一步被推导为未知参数的函数, 并且可以通过序贯方式高效地进行估计.  -->
<!-- 本文余下部分的安排如下: 第 @sec-igintro 节介绍非平稳IG过程及问题设定. 第 @sec-igsimple 节开发了用于估计参数和RUL的在线算法, 并建立了渐近性质. 第 @sec-igre 节进一步将算法扩展至IG随机效应模型. 第 @sec-simulation 节通过模拟验证所提出的在线算法的性能. 第 @sec-case 节通过两个实际应用来说明所提方法.  -->
<p>现有大多关于IG过程的研究主要集中于离线退化数据分析, 侧重于评估分位寿命、 平均寿命和可靠度等总体特征<span class="citation" data-cites="wang2010inverse ye2014inverse peng2015inverse chen2018uncertainty">(<a href="references.html#ref-chen2018uncertainty" role="doc-biblioref">Chen 等, 2018</a>; <a href="references.html#ref-peng2015inverse" role="doc-biblioref">Peng, 2015</a>; <a href="references.html#ref-wang2010inverse" role="doc-biblioref">Wang 等, 2010</a>; <a href="references.html#ref-ye2014inverse" role="doc-biblioref">Ye 等, 2014</a>)</span>. 然而, 随着实际应用中实时获取的退化数据日益增多, 对RUL预测的动态更新需求日益迫切. 在此背景下, <span class="citation" data-cites="pan2016remaining">Pan 等 (<a href="references.html#ref-pan2016remaining" role="doc-biblioref">2016</a>)</span> 基于 IG 过程探讨了 RUL 预测问题. 然而, 其模型假设和估计方法存在以下局限性:</p>
<ul>
<li><p>平稳性假设: 在大多数应用中, 性能退化通常呈现非线性趋势, 平稳性假设可能导致RUL预测结果产生较大偏差.</p></li>
<li><p>单一系统数据: 当前方法仅基于单个系统的退化数据进行 RUL 预测, 而实际中往往需同时监测多个系统, 其他系统的退化数据同样蕴含对目标系统 RUL 有价值的信息. 合理利用这些信息有助于提升预测精度.</p></li>
<li><p>计算负担: 在估计 RUL 分布函数中未知参数时, 当前方法要求将所有历史退化数据作为 EM 算法的输入. 这种非递归估计方法在处理海量数据时会显著增加计算负担, 从而难以满足决策过程中对快速 RUL 预测的需求.</p></li>
</ul>
<p>为克服上述局限性, 实现对实时退化数据的动态处理和 RUL 的快速预测, 本节介绍一种适用于非平稳IG过程的在线RUL预测方法. 本节结构如下: 第 <a href="#sec-igintro" class="quarto-xref"><span> 4.4.1</span></a> 节介绍模型设定及相关问题; 第 <a href="#sec-igsimple" class="quarto-xref"><span> 4.4.2</span></a> 节提出参数估计与RUL预测的在线算法; 第 <a href="#sec-igre" class="quarto-xref"><span> 4.4.3</span></a> 节将方法扩展至随机效应模型; 第 <a href="#sec-simulation" class="quarto-xref"><span> 4.4.4</span></a> 节通过模拟验证方法性能; 第 <a href="#sec-case" class="quarto-xref"><span> 4.4.5</span></a> 节展示实际应用.</p>
<!--@pan2016remaining 采用平稳IG过程进行RUL预测, 
假设性能退化\index{性能退化}随时间线性变化, 并通过引入个体随机效应\index{随机效应}处理系统间异质性. 这项工作虽然奠定了基础, 但在模型假设和估计方法上存在局限: i). 平稳性假设不适用于许多非线性退化情形;  ii). 单一系统数据的建模忽略了多系统间的共性特征, 这些特征能用来提供参数估计的效率;  iii). 需输入全部历史数据的EM算法\index{EM算法}计算效率较低. -->
<section id="sec-igintro" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="sec-igintro"><span class="header-section-number">4.4.1</span> 模型设定</h3>
<p>假设系统的性能退化指标<span class="math inline">\(Y(t) \sim \textrm{\textrm{IG}}(\Lambda_\beta(t)/\nu , \lambda \Lambda^2_\beta(t))\)</span>, 其中<span class="math inline">\(\Lambda_\beta(t)\)</span>是时间<span class="math inline">\(t\)</span>的单调递增函数, 且满足<span class="math inline">\(\Lambda_\beta(0) = 0\)</span>, <span class="math inline">\(\beta\)</span>为待估未知参数. 则退化增量<span class="math inline">\(\Delta Y_{ts} = Y(t) - Y(s)\)</span>服从逆高斯分布<span class="math inline">\(IG(\Delta \Lambda_{ts}/\nu, \lambda \Delta \Lambda_{ts}^2)\)</span>, 其中<span class="math inline">\(\Delta \Lambda_{ts} = \Lambda_\beta(t) - \Lambda_\beta(s)\)</span>. 假设当前有 <span class="math inline">\(n\)</span> 个系统, 在时间点 <span class="math inline">\(0 = t_0 &lt; t_1 &lt; t_2 &lt; \cdots &lt; t_m &lt; \cdots\)</span>, 对所有系统的性能退化值进行测量. 令 <span class="math inline">\(y_{i,j}\)</span> 表示第 <span class="math inline">\(i\)</span> 个系统在时间 <span class="math inline">\(t_j\)</span> 的退化值, <span class="math inline">\(\bm Y^{(i)}_{0:m} = (y_{i,0}, \dots, y_{i,m})\)</span> 表示第 <span class="math inline">\(i\)</span> 个系统在 <span class="math inline">\(t_m\)</span> 之前收集的退化观测数据. 所有系统的观测数据集合表示为 <span class="math inline">\(\bm Y_{0:m} = (\bm Y^{(1)}_{0:m}, \dots, \bm Y^{(n)}_{0:m})\)</span>. 不失一般性, 假设所有系统在相同的时间点进行检测, 本节方法同样适用于系统检测时间点不同的情形. 假设当前时间点为<span class="math inline">\(t_m\)</span>, 在线RUL预测需要解决以下两个问题:</p>
<ul>
<li><p><strong>离线训练</strong>: 基于历史数据<span class="math inline">\(\bm Y_{0:m}\)</span>, 估计未知参数<span class="math inline">\(\bm\theta = (\nu, \lambda, \beta)\)</span>. 假设某个特定系统的历史退化观测值为<span class="math inline">\((y_1, \dots, y_m)\)</span>, 且失效阈值为<span class="math inline">\(\omega\)</span>. 在<span class="math inline">\(t_m\)</span>时刻该系统的RUL定义为<span class="math inline">\(\mathcal{X}_m = \inf\{x: Y(x+t_m) \geq \omega \mid y_{m} &lt; \omega\}\)</span>, 其分布可以利用当前参数估计值<span class="math inline">\(\hat{\boldsymbol{\theta}}^{(m)} = (\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})\)</span>进行估计.</p></li>
<li><p><strong>在线更新</strong>: 记<span class="math inline">\((y_{1,m+1}, \dots, y_{n,m+1})\)</span>为下一个时间点<span class="math inline">\(t_{m+1}\)</span>所收集到的系统退化值. 基于新数据以及之前的估计值<span class="math inline">\(\hat{\boldsymbol{\theta}}^{(m)}\)</span>, 如何高效更新参数估计<span class="math inline">\(\hat{\boldsymbol{\theta}}^{(m+1)}\)</span>. 该在线算法应通过递归方式更新参数, 避免直接使用完整历史数据<span class="math inline">\(\bm Y_{0:m}\)</span>进行重新计算, 以降低计算复杂度.</p></li>
</ul>
<p>由于RUL分布是参数<span class="math inline">\(\bm\theta\)</span>的函数, 在每次参数更新后, 可根据新的参数估计值实时预测RUL. 这种方法不仅适用于单一系统, 还能高效整合多系统间的信息, 提升预测的精度与时效性.</p>
<!-- 假设当前的时间点为$t_m$, 我们的任务有两部分. 首先, 我们基于历史数据$\bm Y_{0}$估计未知参数$\bm\theta = (\nu, \lambda, \beta)$, 这在RUL研究中也被称为离线训练. 假设我们关注一个历史退化水平为$(y_1, \dots, y_m)$的系统, 软失效时间定义为退化水平达到由领域知识或专家经验确定的失效阈值$\omega$的时刻. 系统在$t_m$时刻的RUL定义为$\mathcal{X}_m = \inf\{x: Y(x+t_m) \geq \omega  \mid  y_{m} < \omega\}$, 其分布可以使用当前估计值$\hat{\boldsymbol{\theta}}^{(m)} = (\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})$进行估计. 在下一个检测时间点$t_{m+1}$, 来自$n$个系统的新观测值$(y_{1,m+1}, \dots, y_{n,m+1})$变得可用. 我们的下一个目标是利用这些新观测值、之前的估计值$\hat{\boldsymbol{\theta}}^{(m)}$以及可能仅基于历史数据$\bm Y_{0}$的一些统计量, 高效地获得$\hat{\boldsymbol{\theta}}^{(m+1)}$. 换句话说, 所提出的在线算法不需要使用$\bm Y_{0}$中的所有数据点, 估计值以递归方式进行更新. 随后, 由于RUL的分布是$\boldsymbol{\theta}$的函数, 因此可以基于当前估计参数进行实时RUL预测.  -->
</section>
<section id="sec-igsimple" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="sec-igsimple"><span class="header-section-number">4.4.2</span> 在线估计</h3>
<section id="当-beta-已知时-递归更新-hat-nu-和-hat-lambda" class="level4" data-number="4.4.2.1">
<h4 data-number="4.4.2.1" class="anchored" data-anchor-id="当-beta-已知时-递归更新-hat-nu-和-hat-lambda"><span class="header-section-number">4.4.2.1</span> 当 <span class="math inline">\(\beta\)</span> 已知时, 递归更新 <span class="math inline">\(\hat \nu\)</span> 和 <span class="math inline">\(\hat \lambda\)</span></h4>
<p>高效的在线RUL估计需要快速的递归算法来更新参数<span class="math inline">\(\bm\theta=(\nu, \lambda, \beta)\)</span>的估计值. 为此, 可先基于历史数据 <span class="math inline">\(\bm Y_{0:m}=(\bm Y^{(1)}_{0:m},\dots,\bm Y^{(n)}_{0:m})\)</span>考察参数估计量. 设<span class="math inline">\(\Delta\Lambda_j=\Lambda_\beta(t_j)-\Lambda_\beta(t_{j-1})\)</span> 和 <span class="math inline">\(\Delta y_{i,j}=y_{i,j}-y_{i,j-1}\)</span>, 其中 <span class="math inline">\(i=1,\dots,n\)</span> <span class="math inline">\(j=1,\dots,m\)</span>. 根据IG过程的性质, 给定<span class="math inline">\(\bm Y_{0:m}\)</span>时, <span class="math inline">\(\bm\theta\)</span>的似然函数为 <span class="math display">\[\begin{align}
    L(\bm\theta \mid \bm Y_{0:m}) &amp;=\prod_{i=1}^{n}\prod_{j=1}^{m} \sqrt{\frac{\lambda \Delta\Lambda_{j}^{2}}{2 \pi \Delta y_{i,j}^{3}}} \exp \left\{-\frac{\lambda}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_{j}\right)^{2}\right\} \nonumber\\
    &amp;=C_0\lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j}  \exp \left\{-\lambda  \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{1}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_j\right)^{2}\right\}, \label{iglike}
\end{align}\]</span> 其中常数<span class="math inline">\(C_0=\prod_{i=1}^{n}\prod_{j=1}^{m}\sqrt{\frac{1}{2 \pi \Delta y_{i,j}^{3}}}\)</span>. 假设<span class="math inline">\(\beta\)</span>已知, 则<span class="math inline">\(\nu\)</span>和<span class="math inline">\(\lambda\)</span>的MLE为 (推导见本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a>) <span class="math display">\[\begin{equation}\label{eq:mle}
    \hat{\nu}^{(m)}=\dfrac{n\Lambda_\beta(t_m)}{\sum_{i=1}^{n}y_{i,m}},\quad \hat{\lambda}^{(m)}=\dfrac{nm}{ \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{n^2\Lambda^2_\beta(t_m)}{\sum_{i=1}^{n}y_{i,m}}}.
\end{equation}\]</span> 上述公式表明 <span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span> 的估计可通过递归公式更新. 当收集到新的退化测量值<span class="math inline">\(\mathcal{y}_{m+1} = (y{1,m+1}, \dots, y_{n,m+1})\)</span>时:<br>
<span class="math display">\[\begin{equation}\label{eq:aupdate}
  \hat{\nu}^{(m+1)}=\dfrac{n\Lambda_\beta(t_{m+1})}{\sum_{i=1}^{n}y_{i,m+1}}.
\end{equation}\]</span> 这不需要使用<span class="math inline">\(\bm Y_{0:m}\)</span>中的任何信息. 对于<span class="math inline">\(\hat{\lambda}^{(m+1)}\)</span>, 其分母包含两部分: <span class="math inline">\(\sum_{i=1}^{n}\sum_{j=1}^{m+1} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}\)</span>和<span class="math inline">\(\frac{n^2\Lambda^2_\beta(t_{m+1})}{\sum_{i=1}^{n}y_{i,m+1}}\)</span>. 前者可分解为<span class="math inline">\(\sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}+\sum_{i=1}^{n}\frac{\Delta\Lambda_{m+1}^2}{\Delta y_{i,m+1}}\)</span>, 后者等于<span class="math inline">\(\left[\hat{\nu}^{(m+1)}\right]^2\sum_{i=1}^{n}y_{i,m+1}\)</span>. 基于此, <span class="math inline">\(\hat{\lambda}^{(m+1)}\)</span>的递归公式为<br>
<span class="math display">\[\begin{align}
  \label{eq:bupdate}
  \hat{\lambda}^{(m+1)}&amp;=n(m+1)\Bigg[\frac{nm}{\hat \lambda^{(m)}}+\left[\hat{\nu}^{(m)}\right]^2\sum_{i=1}^{n}y_{i,m}\nonumber\\
  &amp;\quad -\left[\hat{\nu}^{(m+1)}\right]^2\sum_{i=1}^{n}y_{i,m+1}+ \sum_{i=1}^{n}\frac{\Delta\Lambda_{m+1}^2}{\Delta y_{i,m+1}}\Bigg]^{-1}.
\end{align}\]</span> 因此, 只需存储历史数据 <span class="math inline">\(\bm Y_{0:m}\)</span> 中的最后一次退化观测量<span class="math inline">\(\mathcal{y}_m =(y_{1,m}, \dots, y_{n,m})\)</span>, 以及<span class="math inline">\(\hat\nu^{(m)}\)</span>和<span class="math inline">\(\hat\lambda^{(m)}\)</span>, 即可实现参数估计的更新.</p>
<p><strong>注6</strong>: <span class="citation" data-cites="pan2016remaining">Pan 等 (<a href="references.html#ref-pan2016remaining" role="doc-biblioref">2016</a>)</span> 考虑的单个系统情形, 即<span class="math inline">\(n=1\)</span> (单个系统). 根据<span class="math inline">\(\eqref{eq:aupdate}\)</span>, 可知 <span class="math display">\[\hat{\nu}^{(m+1)}=\dfrac{\Lambda_\beta(t_{m+1})}{y_{1,m+1}}.\]</span> 令 <span class="math display">\[\psi_m= \sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{1,j}}-\frac{\Lambda^2_\beta(t_m)} {y_{1,m}},\]</span> 则有 <span class="math display">\[ \psi_{m+1}=\psi_{m}+\dfrac{\Delta y_{1,m+1}y_{1,m+1}}{y_{1,m}}
\left[\hat{\nu}^{(m+1)}-\dfrac{\Delta \Lambda_{m+1}}{\Delta y_{1,m+1}}\right]^2.\]</span> 根据和<span class="math inline">\(\eqref{eq:bupdate}\)</span>, 则可得 <span class="math inline">\(\hat{\lambda}^{(m+1)}\)</span> 的更新公式 <span class="math display">\[
\begin{aligned}
\hat{\lambda}^{(m+1)}&amp;=\dfrac{m+1}{\psi_{m+1}}
=\hat{\lambda}^{(m)}\dfrac{m+1}{m}\dfrac{\psi_{m}}{\psi_{m+1}}\\
&amp;=\hat{\lambda}^{(m)}\dfrac{m+1}{m}
\left[1+\dfrac{\Delta y_{1,m+1}y_{1,m+1}}{\psi_{m}y_{1,m}}
\left[\hat{\nu}^{(m+1)}-\dfrac{\Delta \Lambda_{m+1}}{\Delta y_{1,m+1}}\right]^2\right]^{-1}.
\end{aligned}
\]</span></p>
</section>
<section id="基于一步近似的-hatbeta-递归更新" class="level4" data-number="4.4.2.2">
<h4 data-number="4.4.2.2" class="anchored" data-anchor-id="基于一步近似的-hatbeta-递归更新"><span class="header-section-number">4.4.2.2</span> 基于一步近似的 <span class="math inline">\(\hat{\beta}\)</span> 递归更新</h4>
<p>在上一小节中, 给定参数 <span class="math inline">\(\beta\)</span>时, 得到参数估计<span class="math inline">\(\hat{\nu}\)</span> 和 <span class="math inline">\(\hat{\lambda}\)</span> 的递归公式. 当 <span class="math inline">\(\beta\)</span> 未知时, 可通过历史数据 <span class="math inline">\(\bm Y_{0:m}\)</span> 推导 <span class="math inline">\(\beta\)</span> 的轮廓似然函数(Profile likelihood function), 并利用 <span class="math inline">\(\hat{\beta}^{(m)}\)</span> 的MLE更新 <span class="math inline">\(\hat{\nu}^{(m+1)}\)</span> 和 <span class="math inline">\(\hat{\lambda}^{(m+1)}\)</span>. 另一方面, <span class="math inline">\(\hat{\beta}^{(m+1)}\)</span> 也可通过更新后的 <span class="math inline">\(\hat{\nu}^{(m+1)}\)</span> 和 <span class="math inline">\(\hat{\lambda}^{(m+1)}\)</span> 进一步优化. 然而, 由于 <span class="math inline">\(\hat{\beta}\)</span> 的 MLE 缺乏解析表达式, 直接更新算法较为复杂. 因此, 本小节介绍了一种基于一步近似(one-step approximation)的高效递归算法来更新 <span class="math inline">\(\hat{\beta}\)</span>. 其基本思想是借用一步估计(one-step estimator)的方法: 给定一个初始估计<span class="math inline">\(\tilde{\theta}\)</span>, 一步估计量 <span class="math inline">\(\hat{\theta}\)</span> 表示为 <span class="math display">\[\begin{equation}\label{eq:onestep}
  \hat \theta = \tilde \theta + [I(\tilde \theta)]^{-1} \dot{L}(\tilde \theta),
\end{equation}\]</span> 其中<span class="math inline">\(I(\cdot)\)</span>是Fisher信息矩阵, <span class="math inline">\(\dot{L}(\cdot)\)</span>是得分函数, 定义为<span class="math inline">\(\dot{L}(\theta) = \frac{\partial \log L(\theta)}{\partial \theta}\)</span>, <span class="math inline">\(L(\cdot)\)</span>为似然函数. 如果<span class="math inline">\(\tilde{\theta}\)</span>是<span class="math inline">\(\sqrt{n}\)</span>一致的, 并且<span class="math inline">\(\theta\mapsto \dot{L}(\theta)\)</span>满足一定的可微性条件, 则一步估计量<span class="math inline">\(\hat{\theta}\)</span>也是<span class="math inline">\(\sqrt{n}\)</span>一致的, 且其渐近方差可达到Cramér-Rao下界 <span class="citation" data-cites="van2000asymptotic">(<a href="references.html#ref-van2000asymptotic" role="doc-biblioref">Van der Vaart, 1998</a>)</span>.</p>
<!--按照上述循环迭代过程, 依次更新 ($\hat{\nu}, \hat{\lambda}$) 和 $\hat{\beta}$. 在推导 $\hat{\beta}$ 的递归公式时, 假设 $\nu$ 和 $\lambda$ 是已知的. 
$\hat{\beta}$ 的更新方法是基一步估计(one-step estimator)方法, 这是一种计算高效的 MLE 替代方案.-->
<p>这里假设<span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span>已知来说明更新<span class="math inline">\(\hat{\beta}\)</span>的方法, 具体实施时可通过循环迭代依次更新 (<span class="math inline">\(\hat{\nu}, \hat{\lambda}\)</span>) 和 <span class="math inline">\(\hat{\beta}\)</span>. 设<span class="math inline">\(\hat{\beta}^{(m)}\)</span>为基于观测数据<span class="math inline">\(\bm Y_{0:m}\)</span>得到的参数<span class="math inline">\(\beta\)</span>的一致估计. 若初始估计为MLE估计, 则该估计的一致性可以得到保障. 将<span class="math inline">\(\hat{\beta}^{(m)}\)</span>作为式 <span class="math inline">\(\eqref{eq:onestep}\)</span> 中的初始估计, 可以得到一步估计量<span class="math inline">\(\hat{\beta}^{(m+1)}\)</span>的表达式为 <span class="math display">\[\begin{align}\label{eq:os1}
  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + V_{m+1} (\hat{\beta}^{(m)}) \frac{1}{n} \dot{L}(\nu, \lambda, \hat{\beta}^{(m)} \mid \bm Y_{0:m+1}),
\end{align}\]</span> 其中<span class="math inline">\(V_{m+1}(\beta)\)</span>是由<span class="math inline">\(\bm Y_{0:m+1}\)</span>贡献的Fisher信息矩阵的逆, <span class="math inline">\(L(\cdot)\)</span>为式 <span class="math inline">\(\eqref{iglike}\)</span> 中的似然函数. 给定时刻<span class="math inline">\(t_j\)</span>测量的增量<span class="math inline">\(\Delta \bm{y}_j=(\Delta y_{1,j}, \dots, \Delta y_{n,j})\)</span>, <span class="math inline">\(1\le j\le m\)</span>, <span class="math inline">\(\beta\)</span> 的对数似然函数为 <span class="math display">\[\begin{equation*}
\begin{split}
  l_j(\beta \mid \Delta \bm{y}_j,\nu,\lambda)=&amp;\frac{n}{2}\log\left(\frac{\lambda}{2\pi}\right)+n\log( \Delta\Lambda_{j})-\frac{3}{2}\sum_{i=1}^{n}\log(\Delta y_{i,j})\\
  &amp;-\sum_{i=1}^{n}\frac{\lambda}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_{j}\right)^{2}.
\end{split}
\end{equation*}\]</span> 由第<span class="math inline">\(j\)</span>个增量贡献的<span class="math inline">\(\beta\)</span>的Fisher信息为 <span class="math display">\[\begin{align}\label{fij}
  I_j(\beta \mid \nu,\lambda)&amp;=-\mathbb{E}\left[\dfrac{\partial^2 l_j(\beta \mid \Delta \bm{y}_j,\nu,\lambda)  }{\partial \beta^2}\right]\nonumber\\
  &amp; =n\left[\dfrac{\nu\lambda(\Delta\Lambda_{j}^{'})^2}{\Delta\Lambda_{j}}+2\left(\dfrac{\Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2\right],
\end{align}\]</span> 其中<span class="math inline">\(\Delta\Lambda_{j}^{'}\)</span>是 <span class="math inline">\(\Delta\Lambda_{j}\)</span> 关于 <span class="math inline">\(\beta\)</span> 的导数（详见本节附录 <a href="#sec-Append-4B" class="quarto-xref"><span> 4.2.5</span></a>）. 根据IG过程的性质, 增量<span class="math inline">\(\Delta y_{i,j}\)</span>, <span class="math inline">\(i=1, \dots, n\)</span>, <span class="math inline">\(j=1, \dots, m\)</span>, 是独立的但非同分布. 历史数据<span class="math inline">\(\bm Y_{0:m}\)</span>对<span class="math inline">\(\beta\)</span>的Fisher信息贡献为<span class="math inline">\(\sum_{j=1}^{m} I_j(\beta \mid \nu,\lambda)\)</span>, 因此式 <span class="math inline">\(\eqref{eq:os1}\)</span> 中的<span class="math inline">\(V_{m+1} (\hat{\beta}^{(m)})\)</span>可以表示为<span class="math inline">\(\left[\sum_{j=1}^{m+1} I_j(\hat{\beta}^{(m)} \mid \nu,\lambda)\right]^{-1}\)</span>. 由于<span class="math inline">\(I_j\)</span>需要针对不同时刻下的<span class="math inline">\(\beta\)</span>估计值进行重新计算, <span class="math inline">\(V_{m+1} (\hat{\beta}^{(m)})\)</span>无法通过<span class="math inline">\(V_{m} (\hat{\beta}^{(m-1)})\)</span>迭代更新. 为解决这一问题, 需考虑一个高效递归公式来近似<span class="math inline">\(V_{m+1}(\hat{\beta}^{(m)})\)</span>: 结合每个时间点上<span class="math inline">\(\nu\)</span>和<span class="math inline">\(\lambda\)</span>的估计, 可用<span class="math inline">\(\tilde V_{m+1} = \left[ \sum_{j=1}^{m+1} I_j(\beta^{(j-1)} \mid \nu^{(j-1)},\lambda^{(j-1)}) \right]^{-1}\)</span>近似<span class="math inline">\(V_{m+1}(\hat{\beta}^{(m)})\)</span>.<br>
可发现这种处理方式会有以下的迭代关系 <span class="math display">\[\begin{equation}
\label{eq:vupdate}
\widetilde{V}_{m+1}^{-1}=\widetilde{V}_{m}^{-1}+I_{m+1}(\hat{\beta}^{(m)} \mid \hat{\nu}^{(m)},\hat{\lambda}^{(m)}).
\end{equation}\]</span> <!--该递归公式在 $m \geq 3$ 时表现良好, 初始 $\widetilde{V}m$ 可通过MLE估计获得.--> 基于式 <span class="math inline">\(\eqref{eq:vupdate}\)</span>, <span class="math inline">\(\beta\)</span>估计的递归公式<span class="math inline">\(\eqref{eq:os1}\)</span>可近似为<br>
<span class="math display">\[\begin{equation}
\begin{aligned}
  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + \frac{1}{n}\widetilde V_{m+1}  \dot{L}(\nu, \lambda, \hat{\beta}_n^{(m)}  \mid  \bm Y_{0:m+1}),
\end{aligned} \label{eq:os2}
\end{equation}\]</span> 另一方面, 基于<span class="math inline">\(Y_{0:m}\)</span>所得的<span class="math inline">\(\hat{\beta}^{(m)}\)</span>具有<span class="math inline">\(\sqrt{n}\)</span>一致性, 则有<br>
<span class="math display">\[\dot{L}(\nu, \lambda, \hat{\beta}_n^{(m)}  \mid  \bm Y_{0:m}) = o_P(n^{-1/2}),\]</span> 这表明可以忽略与历史数据相关的部分, 仅需考虑新增观测 <span class="math inline">\(\Delta \bm{y}_{m+1}\)</span> 对似然函数的贡献. 因此, 式 <span class="math inline">\(\eqref{eq:os2}\)</span> 可进一步简化为<br>
<span class="math display">\[\begin{equation}
  \begin{aligned}
  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} +  \frac{1}{n}\widetilde V_{m+1}S_{m+1}(\Delta \bm y_{m+1},\hat{\beta}^{(m)}),
  \end{aligned} \label{eq:lambdaupdate}
\end{equation}\]</span> 其中 <span class="math inline">\(S_j(\bm y,\beta)=\dfrac{\partial l_j(\beta \mid \bm y,\nu,\lambda) }{\partial\beta}\)</span>. 显然, <span class="math inline">\(S_{m+1}(\Delta \bm y_{m+1},\hat{\beta}^{(m)})\)</span> 仅依赖于新增观测 <span class="math inline">\(\Delta \bm y_{m+1}\)</span>.</p>
<p><strong>注7</strong>: 对于非线性和非高斯模型, 粒子滤波器常用来处理在线估计问题<span class="citation" data-cites="ma2019pf">(<a href="references.html#ref-ma2019pf" role="doc-biblioref">Ma 等, 2019</a>)</span>. 然而, 随着粒子数量的增加, 其计算复杂度显著提高, 这对实时应用构成挑战. 此外, 粒子退化可能导致估计偏差, 而重采样过程中的噪声可能进一步降低性能 <span class="citation" data-cites="peng2024coll">(<a href="references.html#ref-peng2024coll" role="doc-biblioref">Peng 等, 2024</a>)</span>. 相比之下, 上述提出的一步更新方法具有更高的计算效率, 通过递归计算, 仅利用新增观测和上一步的估计即可实现估计的更新, 显著减少了存储需求和计算负担.</p>
</section>
<section id="在线算法和rul估计" class="level4" data-number="4.4.2.3">
<h4 data-number="4.4.2.3" class="anchored" data-anchor-id="在线算法和rul估计"><span class="header-section-number">4.4.2.3</span> 在线算法和RUL估计</h4>
<p>本小节介绍估计参数 <span class="math inline">\(\boldsymbol{\theta}=(\nu,\lambda,\beta)\)</span>的整体在线算法. 首先需要初始化参数值. 正如本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a> 所示, 当系统的性能退化仅被测量一次 (即 <span class="math inline">\(m=1\)</span>) 时, 参数 <span class="math inline">\(\beta\)</span> 是不可识别的. 同时数值实验也表明, 基于前三个检测时间点的观测数据进行离线训练比 <span class="math inline">\(m=2\)</span> 的情况更稳健. 因此将基于前三次观测数据得到的MLE <span class="math inline">\(\hat{\boldsymbol{\theta}}^{(3)} = (\hat{\nu}^{(3)}, \hat{\lambda}^{(3)},\hat{\beta}^{(3)})\)</span>作为算法的初始值, 其具体计算步骤详见本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a>. 之后, 当新的退化测量数据到来时, 可通过式 <span class="math inline">\(\eqref{eq:aupdate}\)</span>, <span class="math inline">\(\eqref{eq:bupdate}\)</span> 和 <span class="math inline">\(\eqref{eq:lambdaupdate}\)</span> 依次更新 <span class="math inline">\(\hat{\nu}\)</span>、<span class="math inline">\(\hat{\lambda}\)</span> 和 <span class="math inline">\(\hat{\beta}\)</span>. 以下给出了整体在线估计算法的流程:</p>
<p>定理 <a href="#thm-NRL2024-th1" class="quarto-xref"><span>4.5</span></a> 给出了估计量<span class="math inline">\(\hat{\bm\theta}^{(m)}\)</span>的一致性和渐近正态性结论, 为提出的迭代过程提供了理论支撑. 相比经典估计理论 (如 M 估计和一步估计) , 该算法由于增加近似和迭代特性使得证明渐近性质时有一定区别, 基本思路是通过将MLE<span class="math inline">\(\hat{\bm\theta}^{(3)}\)</span>作为算法初始值, 逐步建立<span class="math inline">\((\hat{\nu}^{(m)}, \hat{\lambda}^{(m)})\)</span> 和 <span class="math inline">\(\hat{\beta}^{(m)}\)</span> 的收敛性; 进一步, 基于 Donsker 类性质 (见本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a>), 证明了估计量的渐近正态性.</p>
<div id="thm-NRL2024-th1" class="theorem">
<p><span class="theorem-title"><strong>定理 4.5</strong></span> 对于每个<span class="math inline">\(m \geq 3\)</span>, 当<span class="math inline">\(n \to \infty\)</span>时, <span class="math inline">\((\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})\)</span>依概率收敛于<span class="math inline">\((\nu_0, \lambda_0, \beta_0)\)</span>. 此外, 估计量序列<span class="math inline">\(\sqrt{n}\{(\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)}) - (\nu_0, \lambda_0, \beta_0)\}\)</span>依分布收敛于均值为零且协方差矩阵为<span class="math inline">\(\Sigma_m\)</span>的三维正态随机向量, 其中矩阵<span class="math inline">\(\Sigma_m\)</span>可用递归公式更新, 其具体形式见本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a>.</p>
</div>
<p>在确定不同检测时间点的估计量后, 可对RUL进行实时更新. 定义系统在时间 <span class="math inline">\(t_m\)</span> 的 RUL 为<span class="math inline">\(\mathcal{X}_m=\inf\{x: Y(x+t_m)\ge \omega \mid y_{m}&lt;\omega\}\)</span>, 其中 <span class="math inline">\(\omega\)</span> 为失效阈值. 若<span class="math inline">\(t_m\)</span>时刻的退化值 <span class="math inline">\(y_m\)</span> 已达到 <span class="math inline">\(\omega\)</span>, 则 RUL 为零. 由于IG过程是单调递增的, 事件 <span class="math inline">\(\{\mathcal{X}_m &lt; x\}\)</span> 等价于 <span class="math inline">\(\{Y(x+t_m)\ge \omega\}\)</span>, 因此 RUL 的CDF 可表示为 <span class="math display">\[\begin{align}\label{cdfrul}
  F_{\mathcal{X}_m}\left(x \mid y_m \right)
  &amp;=P\{Y(x+t_m)\ge \omega\}
  =P\{Y(x+t_m)-y_{m}\ge \omega-y_{m}\}\nonumber\\
  &amp;=\Phi\left({\frac{\sqrt{\lambda}\left[\Delta\Lambda_x-\nu(\omega-y_m)\right]}{\sqrt{\omega-y_m}}}\right) \nonumber\\
  &amp;\quad -\exp\left(2\nu\lambda \Delta \Lambda_x\right)
  \Phi\left(-{\frac{\sqrt{\lambda}\left[\Delta\Lambda_x+\nu(\omega-y_m)\right]}{\sqrt{\omega-y_m}}}\right),
\end{align}\]</span> 其中<span class="math inline">\(\Delta \Lambda_x=\Lambda_\beta(x+t_m)-\Lambda_\beta(t_m)\)</span>, <span class="math inline">\(\Phi(\cdot)\)</span>是标准正态分布的CDF. 使用估计量<span class="math inline">\((\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})\)</span>可对<span class="math inline">\(F_{\mathcal{X}_m}(\cdot)\)</span>进行 实时更新. 此外, 还可推导系统的其他可靠性特征. 例如, RUL 的均值可表示为 <span class="math display">\[\mathbb{E}(\mathcal{X}_m \mid y_m) = \int_0^\infty \left[1-F_{\mathcal{X}_m}\left(x \mid y_m \right)\right]\diff x.\]</span> 然而, 由于<span class="math inline">\(\mathbb{E}(\mathcal{X}_m \mid y_m)\)</span>涉及到非线性时间尺度变换<span class="math inline">\(\Lambda_{\beta}(\cdot)\)</span>, 其解析表达式难以获得, 需要借助数值方法计算 <span class="citation" data-cites="huynh2021adaptive">(<a href="references.html#ref-huynh2021adaptive" role="doc-biblioref">Huynh, 2021</a>)</span>.</p>
</section>
</section>
<section id="sec-igre" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="sec-igre"><span class="header-section-number">4.4.3</span> 考虑随机效应的在线估计</h3>
<p>本小节研究带随机效应IG过程的在线RUL估计. 由于原材料差异、生产过程波动和运行环境变化等因素, 不同系统之间可能存在异质性. 随机效应模型常被用来刻画这类异质特征 <span class="citation" data-cites="zhai2018random wang2021degradation fang2022inverse wu2020maintenance">(<a href="references.html#ref-fang2022inverse" role="doc-biblioref">Fang 等, 2022</a>; <a href="references.html#ref-wang2021degradation" role="doc-biblioref">Wang 等, 2021</a>; <a href="references.html#ref-wu2020maintenance" role="doc-biblioref">Wu 等, 2020</a>; <a href="references.html#ref-zhai2018random" role="doc-biblioref">Zhai, Chen, 等, 2018</a>)</span>. 在 IG 过程中, 可将漂移参数 <span class="math inline">\(\nu\)</span> 设为正态分布随机变量 <span class="math inline">\(\nu \sim N(\mu, \sigma^2)\)</span>, 并假定 <span class="math inline">\(\mu \gg \sigma\)</span>, 以忽略 <span class="math inline">\(\nu\)</span> 取负值的概率 <span class="citation" data-cites="ye2014inverse pan2016remaining">(<a href="references.html#ref-pan2016remaining" role="doc-biblioref">Pan 等, 2016</a>; <a href="references.html#ref-ye2014inverse" role="doc-biblioref">Ye 等, 2014</a>)</span>.</p>
<section id="估计量" class="level4" data-number="4.4.3.1">
<h4 data-number="4.4.3.1" class="anchored" data-anchor-id="估计量"><span class="header-section-number">4.4.3.1</span> 估计量</h4>
<p>在带随机效应IG过程的模型中, 参数为 <span class="math inline">\(\boldsymbol{\theta} = (\lambda, \beta, \mu, \sigma)\)</span>. 基于退化数据<span class="math inline">\(Y_{0:m}\)</span>, 似然函数的形式较为复杂, 无法得到参数<span class="math inline">\(\boldsymbol{\theta}\)</span>的估计量的解析表达式.<br>
本小节将介绍一个两阶段的离线估计方法, 并为模型参数提供结合偏差校正的解析形式估计量.</p>
<p>由于<span class="math inline">\(\beta\)</span>可通过上一节中的一步估计方法获得, 这里先假设其已知. 两阶段估计方法的基本策略是 先估计缺失参数<span class="math inline">\(\nu_1,\dots,\nu_n\)</span>, 然后利用基于这些估计量获取<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma\)</span>的估计. 第一步中, 在给定<span class="math inline">\(\beta\)</span>和观测退化增量<span class="math inline">\(\Delta \bm y_{1}\)</span>, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(\Delta \bm y_{m}\)</span>的条件下, <span class="math inline">\(\lambda\)</span>和<span class="math inline">\(\nu_i\)</span>的MLE分别为 <span class="math display">\[\begin{equation}
\label{eq:remle}
\hat{\lambda}^{(m)}=\dfrac{nm}{\sum_{i=1}^{n}\phi_{i,m}}, ~
\hat{\nu}_i^{(m)}=
\dfrac{\Lambda_\beta(t_{m})}{y_{i,m}},~i=1,\dots,n,
\end{equation}\]</span> 其中<span class="math inline">\(\phi_{i,m}= \sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_m)} {y_{i,m}}\)</span>. 鉴于参数数量较多而单个系统的样本量有限, 当 <span class="math inline">\(m\)</span> 较小时, 这些估计量可能存在较大偏差. 因此, 引入以下方法 来减少估计的偏差. 首先, 对<span class="math inline">\(\hat{\lambda}^{(m)}\)</span>进行校正. 注意到 <span class="math display">\[\Delta y_{i,j}\sim \textrm{\textrm{IG}}(\Delta \Lambda_{j}/\nu_i,\lambda\Delta \Lambda_{j}^2), \quad \quad y_{i,m}\sim \textrm{\textrm{IG}}(\Lambda_{\beta}(t_m)/\nu_i,\lambda\Lambda_{\beta}^2(t_m)).\]</span> 同时有 <span class="math display">\[\mathbb{E}\left[\frac{1}{\Delta y_{i,j}}\right]=\frac{\nu_i}{\Delta \Lambda_{j}}+ \frac{1}{\lambda\Delta \Lambda_{j}^2}, \quad  \quad \mathbb{E}\left[y_{i,m}\right]=\frac{\nu_i}{\Lambda_{\beta}(t_m)}+ \frac{1}{\lambda\Lambda_{\beta}^2(t_m)}.
\]</span> 由此可得 <span class="math display">\[
\begin{aligned}
    \mathbb{E}\left[\phi_{i,m}\right]&amp;=\sum_{j=1}^{m} \mathbb{E}\left[\frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}\right]-\mathbb{E}\left[\frac{\Lambda^2_\beta(t_m)}
    {y_{i,m}}\right]\\
    &amp;=\sum_{j=1}^{m}\left(\nu_i\Delta \Lambda_{j}+\frac{1}{\lambda}\right)-
    \left(\nu_i\Lambda_{\beta}(t_m)+\frac{1}{\lambda}\right)=\frac{m-1}{\lambda}.
\end{aligned}
\]</span> <span class="math inline">\(\sum_{i=1}^{n}\phi_{i,m}\)</span>的期望为 <span class="math display">\[\mathbb{E}\left[\sum_{i=1}^{n}\phi_{i,m}\right]=\frac{n(m-1)}{\lambda},\]</span> 从而可得 <span class="math inline">\(1/\lambda\)</span>的无偏估计量: <span class="math inline">\(T_m = \sum_{i=1}^{n}\phi_{im}/[n(m-1)]\)</span>. 对于任何可微函数<span class="math inline">\(h(\cdot)\)</span>, <span class="math inline">\(h(T_m)\)</span>都可以作为<span class="math inline">\(h(1/\lambda)\)</span>的估计量, 但通常会有偏差. 通过泰勒展开近似可得 <span class="math display">\[\begin{equation*}
\begin{aligned}
\mathbb{E}\left[h(T_m)\right]&amp;\approx
\mathbb{E}\left[h(1/\lambda)+h^{'}(1/\lambda)(T_m-1/\lambda)
+h^{''}(1/\lambda)(T_m-1/\lambda)^2/2\right]\\
&amp;=h(1/\lambda)+\mathbb{Var}(T_m)h^{''}(1/\lambda)/2.
\end{aligned}
\end{equation*}\]</span> 当<span class="math inline">\(h(x) = 1/x\)</span>时, <span class="math inline">\(1/T_m\)</span>的期望可近似为 <span class="math display">\[\begin{equation}\label{bias1}
\mathbb{E}\left[1/T_m\right]\approx
\lambda+\mathbb{Var}(T_m)\lambda^3.
\end{equation}\]</span> 为了找到<span class="math inline">\(\lambda\)</span>的渐近无偏估计量, 需要找到<span class="math inline">\(\mathbb{Var}(T_m)\)</span>的近似. 由于<span class="math inline">\(\phi_{im}, i=1, \dots, n\)</span>独立同分布, 因此<span class="math inline">\(\mathbb{Var}(T_m) = \dfrac{\mathbb{Var}(\phi_{im})}{n(m-1)^2}\)</span>. 给定<span class="math inline">\(\beta\)</span>, <span class="math inline">\(\mathbb{Var}(\phi_{im})\)</span>可以通过<span class="math inline">\(\frac{1}{n-1}\sum_{i=1}^{n}(\phi_{im} - \bar{\phi}_{m})^2\)</span>进行估计, 其中<span class="math inline">\(\bar{\phi}_{m} = \frac{1}{n}\sum_{i=1}^{n}\phi_{im}\)</span>. 因此, 方差的渐近估计量为 <span class="math display">\[\begin{equation}\label{varest}
\widehat{\mathbb{Var}(T_m)}=\dfrac{\frac{1}{n-1}\sum_{i=1}^{n}(\phi_{im}-\bar{\phi}_{m})^2}{n(m-1)^2}.
\end{equation}\]</span> 结合式 <span class="math inline">\(\eqref{eq:remle}\)</span>和 <span class="math inline">\(\eqref{bias1}\)</span>, 可得带偏差校正的<span class="math inline">\(\lambda\)</span>的解析形式估计量为<br>
<span class="math display">\[\begin{equation}
\label{eq:betaest}
\tilde{\lambda}^{(m)}=\dfrac{n(m-1)}{\sum_{i=1}^{n}\phi_{im}}-\dfrac{\sum_{i=1}^{n}(\phi_{im}-\bar{\phi}_{m})^2}{n(n-1)(m-1)^2}
\left(\dfrac{nm}{\sum_{i=1}^{n}\phi_{i,m}}\right)^3.
\end{equation}\]</span> 对于<span class="math inline">\(\hat{\nu}_i^{(m)}\)</span>的偏差校正, 有 <span class="math display">\[\begin{equation}\label{bias2}
\begin{aligned}
\mathbb{E}\left[\hat{\nu}_i^{(m)}\right]&amp;=
\mathbb{E}\left[\mathbb{E}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right]
=\mathbb{E}\left[\nu_i+\frac{1}{\lambda\Lambda_\beta(t_{m})}\right]
=\mu+\frac{1}{\lambda\Lambda_\beta(t_{m})},
\end{aligned}
\end{equation}\]</span> 这意味着偏差为<span class="math inline">\({1}/{(\lambda\Lambda_\beta(t_{m}))}\)</span>. 因此, 带有偏差校正的<span class="math inline">\(\nu\)</span>的解析形式估计量为 <span class="math display">\[\begin{equation}
\label{alphaest}
\tilde{\nu}_i^{(m)} =\hat{\nu}_i^{(m)} -
\frac{1}{\tilde{\lambda}^{(m)}\Lambda_\beta(t_{m})} =\dfrac{\Lambda_\beta(t_{m})}{y_{i,m}}-
\frac{1}{\tilde{\lambda}^{(m)}\Lambda_\beta(t_{m})},~i=1,\dots,n.
\end{equation}\]</span></p>
<p>在第二阶段, 通过估计量 <span class="math inline">\(\boldsymbol{\tilde{\nu}}^{(m)} = \left(\tilde{\nu}_1^{(m)}, \dots, \tilde{\nu}_n^{(m)} \right)\)</span> 来估计随机效应参数 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma\)</span>, 这些参数可被视为 来自 <span class="math inline">\(N(\mu, \sigma^2)\)</span> 的伪样本. <span class="math inline">\(\mu\)</span>的估计量可以直接通过 <span class="math inline">\(\boldsymbol{\tilde{\nu}}^{(m)}\)</span> 的均值计算, 具体为 <span class="math display">\[\begin{equation}\label{muest}
\tilde{\mu}^{(m)}=\frac{1}{n}\sum_{i=1}^{n}\tilde{\nu}_i^{(m)}.
\end{equation}\]</span> 同时, <span class="math inline">\(\tilde{\nu}_i^{(m)}\)</span>的方差近似为 <span class="math display">\[\begin{align}
\label{eq:alphavar}
\mathbb{Var}\left[\tilde{\nu}_i^{(m)}\right] &amp; \approx \mathbb{Var}\left[\hat{\nu}_i^{(m)}\right] =
\mathbb{Var}\left[\mathbb{E}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right]+
\mathbb{E}\left[\mathbb{Var}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right]\nonumber\\
&amp;=\mathbb{Var}\left[\nu_i+\frac{1}{\lambda\Lambda_\beta(t_{m})}\right]+\mathbb{E}\left[\dfrac{2}{\lambda^2\Lambda^4_\beta(t_{m})}+
\dfrac{\nu_i}{\lambda\Lambda^3_\beta(t_{m})}\right]\nonumber\\
&amp;=\sigma^2+\dfrac{2}{\lambda^2\left[\Lambda_\beta(t_{m})\right]^4}+
\dfrac{\mu}{\lambda\left[\Lambda_\beta(t_{m})\right]^3}.
\end{align}\]</span> 基于此, <span class="math inline">\(\sigma\)</span>可用以下估计量来估计 <span class="math display">\[\begin{align}
\label{sigest}
\tilde{\sigma}^{(m)}&amp; = \Bigg\{
\dfrac{1}{n-1}\sum_{i=1}^{n}\left(\tilde{\nu}_i^{(m)}-\tilde{\mu}^{(m)}\right)^2 \nonumber\\
&amp;\quad -\frac{2}{[\tilde{\lambda}^{(m)}]^2\left[\Lambda_\beta(t_{m})\right]^4}-
\frac{\tilde{\mu}^{(m)}}{\tilde{\lambda}^{(m)}\left[\Lambda_\beta(t_{m})\right]^3}\Bigg\}^{-1/2}.
\end{align}\]</span></p>
</section>
<section id="递归更新" class="level4" data-number="4.4.3.2">
<h4 data-number="4.4.3.2" class="anchored" data-anchor-id="递归更新"><span class="header-section-number">4.4.3.2</span> 递归更新</h4>
<p>上节推导的解析形式估计量的一大优势在于: 它们能够利用历史退化数据的汇总(summary)统计量进行高效更新. 为说明这一点, 本小节首先给出了 <span class="math inline">\(\phi_{i,m}\)</span> 的递归表达式. 对于 <span class="math inline">\(i = 1, \dots, n\)</span>, 有 <span class="math display">\[\begin{align}\label{eq:phiupdate}
\phi_{i,m+1} &amp;= \sum_{j=1}^{m+1} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_{m+1})}
{y_{i,m+1}}\nonumber\\
&amp;=\phi_{i,m}+\dfrac{y_{i,m+1} \Delta y_{i,m+1}}{y_{i,m}}
\left[\frac{\Lambda_{\beta}(t_{m+1})}
{y_{i,m+1}}-\frac{\Delta \Lambda_{m+1}}{\Delta y_{i,m+1}}\right]^2,
\end{align}\]</span> 其中 <span class="math inline">\(y_{i,m+1}\)</span>和<span class="math inline">\(\Delta y_{i,m+1}\)</span>分别为第<span class="math inline">\(i\)</span>个系统的新退化测量值和退化增量. 基于递归公式, <span class="math inline">\(\tilde{\lambda}^{(m+1)}\)</span> 可以直接通过式 <span class="math inline">\(\eqref{eq:betaest}\)</span> 更新, 而只需存储 <span class="math inline">\(n\)</span> 个系统的汇总统计量 <span class="math inline">\(\phi_{i,m}\)</span> 和最后一次退化测量值 <span class="math inline">\(y_{i,m}\)</span>, 这些统计量可由历史退化数据 <span class="math inline">\(Y_{0:m}\)</span> 计算.<br>
更新后的 <span class="math inline">\(\tilde{\lambda}^{(m+1)}\)</span> 可用于递归更新 <span class="math inline">\(\boldsymbol{\tilde{\nu}}^{(m+1)}\)</span> (参见式 <span class="math inline">\(\eqref{alphaest}\)</span>) . 随后, 利用式 <span class="math inline">\(\eqref{muest}\)</span> 和 <span class="math inline">\(\eqref{sigest}\)</span> 可分别得到 <span class="math inline">\(\tilde{\mu}^{(m+1)}\)</span> 和 <span class="math inline">\(\tilde{\sigma}^{(m+1)}\)</span>. 上述的递归过程需要输入 <span class="math inline">\(\beta\)</span>. 为了进一步优化, 采用一步估计法得到 <span class="math inline">\(\beta\)</span> 的递推公式, 从而实现 <span class="math inline">\((\tilde{\lambda}, \tilde{\mu}, \tilde{\sigma}, \tilde{\beta})\)</span> 的高效迭代更新. 类似于在不考虑随机效应时的递推公式 <span class="math inline">\(\eqref{eq:lambdaupdate}\)</span>, 在存在随机效应时可用以下递推公式. <span class="math display">\[\begin{equation}
\label{eq:relambdaupdate}
\tilde{\beta}^{(m+1)}=\tilde{\beta}^{(m)}+
\frac{1}{n}\widetilde{RV}_{m+1} RS_{m+1}(\Delta \bm y_{m+1},\tilde{\beta}^{(m)}),
\end{equation}\]</span> 其中 <span class="math inline">\(\widetilde{RV}_{m+1}=\left[\sum_{j=1}^{m+1} RI_j(\tilde{\beta}^{(j-1)} \mid \boldsymbol{\tilde{\nu}}^{(j-1)}, \tilde{\lambda}^{(j-1)})\right]^{-1}\)</span> 是Fisher信息逆矩阵的近似, 且 <span class="math display">\[RI_j(\tilde{\beta}^{(j)} \mid \boldsymbol{\tilde{\nu}}^{(j)},\tilde{\lambda}^{(j)})=\sum_{i=1}^{n}\left[2\left(\dfrac{ \Delta\tilde{\Lambda}_{j}^{'}}{ \Delta\tilde{\Lambda}_{j}}\right)^2+\dfrac{ \tilde{\nu}_i^{(j)}\tilde{\lambda}^{(j)} (\Delta\tilde{\Lambda}_{j}^{'})^2}{\Delta\tilde{\Lambda}_{j}}\right],\]</span> 其中<span class="math inline">\(\Delta\tilde{\Lambda}_{j}\)</span>和<span class="math inline">\(\Delta\tilde{\Lambda}_{j}^{'}\)</span>分别是<span class="math inline">\(\Delta{\Lambda}_{j}\)</span>和<span class="math inline">\(\Delta{\Lambda}_{j}^{'}\)</span>, 只需将<span class="math inline">\(\beta\)</span>替换为<span class="math inline">\(\tilde{\beta}^{(j)}\)</span>. 另一方面, <span class="math inline">\(RS_{j}(\Delta \bm y_{j}, \beta)\)</span>表示第 <span class="math inline">\(j\)</span> 个退化增量的对数似然函数关于 <span class="math inline">\(\beta\)</span> 的导数, 其表达式为 <span class="math display">\[RS_{j}(\Delta \bm y_{j},\tilde{\beta}^{(j-1)})=\dfrac{ n\Delta\tilde{\Lambda}_{j}^{'}}{ \Delta\tilde{\Lambda}_{j}}
+\sum_{i=1}^{n}\left[\tilde{\nu}_i^{(j)}\tilde{\lambda}^{(j)}\Delta\tilde{\Lambda}_{j}^{'}-\dfrac{\tilde{\lambda}^{(j)}
\Delta\tilde{\Lambda}_{j}^{'}\Delta\tilde{\Lambda}_{j}}{y_{ij}}\right]. \]</span> 容易验证, Fisher 信息逆矩阵的近似 <span class="math inline">\(\widetilde{RV}_m\)</span> 可通过以下公式递归更新. <span class="math display">\[\begin{equation}
\label{eq:rvupdate}
\widetilde{RV}_{m+1}^{-1}= \widetilde{RV}_{m}^{-1}+RI_{m+1}(\tilde{\beta}^{(m)} \mid \boldsymbol{\tilde{\nu}}^{(m)},
          \tilde{\lambda}^{(m)})
\end{equation}\]</span> 并且<span class="math inline">\(RS_{m+1}(\Delta \bm y_{m+1}, \tilde{\beta}^{(m)})\)</span>仅依赖于新退化增量<span class="math inline">\(\Delta \bm y_{m+1}\)</span>. 因此, 式 <span class="math inline">\(\eqref{eq:relambdaupdate}\)</span> 中的<span class="math inline">\(\tilde{\beta}\)</span>具有递归结构, 可实现高效更新.</p>
</section>
<section id="在线算法和rul估计-1" class="level4" data-number="4.4.3.3">
<h4 data-number="4.4.3.3" class="anchored" data-anchor-id="在线算法和rul估计-1"><span class="header-section-number">4.4.3.3</span> 在线算法和RUL估计</h4>
<p>基于上述递推公式的推导, 可构建一个全面的在线算法. 类似于不考虑随机效应的情形, 建议采用至少 <span class="math inline">\(m=3\)</span> 次退化测量来获取参数的初始估计. 算法的具体步骤如下:</p>
<p>在推导<span class="math inline">\(t_m\)</span>时刻的RUL分布 <span class="math inline">\(\mathcal{X}_m=\inf\{x: Y(x+t_m)\ge \omega \mid y_{m}&lt;\omega\}\)</span> 时, 需要在式 <span class="math inline">\(\eqref{cdfrul}\)</span> 中对未知的<span class="math inline">\(\nu\)</span>进行积分, 这增加了计算的复杂性. 具体来说, 给定<span class="math inline">\(\nu\)</span>和<span class="math inline">\(y_m\)</span>的情况下, <span class="math inline">\(\mathcal{X}_m\)</span>的CDF为 <span class="math display">\[\begin{equation*}
\begin{aligned}
F_{\mathcal{X}_m}\left(x \mid \nu, y_m \right)=&amp;
\Phi\left({\frac{\sqrt{\lambda}\left[\Delta \Lambda_x-\nu(\omega-y_m)\right]}{\sqrt{\omega-y_m}}}\right)\\
&amp;-\exp \left(2\nu\lambda \Delta \Lambda_x\right)
\Phi\left(-{\frac{\sqrt{\lambda}\left[\Delta \Lambda_x+\nu(\omega-y_m)\right]}{\sqrt{\omega-y_m}}}\right),
\end{aligned}
\end{equation*}\]</span> 其中 <span class="math inline">\(\Delta \Lambda_x = \Lambda_\beta(x+t_m) - \Lambda_\beta(t_m)\)</span>. 通过对<span class="math inline">\(F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)\)</span>关于<span class="math inline">\(\nu\)</span>的条件分布取期望, 可以得到<span class="math inline">\(\mathcal{X}_m\)</span>的边际CDF:<br>
<span class="math display">\[\begin{equation}
\label{eq:rerul}
F_{\mathcal{X}_m}\left(x \mid  y_m \right) = \int_\nu F_{\mathcal{X}_m}\left(x \mid \nu, y_m \right) \pi(\nu  \mid  y_m) \diff \nu,
\end{equation}\]</span> 其中<span class="math inline">\(\pi(\nu \mid y_m)\)</span>表示<span class="math inline">\(\nu\)</span>的后验PDF. 利用本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a> 中<span class="math inline">\(n=1\)</span>的似然函数和贝叶斯公式, <span class="math inline">\(\pi(\nu \mid y_m)\)</span> 为 <span class="math display">\[\begin{equation*}
\begin{split}
\pi(\nu \mid y_m)
&amp; \propto \exp \left\{-\frac{\lambda y_{m}\left(\nu-\Lambda_\beta(t_{m}) / y_{m}\right)^{2}}{2}\right\}
\exp\left\{-\dfrac{\left(\nu-\mu\right)^{2}}{2\sigma^2}\right\}\\
&amp;\propto
\exp\left\{-\dfrac{\left(\nu-\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}\right)^{2}}{2\left(\lambda y_m+\sigma^{-2}\right)^{-1}}\right\},
\end{split}
\end{equation*}\]</span> 化简后可得 <span class="math inline">\(\pi(\nu \mid y_m)\)</span> 为正态分布 <span class="math inline">\(\mathcal{N}(\mu_m, \tau_m)\)</span>, 其中 <span class="math display">\[\mu_m=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}, \quad \quad \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1}.\]</span> 因此, 边际CDF有显式表达式, 如定理 <a href="#thm-th2" class="quarto-xref"><span>4.6</span></a> 所示, 其证明见本节附录 <a href="#sec-Append-4C" class="quarto-xref"><span> 4.4.6</span></a>.</p>
<div id="thm-th2" class="theorem">
<p><span class="theorem-title"><strong>定理 4.6</strong></span> 假设当前<span class="math inline">\(t_m\)</span>时刻的观测退化测量值为 <span class="math inline">\(0&lt;y_1&lt;\cdots&lt;y_m&lt;\omega\)</span>, 且这些值服从带随机效应<span class="math inline">\(\nu \sim N(\mu,\sigma\^2)\)</span>的IG过程. 则<span class="math inline">\(\mathcal{X}_m\)</span>的CDF为 <span class="math display">\[\begin{align}\label{recdfrul}
    F_{\mathcal{X}_{m}}(x \mid y_m) &amp; = \Phi\left(\frac{-K_1\mu_m+K_2}{\sqrt{1+K_1^2\tau_m}}\right)-\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber\\
    &amp;\ \ \  \times
  \Phi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right),
\end{align}\]</span> 其中 <span class="math display">\[\begin{align*}
\mu_m&amp;=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}, \ \ \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1},\\
K_1&amp; =\sqrt{\lambda(\omega-y_m)}, K_2=\frac{\sqrt{\lambda}\Delta \Lambda_x}{\sqrt{(\omega-y_m)}},\ \  K_3=2\lambda\Delta \Lambda_x.
\end{align*}\]</span> 此外, <span class="math inline">\(\mathcal{X}_{m}\)</span>的PDF为 <span class="math display">\[\begin{align}
    \label{pdfrul}
    f_{\mathcal{X}_{m}}(x \mid y_m)
    &amp;=\varphi\left(\frac{-K_1\mu_m+K_2}{\sqrt{1+K_1^2\tau_m}}\right)\frac{K_2^{'}}{\sqrt{1+K_1^2\tau_m}}\nonumber\\
    &amp;\quad -(K_3^{'}\mu_m+K_3^{'}K_3\tau_m)\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber\\
    &amp;\quad \times\Phi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right)\nonumber\\
    &amp;\quad +\frac{K_2^{'}+K_1K_3^{'}\tau_m}{\sqrt{1+K_1^2\tau_m}}\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber\\
    &amp;\quad \times \varphi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right),
\end{align}\]</span> 其中<span class="math inline">\(\varphi(\cdot)\)</span>为标准正态分布的PDF, <span class="math inline">\(K_2^{'}=\frac{\sqrt{\lambda}\Delta \Lambda_x^{'}}{\sqrt{(\omega-y_m)}}\)</span>,<span class="math inline">\(K_3^{'}=2\lambda\Delta \Lambda_x^{'}\)</span>, <span class="math inline">\(\Delta \Lambda_{x}^{'}\)</span> 为 <span class="math inline">\(\Delta \Lambda_{x}\)</span>关于<span class="math inline">\(x\)</span>的一阶导数.</p>
</div>
</section>
</section>
<section id="sec-simulation" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="sec-simulation"><span class="header-section-number">4.4.4</span> 模拟实验</h3>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:olialp1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:olialp1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/olipars.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:olialp1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.18: <span class="math inline">\(\nu\)</span>、<span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\beta\)</span> 参数的估计性能.
</figcaption>
</figure>
</div>
</div>
</div>
<p>本节通过模拟研究评估所提出在线算法的性能. 参数设置: <span class="math display">\[\nu = 3、\lambda = 10, \Lambda_{\beta}(t) = t^2 (\beta = 2).\]</span> 试验中随机选取 <span class="math inline">\(n = 15\)</span> 个系统, 采用等间隔测量, 测量时间在区间<span class="math inline">\([0.1, 10]\)</span>内, 测量间隔为 0.1. 因此, 每个系统的测量次数 <span class="math inline">\(m = 100\)</span>.<br>
采用第 <a href="#sec-igsimple" class="quarto-xref"><span> 4.4.2</span></a> 节提出的在线算法分析数据, 并记录每个时间点的估计值. 该过程重复 10000 次, 总计算耗时 3.27 分钟 (运行环境: 2.7 GHz Intel Core i5, 8 GB RAM) . 通过10000次重复实验, 计算每个测量时间点 <span class="math inline">\(t_j\)</span> 处不同参数的RB和RMSE. 图 <a href="#fig-fig:olialp1" class="quarto-xref"><span>4.18</span></a> 展示参数 <span class="math inline">\(\nu\)</span>、<span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\beta\)</span> 的估计结果. 结果表明, 估计值在几次迭代后迅速稳定, 并最终收敛于真实值.</p>
<p>接下来, 进一步考虑带随机效应的 IG 过程, 假设 <span class="math inline">\(\nu \sim N(3, 0.8^2)\)</span>, 即 <span class="math inline">\(\mu = 3\)</span> 且 <span class="math inline">\(\sigma = 0.8\)</span>. 为说明偏差校正估计量的效果, 本小节对比了带偏差校正和不带偏差校正的在线算法. 本次模拟重复进行 10000 次, 总计算时间为 5.45 分钟. 图 <a href="#fig-fig:rmsecomp" class="quarto-xref"><span>4.19</span></a> 展示了不同参数在不同测量时间点的RMSE, 其中黑色曲线代表带偏差校正的在线算法, 红色曲线代表不带偏差校正的算法. 结果表明, 采用偏差校正后, 估计精度显著提升. 此外, 即使在收集到少量退化测量后, 基于偏差校正的在线算法的估计值也能快速收敛至真实值.</p>
<!-- ```{r} -->
<!-- #| label: fig-fig:rbcomp -->
<!-- #| fig.align: 'center' -->
<!-- #| echo: FALSE -->
<!-- #| out.width: '90%' -->
<!-- #| fig.cap: '基于含随机效应的 IG 模型, 不同方法下参数估计的RB.' -->
<!-- knitr::include_graphics("figures/IG/NRL2024/rbcomp.pdf") -->
<!-- ``` -->
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:rmsecomp" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:rmsecomp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/msecomp.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:rmsecomp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.19: 基于含随机效应的 IG 模型, 不同方法下参数估计的RMSE.
</figcaption>
</figure>
</div>
</div>
</div>
<p>本节还评估了基于含随机效应的 IG 过程的RUL预测性能. 不失一般性, 选取第一个系统的 RUL 作为研究对象, 并将失效阈值设定为 <span class="math inline">\(\omega = 60\)</span>. 在每次模拟中, 持续监测系统的退化水平直至达到失效阈值, 从而在每个检测时间点获得真实的 RUL. 基于 10000 次重复实验, 图 <a href="#fig-fig:rmsrul" class="quarto-xref"><span>4.20</span></a> 展示了第一个系统 RUL 预测的RB和RMSE. 结果表明, 所提出的 RUL 预测方法在仅收集到少量测量值后就能达到较高的预测精度. 后续章节将结合真实数据集进一步分析 RUL 预测性能.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:rmsrul" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:rmsrul-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/rulsimu.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:rmsrul-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.20: 第一个系统RUL预测的RB和RMSE.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-case" class="level3" data-number="4.4.5">
<h3 data-number="4.4.5" class="anchored" data-anchor-id="sec-case"><span class="header-section-number">4.4.5</span> 实例分析</h3>
<p>本节通过两个真实的退化数据集, 验证了所提出方法的有效性. 这些数据表明, IG 过程是一个合适的模型, 且在线算法可以高效地估计模型参数并预测 RUL.</p>
<section id="集成电路器件退化数据" class="level4" data-number="4.4.5.1">
<h4 data-number="4.4.5.1" class="anchored" data-anchor-id="集成电路器件退化数据"><span class="header-section-number">4.4.5.1</span> 集成电路器件退化数据</h4>
<p>本研究选取了在 <span class="math inline">\(195^\circ\)</span>C 下收集的集成电路器件退化数据作为分析对象 (详见图 <a href="01-intro.html#fig-fig:deviceB" class="quarto-xref"><span>1.6</span></a>). 在该温度下, 共测试了 <span class="math inline">\(n=12\)</span> 个器件, 测量次数 <span class="math inline">\(m=16\)</span>, 测量时间点均匀分布在 0 至 2000 小时的区间内. 选取非线性时间函数为 <span class="math inline">\(\Lambda_\beta(t) = t^\beta\)</span>. 图 <a href="#fig-fig:d1fit" class="quarto-xref"><span>4.21</span></a> 展示了退化数据以及拟合的带随机效应和无随机效应的 IG 过程模型. 从图中可以看出, 这两种模型均能够较好地刻画退化路径特征.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:d1fit" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:d1fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/d1fit.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:d1fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.21: 基于集成电路器件的退化数据的不同模型拟合情况.
</figcaption>
</figure>
</div>
</div>
</div>
<p>随后, 运用所提出的在线算法计算参数估计值. 图 <a href="#fig-fig:d1evol1" class="quarto-xref"><span>4.22</span></a> 和图 <a href="#fig-fig:d1evol2" class="quarto-xref"><span>4.23</span></a> 展示了在两种 IG 模型下参数的递归更新估计值. 可看出, 参数估计普遍在0.75 千小时左右后达到稳定. 为了对比两种 IG 模型, 计算了每个时间点下模型的 AIC 值, 其中 AIC 值较低的模型更优. 此外, 将无随机效应的 IG 模型作为原假设, 含随机效应的 IG 模型作为备择假设, 运用似然比检验, 同时计算每个时间下的检验 <span class="math inline">\(p\)</span> 值. 图 <a href="#fig-fig:d1aic" class="quarto-xref"><span>4.24</span></a> 展示每个时间点的 AIC 值和 <span class="math inline">\(p\)</span> 值.<br>
结果显示, 在所有测量时间点, 含随机效应的 IG 模型具有更低的 AIC 值, 表明其拟合效果更佳. 同时, <span class="math inline">\(p\)</span> 值均小于设定的显著性水平 0.05, 说明拒绝原假设. 这些发现表明, 带随机效应的 IG 模型更适用于分析该退化数据集.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:d1evol1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:d1evol1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/d1evol1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:d1evol1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.22: 基于集成电路器件退化数据, 无随机效应的 IG 过程的参数估计演变轨迹.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:d1evol2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:d1evol2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/d1evol2.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:d1evol2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.23: 基于集成电路器件退化数据, 含随机效应的IG过程的参数估计值演变轨迹.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:d1aic" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:d1aic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/d1aic.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:d1aic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.24: 基于集成电路器件退化数据, 两个IG模型的AIC值和<span class="math inline">\(p\)</span>值.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="锂离子电池容量退化数据" class="level4" data-number="4.4.5.2">
<h4 data-number="4.4.5.2" class="anchored" data-anchor-id="锂离子电池容量退化数据"><span class="header-section-number">4.4.5.2</span> 锂离子电池容量退化数据</h4>
<!-- 锂离子电池已广泛应用于电动汽车、电网储能和手机等商业产品中. 锂离子电池的RUL预测在技术发展加速、制造过程优化以及预测与健康管理中发挥着至关重要的作用. 在过去的十年中, 有关锂离子电池的大量研究文献集中于RUL预测; 有关一些最近的研究, 请参见[@ma2019remaining; @xue2020remaining; @cheng2021remaining; @xu2021remaining; @li2022end]. RUL预测通常基于充放电实验中获得的容量退化数据. 图 @fig-fig:capdeg1 展示了17个电池的退化数据, 容量每500次充放电循环进行一次测量. 该数据提取自一个包含多种实验设置下的锂离子电池退化数据的大型数据集[@severson2019data].  -->
<p>以图 <a href="01-intro.html#fig-fig:capdeg1" class="quarto-xref"><span>1.8</span></a> 中的 17 个电池退化数据为例, 首先使用所提出的两种 IG 模型对数据进行拟合. 设定 <span class="math inline">\(\Lambda_\beta(t) = t^\beta\)</span>, 使用所提出的算法获得参数的在线估计, 结果如图 <a href="#fig-fig:evol1" class="quarto-xref"><span>4.25</span></a> 和图 <a href="#fig-fig:evol2" class="quarto-xref"><span>4.26</span></a> 所示. 可发现参数估计在 100 次循环后趋于稳定. 图 <a href="#fig-fig:aicpval" class="quarto-xref"><span>4.27</span></a> 显示了 AIC 值和似然比检验的 <span class="math inline">\(p\)</span> 值. 结果表明, 在显著性水平 0.05 下, 带随机效应的 IG 过程更适合描述该数据. 随后, 通过 Shapiro-Wilk 检验评估了随机效应服从正态分布的假设. 如图 <a href="#fig-fig:normality" class="quarto-xref"><span>4.28</span></a> 所示, 除前几个时间点外, 几乎所有正态性检验的 <span class="math inline">\(p\)</span> 值均大于 0.05, 这表明随机效应 <span class="math inline">\(\nu\)</span> 的正态性假设是合理的.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:evol1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:evol1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/evol1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:evol1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.25: 基于锂离子电池退化数据, 无随机效应的IG过程的参数估计演变轨迹.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:evol2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:evol2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/evol2.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:evol2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.26: 基于锂离子电池退化数据, 带有随机效应的IG过程的参数估计值演变轨迹.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:aicpval" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:aicpval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/aicpval.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:aicpval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.27: 基于锂离子电池退化数据, 两个IG模型的AIC值和<span class="math inline">\(p\)</span>值.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fig:normality" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:normality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/normality.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:normality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.28: 基于锂离子电池退化数据的随机效应正态性检验 <span class="math inline">\(p\)</span> 值.
</figcaption>
</figure>
</div>
</div>
</div>
<p>为了进一步展示随机效应模型在 RUL 预测中的优势, 本小节以#6锂离子电池 为例, 设定失效阈值为 <span class="math inline">\(\omega = 17\)</span>. 基于此阈值, #6 电池 的寿命为 731 个充放电循环, 因此在每个循环中都可以获得其真实 RUL. 采用第 <a href="#sec-igre" class="quarto-xref"><span> 4.4.3</span></a> 节提出的算法, 在 251、326、401、476 和 551 个循环时对#6 电池 的 RUL 进行预测. 图 <a href="#fig-rulpred" class="quarto-xref"><span>4.29 (a)</span></a> 展示了基于两种 IG 模型的 RUL 预测均值和 PDF. 结果表明, 带随机效应的IG 模型提供了更准确的预测, 且随着退化数据量的增加, 预测精度不断提高. 图 <a href="#fig-rulall" class="quarto-xref"><span>4.29 (b)</span></a> 展示了所有 125 个测量时间点的 RUL 预测均值及近似 95% 置信区间. 这些置信区间利用 <span class="math inline">\(F_{\mathcal{X}_{m}}(x \mid y_m)\)</span> 的 2.5% 和 97.5% 分位数和参数的估计值来构造, 见公式 <span class="math inline">\(\eqref{recdfrul}\)</span>. 结果显示, 基于随机效应模型的置信区间中, 125 个真实 RUL 点中有 7 个超出置信区间, 对应的频率覆盖概率为 <span class="math inline">\((125-7)/125 = 94.4\%\)</span>, 接近名义水平 95%. 相比之下,基于无随机效应的 IG 模型所构造的置信区间明显更宽, 仅有 2 个真实 RUL 点超出区间, 对应覆盖概率为 98.4%. 尽管覆盖概率较高, 但较宽的置信区间反映了更大的预测不确定性. 综合来看, 随机效应模型能更有效地利用退化数据, 为 RUL 预测提供更高的精度和更具解释性的信息.</p>
<div id="fig-fig:rulpred2" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig:rulpred2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fig:rulpred2" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rulpred" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rulpred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/rulpred.pdf" class="img-fluid" style="width:95.0%" data-ref-parent="fig-fig:rulpred2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rulpred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) RUL 预测均值和 PDF
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fig:rulpred2" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rulall" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rulall-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/IG/NRL2024/rulall.pdf" class="img-fluid" style="width:95.0%" data-ref-parent="fig-fig:rulpred2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rulall-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) RUL 近似 95% 置信区间
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig:rulpred2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;4.29: 基于锂离子电池退化数据, 两种IG模型的锂离子电池#6的RUL预测结果.
</figcaption>
</figure>
</div>
<!-- ### 总结 {#sec-conclusion} -->
<!-- 本节系统研究了基于非线性IG过程的在线RUL预测. 我们开发了一种复合算法, 通过迭代估计时间尺度变换参数$\beta$及其他参数. 具体而言, 在假设$\beta$已知的情况下, 我们基于闭式估计量推导出其他模型参数的递归公式, 并将其作为使用单步近似法来递归估计$\beta$的输入. 利用递归更新的参数估计, 我们推导出RUL的公式, 并且该公式也可以通过递归方式获得. 此外, 我们将所提出的在线算法扩展至IG随机效应模型. 特别地, 我们提出了带偏差校正的闭式估计量, 从而能够准确且递归地估计IG随机效应模型中的参数. 模拟研究和实际应用表明, 我们提出的算法非常高效, 模型参数的估计值通常在几次迭代内就能收敛到真实值. 更重要的是, RUL也能得到高效且可靠的预测, 从而为后续的在线决策提供支持.  -->
<!-- 有几个潜在的研究主题值得进一步探讨. 首先, 在本研究中, 漂移参数$\nu$假设为每个系统的常数. 然而, 当系统在动态环境中运行时, 随着退化的进展, 漂移参数可能是时间依赖的[@zhai2017rul]. 因此, 研究如何将提出的框架扩展到自适应IG过程模型是一个有趣的问题. 此外, 通过考虑不同的实际场景, IG过程在退化建模中还有其他变体. 本研究应为研究这些更复杂模型提供基础. 最后, 伽马过程\index{伽马过程}作为IG过程的替代, 也被广泛用于建模单调退化数据, 但基于伽马过程\index{伽马过程}的RUL预测在文献中尚未得到充分研究. 将所提出的方法扩展到伽马过程\index{伽马过程}并非易事, 因为伽马过程\index{伽马过程}的闭式ML估计量 (ML估计量) 不存在, 这使得推导递归公式变得困难. 虽然[@paroissin2017online]为平稳伽马过程\index{伽马过程}提出了矩估计量, 但已知这些估计量在有限样本和大样本中均效率不高. 同时, [@ye2017closed]提出了伽马分布的类似闭式ML估计量, 可能可以扩展到平稳伽马过程\index{伽马过程}. 然而, 当考虑时间尺度变换和随机效应时, 扩展这些估计量的过程将极为艰难. 因此, 我们认为需要付出相当大的努力来开发针对伽马过程\index{伽马过程}的有效在线算法.  -->
</section>
</section>
<section id="sec-Append-4C" class="level3" data-number="4.4.6">
<h3 data-number="4.4.6" class="anchored" data-anchor-id="sec-Append-4C"><span class="header-section-number">4.4.6</span> 附录</h3>
<!-- {.unnumbered} -->
<section id="当-beta-已知时-nu-和-lambda-的-mle" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="当-beta-已知时-nu-和-lambda-的-mle">当 <span class="math inline">\(\beta\)</span> 已知时, <span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span> 的 MLE</h4>
<p>在式 <span class="math inline">\(\eqref{iglike}\)</span> 中, 似然函数可写为 <span class="math display">\[\begin{align}\label{nlk}
L(\bm\theta \mid \bm Y_{0:m}) &amp;=C_0 \lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j} \exp \left\{-\frac{\lambda}{2}\left[\sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_{j}^{2}}{\Delta y_{ij}}-\frac{n^2\Lambda_\beta(t_{m})^{2}}{\sum_{i=1}^{n}y_{im}}\right]\right\} \nonumber\\
&amp;\quad\times\exp \left\{-\dfrac{\lambda\sum_{i=1}^{n}y_{im}}{2}
\left(\nu-\dfrac{n\Lambda_\beta(t_{m})}{ \sum_{i=1}^{n}y_{im}}\right)^{2}
\right\}.
\end{align}\]</span> 在 <span class="math inline">\(\eqref{nlk}\)</span> 中, 第一行是 <span class="math inline">\(\lambda\)</span> 的函数 (记为 <span class="math inline">\(G(\lambda)\)</span>) , 而第二行是一个指数函数, 当 <span class="math inline">\(\nu=n\Lambda_\beta(t_{m})/\sum_{i=1}^{n}y_{im}\)</span> 时达到最大值. 另一方面, 当 <span class="math display">\[\lambda=\dfrac{nm}{ \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{ij}}-\frac{n^2\Lambda^2_\beta(t_m)} {\sum_{i=1}^{n}y_{im}}}\]</span> 时, <span class="math inline">\(G(\lambda)\)</span> 达到最大值. 此时, <span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span> 的MLE如 <span class="math inline">\(\eqref{eq:mle}\)</span> 所示.</p>
</section>
<section id="beta-的-fisher-信息的推导" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="beta-的-fisher-信息的推导"><span class="math inline">\(\beta\)</span> 的 Fisher 信息的推导</h4>
<p>给定第 <span class="math inline">\(j\)</span> 个增量 <span class="math inline">\(\Delta \mathcal{y}_j = (\Delta y_{i,j},\dots,\Delta y_{n,j})\)</span> 时, <span class="math inline">\(\beta\)</span> 的对数似然函数为<span class="math inline">\(l_j(\beta)\)</span>. 对 <span class="math inline">\(l_j(\beta)\)</span>关于<span class="math inline">\(\beta\)</span>求一阶导数, 可得 <span class="math display">\[\begin{equation*}
\dfrac{\partial  l_j(\beta \mid \Delta\bm y_j) }{\partial \beta}
=\dfrac{ n\Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}+n\nu\lambda \Delta\Lambda_{j}^{'}-\sum_{i=1}^{n}\dfrac{\lambda  \Delta\Lambda_{j}^{'} \Delta\Lambda_{j}}{\Delta y_{i,j}},
\end{equation*}\]</span> 对 <span class="math inline">\(l_j(\beta)\)</span>关于<span class="math inline">\(\beta\)</span>求二阶导数, 可得 <span class="math display">\[\begin{align*}
\dfrac{\partial^2 l_j(\beta \mid \Delta \bm y_j) }{\partial \beta^2}
&amp;=n\left[\dfrac{ \Delta\Lambda_{j}^{''}}{ \Delta\Lambda_{j}}-
\left(\dfrac{ \Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2
+\nu\lambda \Delta\Lambda_{j}^{''}\right]\\
&amp;\quad -\sum_{i=1}^{n}\left[\dfrac{\lambda  \Delta\Lambda_{j}^{''} \Delta\Lambda_{j}}{\Delta y_{i,j}}+\dfrac{\lambda  (\Delta\Lambda_{j}^{'})^2}{\Delta y_{i,j}}\right],
\end{align*}\]</span> 其中 <span class="math inline">\(\Delta\Lambda_{j}^{'}\)</span> 和 <span class="math inline">\(\Delta\Lambda_{j}^{''}\)</span> 分别是 <span class="math inline">\(\Delta\Lambda_{j}\)</span> 关于 <span class="math inline">\(\beta\)</span> 的一阶和二阶导数. 由于 <span class="math inline">\(\Delta y_{i,j}\sim \textrm{\textrm{IG}}(\Delta\Lambda_j/\nu,\lambda\Delta\Lambda_j^2)\)</span>, 可以计算出 <span class="math inline">\(1/\Delta y_{i,j}\)</span> 的期望为 <span class="math display">\[E\left[\dfrac{1}{\Delta y_{i,j}}\right]=\dfrac{\nu}{\Delta\Lambda_j}+
\dfrac{1}{\lambda\Delta\Lambda_j^2}.\]</span> 因此, 给定观测值 <span class="math inline">\(\Delta y_{i,j}\)</span>, <span class="math inline">\(\beta\)</span> 的 Fisher 信息为<br>
<span class="math display">\[\begin{equation*}
I_j(\beta \mid \nu,\lambda)=-E\left[\dfrac{\partial^2  l_j(\beta \mid \Delta \bm y_j) }{\partial \beta^2}\right]=n\left[
\dfrac{\nu\lambda (\Delta\Lambda_{j}^{'})^2}{\Delta\Lambda_{j}}+
2\left(\dfrac{ \Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2\right].
\end{equation*}\]</span></p>
</section>
<section id="参数的可识别性和离线估计" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="参数的可识别性和离线估计">参数的可识别性和离线估计</h4>
<p>需要证明当 <span class="math inline">\(n\)</span> 个系统仅被测量一次时, 参数是不可识别的. 给定 <span class="math inline">\(\mathcal{y}_1 = (y_{1,1},\dots,y_{n,1})\)</span>, <span class="math inline">\(\bm\theta\)</span> 的对数似然函数为<br>
<span class="math display">\[l(\boldsymbol{\theta}  \mid  \mathcal{y}_1)=C+\dfrac{n}{2}\log\lambda+n\log\Lambda_\beta(t_1)-\lambda\sum_{i=1}^{n}\dfrac{1}{2y_{i,1}}(\nu y_{i,1}-\Lambda_\beta(t_1))^2. \]</span> 根据式 <span class="math inline">\(\eqref{eq:mle}\)</span>, 在给定 <span class="math inline">\(\beta\)</span> 的情况下, <span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span> 的MLE分别为 <span class="math display">\[\dfrac{n\Lambda_\beta(t_1)}{\sum_{i=1}^{n}y_{i1}} \quad \text{和} \quad
\dfrac{n}{\sum_{i=1}^{n}\frac{1}{y_{i1}}(\nu y_{i1}-\Lambda_\beta(t_1))^2}. \]</span> 将这两个估计量代入 <span class="math inline">\(l(\boldsymbol{\theta} \mid \mathcal{y}_1)\)</span> 中, 得到 <span class="math inline">\(\beta\)</span> 的轮廓似然函数为 <span class="math display">\[pl_1(\beta)=C_1-n\log\Lambda_\beta(t_1)+n\log\Lambda_\beta(t_1)-n/2=C_1-n/2,\]</span> 其中 <span class="math inline">\(C_1\)</span> 是一个与 <span class="math inline">\(\beta\)</span> 无关的常数. 因此, <span class="math inline">\(\beta\)</span> 是不可识别的, 因为 <span class="math inline">\(pl_1(\beta)\)</span> 对于任意的 <span class="math inline">\(\beta\)</span> 值均为常数. 这个结果是比较直观的, 因为一条曲线的形状仅通过两个点无法确定. 因此, 为了获得参数的MLE并运用在线算法, 至少需要两次测量. 在实际应用中, 通过前三个测量时间点 <span class="math inline">\(t_1\)</span>、<span class="math inline">\(t_2\)</span> 和 <span class="math inline">\(t_3\)</span> 收集的观测数据, <span class="math inline">\(\nu\)</span> 和 <span class="math inline">\(\lambda\)</span> 的MLE分别为 <span class="math display">\[\hat{\nu}^{(3)}=\dfrac{n\Lambda_{\hat{\beta}^{(3)}}(t_3)}
{\sum_{i=1}^{n}y_{i,3}}, ~\quad
\hat{\lambda}^{(3)}=\dfrac{3n}{ \sum_{i=1}^{n}\sum_{j=1}^{3} \dfrac{\Delta\tilde{\Lambda}_j^2}{\Delta y_{i,j}}-\dfrac{n^2\Lambda^2_{\hat{\beta}^{(3)}}(t_3)}
    {\sum_{i=1}^{n}y_{i,3}}},\]</span> 其中 <span class="math inline">\(\Delta \tilde{\Lambda}_j\)</span> 是<span class="math inline">\(\Delta \Lambda_j\)</span> 的估计, <span class="math inline">\(\beta\)</span> 被替换为<span class="math inline">\(\hat{\beta}^{(3)}\)</span>, 而 <span class="math inline">\(\hat{\beta}^{(3)}\)</span> 可通过最大化以下轮廓似然函数得到. <span class="math display">\[pl_3(\beta)=C_3-\frac{3n}{2}\log\left[\sum_{i=1}^{n}\sum_{j=1}^{3} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{n^2\Lambda^2_\beta(t_3)}
{\sum_{i=1}^{n}y_{i,3}}\right]+
n\sum_{j=1}^{3}\log\Delta\Lambda_j,\]</span> 其中 <span class="math inline">\(C_3\)</span> 是与 <span class="math inline">\(\beta\)</span> 无关的常数.</p>
<p>对于含随机效应的 IG 模型, <span class="math inline">\(\bm\Theta=(\lambda,\nu_1,\dots,\nu_n,\beta)\)</span> 的似然函数为 <span class="math display">\[\begin{align}\label{nlkre}
    L(\bm\Theta \mid \bm Y_{0:m}) &amp;=C_0 \lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j} \exp \left\{-\frac{\lambda}{2}\sum_{i=1}^{n}\left[\sum_{j=1}^{m} \frac{\Delta\Lambda_{j}^{2}}{\Delta y_{ij}}-\frac{n^2\Lambda_\beta(t_{m})^{2}}{\sum_{i=1}^{n}y_{im}}\right]\right\} \nonumber\\
    &amp;\quad\times\exp\left\{-\dfrac{\lambda}{2}\sum_{i=1}^{n}y_{im}\left(\nu_i-\dfrac{\Lambda_\beta(t_{m})}{ y_{im}}\right)^{2} \right\}.
  \end{align}\]</span> 此时可以得到<span class="math inline">\(\eqref{eq:remle}\)</span> 中的 <span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\nu_i\)</span> 的MLE. 再将 <span class="math inline">\(\lambda\)</span> 和 <span class="math inline">\(\nu_i\)</span> 替换为MLE, 可得 <span class="math inline">\(\beta\)</span> 的轮廓似然函数, 即, <span class="math display">\[\begin{equation}\label{inilams}
    pl^\ast_m(\beta)=C_4-\frac{mn}{2}\log\sum_{i=1}^{n}\left[\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_m)}
    {y_{i,m}}\right]+
    n\sum_{j=1}^{m}\log\Delta\Lambda_j,
\end{equation}\]</span> 其中 <span class="math inline">\(C_4\)</span> 是与 <span class="math inline">\(\beta\)</span> 无关的常数. <span class="math inline">\(\beta\)</span> (即 <span class="math inline">\(m=3\)</span>) 的初始估计量可通过最大化轮廓似然函数 <span class="math inline">\(pl^\ast_m(\beta)\)</span> 进行数值求解.</p>
</section>
<section id="理论-thm-nrl2024-th1-证明" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="理论-thm-nrl2024-th1-证明">理论 <a href="#thm-NRL2024-th1" class="quarto-xref"><span>4.5</span></a> 证明</h4>
<p>为了方便表示, 做以下定义. <span class="math display">\[\begin{align*}
\ell^{(j)}(\boldsymbol{\theta}; \Delta y_j)\equiv \frac{1}{2}\log\left(\frac{\lambda}{2\pi}\right) + \log(\Delta\Lambda_j) - \frac{3}{2}\log(\Delta y_{j}) - \frac{\lambda}{2\Delta y_j}(\nu \Delta y_j - \Delta \Lambda_j)^2,
\end{align*}\]</span> 并且<span class="math inline">\(\ell^m(\boldsymbol{\theta}; \Delta Y) \equiv \sum_{j=1}^m \ell^{(j)}(\boldsymbol{\theta}; \Delta y_j)\)</span> 表示单系统的对数似然函数.</p>
<p>令 <span class="math inline">\(\mathcal{I}^{(j)} = P\ddot{\ell}^{(j)}(\nu_0, \lambda_0, \beta_0)\)</span> 表示基于第<span class="math inline">\(j\)</span>次检测时间点的Fisher信息矩阵, 它可以表示为矩阵块的形式 <span class="math display">\[\begin{align*}
\mathcal{I}^{(j)} \equiv \left(\begin{array}{ccccc}
\mathcal{I}_{(\nu, \lambda)}^{(j)} &amp;\mathcal{I}_{(\nu, \lambda),\beta}^{(j)}\\
\mathcal{I}_{\beta, (\nu, \lambda)}^{(j)} &amp;\mathcal{I}_{\beta}^{(j)}
\end{array}\right),\quad \mathcal{I}_{(\nu, \lambda)}^{(j)}\in\mathbb{R}^{2\times 2}, \quad \mathcal{I}_{(\nu, \lambda),\beta}^{(j)} = \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)} \in\mathbb{R}^{2\times 1},
\end{align*}\]</span> 其中下标 <span class="math inline">\((\nu, \lambda)\)</span> 对应于 <span class="math inline">\((\nu, \lambda)\)</span> 的维度, 而下标 <span class="math inline">\(\beta\)</span> 对应于 <span class="math inline">\(\beta\)</span> 的维度. 令 <span class="math inline">\(\mathcal{I}^{m} = \sum_{j=1}^m \mathcal{I}^{(j)}\)</span>, 并以类似的方式定义 <span class="math inline">\(\mathcal{I}{(\nu, \lambda)}^{m}\)</span>、<span class="math inline">\(\mathcal{I}{(\nu, \lambda),\beta}^{m}\)</span> 和 <span class="math inline">\(\mathcal{I}_{\beta}^{m}\)</span>.</p>
<p>首先, 通过经典的大样本理论, 可以确立初始MLE <span class="math inline">\(\nu^{(3)}\)</span>、<span class="math inline">\(\lambda^{(3)}\)</span> 和 <span class="math inline">\(\beta^{(3)}\)</span> 的一致性. 目标是在 <span class="math inline">\(\nu^{(m)}\)</span>、<span class="math inline">\(\lambda^{(m)}\)</span> 和 <span class="math inline">\(\beta^{(m)}\)</span> 的一致性基础上, 证明对于每个 <span class="math inline">\(m\geq 3\)</span>, <span class="math inline">\(\nu^{(m+1)}\)</span>、<span class="math inline">\(\lambda^{(m+1)}\)</span> 和 <span class="math inline">\(\beta^{(m+1)}\)</span> 也具有一致性. 利用大数定律, 可以得到以下结论. <span class="math display">\[\begin{align*}
n^{-1}\sum_{i=1}^n y_{i, m} &amp;\to_P \frac{\Lambda_{\beta_0}(t_{m})}{\nu},\\
\quad n^{-1}\sum_{i=1}^n \frac{1}{\Delta y_{i, m+1}} &amp; \to_P \frac{\nu_0}{\Delta\Lambda_{\beta_0}(t_{m+1})} + \frac{1}{\lambda_0 \Delta\Lambda_{\beta_0}(t_{m+1})^2}.
\end{align*}\]</span> 如果 <span class="math inline">\(\beta^{(m)}\to_P \beta_0\)</span>, 由于 <span class="math inline">\(\Lambda_\beta(t)\)</span> 关于 <span class="math inline">\(\beta\)</span> 的可微性, 利用连续映射定理可以得到 <span class="math display">\[\begin{align*}
\Lambda_{\beta^{(m)}}(t_m) &amp; \to_P \Lambda_{\beta_0}(t_m),\\
\Delta\Lambda_{\beta^{(m)}}(t_{m+1}) &amp;\to_P \Delta\Lambda_{\beta_0}(t_{m+1}).
\end{align*}\]</span> 再次使用连续映射定理, 得到 <span class="math display">\[\nu^{(m+1)} = \Lambda_{\beta^{(m)}}(t_m)/(n^{-1}\sum_{i=1}^n y_{i, m}) \to_P \nu_0\]</span> <span class="math display">\[\begin{align*}
\lambda^{(m+1)} &amp;= (m+1)\Bigg\{m/\hat{\lambda}^{(m)} + \left[\hat{\nu}^{(m)}\right]^2 n^{-1}\sum_{i=1}^n y_{i, m}\\
&amp; \quad - \left[\hat{\nu}^{(m+1)}\right]^2 n^{-1}\sum_{i=1}^n y_{i, m+1} + \Delta\Lambda^2_{\hat{\beta}^{(m)}}(t_{m+1}) n^{-1}\sum_{i=1}^n/\Delta y_{i, m+1}\Bigg\}^{-1}\\
&amp;\to_P (m+1)\Big\{m/\lambda_0 - \nu n^{-1}\Delta\Lambda_{\beta_0}(t_{m+1}) \\
&amp; \quad + \Delta\Lambda^2_{\beta_0}(t_{m+1}) \left[\nu_0/\Delta\Lambda^2_{\beta_0}(t_{m+1}) + (\lambda_0\Delta\Lambda^2_{\beta_0}(t_{m+1}))^{-1}\right]\Big\}^{-1} = \lambda_0,
\end{align*}\]</span> 其中, 后一项的弱收敛依赖于 <span class="math inline">\(\nu^{(m+1)}\)</span> 的一致性. 要利用一致的 <span class="math inline">\(\nu^{(m+1)}\)</span> 和 <span class="math inline">\(\lambda^{(m+1)}\)</span> 去证明 <span class="math inline">\(\beta^{(m+1)}\)</span> 的一致性, 需要以下引理.</p>
<div id="lem-Donsker-class" class="theorem lemma">
<p><span class="theorem-title"><strong>引理 4.1</strong></span> 若 <span class="math inline">\(\Delta \Lambda_j\)</span> 关于 <span class="math inline">\(\beta\)</span> 在 <span class="math inline">\(\beta_0\)</span> 的邻域内是二阶连续可微的, 存在 <span class="math inline">\(\delta &gt; 0\)</span> 使得函数类 <span class="math inline">\(\mathcal{F}_\delta\)</span> 是 Donsker 类, 其中 <span class="math display">\[\begin{align*}
\mathcal{F}_\delta &amp;\equiv \left\{\dot{\ell}^m(\boldsymbol{\theta}; \Delta Y) - \dot{\ell}^m(\boldsymbol{\theta}_0; \Delta Y): \Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert \leq \delta\right\},
\end{align*}\]</span> 且 <span class="math inline">\(\dot{\ell}^m(\boldsymbol{\theta}; \Delta Y)\)</span> 是 <span class="math inline">\(\ell^m(\boldsymbol{\theta};\Delta Y)\)</span> 关于 <span class="math inline">\((\nu, \lambda, \beta)\)</span> 的导数. 对于每一个满足 <span class="math inline">\(\tilde{\boldsymbol{\theta}}_n\to_P \boldsymbol{\theta}_0\)</span> 的序列 <span class="math inline">\({\tilde{\boldsymbol{\theta}}n}{n=1}^\infty\)</span> 有 <span class="math display">\[\begin{align*}
\mathbb{G}_n \left[\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right] \equiv \sqrt{n}(\mathbb{P}_n - P)\left[\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right] = o_P(1).
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>证明</em>. </span>对于任意 <span class="math inline">\(M &gt; 0\)</span>, 存在 <span class="math inline">\(\delta &gt; 0\)</span>, 使得当 <span class="math inline">\(\Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta\)</span> 时, <span class="math inline">\(\Delta\Lambda_j\)</span>、<span class="math inline">\(\Delta\Lambda_j'\)</span> 和 <span class="math inline">\(\Delta\Lambda_j''\)</span> 都是上有界且远离零的. 因此可以得到 <span class="math display">\[\begin{align*}
\left\Vert\ddot{\ell}^m(\boldsymbol{\theta}; \Delta Y)\right\Vert \lesssim (\sum_{j=1}^m \Delta y_j)\bigvee (\sum_{j=1}^m \Delta 1/y_j),
\end{align*}\]</span> 其中右侧是可积函数. 由于二阶导数在 <span class="math inline">\(\Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta\)</span> 上一致有界, 存在一个函数 <span class="math inline">\(h(y)\)</span> 使得以下的 Lipschitz 条件成立. <span class="math display">\[\begin{align*}
\Vert \dot{\ell}^m(\boldsymbol{\theta}_1; \Delta Y) - \dot{\ell}^m(\boldsymbol{\theta}_2; \Delta Y)\Vert \leq h(y)\Vert \boldsymbol{\theta}_1 - \boldsymbol{\theta}_2\Vert, \ \text{任意}\ \boldsymbol{\theta}_1, \boldsymbol{\theta}_2.
\end{align*}\]</span> 因此, 类似于 <span class="citation" data-cites="van2000asymptotic">(<a href="references.html#ref-van2000asymptotic" role="doc-biblioref">Van der Vaart, 1998</a>)</span> 中的例子 19.7, <span class="math inline">\(\mathcal{F}_\delta\)</span> 的包围数满足 <span class="math display">\[\begin{align*}
N_{[\ ]}(\epsilon\Vert h\Vert_{L_2(P_0)}, \mathcal{F}_{\delta}, L_2(P_0)) \lesssim (\delta/\epsilon)^3, \ \forall  0&lt;\epsilon&lt;\delta.
\end{align*}\]</span> 因此, 包围积分是有限的, 这意味着 <span class="math inline">\(\mathcal{F}_\delta\)</span> 是 Donsker 类.</p>
<p>接下来证明 <span class="math inline">\(\mathbb{G}_n \left[\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right] = o_{P}(1)\)</span>. 类似于 <span class="math inline">\(\ddot{\ell}^m(\boldsymbol{\theta}; \Delta Y)\)</span> 的构造, 可以证明函数类 <span class="math inline">\(\mathcal{F}_\delta\)</span> 被平方可积函数所界定. 因此, 通过对 <span class="math inline">\(\tilde{\boldsymbol{\theta}}_n\)</span> 的几乎处处收敛子序列进行讨论, 使用支配收敛定理, 得到 <span class="math display">\[\begin{align*}
P_0 \left[ \dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right]^2 \to_P 0.
\end{align*}\]</span> 因此, <a href="#lem-Donsker-class" class="quarto-xref"><span>4.1</span></a> 引理的第二部分可以通过 [<span class="citation" data-cites="van2000asymptotic">Van der Vaart (<a href="references.html#ref-van2000asymptotic" role="doc-biblioref">1998</a>)</span>] 中的定理 19.24 推导得出.</p>
</div>
<p>此时可利用 <span class="math inline">\((\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})\)</span> 依概率收敛于 <span class="math inline">\((\nu_0, \lambda_0)\)</span> 来证明 <span class="math inline">\(\hat{\beta}^{(m+1)}\)</span> 的一致性. 根据在线算法, 估计量 <span class="math inline">\(\hat{\beta}^{(m+1)}\)</span> 表达式如下. <span class="math display">\[\begin{align*}
\hat{\beta}^{(m+1)} = \hat{\beta}_n^{(m)} + \widetilde{V}_{m+1}^{-1} n\mathbb{P}_n \dot{\ell}^{(m+1)}(\hat{\nu}_n^{(m+1)}, \hat{\lambda}_n^{(m+1)}, \hat{\beta}_n^{(m)}).
\end{align*}\]</span> 根据假设, 第一项 <span class="math inline">\(\hat{\beta}^{(m)}\)</span> 以概率收敛到 <span class="math inline">\(\beta_0\)</span>. 类似于引理 <a href="#lem-Donsker-class" class="quarto-xref"><span>4.1</span></a> 的证明, 序列 <span class="math display">\[{\ell^{(m+1)}(\boldsymbol{\theta}) - \ell^{(m+1)}(\boldsymbol{\theta}_0): \Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta}\]</span> 形成一个 Donsker 类, 这意味着: <span class="math display">\[\begin{align*}
\mathbb{P}_n \dot{\ell}^{(m+1)}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) = o_P(n^{-1/2}).
\end{align*}\]</span> 由于每个 <span class="math inline">\(I_j\)</span> 都是关于 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的连续函数, 利用连续映射定理得到 <span class="math display">\[n\widetilde{V}_{m+1}(\hat{\nu}_n^{(m+1)}, \hat{\lambda}_n^{(m+1)}, \hat{\beta}_n^{(m)}) = O_P(1).
\]</span> 因此, 第二项是 <span class="math inline">\(O_P(n^{-1/2}) = o_P(1)\)</span>. 综上所述, <span class="math inline">\(\hat{\beta}_n^{(m+1)} \to_P \beta_0\)</span>.</p>
<p>接下来, 通过利用 <span class="math inline">\((\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(j)})\)</span> 在 <span class="math inline">\(j = 3, \cdots, m\)</span> 时的收敛速度, 建立 <span class="math inline">\((\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)})\)</span> 的渐近正态性. 为此, 提供一个关于 <span class="math inline">\((\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)})\)</span> 渐近分布的递推关系, 并建立 <span class="math display">\[\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)}) - (\nu_0, \lambda_0, \beta_0)\right]
\]</span> 的弱收敛结果. <span class="math inline">\((\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(3)})\)</span> 的 <span class="math inline">\(\sqrt{n}\)</span>-一致性可通过 MLE 估计的 <span class="math inline">\(\sqrt{n}\)</span>-一致性来保证, 后者可通过经典统计方法得到验证. 在此基础上, 通过数学归纳法假设, 对于每个 <span class="math inline">\(j = 3, \cdots, m\)</span>, 估计量 <span class="math inline">\((\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(j)})\)</span> 均满足 <span class="math inline">\(\sqrt{n}\)</span>-一致性. 对于 <span class="math inline">\((\nu, \lambda)\)</span> 的估计量, 因为 <span class="math inline">\((\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})\)</span>最大化了 <span class="math inline">\(\mathbb{P}_n \dot{\ell}^{m+1}(\nu, \lambda, \hat{\beta}^{(m)})\)</span>, 对于固定的 <span class="math inline">\(\hat{\beta}^{(m)}\)</span> 的值有 <span class="math display">\[\begin{align*}
\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, &amp; \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})\\
&amp; \equiv \mathbb{P}_n \left.\frac{\partial}{\partial(\nu, \lambda)}\right|_{(\nu, \lambda)=(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})}\ell^{m+1}(\nu, \lambda, \hat{\beta}^{(m)}) = 0.
\end{align*}\]</span> 通过向量 <span class="math inline">\((\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})\)</span>的一致性, 并使用引理 <a href="#lem-Donsker-class" class="quarto-xref"><span>4.1</span></a> 得到 <span class="math display">\[\begin{align*}
\mathbb{G}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) = \mathbb{G}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0) + o_P(1).
\end{align*}\]</span> 由 <span class="math inline">\(P\dot{\ell}^{m+1}(\nu_0, \lambda_0, \beta_0) = 0\)</span> 得 <span class="math display">\[\begin{align*}
\sqrt{n}\Big[P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, &amp;\hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})
- P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)\Big]\\
&amp; = -\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0) + o_P(1)
\end{align*}\]</span> 对于每一个 <span class="math inline">\(j\)</span>, 得分函数的期望可以写为 <span class="math display">\[\begin{align*}
P\dot{\ell}_{(\nu, \lambda)}^{(j)}(\boldsymbol{\theta})
=\left(\begin{array}{cccc}- \lambda( \Delta \Lambda_{j;0} - \Delta \Lambda_j)\\
\frac{\Delta \Lambda_{j;0}^2 - \Delta \Lambda_{j}^2 - \nu\lambda(\Delta \Lambda_{j;0} - \Delta \Lambda_{j})^2}{2\lambda\Delta \Lambda_{j;0}^2}
\end{array}\right),
\end{align*}\]</span> 函数 <span class="math inline">\(\boldsymbol{\theta}\mapsto P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\boldsymbol{\theta})\)</span>是连续可微的. 因此有 <span class="math display">\[\begin{align*}
&amp;\sqrt{n}\left[P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) - P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)\right]\\
&amp;= -\mathcal{I}_{(\nu, \lambda)}^{m+1}\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right] - \mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)} - \beta_0) \\
&amp;\quad + O_P\left(\sqrt{n}\Vert(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\Vert^2 + \sqrt{n}\Vert \hat{\beta}^{(m)} - \beta_0\Vert^2\right).
\end{align*}\]</span> 使用 <span class="math inline">\(\hat{\beta}^{(m)}\)</span> 的 <span class="math inline">\(\sqrt{n}\)</span> 一致性和 <span class="math inline">\(\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)\)</span>, 得到 <span class="math display">\[
(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0) = O_p(n^{-1/2}),
\]</span> 这进一步意味着如下近似关系. <span class="math display">\[\begin{align}
&amp;\mathcal{I}_{(\nu, \lambda)}^{m+1}\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right]\nonumber\\
&amp;= \sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)
- \mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)} - \beta_0) + o_P(1).\label{eq: iteration for alpha+beta}
\end{align}\]</span> 对于 <span class="math inline">\(\beta\)</span> 的估计, 迭代算法由以下公式给出 <span class="math display">\[\begin{align*}
\hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + \widetilde{V}_{m+1} n\mathbb{P}_n \dot{\ell}_\beta^{(m+1)}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}).
\end{align*}\]</span> 假设以下方程对 <span class="math inline">\(m\geq 4\)</span> 都成立 <span class="math display">\[\begin{align}\label{eq: iteration assymption for lambda_(m+1)}
\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m)}) + \sum_{j=4}^m \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)}) = o_P(n^{-1/2}).
\end{align}\]</span> 实际上, 根据MLE估计的定义, 有 <span class="math inline">\(\mathbb{P}n \dot{\ell}\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(3)}) = o_P(n^{-1/2})\)</span>. 接着, 将通过递归关系证明该等式在 <span class="math inline">\(m=4\)</span> 时成立, 并假设当方程 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 对 <span class="math inline">\(m\)</span> 成立时, 它对 <span class="math inline">\(m+1\)</span> 也成立. 再将利用递推关系证明该等式在 <span class="math inline">\(m=4\)</span> 的情况下成立, 并在此基础上, 假设方程 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 对 <span class="math inline">\(m\)</span> 成立, 则其对 <span class="math inline">\(m+1\)</span> 也成立. 若方程 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 成立, 可以推导出以下结论. <span class="math display">\[\begin{align}
&amp;n\widetilde{V}_{m+1}^{-1}(\hat{\beta}^{(m+1)}-\beta_0) - n\widetilde{V}_{m+1}^{-1}(\hat{\beta}^{(m)} - \beta_0)\nonumber\\
&amp;= \mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)}) + o_P(n^{-1/2}).\label{eq: expansion for lambda_(m+1)}
\end{align}\]</span> 根据 <span class="math inline">\((\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})\)</span> 的一致性以及引理 <a href="#lem-Donsker-class" class="quarto-xref"><span>4.1</span></a> , 可得以下结论. <span class="math display">\[\begin{align*}
\mathbb{G}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})
- \mathbb{G}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0) = o_P(1),\ \text{任意}\ 1\leq j\leq m+1,
\end{align*}\]</span> 这意味着<span class="math inline">\(\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})\)</span> 可以表示为 <span class="math display">\[\begin{align*}
\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})
&amp;= \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0)
-\mathcal{I}_{\beta}^{(j)}(\hat{\beta}^{(m)} - \beta_0)\\
&amp; \quad - \mathcal{I}_{(\nu,\lambda),\beta}^{(j)}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] + O_P(n^{-1/2}).
\end{align*}\]</span> 因此, <span class="math inline">\(\eqref{eq: expansion for lambda_(m+1)}\)</span> 的右侧可以表示为 <span class="math display">\[\begin{align*}
&amp;\mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0)
- \mathcal{I}_{\beta}^{m+1}(\hat{\beta}^{(m)} - \beta_0) + \sum_{j=4}^{m+1} \mathcal{I}_{\beta,(\nu, \lambda)}^{(j)}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] \\
&amp;+ \mathcal{I}_{\beta, (\nu, \lambda)}^{3}\left[(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right] + o_P(n^{-1/2}).
\end{align*}\]</span> </p>
<p>借助 <span class="math inline">\(n\widetilde{V}{m+1}^{-1}\to_P \mathcal{I}{\beta}^{m+1}\)</span> 这一事实, 可以得到以下近似关系. <span class="math display">\[\begin{align}
\mathcal{I}_{\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m+1)}-\beta_0)
&amp;= \sqrt{n}\mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0)
- \mathcal{I}_{\beta, (\nu, \lambda)}^{3}\sqrt{n}\left[(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right]\nonumber\\
&amp;\quad - \sum_{j=4}^{m+1} \mathcal{I}_{\beta,(\nu, \lambda)}^{(j)}\sqrt{n}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] + o_P(1).\label{eq: asymptotic form for lambda_(m+1)}
\end{align}\]</span> 因此证得 <span class="math inline">\(\hat{\beta}^{(m+1)}-\beta_0 = O_P(n^{-1/2})\)</span>.</p>
<p>接下来证明渐近性质可以从 <span class="math inline">\(m\)</span> 传递到 <span class="math inline">\(m+1\)</span>, 即 <span class="math display">\[\begin{align*}
\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m+1)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)}) = o_P(n^{-1/2}).
\end{align*}\]</span> 再次使用引理 <a href="#lem-Donsker-class" class="quarto-xref"><span>4.1</span></a> , 对于每一个 <span class="math inline">\(j\)</span> 有 <span class="math display">\[\begin{align*}
&amp;\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)}) \\
&amp;= \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0) - \mathcal{I}_{\beta}^{(j)}\left[\hat{\beta}^{(m+1)} - \beta_0\right] - \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] + o_P(n^{-1/2}).\\
&amp;\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m+1)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)})\\
&amp;= \mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0) -\mathcal{I}_{\beta}^{m+1}\left(\hat{\beta}^{(m+1)} - \beta_0\right) -\mathcal{I}_{\beta, (\nu, \lambda)}^{3}\left[(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right] \\
&amp;- \sum_{j=4}^{m+1}\mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] + o_P(n^{-1/2}).
\end{align*}\]</span> 再利用式 <span class="math inline">\(\eqref{eq: asymptotic form for lambda_(m+1)}\)</span> 将 <span class="math inline">\(\hat{\beta}n^{(m+1)} - \beta_0\)</span> 进行替换, 可以得到右侧等于 <span class="math inline">\(o_P(n^{-1/2})\)</span>, 从而证明了式 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 对于 <span class="math inline">\(m+1\)</span> 成立. 因此, 公式 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 对于每个 <span class="math inline">\(m \geq 4\)</span> 都成立.</p>
<p>最后, 需推导 <span class="math inline">\(\Sigma_{m+1}\)</span> 的渐近协方差. 对于 <span class="math inline">\(m=3\)</span>, 利用MLE的渐近性质, 可以得到 <span class="math display">\[\begin{align*}
\sqrt{n}\left[(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right]
&amp;= (\tilde{\mathcal{I}}_{(\nu, \lambda)}^3)^{-1} \left(I_2, -\mathcal{I}_{(\nu, \lambda), \beta}^3\left(\mathcal{I}_{\beta}^3\right)^{-1} \right)\sqrt{n}\mathbb{P}\dot{\ell}^3(\boldsymbol{\theta}_0) + o_P(1),\\
\sqrt{n}\left(\hat{\beta}^{(3)} - \beta_0\right)
&amp;=  \left(-(\tilde{\mathcal{I}}_\beta^3)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}, (\tilde{\mathcal{I}}_\beta^3)^{-1} \right)\sqrt{n}\mathbb{P}\dot{\ell}^3(\boldsymbol{\theta}_0) + o_P(1),
\end{align*}\]</span> 其中<span class="math inline">\(I_2\)</span> 是 2×2 的单位矩阵, <span class="math inline">\(\tilde{\mathcal{I}}_{(\nu, \lambda)}^3\)</span>和 <span class="math inline">\(\tilde{\mathcal{I}}_{\beta}^3\)</span> 分别表示有效信息矩阵, 其定义如下. <span class="math display">\[\begin{align*}
\tilde{\mathcal{I}}_{(\nu, \lambda)}^3 &amp;= \mathcal{I}_{(\nu, \lambda)}^3 - \mathcal{I}_{(\nu, \lambda), \beta}^3\left(\mathcal{I}_{\beta}^3\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3,\\
\tilde{\mathcal{I}}_{\beta}^3 &amp;= \mathcal{I}_{\beta}^3 - \mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}\mathcal{I}_{(\nu, \lambda), \beta}^3.
\end{align*}\]</span> 对于 <span class="math inline">\(m=4\)</span>, 根据递推关系有 <span class="math display">\[\begin{align*}
\sqrt{n}&amp;\left[(\hat{\nu}^{(4)}, \hat{\lambda}^{(4)}) - (\nu_0, \lambda_0)\right]\\
&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left[\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{4}(\boldsymbol{\theta}_0)
- \mathcal{I}_{(\nu, \lambda),\beta}^{4}\sqrt{n}(\hat{\beta}^{(3)} - \beta_0)\right]+ o_P(1) \\
&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left(I_2 + \mathcal{I}_{(\nu, \lambda),\beta}^{4}\left(\tilde{\mathcal{I}}_{\beta}^3\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}, \mathcal{I}_{(\nu, \lambda),\beta}^{4}\left(\tilde{\mathcal{I}}_{\beta}^3\right)^{-1}\right)\sqrt{n}\mathbb{P}_n\dot{\ell}^3(\boldsymbol{\theta}_0) \\
&amp;\quad + \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n\dot{\ell}^{(4)}(\boldsymbol{\theta}_0) + o_P(1),\\
\sqrt{n}&amp;(\hat{\beta}^{(4)}-\beta_0)\\
&amp;= \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\left\{\sqrt{n}\mathbb{P}_n \dot{\ell}_\beta^{4}(\boldsymbol{\theta}_0)
- \mathcal{I}_{\beta, (\nu, \lambda)}^{3}\sqrt{n}\left[(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right] \right. \\
&amp;\quad \left. - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)}\sqrt{n}\left[(\hat{\nu}^{(4)}, \hat{\lambda}^{(4)}) - (\nu_0, \lambda_0)\right]\right\} + o_P(1)\\
&amp;= \left(\begin{array}{cccc}
-\left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3(\tilde{\mathcal{I}}_{\beta}^3)^{-1} - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)} - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)}\mathcal{I}_{(\nu, \lambda), \beta}^4 (\tilde{\mathcal{I}}_{\beta}^3)^{-1} \mathcal{I}_{\beta, (\nu, \lambda)}^3 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}\\
\left(\mathcal{I}_{\beta}^{4}\right)^{-1} + \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3(\tilde{\mathcal{I}}_{\beta}^3)^{-1} \mathcal{I}_{(\nu, \lambda), \beta}^3 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}
-\mathcal{I}_{\beta,(\nu, \lambda)}^{(4)}\mathcal{I}_{(\nu, \lambda), \beta}^4 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}
\end{array}\right)^\top\\
&amp;\quad \times \sqrt{n}\mathbb{P}_n \dot{\ell}^3(\boldsymbol{\theta}_0) + \left(-\left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta,(\nu, \lambda)}^{(4)}(\mathcal{I}_{(\nu, \lambda)}^4)^{-1}, \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{(4)}(\boldsymbol{\theta}_0) + o_P(1),
\end{align*}\]</span> 其中<span class="math inline">\(\sqrt{n}\mathbb{P}_n \ell^3(\boldsymbol{\theta}_0)\leadsto N(0, \mathcal{I}^{3})\)</span> 和 <span class="math inline">\(\sqrt{n}\mathbb{P}_n \ell^{(4)}(\boldsymbol{\theta}_0)\leadsto N(0, \mathcal{I}^{(4)})\)</span>是独立的. 结合这两个近似结果, 可以得到 <span class="math inline">\(\Sigma_4\)</span> 的表达式.</p>
<p>要建立对于每个 <span class="math inline">\(m \geq 4\)</span> 的渐近协方差 <span class="math inline">\(\Sigma_{m+1}\)</span>, 注意 <span class="math inline">\(\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)\)</span> 可以表示为 <span class="math display">\[\begin{align*}
\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)
&amp;= A_{m,3}\sqrt{n}\mathbb{P}_n \dot{\ell}^3(\boldsymbol{\theta}_0) + A_{m,4}\sqrt{n}\mathbb{P}_n \dot{\ell}^{(4)}(\boldsymbol{\theta}_0)\\
&amp; \quad + \cdots + A_{m,m}\sqrt{n}\mathbb{P}_n \dot{\ell}^{(m)}(\boldsymbol{\theta}_0),
\end{align*}\]</span> 其中<span class="math inline">\(A_{m, 3}, \cdots, A_{m, m}\)</span> 是 <span class="math inline">\(3 \times 1\)</span> 的矩阵. 接下来为这些系数矩阵建立一个递推关系. 根据 <span class="math inline">\(\sqrt{n}(\hat{\beta}^{(m)} - \beta_0)\)</span> 的近似式, 得到 <span class="math display">\[\begin{align*}
&amp;\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right]\\
&amp; = \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{m+1}(\boldsymbol{\theta}_0) - \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)\\
&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left\{\left[\left(I_2, 0\right) - A_{m, 3}\right]\sqrt{n}\mathbb{P}_n \dot{\ell}^{3}(\boldsymbol{\theta}_0) + \sum_{j=4}^{m} \left[\left(I_2, 0\right) - A_{m, j}\right]\sqrt{n}\mathbb{P}_n \dot{\ell}^{(j)}(\boldsymbol{\theta}_0)\right\}\\
&amp;\quad + \sum_{j=4}^{m} \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{(m+1)}(\boldsymbol{\theta}_0).
\end{align*}\]</span> 再利用式 <span class="math inline">\(\eqref{eq: iteration assymption for lambda_(m+1)}\)</span> 中关于<span class="math inline">\(\sqrt{n}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right]\)</span> 的近似, 可以得到 <span class="math display">\[\begin{align*}
A_{m+1, 3} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}\left\{(0,0,1) - \mathcal{I}_{\beta, (\nu, \lambda)}^3 A_{3,3}\vphantom{\sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}}\right.\\
&amp; \quad \left. - \sum_{j=4}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left(\mathcal{I}_{(\nu, \lambda
)}^{j}\right)^{-1}\left[(I_2, 0) - A_{m, 3}\right]\right\},\\
A_{m+1, j} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}\left\{(0,0,1) - \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left(\mathcal{I}_{(\nu, \lambda)}^{j}\right)^{-1}(I_2, 0) \vphantom{\sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}} \right.\\
&amp;\quad \left. - \sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}\left(\mathcal{I}_{(\nu, \lambda)}^{(l)}\right)^{-1}\left[(I_2, 0) - A_{m, l}\right]\right\},\\
A_{m+1, m+1} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}(0,0,1),
\end{align*}\]</span> 其中 <span class="math inline">\(j = 4, \cdots, m\)</span>. 结合 <span class="math inline">\(\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right]\)</span> 和 <span class="math inline">\(\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)\)</span> 的近似, 可以得到协方差矩阵 <span class="math inline">\(\Sigma_{m+1}\)</span>.</p>
</section>
<section id="定理-thm-th2-证明" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="定理-thm-th2-证明">定理 <a href="#thm-th2" class="quarto-xref"><span>4.6</span></a> 证明</h4>
<p>基于 <span class="math inline">\(\eqref{eq:rerul}\)</span>, <span class="math inline">\(\mathcal{X}_m\)</span> 的 CDF 可以表示为 <span class="math inline">\(\mathbb{E}_{\pi(\nu \mid y_m)}[F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)]\)</span>, 并且已知 <span class="math inline">\(\pi(\nu \mid y_m)\)</span> 是一个正态分布, 其均值和方差分别为 <span class="math display">\[\mu_m=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}},\quad \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1}.\]</span> 另一方面, <span class="math inline">\(F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)\)</span> 在 <span class="math inline">\(\eqref{cdfrul}\)</span> 中给出, 由两个部分组成, 其形式为 <span class="math inline">\(\Phi(aX+b)\)</span> 和 <span class="math inline">\(\exp(cX)\Phi(aX+b)\)</span>, 其中 <span class="math inline">\(a\)</span>、<span class="math inline">\(b\)</span> 和 <span class="math inline">\(c\)</span> 为实数. 因此, <span class="math inline">\(F_{\mathcal{X}_m}\left(x \mid \nu\right)\)</span>可以根据以下结果推导 <span class="citation" data-cites="si2013generalized">(<a href="references.html#ref-si2013generalized" role="doc-biblioref">Si 等, 2013</a>)</span>:</p>
<ol type="i">
<li><p>如果 <span class="math inline">\(X\sim \mathcal{N}(w,\delta^2)\)</span>, 且 <span class="math inline">\(a,b\in \mathbb{R}\)</span>, 则有 <span class="math inline">\(\mathbb{E}[\Phi(aX+b)]=\Phi\left(\frac{aw+b}{\sqrt{1+a^2\delta^2}}\right)\)</span>.</p></li>
<li><p>如果 <span class="math inline">\(X\sim \mathcal{N}(w,\delta^2)\)</span>, 且 <span class="math inline">\(a,b, c\in \mathbb{R}\)</span>, 则 <span class="math display">\[\mathbb{E}[\exp(cX)\Phi(aX+b)]=\exp\left(cw+c^2\delta^2/2\right)\Phi\left(\frac{aw+b+ac\delta^2}{\sqrt{1+a^2\delta^2}}\right).\]</span></p></li>
</ol>



<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-al1989failure" class="csl-entry" role="listitem">
Al-Hussaini E K, Abd-El-Hakim N S, 1989. Failure rate of the inverse Gaussian-Weibull mixture model[J]. Annals of the Institute of Statistical Mathematics, 41(3): 617–622.
</div>
<div id="ref-Barndorff1998" class="csl-entry" role="listitem">
Barndorff-Nielsen O E, Koudou A E, 1998. Trees with random conductivities and the (Reciprocal) inverse <span>G</span>aussian distribution[J]. Advances in Applied Probability, 30(2): 409–424.
</div>
<div id="ref-bernardo2009bayesian" class="csl-entry" role="listitem">
Bernardo J M, Smith A F, 2009. Bayesian Theory[M]. John Wiley &amp; Sons.
</div>
<div id="ref-celeux2000computational" class="csl-entry" role="listitem">
Celeux G, Hurn M, Robert C P, 2000. Computational and inferential difficulties with mixture posterior distributions[J]. Journal of the American Statistical Association, 95(451): 957–970.
</div>
<div id="ref-Chen2013" class="csl-entry" role="listitem">
Chen N, Tsui K L, 2013. Condition monitoring and remaining useful life prediction using degradation signals: revisited[J]. IIE Transactions, 45(9): 939–952. DOI:<a href="https://doi.org/10.1080/0740817X.2012.706376">10.1080/0740817X.2012.706376</a>.
</div>
<div id="ref-chen2018uncertainty" class="csl-entry" role="listitem">
Chen P, Ye Z-S, 2018. Uncertainty quantification for monotone stochastic degradation models[J]. Journal of Quality Technology, 50(2): 207–219.
</div>
<div id="ref-Duan2017" class="csl-entry" role="listitem">
Duan F, Wang G, 2017. Reliability modeling of two-phase inverse <span>G</span>aussian degradation process[C]//2017 Second International Conference on Reliability Systems Engineering (ICRSE). IEEE: 1–6.
</div>
<div id="ref-efron2012bayesian" class="csl-entry" role="listitem">
Efron B, 2012. Bayesian inference and the parametric bootstrap[J]. The Annals of Applied Statistics, 6(4): 1971–1997. DOI:<a href="https://doi.org/10.1214/12-AOAS571">10.1214/12-AOAS571</a>.
</div>
<div id="ref-Johnson1993" class="csl-entry" role="listitem">
Efron B, Tibshirani R, 1993. An introduction to the bootstrap[M]. Chapman &amp; Hall: 49–54.
</div>
<div id="ref-ericsouglu2011mixture" class="csl-entry" role="listitem">
Erişoğlu Ü, Erişoğlu M, Erol H, 2011. A mixture model of two different distributions approach to the analysis of heterogeneous survival data[J]. International Journal of Computational and Mathematical Sciences, 5(6): 544–548.
</div>
<div id="ref-fan2023complete" class="csl-entry" role="listitem">
Fan T-H, Dong Y-S, Peng C-Y, 2024. A complete <span>B</span>ayesian degradation analysis based on inverse <span>G</span>aussian processes[J]. IEEE Transactions on Reliability, 73(1): 536–548. DOI:<a href="https://doi.org/10.1109/TR.2023.3304673">10.1109/TR.2023.3304673</a>.
</div>
<div id="ref-fang2022inverse" class="csl-entry" role="listitem">
Fang G, Pan R, Wang Y, 2022. Inverse Gaussian processes with correlated random effects for multivariate degradation modeling[J]. European Journal of Operational Research, 300(3): 1177–1193.
</div>
<div id="ref-fouladirad2011" class="csl-entry" role="listitem">
Fouladirad M, Grall A, 2011. Condition-based maintenance for a system subject to a non-homogeneous wear process with a wear rate transition[J]. Reliability Engineering &amp; System Safety, 96(6): 611–618. DOI:<a href="https://doi.org/10.1016/j.ress.2010.12.008">10.1016/j.ress.2010.12.008</a>.
</div>
<div id="ref-fouladirad2008use" class="csl-entry" role="listitem">
Fouladirad M, Grall A, Dieulle L, 2008. On the use of on-line detection for maintenance of gradually deteriorating systems[J]. Reliability Engineering &amp; System Safety, 93(12): 1814–1820. DOI:<a href="https://doi.org/10.1016/j.ress.2008.03.020">10.1016/j.ress.2008.03.020</a>.
</div>
<div id="ref-gelman2006" class="csl-entry" role="listitem">
Gelman A, 2006. Prior distributions for variance parameters in hierarchical models[J]. Bayesian Analysis, 1(3): 515–533.
</div>
<div id="ref-gilks1995" class="csl-entry" role="listitem">
Gilks W R, Best N G, Tan K K C, 2022. Adaptive rejection Metropolis sampling within <span>G</span>ibbs sampling[J]. Applied Statistics, 44: 455–472. DOI:<a href="https://doi.org/10.2307/2986138">10.2307/2986138</a>.
</div>
<div id="ref-grall2008maintenance" class="csl-entry" role="listitem">
Grall A, Fouladirad M, 2008. Maintenance decision rule with embedded online <span>B</span>ayesian change detection for gradually non-stationary deteriorating systems[J]. Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability, 222(3): 359–369. DOI:<a href="https://doi.org/10.1243/1748006XJRR141">10.1243/1748006XJRR141</a>.
</div>
<div id="ref-hao2019degradation" class="csl-entry" role="listitem">
Hao S, Yang J, Berenguer C, 2019. Degradation analysis based on an extended inverse <span>G</span>aussian process model with skew-normal random effects and measurement errors[J]. Reliability Engineering &amp; System Safety, 189: 261–270. DOI:<a href="https://doi.org/10.1016/j.ress.2019.04.031">10.1016/j.ress.2019.04.031</a>.
</div>
<div id="ref-hartzell2011lifetime" class="csl-entry" role="listitem">
Hartzell A L, Da Silva M G, Shea H R, 2011. Lifetime Prediction[M]//MEMS Reliability. Springer, New York: 9–42.
</div>
<div id="ref-huynh2021adaptive" class="csl-entry" role="listitem">
Huynh K T, 2021. An adaptive predictive maintenance model for repairable deteriorating systems using inverse Gaussian degradation process[J]. Reliability Engineering &amp; System Safety, 213: 107695.
</div>
<div id="ref-jamshidian1997" class="csl-entry" role="listitem">
Jamshidian M, Jennrich R I, 1997. Acceleration of the <span>EM</span> algorithm by using quasi-<span>N</span>ewton methods[J]. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 59(3): 569–587. DOI:<a href="https://doi.org/10.1111/1467-9868.00083">10.1111/1467-9868.00083</a>.
</div>
<div id="ref-komarek2008generalized" class="csl-entry" role="listitem">
Komárek A, Lesaffre E, 2008. Generalized linear mixed model with a penalized Gaussian mixture as a random effects distribution[J]. Computational Statistics &amp; Data Analysis, 52(7): 3441–3458.
</div>
<div id="ref-Kong2017" class="csl-entry" role="listitem">
Kong D J, Balakrishnan N, Cui L R, 2017. Two-phase degradation process model with abrupt jump at change point governed by <span>W</span>iener process[J]. IEEE Transactions on Reliability, 66(4): 1345–1360. DOI:<a href="https://doi.org/10.1109/Tr.2017.2711621">10.1109/Tr.2017.2711621</a>.
</div>
<div id="ref-kontar2017remaining" class="csl-entry" role="listitem">
Kontar R, Son J, Zhou S, 等, 2017. Remaining useful life prediction based on the mixed effects model with mixture prior distribution[J]. IISE Transactions, 49(7): 682–697.
</div>
<div id="ref-lawless2004covariates" class="csl-entry" role="listitem">
Lawless J, Crowder M, 2004. Covariates and random effects in a gamma process model with application to degradation and failure[J]. Lifetime Data Analysis, 10: 213–227. DOI:<a href="https://doi.org/10.1023/B:LIDA.0000036389.14073.dd">10.1023/B:LIDA.0000036389.14073.dd</a>.
</div>
<div id="ref-lesaffre1991multivariate" class="csl-entry" role="listitem">
Lesaffre E, Molenberghs G, 1991. Multivariate probit analysis: a neglected procedure in medical statistics[J]. Statistics in Medicine, 10(9): 1391–1403.
</div>
<div id="ref-li2017nonparametric" class="csl-entry" role="listitem">
Li M, Meng H, Zhang Q, 2017. A nonparametric Bayesian modeling approach for heterogeneous lifetime data with covariates[J]. Reliability Engineering &amp; System Safety, 167: 95–104.
</div>
<div id="ref-lindbate1988" class="csl-entry" role="listitem">
Lindstrom M J, Bates D M, 1988. Newton-Raphson and EM algorithms for linear mixed-effects models for repeated-measures data[J]. Journal of the American Statistical Association, 83: 1014–1022.
</div>
<div id="ref-linngtsu2019" class="csl-entry" role="listitem">
Ling M H, Ng H, Tsui K L, 2019. Bayesian and likelihood inferences on remaining useful life in two-phase degradation models under gamma process[J]. Reliability Engineering &amp; System Safety, 184: 77–85.
</div>
<div id="ref-Lin2021b" class="csl-entry" role="listitem">
Lin C P, Ling M H, Cabrera J, 等, 2021. Prognostics for lithium-ion batteries using a two-phase gamma degradation process model[J]. Reliability Engineering &amp; System Safety, 214: 107797. DOI:<a href="https://doi.org/10.1016/j.ress.2021.107797">10.1016/j.ress.2021.107797</a>.
</div>
<div id="ref-louis1982" class="csl-entry" role="listitem">
Louis T A, 1982. Finding the observed information matrix when using the EM Algorithm[J]. Journal of the Royal Statistical Society, Series B, 44: 226–233.
</div>
<div id="ref-Lu2022" class="csl-entry" role="listitem">
Lu B, Chen Z, Zhao X, 2022. Data-driven dynamic adaptive replacement policy for units subject to heterogeneous degradation[J]. Computers &amp; Industrial Engineering, 171: 108478. DOI:<a href="https://doi.org/10.1016/j.cie.2022.108478">10.1016/j.cie.2022.108478</a>.
</div>
<div id="ref-Lu2020" class="csl-entry" role="listitem">
Lu L, Wang B, Hong Y, 等, 2020. General path models for degradation data with multiple characteristics and covariates[J]. Technometrics, 63(3): 354–369.
</div>
<div id="ref-ma2019pf" class="csl-entry" role="listitem">
Ma Y, Chen Y, Zhou X, 等, 2019. Remaining useful life prediction of lithium-ion battery based on Gauss–Hermite particle filter[J]. IEEE Transactions on Control Systems Technology, 27(4): 1788–1795.
</div>
<div id="ref-matin2005" class="csl-entry" role="listitem">
Marin J-M, Mengersen K, Robert C P, 2005. Bayesian modelling and inference on mixtures of distributions[J]. Handbook of Statistics, 25: 459–507.
</div>
<div id="ref-pan2016remaining" class="csl-entry" role="listitem">
Pan D, Liu J-B, Cao J, 2016. Remaining useful life estimation using an inverse Gaussian degradation model[J]. Neurocomputing, 185: 64–72.
</div>
<div id="ref-park2006stochastic" class="csl-entry" role="listitem">
Park C, Padgett W J, 2006. Stochastic degradation models with several accelerating variables[J]. IEEE Transactions on Reliability, 55(2): 379–390. DOI:<a href="https://doi.org/10.1109/TR.2006.874937">10.1109/TR.2006.874937</a>.
</div>
<div id="ref-peng2015inverse" class="csl-entry" role="listitem">
Peng C-Y, 2015. Inverse <span>G</span>aussian processes with random effects and explanatory variables for degradation data[J]. Technometrics, 57(1): 100–111.
</div>
<div id="ref-peng2024coll" class="csl-entry" role="listitem">
Peng W, Chen Y, Xu A, 等, 2024. Collaborative online RUL prediction of multiple assets with analytically recursive Bayesian inference[J]. IEEE Transactions on Reliability, 73(1): 506–520.
</div>
<div id="ref-peng2014inverse" class="csl-entry" role="listitem">
Peng W, Li Y-F, Yang Y-J, 等, 2014. Inverse Gaussian process models for degradation analysis: A Bayesian perspective[J]. Reliability Engineering &amp; System Safety, 130: 175–189.
</div>
<div id="ref-peng2017bayesian" class="csl-entry" role="listitem">
Peng W, Li Y-F, Yang Y-J, 等, 2017. Bayesian degradation analysis with inverse <span>G</span>aussian process models under time-varying degradation rates[J]. IEEE Transactions on Reliability, 66(1): 84–96. DOI:<a href="https://doi.org/10.1109/TR.2016.2635149">10.1109/TR.2016.2635149</a>.
</div>
<div id="ref-peng2018joint" class="csl-entry" role="listitem">
Peng W, Ye Z-S, Chen N, 2018. Joint online <span>RUL</span> prediction for multivariate deteriorating systems[J]. IEEE Transactions on Industrial Informatics, 15(5): 2870–2878. DOI:<a href="https://doi.org/10.1109/TII.2018.2869429">10.1109/TII.2018.2869429</a>.
</div>
<div id="ref-polsco2012" class="csl-entry" role="listitem">
Polson N G, Scott J G, 2012. On the half-cauchy prior for a global scale parameter[J]. Bayesian Analysis, 7(4): 887–901.
</div>
<div id="ref-shen2018degradation" class="csl-entry" role="listitem">
Shen L, Wang Y, Zhai Q, 等, 2018. Degradation modeling using stochastic processes with random initial degradation[J]. IEEE Transactions on Reliability, 68(4): 1320–1329. DOI:<a href="https://doi.org/10.1109/TR.2018.2885133">10.1109/TR.2018.2885133</a>.
</div>
<div id="ref-sheu2019optimal" class="csl-entry" role="listitem">
Sheu S-H, Tsai H-N, Sheu U-Y, 等, 2019. Optimal replacement policies for a system based on a one-cycle criterion[J]. Reliability Engineering &amp; System Safety, 191: 106527. DOI:<a href="https://doi.org/10.1016/j.ress.2019.106527">10.1016/j.ress.2019.106527</a>.
</div>
<div id="ref-Si2012" class="csl-entry" role="listitem">
Si X-S, Wang W, Hu C-H, 等, 2012. Remaining useful life estimation based on a nonlinear diffusion degradation process[J]. IEEE Transactions on Reliability, 61(1): 50–67.
</div>
<div id="ref-si2013generalized" class="csl-entry" role="listitem">
Si X-S, Zhou D, 2013. A generalized result for degradation model-based reliability estimation[J]. IEEE Transactions on Automation Science and Engineering, 11(2): 632–637.
</div>
<div id="ref-taylor2022bayesian" class="csl-entry" role="listitem">
Taylor D, Rigdon S E, Pan R, 等, 2024. Bayesian <span>D</span>-optimal design for life testing with censoring[J]. Quality and Reliability Engineering International, 40(1): 71–90. DOI:<a href="https://doi.org/10.1002/qre.322">10.1002/qre.322</a>.
</div>
<div id="ref-van2000asymptotic" class="csl-entry" role="listitem">
Van der Vaart A W, 1998. Asymptotic Statistics[M]. Cambridge University Press.
</div>
<div id="ref-wangschda2007" class="csl-entry" role="listitem">
Wang X, Schumitzky A, D’Argenio D Z, 2007. Nonlinear random effects mixture models: Maximum likelihood estimation via the EM algorithm[J]. Computational Statistics <span class="math inline">\(\&amp;\)</span> Data Analysis, 51: 6614–6623.
</div>
<div id="ref-Wang2018itr" class="csl-entry" role="listitem">
Wang P, Tang Y, Bae S J, 等, 2018. Bayesian approach for two-phase degradation data based on change-point <span>W</span>iener process with measurement errors[J]. IEEE Transactions on Reliability, 67(2): 688–700. DOI:<a href="https://doi.org/10.1109/tr.2017.2785978">10.1109/tr.2017.2785978</a>.
</div>
<div id="ref-Wang2018ress" class="csl-entry" role="listitem">
Wang P, Tang Y, Joo Bae S, 等, 2018. Bayesian analysis of two-phase degradation data based on change-point <span>W</span>iener process[J]. Reliability Engineering &amp; System Safety, 170: 244–256. DOI:<a href="https://doi.org/10.1016/j.ress.2017.09.027">10.1016/j.ress.2017.09.027</a>.
</div>
<div id="ref-wang2010inverse" class="csl-entry" role="listitem">
Wang X, Xu D, 2010. An inverse Gaussian process model for degradation data[J]. Technometrics, 52(2): 188–197.
</div>
<div id="ref-wang2021degradation" class="csl-entry" role="listitem">
Wang Z, Zhai Q, Chen P, 2021. Degradation modeling considering unit-to-unit heterogeneity-A general model and comparative study[J]. Reliability Engineering &amp; System Safety, 216: 107897.
</div>
<div id="ref-wu1983" class="csl-entry" role="listitem">
Wu C, 1983. On the convergence properties of the EM algorithm[J]. The Annals of Statistics, 11(1): 95–103.
</div>
<div id="ref-wu2020maintenance" class="csl-entry" role="listitem">
Wu S, Castro I T, 2020. Maintenance policy for a system with a weighted linear combination of degradation processes[J]. European Journal of Operational Research, 280(1): 124–133.
</div>
<div id="ref-wu2022interval" class="csl-entry" role="listitem">
Wu W, Wang B X, Chen J, 等, 2023. Interval estimation of the two-parameter exponential constant stress accelerated life test model under Type-<span>II</span> censoring[J]. Quality Technology &amp; Quantitative Management, 20(6): 751–762. DOI:<a href="https://doi.org/10.1080/16843703.2022.2147688">10.1080/16843703.2022.2147688</a>.
</div>
<div id="ref-xiao2023hybrid" class="csl-entry" role="listitem">
Xiao T, Park C, Lin C, 等, 2023. Hybrid reliability analysis with incomplete interval data based on adaptive <span>K</span>riging[J]. Reliability Engineering &amp; System Safety, 237: 109362. DOI:<a href="https://doi.org/10.1016/j.ress.2023.10936">10.1016/j.ress.2023.10936</a>.
</div>
<div id="ref-xujor1996" class="csl-entry" role="listitem">
Xu L, Jordan M I, 1996. On convergence properties of the EM algorithm for gaussian mixtures[J]. Neural Computation, 8: 129–151.
</div>
<div id="ref-yang2017condition" class="csl-entry" role="listitem">
Yang L, Ma X, Zhao Y, 2017. A condition-based maintenance model for a three-state system subject to degradation and environmental shocks[J]. Computers &amp; Industrial Engineering, 105: 210–222. DOI:<a href="https://doi.org/10.1016/j.cie.2017.01.012">10.1016/j.cie.2017.01.012</a>.
</div>
<div id="ref-ye2014inverse" class="csl-entry" role="listitem">
Ye Z-S, Chen N, 2014. The inverse Gaussian process as a degradation model[J]. Technometrics, 56(3): 302–311.
</div>
<div id="ref-ye2013heterogeneities" class="csl-entry" role="listitem">
Ye Z-S, Hong Y, Xie Y, 2013. How do heterogeneities in operating environments affect field failure predictions and test planning?[J]. The Annals of Applied Statistics, 7(4): 2249–2271.
</div>
<div id="ref-yuan2015hierarchical" class="csl-entry" role="listitem">
Yuan T, Ji Y, 2015. A hierarchical Bayesian degradation model for heterogeneous data[J]. IEEE Transactions on Reliability, 64(1): 63–70.
</div>
<div id="ref-yuan2012reliability" class="csl-entry" role="listitem">
Yuan T, Zhu X, 2012. Reliability study of ultra-thin dielectric films with variable thickness levels[J]. IIE Transactions, 44(9): 744–753.
</div>
<div id="ref-zhai2018random" class="csl-entry" role="listitem">
Zhai Q, Chen P, Hong L, 等, 2018. A random-effects Wiener degradation model based on accelerated failure time[J]. Reliability Engineering &amp; System Safety, 180: 94–103.
</div>
<div id="ref-Zhai2018" class="csl-entry" role="listitem">
Zhai Q, Ye Z-S, 2018. Degradation in common dynamic environments[J]. Technometrics, 60(4): 461–471. DOI:<a href="https://doi.org/10.1080/00401706.2017.1375994">10.1080/00401706.2017.1375994</a>.
</div>
<div id="ref-Zhai2023multivariate" class="csl-entry" role="listitem">
Zhai Q, Ye Z-S, 2023. A multivariate stochastic degradation model for dependent performance characteristics[J]. Technometrics, 65(3): 315–327. DOI:<a href="https://doi.org/10.1080/00401706.2022.2157881">10.1080/00401706.2022.2157881</a>.
</div>
<div id="ref-zhang2023joint" class="csl-entry" role="listitem">
Zhang Y, Feng F, Wang S, 等, 2023. Joint nonlinear-drift-driven <span>W</span>iener process-<span>M</span>arkov chain degradation switching model for adaptive online predicting lithium-ion battery remaining useful life[J]. Applied Energy, 341: 121043. DOI:<a href="https://doi.org/10.1016/j.apenergy.2023.121043">10.1016/j.apenergy.2023.121043</a>.
</div>
<div id="ref-zhang2016optimal" class="csl-entry" role="listitem">
Zhang J, Huang X, Fang Y, 等, 2016. Optimal inspection-based preventive maintenance policy for three-state mechanical components under competing failure modes[J]. Reliability Engineering &amp; System Safety, 152: 95–103. DOI:<a href="https://doi.org/10.1016/j.ress.2016.02.007">10.1016/j.ress.2016.02.007</a>.
</div>
<div id="ref-zhang2017stochastic" class="csl-entry" role="listitem">
Zhang Z, Hu C, Si X, 等, 2017. Stochastic degradation process modeling and remaining useful life estimation with flexible random-effects[J]. Journal of the Franklin Institute, 354(6): 2477–2499.
</div>
<div id="ref-zhang2024condition" class="csl-entry" role="listitem">
Zhang Y, Ouyang L, Meng X, 等, 2024. Condition-based maintenance considering imperfect inspection for a multi-state system subject to competing and hidden failures[J]. Computers &amp; Industrial Engineering, 188: 109856. DOI:<a href="https://doi.org/10.1016/j.cie.2023.109856">10.1016/j.cie.2023.109856</a>.
</div>
<div id="ref-zhang2018degradation" class="csl-entry" role="listitem">
Zhang Z, Si X, Hu C, 等, 2018. Degradation data analysis and remaining useful life estimation: A review on Wiener-process-based methods[J]. European Journal of Operational Research, 271(3): 775–796.
</div>
<div id="ref-zhou2023fast" class="csl-entry" role="listitem">
Zhou S, Xu A, Tang Y, 等, 2023. Fast <span>B</span>ayesian inference of reparameterized gamma process with random effects[J]. IEEE Transactions on Reliability, 73(1): 399–412. DOI:<a href="https://doi.org/10.1109/TR.2023.3263940">10.1109/TR.2023.3263940</a>.
</div>
<div id="ref-zhu2022bayesian" class="csl-entry" role="listitem">
Zhu R, Chen Y, Peng W, 等, 2022. Bayesian deep-learning for <span>RUL</span> prediction: <span>A</span>n active learning perspective[J]. Reliability Engineering &amp; System Safety, 228: 108758. DOI:<a href="https://doi.org/10.1016/j.ress.2022.108758">10.1016/j.ress.2022.108758</a>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/03-Gamma.html" class="pagination-link" aria-label="基于伽马过程的统计建模">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">基于伽马过程的统计建模</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/05-ED.html" class="pagination-link" aria-label="基于指数分散过程的统计建模">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">基于指数分散过程的统计建模</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">源代码</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a>\setcounter{chapter}{4}</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu"># 基于逆高斯过程的统计建模 {#sec-04-IG}</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">## 逆高斯过程 {#sec-IG}</span></span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a>尽管维纳过程\index{维纳过程}和伽马过程\index{伽马过程}在退化建模领域得到了广泛应用, 但在处理复杂退化数据时, 其拟合能力可能受到一定限制. 尤其是当退化路径存在显著异质性\index{异质性}或动态变化特征时, 传统方法可能难以精准刻画系统的退化规律. 相比之下, 逆高斯(Inverse Gaussian, IG)过程凭借其灵活的分布形式和参数结构, 能够更有效地捕捉退化数据中的异质性\index{异质性}和动态演化特征. 其在单调退化建模场景中的适用性已在多个研究中得到验证, 并展现出优越的拟合能力和预测性能 <span class="co">[</span><span class="ot">@wang2010inverse; @ye2014inverse; @peng2014inverse</span><span class="co">]</span>.</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a>若随机过程 $<span class="sc">\{</span>Y(t), t \ge 0<span class="sc">\}</span>$ 满足以下性质:</span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a>(i) $Y(0)=0$, 概率为1;</span>
<span id="cb1-12"><a href="#cb1-12"></a></span>
<span id="cb1-13"><a href="#cb1-13"></a>(ii) 对于 $t&gt;s&gt;u$, 增量$Y(t)-Y(s)$ 与 $Y(s)-Y(u)$ 相互独立;</span>
<span id="cb1-14"><a href="#cb1-14"></a></span>
<span id="cb1-15"><a href="#cb1-15"></a>(iii) 对于 $t&gt;s \geq 0$, 增量 $Y(t)-Y(s)$ 服从 IG 分布 $\textrm{IG}\left(\alpha (t-s), \lambda(t-s)^2\right)$. 其PDF为 $$</span>
<span id="cb1-16"><a href="#cb1-16"></a>      f_{\textrm{IG}}(y; \alpha, \lambda)=\sqrt{\frac{\lambda t^2}{2\pi y^3}} \exp\left<span class="sc">\{</span>-\frac{\lambda}{2y} \left( \frac{y}{\alpha} - t \right)^2\right<span class="sc">\}</span>.</span>
<span id="cb1-17"><a href="#cb1-17"></a>      $$ 则称该过程为{\textrm{IG}过程, 记作 $<span class="sc">\{</span>Y(t), t \ge 0<span class="sc">\}</span> \sim \textrm{\textrm{IG}}(\alpha t, \lambda t^2)$.</span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a>IG过程的均值和方差分别为$\mathbb{E}<span class="co">[</span><span class="ot">Y(t)</span><span class="co">]</span>=\alpha t$和$\mathbb{Var}<span class="co">[</span><span class="ot">Y(t)</span><span class="co">]</span>=\alpha^3 t/\lambda$. 从其数学表达形式可以看出, IG过程在刻画产品性能退化\index{性能退化}规律时具有清晰的物理解释. 其中, 参数 $\alpha$ 表示退化速率, 直接反映系统性能随时间推移的衰减速度, 而参数 $\lambda$ 作为扩散系数, 衡量退化过程\index{退化过程}的波动程度, 表征退化路径的随机性和不确定性. 假设产品失效阈值为 $\omega$, 则产品寿命\index{寿命}定义为 $T= \inf <span class="sc">\{</span>t \mid Y(t) \geq \omega<span class="sc">\}</span>$. 此时, 产品寿命 $T$ 的CDF为 \begin{align}</span>
<span id="cb1-20"><a href="#cb1-20"></a>F(t) &amp;=P(T \leq t)=P(Y(t)&gt;\omega)\nonumber<span class="sc">\\</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>%=1-F_{I G}\left(\omega ; \alpha t, \lambda t^2\right) \nonumber<span class="sc">\\</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>&amp;=\Phi\left[ \sqrt{\frac{\lambda}{\omega}}(t - \frac{\omega}{\alpha})</span>
<span id="cb1-23"><a href="#cb1-23"></a>\right] - \exp\left({\frac{2 \lambda t}{\alpha}}\right) \Phi\left<span class="co">[</span><span class="ot">-\sqrt{\frac{\lambda}{\omega}}(\frac{\omega}{\alpha} +t)\right</span><span class="co">]</span>,</span>
<span id="cb1-24"><a href="#cb1-24"></a>\end{align} 其中 $\Phi(\cdot)$ 为标准正态分布\index{正态分布}的CDF.</span>
<span id="cb1-25"><a href="#cb1-25"></a></span>
<span id="cb1-26"><a href="#cb1-26"></a>在退化建模中, IG过程 $\mathcal{IG}(\alpha t, \lambda t^2)$ 假设了线性的平均退化路径. 然而, 实际退化数据通常表现为非线性特征, 并且存在显著的异质性\index{异质性}, 即不同产品或系统的退化行为存在差异. 为了克服这些局限性, 本章对经典 IG 模型进行了扩展: 首先, 引入了子群体异质性\index{异质性}(详见第 @sec-Hetero-IG 节), 以便更精准地刻画不同群体之间的异质性\index{异质性}, 从而提高模型在复杂数据中的适应性. 其次, 针对某些产品在退化过程\index{退化过程}中存在明显的阶段性变化, 提出一类新的两阶段重参数化IG过程(详见第 @sec-tp-IG 节), 并基于RUL分布给出了一种自适应替换\index{自适应替换}策略; 最后, 针对非线性退化和带随机效应\index{随机效应}的IG过程, 介绍一种高效的在线算法, 实现动态更新参数估计并RUL分布的预测 (详见 @sec-Online-IG 节).</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a><span class="fu">## 子总体异质性下的逆高斯过程 {#sec-Hetero-IG}</span></span>
<span id="cb1-29"><a href="#cb1-29"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a>退化数据通常因不可观测的内生因素（如原材料的初始缺陷）和外部因素（如使用模式）表现出显著的群体内异质性\index{异质性} <span class="co">[</span><span class="ot">@ye2013heterogeneities</span><span class="co">]</span>. 随机效应\index{随机效应}模型通过引入服从特定分布（如正态分布\index{正态分布} <span class="co">[</span><span class="ot">@Si2012</span><span class="co">]</span>、截断正态分布\index{正态分布} <span class="co">[</span><span class="ot">@ye2014inverse</span><span class="co">]</span>、伽马分布\index{伽马分布} <span class="co">[</span><span class="ot">@peng2014inverse; @peng2017bayesian</span><span class="co">]</span>）的随机参数来表征单元间的差异. 然而, 这些模型通常仅适用于描述同一群体内的异质性\index{异质性}, 难以处理多个子群体的情况. 在实际应用中, 多子群体共存的现象非常普遍. 例如, 制造过程中的高度变异可能导致微机电系统设备的失效时间\index{失效时间}呈现多峰分布 <span class="co">[</span><span class="ot">@hartzell2011lifetime; @yuan2012reliability</span><span class="co">]</span>, 或者在激光单元数据中, 假设多个子群体的模型优于同质群体模型 <span class="co">[</span><span class="ot">@yuan2015hierarchical</span><span class="co">]</span>. 类似情况也出现在口腔冲洗器 <span class="co">[</span><span class="ot">@ericsouglu2011mixture</span><span class="co">]</span> 和汽车铅酸电池 <span class="co">[</span><span class="ot">@kontar2017remaining</span><span class="co">]</span> 的研究中. 为处理这种子群体异质性\index{异质性}, 研究者广泛采用混合分布随机效应\index{随机效应}模型 <span class="co">[</span><span class="ot">@ericsouglu2011mixture; @al1989failure; @li2017nonparametric</span><span class="co">]</span>. 然而, 由于此类数据通常较为稀缺, 这些方法在高可靠性\index{可靠性}产品的失效数据\index{失效数据}建模中效果有限. 随着传感器技术的进步, 退化数据的可用性显著提高, 但如何建模来自异质群体且具有子群体结构的退化数据, 现有研究仍显不足. 例如, 基于混合高斯模型的广义路径模型 <span class="co">[</span><span class="ot">@yuan2015hierarchical</span><span class="co">]</span> 虽然能够表征单元间的变异性, 但仅适用于环境随机性较小的情况; 而基于混合正态分布\index{正态分布}参数的维纳退化过程\index{退化过程} <span class="co">[</span><span class="ot">@zhang2017stochastic</span><span class="co">]</span> 则无法有效建模单调退化过程\index{退化过程}. 因此, 针对子群体异质性\index{异质性}退化数据的建模方法仍存在较大局限性, 需进一步研究和改进.</span>
<span id="cb1-31"><a href="#cb1-31"></a></span>
<span id="cb1-32"><a href="#cb1-32"></a>基于上述讨论, 本节提出了一种基于IG过程的新模型, 用于建模存在子群体异质性\index{异质性}的退化数据. 该模型引入混合高斯分布作为随机效应\index{随机效应}分布, 能够近似任意形式的分布 <span class="co">[</span><span class="ot">@lesaffre1991multivariate; @komarek2008generalized</span><span class="co">]</span>, 同时利用IG过程来有效建模单调退化过程\index{退化过程}. 针对模型参数增多时对初始值敏感的问题<span class="co">[</span><span class="ot">@lindbate1988</span><span class="co">]</span>, 提出一种高效的EM算法\index{EM算法}, 通过边际化方法实现稳健的参数估计, 并结合偏差修正的百分位数自助法进行区间估计. 本节的结构如下: 第 @sec-AMM2020-s2 节介绍带有混合高斯分布随机效应\index{随机效应}的IG过程; 第 @sec-AMM2020-s3 节详细介绍了统计推断方法; 第 @sec-AMM2020-s4 节通过模拟研究验证模型与算法的性能; 第 @sec-AMM2020-s5 节通过两个案例研究展示模型与算法的实际效果. <span class="co">&lt;!-- 第 @sec-AMM2020-s6 节总结了本文并提出了一些未来的研究方向.  --&gt;</span></span>
<span id="cb1-33"><a href="#cb1-33"></a></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="fu">### 模型构建 {#sec-AMM2020-s2}</span></span>
<span id="cb1-35"><a href="#cb1-35"></a></span>
<span id="cb1-36"><a href="#cb1-36"></a>本小节首先将第 @sec-IG 节中定义的IG过程扩展到非线性退化路径的情形. 令 $\Lambda(t, \beta)$ 为时间尺度变换函数, 用于描述退化路径的非线性特征, 其中 $\Lambda(0, \beta) = 0$. 与上一节中定义的IG过程不同, 本节中的增量 $Y(t + \Delta t) - Y(t)$ 服从 $IG(\alpha \Delta \Lambda(t, \beta), \lambda \Delta \Lambda(t, \beta)^2)$, 其中 $\Delta \Lambda(t, \beta) = \Lambda(t + \Delta t, \beta) - \Lambda(t, \beta)$. 为了同时刻画单元与子总体的异质性\index{异质性}, 定义 $\nu = 1/\alpha$ 为随机效应\index{随机效应}, 并假设其服从混合高斯分布. 在这种设置下, $\nu$ 同时影响退化过程\index{退化过程}的均值和方差, 从而刻画了单元间的变异性, 并灵活地将总体划分为多个子总体. 设第 $k$ 个高斯分布的均值和方差分别为 $\mu_k$ 和 $\sigma_k^2 / \lambda$, 则具有子总体异质性\index{异质性}的 IG 退化模型为 \begin{equation}\label{mnd}</span>
<span id="cb1-37"><a href="#cb1-37"></a>    \begin{split}</span>
<span id="cb1-38"><a href="#cb1-38"></a>    Y(t) \mid \nu &amp;\sim \textrm{\textrm{IG}}(\Lambda(t,\beta)/\nu, \lambda\Lambda(t,\beta)^2),<span class="sc">\\</span></span>
<span id="cb1-39"><a href="#cb1-39"></a>    \nu &amp;\sim \sum\limits_{k=1}^Kp_k{N}(\mu_k,\sigma_k^2/\lambda),</span>
<span id="cb1-40"><a href="#cb1-40"></a>    \end{split}</span>
<span id="cb1-41"><a href="#cb1-41"></a>\end{equation} 其中 $p_k$ 为第 $k$ 个子总体的比例, ${N}(\cdot)$ 表示高斯分布, $K$ 为子群体总数.</span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a>**注2**: 模型\eqref{mnd}中子总体的方差设定为$\sigma_k^2/\lambda$, 目的是为了 简化数学推导. 实际上, 从模型的角度来看, 这一设定等同于假设 $\nu \sim \sum\limits_{k=1}^K p_k N(\mu_k, \delta_k^2)$. 通过参数变换 $\delta_k^2 = \sigma_k^2 / \lambda$可知两者是等价的. 然而, 模型 \eqref{mnd} 的设定在数学表达和后续统计推断中会更加简洁和方便.</span>
<span id="cb1-44"><a href="#cb1-44"></a></span>
<span id="cb1-45"><a href="#cb1-45"></a>基于模型\eqref{mnd}, 定义产品寿命\index{寿命}$T= \inf <span class="sc">\{</span>t \mid Y(t) \geq \omega<span class="sc">\}</span>$. 则$T$的分布可由以下定理给出.</span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a>::: {#thm-AMM2020-1}</span>
<span id="cb1-48"><a href="#cb1-48"></a>在模型\eqref{mnd}下, 产品寿命\index{寿命}$T$的CDF为\</span>
<span id="cb1-49"><a href="#cb1-49"></a>\begin{align}\label{cdf}</span>
<span id="cb1-50"><a href="#cb1-50"></a>    F_T(t)&amp;=\int_{-\infty}^{\infty}<span class="co">[</span><span class="ot">1-P(Y(t)\le \omega \mid \nu)</span><span class="co">]</span>f(\nu)\text{d}\nu\nonumber<span class="sc">\\</span></span>
<span id="cb1-51"><a href="#cb1-51"></a>    &amp;=\sum\limits_{k=1}^Kp_k\Phi\left(\dfrac{\sqrt{\lambda}(\Lambda(t,\beta)-\omega\mu_k) }{\sqrt{\omega(1+\omega\sigma_k^2)}}\right)\nonumber<span class="sc">\\</span></span>
<span id="cb1-52"><a href="#cb1-52"></a>    &amp;\quad -\sum\limits_{k=1}^Kp_k\exp\left<span class="co">[</span><span class="ot">2\lambda\Lambda(t,\beta)(\sigma_k^2\Lambda(t,\beta)+\mu_k)\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-53"><a href="#cb1-53"></a>    &amp;\quad\times\Phi\left( -\dfrac{\sqrt{\lambda}<span class="co">[</span><span class="ot">(1+2\omega\sigma_k^2)\Lambda(t,\beta)+\omega\mu_k</span><span class="co">]</span> }{\sqrt{\omega(1+\omega\sigma_k^2)}}\right).</span>
<span id="cb1-54"><a href="#cb1-54"></a>\end{align}</span>
<span id="cb1-55"><a href="#cb1-55"></a>:::</span>
<span id="cb1-56"><a href="#cb1-56"></a></span>
<span id="cb1-57"><a href="#cb1-57"></a>根据定理 @thm-AMM2020-1 可知, 当 $K = 1$ 时, 式 \eqref{cdf} 就简化为 @peng2015inverse 的结果, 表示所有单元来自同一总体; 当 $K &gt; 1$ 时, 则刻画了包含 $K$ 个子总体的一般情况.</span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a><span class="fu">### 统计推断 {#sec-AMM2020-s3}</span></span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a>假设在退化试验中有 $n$ 个样品. 设 $y_{ij}$ 为第 $i$ 个样品在测量时间 $t_{ij}$ ($j=1,\dots,m_i$, $i=1,\dots,n$) 时所观测到的退化值. 令 $\Delta \bm{y_i}=(\Delta y_{i1},\dots,\Delta y_{im_i})^{'}$, 其中 $\Delta y_{i1}=y_{i1}$, 且 $\Delta y_{ij} = y_{ij}-y_{i(j-1)}$, $i=1,\dots,n$, $\bm y=(\Delta \bm y_{1},\dots, \Delta \bm y_{n})^{'}$. 设 $h_{ij}(\beta)=\Lambda(t_{ij},\beta)-\Lambda(t_{i(j-1)},\beta)$, 并且 $t_{i0}=0$, $j=1,\dots,m_i$, $i=1,\dots,n$. 假设样品性能的退化过程\index{退化过程}服从模型 \eqref{mnd}, 则基于第 $i$ 个样品的退化数据, 给定 $\nu_i$, 对任意的 $j$, 有$\Delta y_{ij} \sim IG(h_{ij}(\beta)/\nu_i, \lambda h_{ij}(\beta)^2)$, 且 $\nu_i \sim \sum_{k=1}^K p_k N(\mu_k, \sigma_k^2/\lambda)$. 令 $\bm \Theta=(\lambda,\beta,p_k,\mu_k,\sigma_k^2,k=1,\dots,K)$. 对于第 $i$ 个退化路径的完整数据 $(\Delta \bm y_{i},\nu_i)$, 其似然函数\index{似然函数}为 \begin{align}</span>
<span id="cb1-62"><a href="#cb1-62"></a>    L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)&amp;=\prod\limits_{j=1}^{m_i}</span>
<span id="cb1-63"><a href="#cb1-63"></a>    \sqrt{\dfrac{\lambda h_{ij}(\beta)^2}{2\pi \Delta y_{ij}^3}}\exp\left<span class="sc">\{</span>-\dfrac{\lambda}{2\Delta y_{ij}}\left(\nu_i\Delta y_{ij}-h_{ij}(\beta)\right)^2\right<span class="sc">\}</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-64"><a href="#cb1-64"></a>    &amp;\quad \times \sum\limits_{k=1}^K p_k\sqrt{\frac{\lambda}{2\pi\sigma_k^2}}\exp\left<span class="sc">\{</span>-\dfrac{\lambda(\nu_i-\mu_k)^2}{2\sigma_k^2}\right<span class="sc">\}</span>.\label{compdata}</span>
<span id="cb1-65"><a href="#cb1-65"></a>\end{align} 基于 $\prod_{i=1}^n L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)$ 求解参数 $\bm \Theta$ 的估计通常有两种方法:</span>
<span id="cb1-66"><a href="#cb1-66"></a></span>
<span id="cb1-67"><a href="#cb1-67"></a>(1) EM算法\index{EM算法}: @wangschda2007 提出了一类EM算法\index{EM算法}, 用于求非线性随机效应\index{随机效应}混合模型的参数估计. 然而, 该方法在数学推导上较为复杂, 难以求解, 并且需要处理两类潜在变量, 这显著降低了计算效率.</span>
<span id="cb1-68"><a href="#cb1-68"></a>(2) 贝叶斯\index{贝叶斯}分析: 引入潜在变量简化 \eqref{compdata} 中的求和结构, 并为参数 $\bm{\Theta}$ 指定先验\index{先验}分布, 结合 MCMC\index{MCMC} 算法生成后验样本, 从而估计 $\bm \Theta$. 然而, 在实际实施过程中, 后验抽样可能面临一些挑战. 特别是参数 $\sigma_k^2$ 的先验\index{先验}分布难以确定, 一些弱信息先验\index{先验}（如均匀分布或逆伽马分布）在特定情况下可能导致后验分布不存在, 相关问题已在文献中得到详细讨论 <span class="co">[</span><span class="ot">@gelman2006; @polsco2012</span><span class="co">]</span>.</span>
<span id="cb1-69"><a href="#cb1-69"></a></span>
<span id="cb1-70"><a href="#cb1-70"></a>基于以上分析, 本小节提出一种新的EM算法\index{EM算法}: 首先对$\nu_i$做边际化处理, 然后构造EM算法\index{EM算法}来实现参数估计.</span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a><span class="fu">#### EM 算法 {#sec-AMM2020-s3-1}</span></span>
<span id="cb1-73"><a href="#cb1-73"></a></span>
<span id="cb1-74"><a href="#cb1-74"></a>由于 $\nu_i$ 不可观测, 对 $L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)$ 中的 $\nu_i$ 进行积分后, 基于第 $i$ 个样品退化数据的似然函数\index{似然函数}为 \begin{align}\label{margi}</span>
<span id="cb1-75"><a href="#cb1-75"></a>    L_i(\Delta \bm y_{i} \mid \bm \Theta)&amp;=\int_{-\infty}^\infty L_i(\Delta \bm y_{i},\nu_i \mid \bm \Theta)\text{d}\nu_i \nonumber<span class="sc">\\</span></span>
<span id="cb1-76"><a href="#cb1-76"></a>    &amp;=(2\pi\lambda)^{m_i/2-1}y_{im_i}^{-1/2}\prod\limits_{j=1}^{m_i}\dfrac{h_{ij}(\beta)}{\Delta y_{ij}^{3/2}}\nonumber<span class="sc">\\</span></span>
<span id="cb1-77"><a href="#cb1-77"></a>    &amp;\ \ \ \times\exp\left<span class="sc">\{</span>-\dfrac{\lambda}{2}\left<span class="co">[</span><span class="ot">\sum\limits_{j=1}^{m_i}h_{ij}(\beta)^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta)^2/y_{im_i} \right</span><span class="co">]</span>\right<span class="sc">\}</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-78"><a href="#cb1-78"></a>    &amp;\quad\times\sum\limits_{k=1}^K \dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}</span>
<span id="cb1-79"><a href="#cb1-79"></a>    \exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-80"><a href="#cb1-80"></a>    &amp;=G_i(\Delta \bm y_{i},\beta,\lambda)\sum\limits_{k=1}^K \dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}\nonumber<span class="sc">\\</span></span>
<span id="cb1-81"><a href="#cb1-81"></a>    &amp;\quad \times\exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>,</span>
<span id="cb1-82"><a href="#cb1-82"></a>\end{align} 其中 \begin{equation*}</span>
<span id="cb1-83"><a href="#cb1-83"></a>  \begin{split}</span>
<span id="cb1-84"><a href="#cb1-84"></a>  G_i(\Delta \bm y_{i},&amp;\beta,\lambda)=(2\pi\lambda)^{m_i/2-1}y_{im_i}^{-1/2}<span class="sc">\\</span></span>
<span id="cb1-85"><a href="#cb1-85"></a>  &amp;\times \prod\limits_{j=1}^{m_i}\dfrac{h_{ij}(\beta)}{\Delta y_{ij}^{3/2}}\exp\left<span class="sc">\{</span>-\dfrac{\lambda}{2}\left<span class="co">[</span><span class="ot">\sum\limits_{j=1}^{m_i}h_{ij}(\beta)^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta)^2/y_{im_i} \right</span><span class="co">]</span>\right<span class="sc">\}</span>.</span>
<span id="cb1-86"><a href="#cb1-86"></a>  \end{split}</span>
<span id="cb1-87"><a href="#cb1-87"></a>\end{equation*} 为简化式 \eqref{margi}, 引入潜在变量 $\bm Z_i=(Z_{i1},\dots,Z_{iK})^{'}$ 表示第 $i$ 个样品对应的子总体标签. $\bm Z_i$ 为多项分布变量, 当 $Z_{ik}=1$ 且 $Z_{ij}=0, \forall j \neq k$ 时, 第 $i$ 个样品属于第 $k$ 个子总体. 给定 $Z_{ik}=1$ 时, 似然函数\index{似然函数}为\</span>
<span id="cb1-88"><a href="#cb1-88"></a>\begin{equation*}</span>
<span id="cb1-89"><a href="#cb1-89"></a>  \begin{split}</span>
<span id="cb1-90"><a href="#cb1-90"></a>    L_i(\Delta \bm y_{i} \mid &amp;Z_{ik}=1,\bm \Theta)=G_i(\Delta \bm y_{i},\bm \beta,\lambda) <span class="sc">\\</span></span>
<span id="cb1-91"><a href="#cb1-91"></a>    &amp;\times \dfrac{\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}</span>
<span id="cb1-92"><a href="#cb1-92"></a>    \exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>.</span>
<span id="cb1-93"><a href="#cb1-93"></a>  \end{split}</span>
<span id="cb1-94"><a href="#cb1-94"></a>\end{equation*} 因此, 给定第 $i$ 个样品的完整数据 $(\Delta \bm y_{i}, \bm Z_i)$, 似然函数\index{似然函数}可表示为\</span>
<span id="cb1-95"><a href="#cb1-95"></a>\begin{equation*}</span>
<span id="cb1-96"><a href="#cb1-96"></a>\begin{split}</span>
<span id="cb1-97"><a href="#cb1-97"></a>  L_i(\Delta \bm y_{i},&amp;\bm Z_i \mid \bm \Theta) = G_i(\Delta \bm y_{i},\beta,\lambda)<span class="sc">\\</span></span>
<span id="cb1-98"><a href="#cb1-98"></a>  &amp;\times \prod\limits_{k=1}^K \left<span class="co">[</span><span class="ot">\dfrac{p_k\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}} \exp\left\{-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right\}\right</span><span class="co">]</span>^{Z_{ik}}.</span>
<span id="cb1-99"><a href="#cb1-99"></a>\end{split}</span>
<span id="cb1-100"><a href="#cb1-100"></a>\end{equation*} 对于所有样品的完整数据 $(\Delta \bm y, \bm Z)$, 参数 $\bm \Theta$ 的对数似然函数\index{似然函数}为 \begin{align}\label{lf}</span>
<span id="cb1-101"><a href="#cb1-101"></a>    l(\Delta \bm y, \bm Z \mid \bm \Theta)&amp;=\sum\limits_{i=1}^n\log(L_i(\Delta \bm y_{i},\bm Z_i \mid \bm \Theta))\nonumber<span class="sc">\\</span></span>
<span id="cb1-102"><a href="#cb1-102"></a>    &amp;=C+\dfrac{1}{2}\sum\limits_{i=1}^nm_i\log(\lambda)+\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i}\log h_{ij}(\beta)\nonumber<span class="sc">\\</span></span>
<span id="cb1-103"><a href="#cb1-103"></a>    &amp;\quad -\dfrac{\lambda}{2}\left<span class="co">[</span><span class="ot">\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}-\sum\limits_{i=1}^n\Lambda(t_{im_i},\beta)^2/y_{im_i}\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-104"><a href="#cb1-104"></a>    &amp;\quad +\sum\limits_{i=1}^n\sum\limits_{k=1}^{K} Z_{ik}\Bigg[\log p_k-\dfrac{1}{2}\log(1/y_{im_i}+\sigma_k^2)\nonumber<span class="sc">\\</span></span>
<span id="cb1-105"><a href="#cb1-105"></a>    &amp;\quad -</span>
<span id="cb1-106"><a href="#cb1-106"></a>    \dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)}  \Bigg],</span>
<span id="cb1-107"><a href="#cb1-107"></a>\end{align} 其中 $$C = -\sum_{i=1}^n \left<span class="co">[</span><span class="ot"> m_i \log(2\pi) + \log(y_{im_i}) + 3 \sum_{j=1}^{m_i} \log(\Delta y_{ij}) \right</span><span class="co">]</span> / 2.</span>
<span id="cb1-108"><a href="#cb1-108"></a>$$ EM 算法是一个迭代算法, 包含E步和M步. E 步的计算是在观测数据 $\Delta \bm y$ 和上次迭代参数值 $\bm \Theta^{(s)}$ 条件下, 对 $\bm Z$ 的对数似然函数\index{似然函数}的期望. 可知$\bm Z_i$ 的条件分布为多项分布: $\bm Z_i \mid \Delta \bm y_{i},\bm \Theta\sim \mathcal{MN}(1;w_{i1}(\bm \Theta),\dots,w_{iK}(\bm \Theta))$, 其中 \begin{equation*}</span>
<span id="cb1-109"><a href="#cb1-109"></a>  w_{ik}(\bm \Theta)=\dfrac{ p_k(1/y_{im_i}+\sigma_k^2)^{-1}</span>
<span id="cb1-110"><a href="#cb1-110"></a>        \exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>}</span>
<span id="cb1-111"><a href="#cb1-111"></a>    {\sum\limits_{k=1}^K p_k(1/y_{im_i}+\sigma_k^2)^{-1}</span>
<span id="cb1-112"><a href="#cb1-112"></a>        \exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>},</span>
<span id="cb1-113"><a href="#cb1-113"></a>\end{equation*} 表示第 $i$ 个样品属于第 $k$ 个子总体的概率. 在 E 步中, 结合$\bm Z_i$ 的条件分布, 对$l(\Delta \bm y,\bm Z \mid \bm \Theta)$ 关于 $\bm Z$求期望可得 \begin{equation*}\label{fcdata}</span>
<span id="cb1-114"><a href="#cb1-114"></a>    \begin{split}</span>
<span id="cb1-115"><a href="#cb1-115"></a>    Q (\bm \Theta,\bm \Theta^{(s)})</span>
<span id="cb1-116"><a href="#cb1-116"></a>        %=\text{E}\left(l(\Delta \bm y, \bm Z \mid \bm \Theta) \mid \Delta\bm  y, \bm \Theta^{(s)}\right)<span class="sc">\\</span></span>
<span id="cb1-117"><a href="#cb1-117"></a>        =\  &amp; C+\dfrac{1}{2}\sum\limits_{i=1}^nm_i\log(\lambda)+\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i}\log h_{ij}(\beta)<span class="sc">\\</span></span>
<span id="cb1-118"><a href="#cb1-118"></a>        &amp;-\dfrac{\lambda}{2}\left<span class="co">[</span><span class="ot">\sum\limits_{i=1}^n\sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}-\sum\limits_{i=1}^n\Lambda(t_{im_i},\beta)^2/y_{im_i}\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-119"><a href="#cb1-119"></a>        &amp;+\sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\Bigg[\log p_k-\dfrac{1}{2}\log(1/y_{im_i}+\sigma_k^2)\nonumber<span class="sc">\\</span></span>
<span id="cb1-120"><a href="#cb1-120"></a>        &amp;\qquad -\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)}  \Bigg],</span>
<span id="cb1-121"><a href="#cb1-121"></a>    \end{split}</span>
<span id="cb1-122"><a href="#cb1-122"></a>\end{equation*} 其中 $w_{ik}^{(s)}=w_{ik}(\bm \Theta^{(s)})$. 在 M 步中通过最大化$Q(\bm \Theta,\bm \Theta^{(s)})$得到 $\bm \Theta^{(s+1)}$. 具体更新公式见式 \eqref{wiener-RESS2021-arg}, 详细推导见本节附录 @sec-Append-4B. EM 算法的实施过程与 @sec-RESS2021-s3-1 节类似, 这里不再重复介绍.</span>
<span id="cb1-123"><a href="#cb1-123"></a></span>
<span id="cb1-124"><a href="#cb1-124"></a><span class="co">&lt;!-- - **步骤 1**. 设置参数 $\bm \Theta^{(0)}$ 的初始值和容忍误差 $\epsilon$.  --&gt;</span></span>
<span id="cb1-125"><a href="#cb1-125"></a></span>
<span id="cb1-126"><a href="#cb1-126"></a><span class="co">&lt;!-- - **步骤 2**. 给定第 $s$ 次迭代的参数估计 $\bm \Theta^{(s)}$, 通过 \eqref{pmulam}-\eqref{betas} 更新第 $(s+1)$ 次迭代的参数估计 $\bm \Theta^{(s+1)}$.  --&gt;</span></span>
<span id="cb1-127"><a href="#cb1-127"></a></span>
<span id="cb1-128"><a href="#cb1-128"></a><span class="co">&lt;!-- - **步骤 3**. 重复步骤 2, 直到满足 $|\sum_{i=1}^n[\log L_i(\bm \Delta y_i|\bm \Theta^{(s+1)})-\log L_i(\bm \Delta y_i|\bm \Theta^{(s)})]|&lt;\epsilon$ 或 $|\bm \Theta^{(s+1)} - \bm \Theta^{(s)}| &lt; \epsilon$.  --&gt;</span></span>
<span id="cb1-129"><a href="#cb1-129"></a></span>
<span id="cb1-130"><a href="#cb1-130"></a><span class="co">&lt;!-- - **步骤 4**. 得到 $\bm \Theta$ 的ML估计为 $\bm{\hat\Theta}=\bm\Theta^{(s+1)}$.  --&gt;</span></span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a>**注3**: 混合模型存在识别问题, 即交换子总体标签不会影响似然函数\index{似然函数} $\prod_{i=1}^n L_i(\Delta \bm y_i \mid \bm \Theta)$ 的值 <span class="co">[</span><span class="ot">@celeux2000computational</span><span class="co">]</span>. 为确保参数可识别性, 在计算过程中可对子总体均值 $\mu_k$ 按递增顺序排列.</span>
<span id="cb1-133"><a href="#cb1-133"></a></span>
<span id="cb1-134"><a href="#cb1-134"></a>**注4**: 所提出的 EM 算法基于给定的子总体数 $K$ 进行计算. $K$ 的选择属于模型选择问题, 本节通过 AIC\index{AIC} 来确定最优的 $K$. AIC\index{AIC} 定义为 $${\rm AIC} = -2\sum_{i=1}^n \log L_i(\Delta \bm y_i \mid \bm{\hat{\Theta}}) + 2 \times (3K + 1).$$ 最小的 AIC 值对应最优的$K$. 在实际操作中, 可预设一个最大值 $K$, 该值取决于样本大小 $n$, 确保 $n$ 大于模型参数个数, 以保证参数的可识别性.</span>
<span id="cb1-135"><a href="#cb1-135"></a></span>
<span id="cb1-136"><a href="#cb1-136"></a>**注5**: 本节中样品的标签信息不可观测. 基于参数估计值 $\hat{\Theta}$, 可通过后验概率 $w_{ik}(\hat{\Theta})$ 估计样品的标签. 若 $w_{ij}(\hat{\Theta}) = \max<span class="sc">\{</span>w_{ik}(\hat{\Theta}), k=1,\dots,K<span class="sc">\}</span>$, 则样品 $i$ 被归为第 $j$ 个子总体. 因此, EM 算法的实施过程同时也是样品聚类的学习过程.</span>
<span id="cb1-137"><a href="#cb1-137"></a></span>
<span id="cb1-138"><a href="#cb1-138"></a><span class="fu">#### 收敛速率 {#sec-AMM2020-s3-2}</span></span>
<span id="cb1-139"><a href="#cb1-139"></a></span>
<span id="cb1-140"><a href="#cb1-140"></a>EM算法\index{EM算法}通过迭代不断优化参数估计. 根据 @wu1983 的定理1, 该算法能够使对数似然函数\index{似然函数}收敛到一个稳定点或局部极大值. 为实现该算法, 需要随机初始化参数值, 通过多次迭代寻找最优解. 最终, 选取使似然函数\index{似然函数}值达到最大的点作为参数估计.</span>
<span id="cb1-141"><a href="#cb1-141"></a></span>
<span id="cb1-142"><a href="#cb1-142"></a>对于混合高斯分布, @xujor1996 的定理1表明, EM算法\index{EM算法}本质上是一种梯度上升算法, 且收敛速度与对数似然函数\index{似然函数}的Hessian矩阵的条件数有关. 在本模型中, Hessian矩阵 $H(\bm{\Theta})$ 可由对数似然函数\index{似然函数} $l(\bm{\Theta}) = \sum_{i=1}^n \log L_i(\Delta \bm{y}_i \mid \bm{\Theta})$ 求得, 具体为 $H(\bm\Theta)=\dfrac{\partial^2 l(\bm\Theta)}{\partial\bm\Theta\partial\bm\Theta^{'}}.$ 在参数更新中, 使用牛顿法求解 $\sigma_k^2$ 和 $\beta$ (见式 \eqref{sigmas} 和 \eqref{betas}) . 因此, 所提的EM算法\index{EM算法}也可视为一种梯度上升算法.</span>
<span id="cb1-143"><a href="#cb1-143"></a></span>
<span id="cb1-144"><a href="#cb1-144"></a>::: {#thm-AMM2020-2}</span>
<span id="cb1-145"><a href="#cb1-145"></a>在EM算法\index{EM算法}的每次迭代中有 \begin{eqnarray*}</span>
<span id="cb1-146"><a href="#cb1-146"></a>   P^{(s+1)}-P^{(s)}&amp;=&amp;G_P^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}},<span class="sc">\\</span></span>
<span id="cb1-147"><a href="#cb1-147"></a>  \mu_k^{(s+1)}-\mu_k^{(s)}&amp;=&amp;G_{\mu_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}},<span class="sc">\\</span></span>
<span id="cb1-148"><a href="#cb1-148"></a>   \lambda^{(s+1)}-\lambda^{(s)}&amp;=&amp;G_{\lambda}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}},<span class="sc">\\</span></span>
<span id="cb1-149"><a href="#cb1-149"></a>    (\sigma_k^2)^{(s+1)}-(\sigma_k^2)^{(s)}&amp;=&amp;G_{\sigma_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \sigma_k^2}\Big|_{\bm\Theta=\bm\Theta^{(s)}},<span class="sc">\\</span></span>
<span id="cb1-150"><a href="#cb1-150"></a> \beta^{(s+1)}-\beta^{(s)}&amp;=&amp;G_{\beta}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \beta}\Big|_{\bm\Theta=\bm\Theta^{(s)}},</span>
<span id="cb1-151"><a href="#cb1-151"></a>\end{eqnarray*} 其中 $P=(p_1,\dots,p_K)^{'}$, \begin{align*}</span>
<span id="cb1-152"><a href="#cb1-152"></a>h_{ij}&amp;=h_{ij}(\beta^{(s)}), h^{'}_{ij}=h^{'}_{ij}(\beta^{(s)}), h^{''}_{ij}=h^{''}_{ij}(\beta^{(s)}),\\ \Lambda_i&amp;=\Lambda(t_{im_i},\beta^{(s)}), \Lambda_i^{'}=\Lambda^{'}(t_{im_i},\beta^{(s)}), \Lambda_i^{''}=\Lambda^{''}(t_{im_i},\beta^{(s)}),<span class="sc">\\</span> </span>
<span id="cb1-153"><a href="#cb1-153"></a>G_P^{(s)}&amp;=\dfrac{1}{n}\left<span class="co">[</span><span class="ot">\textrm{diag}\{p_1^{(s)},\dots,p_K^{(s)}\}-P^{(s)}\left(P^{(s)}\right)^{'}\right</span><span class="co">]</span>,<span class="sc">\\</span></span>
<span id="cb1-154"><a href="#cb1-154"></a>    G_{\mu_k}^{(s)}&amp;=\left<span class="co">[</span><span class="ot">\sum_{i=1}^{n}\lambda^{(s)}w_{ik}^{(s)}/\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)\right</span><span class="co">]</span>^{-1},<span class="sc">\\</span></span>
<span id="cb1-155"><a href="#cb1-155"></a>    G_{\lambda}^{(s)}&amp;=2\lambda^{(s)}</span>
<span id="cb1-156"><a href="#cb1-156"></a>    \left<span class="sc">\{</span>\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} \dfrac{h_{ij}^2}{\Delta y_{ij}}-\dfrac{\Lambda_i^2}{y_{im_i}}+</span>
<span id="cb1-157"><a href="#cb1-157"></a>    \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right] \right<span class="sc">\}</span>^{-1},<span class="sc">\\</span></span>
<span id="cb1-158"><a href="#cb1-158"></a>        G_{\sigma_k}^{(s)}&amp;=-\left<span class="sc">\{</span></span>
<span id="cb1-159"><a href="#cb1-159"></a>        \sum\limits_{i=1}^nw_{ik}^{(s)}\left<span class="co">[</span><span class="ot">\dfrac{\lambda^{(s)}(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^3}-\dfrac{1}{2\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^2}\right</span><span class="co">]</span> \right<span class="sc">\}</span>^{-1},<span class="sc">\\</span></span>
<span id="cb1-160"><a href="#cb1-160"></a>    G_{\beta}^{(s)}&amp;=-\Bigg<span class="sc">\{</span>\sum_{i=1}^{n}\Bigg[\sum_{j=1}^{m_i}\dfrac{h_{ij}^{''}h_{ij}-(h_{ij}^{'})^2}{h_{ij}^2}<span class="sc">\\</span></span>
<span id="cb1-161"><a href="#cb1-161"></a>    &amp;-\lambda^{(s)}\left(\sum_{j=1}^{m_i}\dfrac{h_{ij}^{''}h_{ij}+(h_{ij}^{'})^2}{\Delta y_{ij}}-\dfrac{\Lambda_{i}^{''}\Lambda_{i}-(\Lambda_{i}^{'})^2}{y_{im_i}}\right)\Bigg]<span class="sc">\\</span></span>
<span id="cb1-162"><a href="#cb1-162"></a>    &amp;-\sum_{i=1}^{n}\sum_{j=1}^{m_i}\dfrac{\lambda^{(s)}w_{ik}^{(s)}}{1+y_{im_i}(\sigma_k^2)^{(s)}}\left(\dfrac{\Lambda_{i}^{''}\Lambda_{i}^2+2(\Lambda_{i}^{'})^2\Lambda_i}{y_{im_i}}</span>
<span id="cb1-163"><a href="#cb1-163"></a>    -\mu_k^{(s)}\left(\Lambda_{i}^{''}\Lambda_{i}+(\Lambda_{i}^{'})^2\right)\right) \Bigg<span class="sc">\}</span>^{-1}.    </span>
<span id="cb1-164"><a href="#cb1-164"></a>\end{align*}</span>
<span id="cb1-165"><a href="#cb1-165"></a>:::</span>
<span id="cb1-166"><a href="#cb1-166"></a></span>
<span id="cb1-167"><a href="#cb1-167"></a>定理 @thm-AMM2020-2 的证明见本节附录 @sec-Append-4B. @xujor1996 表明, 在约束条件 $\sum_{k=1}^{K} p_k^{(s)} = 1$ 且 $p_k^{(s)} \ge 0$ (对所有 $k$) 的情况下, $G_P^{(s)}$ 是正定矩阵, $G_{\mu_k}^{(s)}$ 和 $G_{\lambda}^{(s)}$ 是正值, 这一点易于验证. 在定理 @thm-AMM2020-2 的证明中, $G_{\sigma_k}^{(s)}$ 和 $G_{\beta}^{(s)}$ 分别为 $$G_{\sigma_k}^{(s)} = - \frac{\partial^2 l(\bm{\Theta})}{\partial \sigma_k^2 \partial \sigma_k^2} \Big|{\bm{\Theta}=\bm{\Theta}^{(s)}} \quad \text{和} \quad G_{\beta}^{(s)} = - \frac{\partial^2 l(\bm{\Theta})}{\partial \beta \partial \beta} \Big|_{\bm{\Theta}=\bm{\Theta}^{(s)}},$$ 对于足够大的 $n$, 这些值均为正. 定义 $$\mathcal{G}(\bm\Theta)=\textrm{diag}\{G_{\lambda},~G_{\beta},~G_P,~ G_{\mu_1},~\dots,~G_{\mu_K},~G_{\sigma_1},~\dots,~G_{\sigma_K} <span class="sc">\}</span>,$$ 这是一个正定矩阵. 根据定理 @thm-AMM2020-2 可写为 \begin{equation}</span>
<span id="cb1-168"><a href="#cb1-168"></a>\bm\Theta^{(s+1)}=\bm\Theta^{(s)}+\mathcal{G}(\bm\Theta^{(s)})~\dfrac{\partial l(\bm\Theta)}{\partial \bm\Theta}\Big|_{\bm\Theta=\bm\Theta^{(s)}}.</span>
<span id="cb1-169"><a href="#cb1-169"></a>\end{equation} 因此, 在每次EM算法\index{EM算法}迭代中, 搜索方向 $\bm{\Theta}^{(s+1)} - \bm{\Theta}^{(s)}$ 在对数似然函数\index{似然函数}梯度上具有正投影. 令 $\mathcal{E} = <span class="sc">\{</span>\mathcal{E}_1, \dots, \mathcal{E}_d\}$ 为一组独立的单位基向量, 覆盖 $\bm{\Theta}$ 的参数空间. 令 $\gamma_{s+1} = \frac{|\bm{\Theta}^{(s+1)} - \bm{\Theta}^{\ast}|}{|\bm{\Theta}^{(s)} - \bm{\Theta}^{\ast}|}$, 其中 $\bm{\Theta}^{\ast}$ 是 $\bm{\Theta}$ 的真实值. 根据 @xujor1996 的式(16), EM算法\index{EM算法}的收敛速度由以下不等式界定: \begin{equation}\label{crate}</span>
<span id="cb1-170"><a href="#cb1-170"></a>\gamma_{s+1}\le\sqrt{1+\kappa_M^2\left<span class="co">[</span><span class="ot">\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right</span><span class="co">]</span>-2\kappa_m\left<span class="co">[</span><span class="ot">\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right</span><span class="co">]</span>},</span>
<span id="cb1-171"><a href="#cb1-171"></a>\end{equation} 其中 $\kappa_m<span class="co">[</span><span class="ot">A</span><span class="co">]</span>$ 和 $\kappa_M<span class="co">[</span><span class="ot">A</span><span class="co">]</span>$ 分别表示矩阵 $A$ 的最小和最大特征值. EM算法\index{EM算法}的收敛速度依赖于矩阵 $\mathcal{E}' \mathcal{G}(\bm{\Theta}^{\ast}) H(\bm{\Theta}^{\ast}) \mathcal{E}$ 的条件数, 定义为\</span>
<span id="cb1-172"><a href="#cb1-172"></a>\begin{equation}\label{condnum}</span>
<span id="cb1-173"><a href="#cb1-173"></a>\mathcal{C}=\kappa_M\left<span class="co">[</span><span class="ot">\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right</span><span class="co">]</span>/\kappa_m\left<span class="co">[</span><span class="ot">\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right</span><span class="co">]</span>.</span>
<span id="cb1-174"><a href="#cb1-174"></a>\end{equation} 较大的 $\mathcal{C}$ 会导致较慢的收敛速度. 当 $\mathcal{C}=1$ 且 $\kappa_M<span class="co">[</span><span class="ot">\mathcal{E}' \mathcal{G}(\bm{\Theta}^{\ast}) H(\bm{\Theta}^{\ast}) \mathcal{E}</span><span class="co">]</span> = 1$ 时, 式\eqref{crate}中的上界收敛至 $0$, 实现超线性收敛速度. <span class="co">&lt;!-- 我们有 $$\sqrt{1+\kappa_M^2\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]-2\kappa_m\left[\mathcal{E}^{'}\mathcal{G}(\bm\Theta^\ast)H(\bm\Theta^\ast)\mathcal{E}\right]}=0,$$ --&gt;</span> 在算法实施中, 用每次迭代的估计值代替 \eqref{condnum} 中的 $\bm{\Theta}^\ast$, 以监控条件数 $\mathcal{C}$ 的变化, 从而评估不同算法的收敛速度.</span>
<span id="cb1-175"><a href="#cb1-175"></a></span>
<span id="cb1-176"><a href="#cb1-176"></a><span class="fu">#### 自助法计算区间 {#sec-AMM2020-s3-3}</span></span>
<span id="cb1-177"><a href="#cb1-177"></a></span>
<span id="cb1-178"><a href="#cb1-178"></a>@louis1982 提出了推导参数 Fisher 信息矩阵的方法. 但该模型获得其解析形式较为困难. 因此, 可采用偏差校正百分位自助法计算参数的区间估计 <span class="co">[</span><span class="ot">@Johnson1993</span><span class="co">]</span>. 对于参数的任意函数 $\eta = g(\bm{\Theta})$, 具体实施步骤如下:</span>
<span id="cb1-179"><a href="#cb1-179"></a></span>
<span id="cb1-180"><a href="#cb1-180"></a><span class="in">```{=latex}</span></span>
<span id="cb1-181"><a href="#cb1-181"></a><span class="in">\begin{framed}</span></span>
<span id="cb1-182"><a href="#cb1-182"></a><span class="in">{\bf 基于偏差校正的自助法}</span></span>
<span id="cb1-183"><a href="#cb1-183"></a><span class="in">\begin{enumerate}</span></span>
<span id="cb1-184"><a href="#cb1-184"></a><span class="in">  \item[(1)] 给定观测退化数据 $\Delta \bm{y}$, 使用 EM 算法基于模型 \eqref{mnd} 计算 MLE $\bm{\hat{\Theta}}$, 并获得 $\hat{\eta} = g(\bm{\hat{\Theta}})$. </span></span>
<span id="cb1-185"><a href="#cb1-185"></a><span class="in">  \item[(2)] 设置自助法样本数 $B$, 通过以下步骤生成每个自助法样本的估计值 $\hat{\eta}_b$, $b=1,\dots,B$: </span></span>
<span id="cb1-186"><a href="#cb1-186"></a><span class="in">  \begin{enumerate}[]</span></span>
<span id="cb1-187"><a href="#cb1-187"></a><span class="in">    \item[(a)] 根据 $\nu_i \sim \sum{k=1}^K \hat{p}_k N(\hat{\mu}_k, \hat{\sigma}_k^2 / \hat{\lambda})$, $i=1,\dots,n$ 生成 $\nu_i$, 确保每个子群体至少包含两个 $\nu_i$, 以避免信息不足影响模型估计.</span></span>
<span id="cb1-188"><a href="#cb1-188"></a><span class="in">    \item[(b)] 根据 $\Delta y_{ij} \sim \textrm{\textrm{IG}}(h_{ij}(\hat{\beta})/\nu_i, \hat{\lambda} h_{ij}(\hat{\beta})^2)$, $j=1,\dots,m_i$, $i=1,\dots,n$ 生成退化数据. </span></span>
<span id="cb1-189"><a href="#cb1-189"></a><span class="in">  \end{enumerate}</span></span>
<span id="cb1-190"><a href="#cb1-190"></a><span class="in">  \item[(3)] 对估计值 $\hat{\eta}{(1)} \leq \hat{\eta}{(2)} \leq \cdots \leq \hat{\eta}{(B)}$ 进行排序, 计算 $\eta$ 的 $100(1-\gamma)\%$ 置信区间为 $(\hat{\eta}_{(L)}, \hat{\eta}_{(U)})$, 其中 $L = B \times \Phi(2\Phi^{-1}(p_0) + \Phi^{-1}(\gamma/2))$, $U = B \times \Phi(2\Phi^{-1}(p_0) + \Phi^{-1}(1-\gamma/2))$, $p_0$ 是小于 $\hat{\eta}$ 的自助法估计值的比例. </span></span>
<span id="cb1-191"><a href="#cb1-191"></a><span class="in">\end{enumerate}</span></span>
<span id="cb1-192"><a href="#cb1-192"></a><span class="in">\end{framed}</span></span>
<span id="cb1-193"><a href="#cb1-193"></a><span class="in">```</span></span>
<span id="cb1-194"><a href="#cb1-194"></a><span class="fu">### 模拟实验 {#sec-AMM2020-s4}</span></span>
<span id="cb1-195"><a href="#cb1-195"></a></span>
<span id="cb1-196"><a href="#cb1-196"></a>本节将通过蒙特卡洛仿真来验证EM算法\index{EM算法}的有效性. 设定总体包含两个子群体 ($K=2$), 异质性\index{异质性}参数为 $p_1=0.4$、$p_2=0.6$、$\mu_1=2$、$\mu_2=4$、$\sigma_1^2=0.2$、$\sigma_2^2=0.5$. 模型的其他参数包括 $\Lambda(t,\beta) = t^{1.5}$ 和 $\lambda = 1$, 测量时间点设置为 $(t_1,t_2,\dots,t_m) = (2,4,\dots,2m)$. 样本大小和测量次数分别选取 $n=50,100$ 和 $m=10,20$. 为评估不同 $(n,m)$ 组合对估计结果的影响, 每个组合重复模拟2000次, EM算法\index{EM算法}的容忍误差设为 $\epsilon = 10^{-5}$.</span>
<span id="cb1-197"><a href="#cb1-197"></a></span>
<span id="cb1-198"><a href="#cb1-198"></a>表 \ref{tbl-simu1} 列出了基于2000次模拟的模型参数估计结果. 可发现:</span>
<span id="cb1-199"><a href="#cb1-199"></a></span>
<span id="cb1-200"><a href="#cb1-200"></a>(1) 在固定 $m$ 的情况下, 随着样本量 $n$ 增加, 参数估计的偏差和RMSE显著降低.</span>
<span id="cb1-201"><a href="#cb1-201"></a></span>
<span id="cb1-202"><a href="#cb1-202"></a>(2) 在固定 $n$ 的情况下, 随着测量次数 $m$ 增加, 参数 $\lambda$ 和 $\beta$ 的RMSE明显减少, 而其他模型参数的 RMSE 几乎保持不变. 这是因为异质性\index{异质性}的信息主要由样本量决定, 而参数 $\lambda$ 和 $\beta$ 的估计精度依赖于总测量次数$n \times m$. 例如, 当 $(n,m) = (50,20)$ 和 $(100,10)$ 时, 两者总测量次数均为1000, 对应的 $\lambda$ 和 $\beta$ 的估计RMSE非常接近.</span>
<span id="cb1-203"><a href="#cb1-203"></a></span>
<span id="cb1-204"><a href="#cb1-204"></a>假设阈值为 $\omega=10$, 根据式 \eqref{cdf} 绘制产品失效时间\index{失效时间}的分布函数. 图 @fig-fig:meancdf 展示了基于估计的分布函数, 其中实线为真实分布函数, 虚线为表 \ref{tbl-simu1} 中平均估计得到的分布函数, 灰色虚线为每个数据集的估计结果 (仅绘制前100条以便说明) . 从图中可以看出, 随着样本量增加, 分布函数的估计精度逐步提高. 对于固定样本量, 不同 $m$ 的分布函数估计结果相似, 这与表 \ref{tbl-simu1} 的分析一致.</span>
<span id="cb1-205"><a href="#cb1-205"></a></span>
<span id="cb1-206"><a href="#cb1-206"></a><span class="in">```{=latex}</span></span>
<span id="cb1-207"><a href="#cb1-207"></a><span class="in">    \begin{table}</span></span>
<span id="cb1-208"><a href="#cb1-208"></a><span class="in">    \centering</span></span>
<span id="cb1-209"><a href="#cb1-209"></a><span class="in">            \caption{参数估计性能评估. }</span></span>
<span id="cb1-210"><a href="#cb1-210"></a><span class="in">            \label{tbl-simu1}</span></span>
<span id="cb1-211"><a href="#cb1-211"></a><span class="in">            \vskip 0mm \setlength{\tabcolsep}{2mm}</span></span>
<span id="cb1-212"><a href="#cb1-212"></a><span class="in">            \renewcommand{\arraystretch}{1.5}</span></span>
<span id="cb1-213"><a href="#cb1-213"></a><span class="in">                \begin{tabular}{ccccccccc}</span></span>
<span id="cb1-214"><a href="#cb1-214"></a><span class="in">                    \hline</span></span>
<span id="cb1-215"><a href="#cb1-215"></a><span class="in">                    $(n,m)$ &amp; 估计值 &amp;$p_1$ &amp; $\mu_1$ &amp;$\mu_2$ &amp; $\sigma_1^2$ &amp;$\sigma_2^2$ &amp;$\lambda$&amp;$\beta$\\</span></span>
<span id="cb1-216"><a href="#cb1-216"></a><span class="in">                    %\hline</span></span>
<span id="cb1-217"><a href="#cb1-217"></a><span class="in">                    %True Values &amp;0.4 &amp; 2 &amp; 4 &amp; 0.2 &amp; 0.4 &amp;1 &amp;1.5\\</span></span>
<span id="cb1-218"><a href="#cb1-218"></a><span class="in">                    \hline</span></span>
<span id="cb1-219"><a href="#cb1-219"></a><span class="in">                    &amp;均值&amp; 0.346 &amp; 2.066&amp; 3.665&amp;   0.178 &amp; 0.563 &amp; 1.012&amp; 1.499\\</span></span>
<span id="cb1-220"><a href="#cb1-220"></a><span class="in">                    (50,10) &amp;Bias&amp; 0.054 &amp; 0.066&amp; 0.335&amp;   0.022 &amp; 0.063 &amp; 0.012&amp; 0.001\\</span></span>
<span id="cb1-221"><a href="#cb1-221"></a><span class="in">                    &amp;RMSE&amp; 0.172 &amp; 0.589 &amp;0.621&amp; 0.256 &amp; 0.397 &amp;  0.0951 &amp; 0.0119\\</span></span>
<span id="cb1-222"><a href="#cb1-222"></a><span class="in">                    \hline</span></span>
<span id="cb1-223"><a href="#cb1-223"></a><span class="in">                    &amp;均值&amp; 0.349 &amp; 2.005&amp; 3.657&amp;   0.182 &amp; 0.554 &amp; 1.004&amp; 1.500\\</span></span>
<span id="cb1-224"><a href="#cb1-224"></a><span class="in">                    (50,20)&amp;Bias &amp; 0.051 &amp;0.005 &amp;0.343 &amp; 0.018  &amp; 0.054 &amp;  0.004&amp;  0.000\\</span></span>
<span id="cb1-225"><a href="#cb1-225"></a><span class="in">                    &amp;RMSE&amp;0.174 &amp;0.533&amp; 0.535 &amp; 0.211 &amp; 0.390&amp;  0.0675&amp;  0.0074\\</span></span>
<span id="cb1-226"><a href="#cb1-226"></a><span class="in">                    \hline</span></span>
<span id="cb1-227"><a href="#cb1-227"></a><span class="in">                    &amp;均值&amp; 0.377 &amp; 2.029&amp; 3.821&amp;   0.186 &amp; 0.511 &amp; 1.004&amp; 1.500\\</span></span>
<span id="cb1-228"><a href="#cb1-228"></a><span class="in">                    (100,10) &amp;Bias&amp; 0.023 &amp; 0.029 &amp; 0.179&amp;  0.014 &amp; 0.011 &amp; 0.004 &amp; 0.000\\</span></span>
<span id="cb1-229"><a href="#cb1-229"></a><span class="in">                    &amp;RMSE&amp;0.128&amp;  0.412 &amp; 0.456 &amp;  0.161&amp; 0.313&amp;  0.0664&amp; 0.0076\\</span></span>
<span id="cb1-230"><a href="#cb1-230"></a><span class="in">                    \hline</span></span>
<span id="cb1-231"><a href="#cb1-231"></a><span class="in">                    &amp;均值&amp; 0.380 &amp; 2.022&amp; 3.792&amp;   0.189 &amp; 0.515 &amp; 1.001&amp; 1.500\\</span></span>
<span id="cb1-232"><a href="#cb1-232"></a><span class="in">                    (100,20) &amp;Bias&amp; 0.020 &amp;  0.022 &amp; 0.208&amp;  0.011 &amp; 0.015 &amp;0.001 &amp;  0.000\\</span></span>
<span id="cb1-233"><a href="#cb1-233"></a><span class="in">                    &amp;RMSE&amp; 0.118&amp;  0.408 &amp; 0.451 &amp; 0.153 &amp;0.315 &amp; 0.0468 &amp; 0.0050\\</span></span>
<span id="cb1-234"><a href="#cb1-234"></a><span class="in">                    \hline</span></span>
<span id="cb1-235"><a href="#cb1-235"></a><span class="in">                \end{tabular}</span></span>
<span id="cb1-236"><a href="#cb1-236"></a><span class="in">    \end{table} </span></span>
<span id="cb1-237"><a href="#cb1-237"></a><span class="in">```</span></span>
<span id="cb1-240"><a href="#cb1-240"></a><span class="in">```{r}</span></span>
<span id="cb1-241"><a href="#cb1-241"></a><span class="co">#| label: fig-fig:meancdf</span></span>
<span id="cb1-242"><a href="#cb1-242"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-243"><a href="#cb1-243"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-244"><a href="#cb1-244"></a><span class="co">#| out.width: '95%'</span></span>
<span id="cb1-245"><a href="#cb1-245"></a><span class="co">#| fig.cap: '不同$(n,m)$条件下失效时间的CDF估计值. '</span></span>
<span id="cb1-246"><a href="#cb1-246"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/AMM2020/mean.pdf"</span>)</span>
<span id="cb1-247"><a href="#cb1-247"></a><span class="in">```</span></span>
<span id="cb1-248"><a href="#cb1-248"></a></span>
<span id="cb1-249"><a href="#cb1-249"></a><span class="fu">### 实例分析 {#sec-AMM2020-s5}</span></span>
<span id="cb1-250"><a href="#cb1-250"></a></span>
<span id="cb1-251"><a href="#cb1-251"></a>本节应用所提模型分析两个实际数据集. 第 @sec-AMM2020-s5-1 节展示模型可准确识别子总体数量, 并对每个样品实现分类. 第 @sec-AMM2020-s5-2 节通过与其他两种考虑子总体的现有模型进行 AIC\index{AIC} 比较, 验证模型有效性, 同时评估 EM 算法的计算效率.</span>
<span id="cb1-252"><a href="#cb1-252"></a></span>
<span id="cb1-253"><a href="#cb1-253"></a><span class="fu">#### 集成电路器件退化数据 {#sec-AMM2020-s5-1}</span></span>
<span id="cb1-254"><a href="#cb1-254"></a></span>
<span id="cb1-255"><a href="#cb1-255"></a><span class="co">&lt;!-- 数据表明, 集成电路器件的功率随时间下降. 它们在三种温度条件下进行测试: $150^\circ C$、$195^\circ C$ 和 $237^\circ C$. 在这三种温度下的样本量分别为 7、12 和 15.  --&gt;</span></span>
<span id="cb1-256"><a href="#cb1-256"></a></span>
<span id="cb1-257"><a href="#cb1-257"></a>为验证模型的有效性, 选取了一个集成电路器件退化数据的实际案例进行分析 (详见图 @fig-fig:deviceB). 根据测试条件, 设备被分为三个子总体, 且每个设备的子总体归属已知. 图 @fig-fig:newcl-(a) 显示了设备分类结果, 不同颜色代表不同子总体. 采用第 @sec-AMM2020-s3-1 节的方法, 通过AIC\index{AIC}确定子总体数量, 并在算法运行后估计设备标签. 由于真实数据已知, 可直接评估模型和算法的分类准确性.</span>
<span id="cb1-258"><a href="#cb1-258"></a></span>
<span id="cb1-259"><a href="#cb1-259"></a>数据采用线性退化路径 $\Lambda(t,\beta) = t$ 进行拟合. 表 \ref{tbl-laserpar} 列出了不同子总体数量 $K=1, 2, 3, 4$ 时的参数估计和AIC\index{AIC}值. 结果显示, $K=3$对应最小的AIC\index{AIC}值, 表明数据中存在三个子群体, 与实际情况相符. 图 @fig-fig:newcl-(b) 展示了基于 $K=3$ 的分类结果. 此外, 本方法与广义路径模型 <span class="co">[</span><span class="ot">@yuan2015hierarchical</span><span class="co">]</span> (图 @fig-fig:newcl-(c)) 和维纳过程\index{维纳过程}模型 <span class="co">[</span><span class="ot">@zhang2017stochastic</span><span class="co">]</span> (图 @fig-fig:newcl-(d)) 进行了比较. 在本方法中, 仅有一个 $237^\circ C$ 组的样品被错误分类为 $195^\circ C$ (用粗长虚线标出) , 分类准确率达到 $97.06%$. 相比之下, 其他两种模型各有三个样品分类错误, 表明本方法分类效果更佳. 值得注意的是, @wangschda2007 提出的EM算法\index{EM算法}不适用于此例, 其复杂的数学表达式使得推导困难. 同样, 基于MCMC\index{MCMC}的贝叶斯\index{贝叶斯}分析也不适用, 因为在没有先验\index{先验}信息的情况下指定九个参数的先验\index{先验}分布可能导致不适当的后验分布 <span class="co">[</span><span class="ot">@gelman2006; @polsco2012</span><span class="co">]</span>, 且MCMC\index{MCMC}算法计算负担重, 收敛时间长. 这些结果进一步证实了模型和算法在确定子总体数量和准确分类方面的有效性.</span>
<span id="cb1-260"><a href="#cb1-260"></a></span>
<span id="cb1-261"><a href="#cb1-261"></a><span class="in">```{=latex}</span></span>
<span id="cb1-262"><a href="#cb1-262"></a><span class="in">\begin{table}</span></span>
<span id="cb1-263"><a href="#cb1-263"></a><span class="in">    \centering</span></span>
<span id="cb1-264"><a href="#cb1-264"></a><span class="in">    \caption{集成电路器件退化数据的参数估计结果 ($\Lambda(t,\beta) = t$) . }</span></span>
<span id="cb1-265"><a href="#cb1-265"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-266"><a href="#cb1-266"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{2.5mm}</span></span>
<span id="cb1-267"><a href="#cb1-267"></a><span class="in">    \label{tbl-laserpar}</span></span>
<span id="cb1-268"><a href="#cb1-268"></a><span class="in">    \begin{tabular}{ccccccc}</span></span>
<span id="cb1-269"><a href="#cb1-269"></a><span class="in">        \toprule</span></span>
<span id="cb1-270"><a href="#cb1-270"></a><span class="in">        $K$ &amp; $k$ &amp; $p_k$ &amp; $\mu_k$ &amp; $\sigma_k^2$ &amp; $\lambda (\times 10^{-5})$ &amp; AIC值 \\</span></span>
<span id="cb1-271"><a href="#cb1-271"></a><span class="in">        \midrule</span></span>
<span id="cb1-272"><a href="#cb1-272"></a><span class="in">        1 &amp; 1 &amp; 1 &amp; 2910.2 &amp; 173.98 &amp; 1.234 &amp; -612.61 \\</span></span>
<span id="cb1-273"><a href="#cb1-273"></a><span class="in">        \midrule</span></span>
<span id="cb1-274"><a href="#cb1-274"></a><span class="in">        \multirow{2}[2]{*}{2} &amp; 1 &amp; 0.793 &amp; 1138.8 &amp; 1.199 &amp; \multirow{2}[2]{*}{1.285} &amp; \multirow{2}[2]{*}{-668.39} \\</span></span>
<span id="cb1-275"><a href="#cb1-275"></a><span class="in">         &amp; 2 &amp; 0.207 &amp; 9599.7 &amp; 59.56 &amp;  &amp;  \\</span></span>
<span id="cb1-276"><a href="#cb1-276"></a><span class="in">        \midrule</span></span>
<span id="cb1-277"><a href="#cb1-277"></a><span class="in">        \multirow{3}[2]{*}{3} &amp; 1 &amp; 0.342 &amp; 686.8 &amp; 0.069 &amp; \multirow{3}[2]{*}{1.349} &amp; \multirow{3}[2]{*}{\textbf{-683.28}} \\</span></span>
<span id="cb1-278"><a href="#cb1-278"></a><span class="in">         &amp; 2 &amp; 0.449 &amp; 1444.9 &amp; 2.248 &amp;  &amp;  \\</span></span>
<span id="cb1-279"><a href="#cb1-279"></a><span class="in">         &amp; 3 &amp; 0.209 &amp; 9747.3 &amp; 62.16 &amp;  &amp;  \\</span></span>
<span id="cb1-280"><a href="#cb1-280"></a><span class="in">        \midrule</span></span>
<span id="cb1-281"><a href="#cb1-281"></a><span class="in">        \multirow{4}[4]{*}{4} &amp; 1 &amp; 0.189 &amp; 618.6 &amp; 1.36$\times10^{-2}$ &amp; \multirow{4}[4]{*}{1.354} &amp; \multirow{4}[4]{*}{-679.96} \\</span></span>
<span id="cb1-282"><a href="#cb1-282"></a><span class="in">         &amp; 2 &amp; 0.136 &amp; 725.6 &amp; 1.62$\times10^{-3}$ &amp;  &amp;  \\</span></span>
<span id="cb1-283"><a href="#cb1-283"></a><span class="in">         &amp; 3 &amp; 0.466 &amp; 1425.6 &amp; 2.242 &amp;  &amp;  \\</span></span>
<span id="cb1-284"><a href="#cb1-284"></a><span class="in">         &amp; 4 &amp; 0.209 &amp; 9747.3 &amp; 62.16 &amp;  &amp;  \\</span></span>
<span id="cb1-285"><a href="#cb1-285"></a><span class="in">        \bottomrule</span></span>
<span id="cb1-286"><a href="#cb1-286"></a><span class="in">    \end{tabular}</span></span>
<span id="cb1-287"><a href="#cb1-287"></a><span class="in">\end{table}</span></span>
<span id="cb1-288"><a href="#cb1-288"></a><span class="in">```</span></span>
<span id="cb1-291"><a href="#cb1-291"></a><span class="in">```{r}</span></span>
<span id="cb1-292"><a href="#cb1-292"></a><span class="co">#| label: fig-fig:newcl</span></span>
<span id="cb1-293"><a href="#cb1-293"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-294"><a href="#cb1-294"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-295"><a href="#cb1-295"></a><span class="co">#| out.width: '95%'</span></span>
<span id="cb1-296"><a href="#cb1-296"></a><span class="co">#| fig.cap: '(a) 图为原始数据, (b)-(d) 分别展示了所提模型与其他模型的分类结果. '</span></span>
<span id="cb1-297"><a href="#cb1-297"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/AMM2020/rclus.pdf"</span>)</span>
<span id="cb1-298"><a href="#cb1-298"></a><span class="in">```</span></span>
<span id="cb1-299"><a href="#cb1-299"></a></span>
<span id="cb1-300"><a href="#cb1-300"></a><span class="fu">#### 铝合金裂纹退化数据 {#sec-AMM2020-s5-2}</span></span>
<span id="cb1-301"><a href="#cb1-301"></a></span>
<span id="cb1-302"><a href="#cb1-302"></a><span class="co">&lt;!-- 铝合金裂纹退化数据来自2024-T351铝合金的寿命实验, 相关数据可以在[@Wu2003A] 的表1中找到. 实验中使用了30个抛光铝合金样本, 在室温下使用相同的测量设备进行测试. 时间单位为10,000个循环, 范围从1到4, 步长为0.5. 当单个样本的裂纹长度超过15mm时, 视为报废, 记录的循环数即为该单元的寿命.  --&gt;</span></span>
<span id="cb1-303"><a href="#cb1-303"></a></span>
<span id="cb1-304"><a href="#cb1-304"></a>本小节以铝合金裂纹退化数据为例 (详见图 @fig-fig:crack), 考虑非线性退化路径函数 $\Lambda(t,\beta)=t^\beta$ 和 $\Lambda(t,\beta)=\exp{(\beta t)}-1$, 并分别设置 $K=1,2,3,4$. 各模型的点估计结果和 AIC\index{AIC} 值列于表 \ref{tbl-crackesti}. 结果显示, $\Lambda(t,\beta)=\exp{(\beta t)}-1$ 的模型在 AIC\index{AIC} 值上显著优于其他模型. 为方便表述, 本小节后续将直接以“模型”代指“使用 $\Lambda(t,\beta)=\exp{(\beta t)}-1$ 的模型”. 在子总体数量的选择上, $K=2$ 的模型 AIC\index{AIC} 值最小, 其次是 $K=3$ 的模型, 两者 AIC\index{AIC} 值非常接近.</span>
<span id="cb1-305"><a href="#cb1-305"></a></span>
<span id="cb1-306"><a href="#cb1-306"></a><span class="in">```{=latex}</span></span>
<span id="cb1-307"><a href="#cb1-307"></a><span class="in">\begin{table}</span></span>
<span id="cb1-308"><a href="#cb1-308"></a><span class="in">\centering</span></span>
<span id="cb1-309"><a href="#cb1-309"></a><span class="in">\caption{对疲劳裂纹数据使用不同的$\Lambda(t,\beta)$进行参数估计. }</span></span>
<span id="cb1-310"><a href="#cb1-310"></a><span class="in">\begin{tabular}{cccccccc}</span></span>
<span id="cb1-311"><a href="#cb1-311"></a><span class="in">\toprule</span></span>
<span id="cb1-312"><a href="#cb1-312"></a><span class="in">\multirow{2}{*}{$K$} &amp; \multirow{2}{*}{$k$} &amp; \multicolumn{6}{c}{$\Lambda(t,\beta)=t^\beta$} \\</span></span>
<span id="cb1-313"><a href="#cb1-313"></a><span class="in">      \cmidrule(lr){3-8}</span></span>
<span id="cb1-314"><a href="#cb1-314"></a><span class="in">      &amp;  &amp; $p_k$ &amp; $\mu_k$ &amp; $\sigma_k^2$ &amp; $\lambda$ &amp; $\beta$ &amp; AIC</span></span>
<span id="cb1-315"><a href="#cb1-315"></a><span class="in">\\ \midrule</span></span>
<span id="cb1-316"><a href="#cb1-316"></a><span class="in">1 &amp; 1 &amp; 1 &amp; 1.207 &amp; 2.935 &amp; 19.304 &amp; 1.377 &amp; -51.34 \\ \hline</span></span>
<span id="cb1-317"><a href="#cb1-317"></a><span class="in">\multirow{2}{*}{2} &amp; 1 &amp; 0.612 &amp; 0.924 &amp; 0.453 &amp; \multirow{2}{*}{19.343} &amp; \multirow{2}{*}{1.377} &amp; \multirow{2}{*}{-54.94} \\ </span></span>
<span id="cb1-318"><a href="#cb1-318"></a><span class="in"> &amp; 2 &amp; 0.388 &amp; 1.655 &amp; 0.697 &amp; &amp; &amp; \\ \hline</span></span>
<span id="cb1-319"><a href="#cb1-319"></a><span class="in">\multirow{3}{*}{3} &amp; 1 &amp; 0.612 &amp; 0.923 &amp; 0.443 &amp; \multirow{3}{*}{19.866} &amp; \multirow{3}{*}{1.377} &amp; \multirow{3}{*}{-53.74} \\</span></span>
<span id="cb1-320"><a href="#cb1-320"></a><span class="in"> &amp; 2 &amp; 0.180 &amp; 1.455 &amp; 0.205 &amp; &amp; &amp; \\</span></span>
<span id="cb1-321"><a href="#cb1-321"></a><span class="in"> &amp; 3 &amp; 0.204 &amp; 1.842 &amp; 0.264 &amp; &amp; &amp; \\ \hline</span></span>
<span id="cb1-322"><a href="#cb1-322"></a><span class="in">\multirow{4}{*}{4} &amp; 1 &amp; 0.185 &amp; 0.716 &amp; 0.085 &amp; \multirow{4}{*}{19.866} &amp; \multirow{4}{*}{1.377} &amp; \multirow{4}{*}{-51.18} \\</span></span>
<span id="cb1-323"><a href="#cb1-323"></a><span class="in"> &amp; 2 &amp; 0.415 &amp; 1.002 &amp; 0.134 &amp; &amp; &amp; \\</span></span>
<span id="cb1-324"><a href="#cb1-324"></a><span class="in"> &amp; 3 &amp; 0.192 &amp; 1.447 &amp; 0.251 &amp; &amp; &amp; \\</span></span>
<span id="cb1-325"><a href="#cb1-325"></a><span class="in"> &amp; 4 &amp; 0.208 &amp; 1.842 &amp; 0.264 &amp; &amp; &amp; \\</span></span>
<span id="cb1-326"><a href="#cb1-326"></a><span class="in">\midrule</span></span>
<span id="cb1-327"><a href="#cb1-327"></a><span class="in">\multirow{2}{*}{$K$} &amp; \multirow{2}{*}{$k$} &amp; \multicolumn{6}{c}{$\Lambda(t,\beta)=\exp(\beta t)-1$} \\</span></span>
<span id="cb1-328"><a href="#cb1-328"></a><span class="in">      \cmidrule(lr){3-8}</span></span>
<span id="cb1-329"><a href="#cb1-329"></a><span class="in">      &amp;  &amp; $p_k$ &amp; $\mu_k$ &amp; $\sigma_k^2$ &amp; $\lambda$ &amp; $\beta$ &amp; AIC</span></span>
<span id="cb1-330"><a href="#cb1-330"></a><span class="in">\\ \midrule</span></span>
<span id="cb1-331"><a href="#cb1-331"></a><span class="in">1 &amp; 1 &amp; 1 &amp; 0.344 &amp; 4.950 &amp; 391.00 &amp; 0.268 &amp; -133.52 \\ \hline</span></span>
<span id="cb1-332"><a href="#cb1-332"></a><span class="in">\multirow{2}{*}{2} &amp; 1 &amp; 0.608 &amp; 0.263 &amp; 0.804 &amp; \multirow{2}{*}{390.85} &amp; \multirow{2}{*}{0.268} &amp; \multirow{2}{*}{-137.26} \\</span></span>
<span id="cb1-333"><a href="#cb1-333"></a><span class="in"> &amp; 2 &amp; 0.392 &amp; 0.471 &amp; 1.314 &amp; &amp; &amp; \\ \hline</span></span>
<span id="cb1-334"><a href="#cb1-334"></a><span class="in">\multirow{3}{*}{3} &amp; 1 &amp; 0.615 &amp; 0.263 &amp; 0.811 &amp; \multirow{3}{*}{396.23} &amp; \multirow{3}{*}{0.268} &amp; \multirow{3}{*}{-137.12} \\</span></span>
<span id="cb1-335"><a href="#cb1-335"></a><span class="in"> &amp; 2 &amp; 0.181 &amp; 0.416 &amp; 0.016 &amp; &amp; &amp; \\</span></span>
<span id="cb1-336"><a href="#cb1-336"></a><span class="in"> &amp; 3 &amp; 0.204 &amp; 0.207 &amp; 0.692 &amp; &amp; &amp; \\ \hline</span></span>
<span id="cb1-337"><a href="#cb1-337"></a><span class="in">\multirow{4}{*}{4} &amp; 1 &amp; 0.400 &amp; 0.288 &amp; 0.135 &amp; \multirow{4}{*}{395.73} &amp; \multirow{4}{*}{0.268} &amp; \multirow{4}{*}{-133.69} \\</span></span>
<span id="cb1-338"><a href="#cb1-338"></a><span class="in"> &amp; 2 &amp; 0.196 &amp; 0.413 &amp; 0.047 &amp; &amp; &amp; \\</span></span>
<span id="cb1-339"><a href="#cb1-339"></a><span class="in"> &amp; 3 &amp; 0.204 &amp; 0.526 &amp; 0.078 &amp; &amp; &amp; \\</span></span>
<span id="cb1-340"><a href="#cb1-340"></a><span class="in"> &amp; 4 &amp; 0.200 &amp; 0.207 &amp; 0.692 &amp; &amp; &amp; \\</span></span>
<span id="cb1-341"><a href="#cb1-341"></a><span class="in">\bottomrule</span></span>
<span id="cb1-342"><a href="#cb1-342"></a><span class="in">\end{tabular}</span></span>
<span id="cb1-343"><a href="#cb1-343"></a><span class="in">\end{table}</span></span>
<span id="cb1-344"><a href="#cb1-344"></a><span class="in">```</span></span>
<span id="cb1-347"><a href="#cb1-347"></a><span class="in">```{r}</span></span>
<span id="cb1-348"><a href="#cb1-348"></a><span class="co">#| label: fig-fig:crackci4</span></span>
<span id="cb1-349"><a href="#cb1-349"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-350"><a href="#cb1-350"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-351"><a href="#cb1-351"></a><span class="co">#| out.width: '75%'</span></span>
<span id="cb1-352"><a href="#cb1-352"></a><span class="co">#| fig.cap: '基于疲劳裂纹数据的不同 $K$ 的 CDF 估计.'</span></span>
<span id="cb1-353"><a href="#cb1-353"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/AMM2020/crackci.pdf"</span>)</span>
<span id="cb1-354"><a href="#cb1-354"></a><span class="in">```</span></span>
<span id="cb1-355"><a href="#cb1-355"></a></span>
<span id="cb1-356"><a href="#cb1-356"></a>图 @fig-fig:crackci4 展示了不同 $K$ 值下估计的失效时间\index{失效时间}分布, 其中黑点为拟合随机效应\index{随机效应}非线性模型的结果, 可视为“伪”失效时间\index{失效时间}点. 可以看出, $K=3$ 的模型拟合效果更好. 然而, AIC\index{AIC} 综合考虑了拟合优度与模型复杂度, 表明 $K=2$ 的模型更合适. 这可能是因为 $K=3$ 的模型存在过拟合现象. 表 \ref{tbl-crackci5} 列出了 $K=2$ 和 $K=3$ 模型参数的 95% 自助法置信区间\index{置信区间}, 图 @fig-fig:crackci4 同时展示了 $K=2$ 模型的 95% 点估计自助法置信区间\index{置信区间}. 似然比检验结果显示: 原假设为$K=1$对备择假设$K=2$ 的 检验P值为 0.021, 而原假设为 $K=2$对 备择假设$K=3$ 的检验P值为 0.12. 这表明在显著性水平 0.05 下, 30 个样本中存在两个子总体. 对于 $K=2$ 的情况, 广义路径模型 <span class="co">[</span><span class="ot">@yuan2015hierarchical</span><span class="co">]</span> 和维纳过程\index{维纳过程}模型 <span class="co">[</span><span class="ot">@zhang2017stochastic</span><span class="co">]</span> 的 AIC\index{AIC} 值分别为 -105.69 和 -117.83, 而该模型的 AIC\index{AIC} 值更低, 显示了更优的性能. 这可能是因为广义路径模型未能捕捉时间变化的退化波动, 而维纳过程\index{维纳过程}更适合非单调退化路径. 需要注意的是, 混合高斯分布可能导致负值, 与单调递增退化路径的假设冲突, 但根据估计参数, $\nu$ 为负的概率仅为 $2.031 \times 10^{-6}$, 可忽略不计.</span>
<span id="cb1-357"><a href="#cb1-357"></a></span>
<span id="cb1-358"><a href="#cb1-358"></a><span class="in">```{=latex}</span></span>
<span id="cb1-359"><a href="#cb1-359"></a><span class="in">\begin{table}</span></span>
<span id="cb1-360"><a href="#cb1-360"></a><span class="in">    \centering</span></span>
<span id="cb1-361"><a href="#cb1-361"></a><span class="in">    \caption{当 $\Lambda(t,\beta)=\exp(\beta t)-1$ 时, 参数估计的 95\% 置信区间. }</span></span>
<span id="cb1-362"><a href="#cb1-362"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-363"><a href="#cb1-363"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{1.5mm}</span></span>
<span id="cb1-364"><a href="#cb1-364"></a><span class="in">    \label{tbl-crackci5}</span></span>
<span id="cb1-365"><a href="#cb1-365"></a><span class="in">    \begin{tabular}{ccccc}</span></span>
<span id="cb1-366"><a href="#cb1-366"></a><span class="in">        \toprule</span></span>
<span id="cb1-367"><a href="#cb1-367"></a><span class="in">        &amp; $p_1$ &amp; $\mu_1$ &amp; $\sigma_1^2$ &amp; $\lambda$ \\</span></span>
<span id="cb1-368"><a href="#cb1-368"></a><span class="in">        \midrule</span></span>
<span id="cb1-369"><a href="#cb1-369"></a><span class="in">        &amp; (0.432, 0.768) &amp; (0.230, 0.298) &amp; (0.608, 1.172) &amp; (297.29, 543.82) \\</span></span>
<span id="cb1-370"><a href="#cb1-370"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-371"><a href="#cb1-371"></a><span class="in">        \multirow{2}{*}{$K=2$} &amp; $p_2$ &amp; $\mu_2$ &amp; $\sigma_2^2$ &amp; $\beta$ \\</span></span>
<span id="cb1-372"><a href="#cb1-372"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-373"><a href="#cb1-373"></a><span class="in">        &amp; (0.231, 0.567) &amp; (0.407, 0.530) &amp; (0.746, 2.012) &amp; (0.248, 0.285) \\</span></span>
<span id="cb1-374"><a href="#cb1-374"></a><span class="in">        \midrule</span></span>
<span id="cb1-375"><a href="#cb1-375"></a><span class="in">        &amp; $p_1$ &amp; $\mu_1$ &amp; $\sigma_1^2$ &amp; $\lambda$ \\</span></span>
<span id="cb1-376"><a href="#cb1-376"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-377"><a href="#cb1-377"></a><span class="in">        &amp; (0.366, 0.734) &amp; (0.225, 0.301) &amp; (0.620, 1.183) &amp; (305.18, 554.02) \\</span></span>
<span id="cb1-378"><a href="#cb1-378"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-379"><a href="#cb1-379"></a><span class="in">        \multirow{3}{*}{$K=3$} &amp; $p_2$ &amp; $\mu_2$ &amp; $\sigma_2^2$ &amp; $\beta$ \\</span></span>
<span id="cb1-380"><a href="#cb1-380"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-381"><a href="#cb1-381"></a><span class="in">        &amp; (0.068, 0.466) &amp; (0.208, 0.469) &amp; (3.06$\times 10^{-4}$, 0.117) &amp; (0.249, 0.289) \\</span></span>
<span id="cb1-382"><a href="#cb1-382"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-383"><a href="#cb1-383"></a><span class="in">        &amp; $p_3$ &amp; $\mu_3$ &amp; $\sigma_3^2$ &amp;  \\</span></span>
<span id="cb1-384"><a href="#cb1-384"></a><span class="in">        \cmidrule(lr){2-5}</span></span>
<span id="cb1-385"><a href="#cb1-385"></a><span class="in">        &amp; (0.097, 0.435) &amp; (0.423, 0.583) &amp; (2.36$\times 10^{-4}$, 0.247) &amp;  \\</span></span>
<span id="cb1-386"><a href="#cb1-386"></a><span class="in">        \bottomrule</span></span>
<span id="cb1-387"><a href="#cb1-387"></a><span class="in">    \end{tabular}</span></span>
<span id="cb1-388"><a href="#cb1-388"></a><span class="in">\end{table}</span></span>
<span id="cb1-389"><a href="#cb1-389"></a><span class="in">```</span></span>
<span id="cb1-390"><a href="#cb1-390"></a><span class="in">```{=latex}</span></span>
<span id="cb1-391"><a href="#cb1-391"></a><span class="in">\begin{table}</span></span>
<span id="cb1-392"><a href="#cb1-392"></a><span class="in">    \centering</span></span>
<span id="cb1-393"><a href="#cb1-393"></a><span class="in">    \caption{不同方法下参数估计及计算时间 ($\Lambda(t,\beta)=\exp(\beta t)-1$, $K=2$) . }</span></span>
<span id="cb1-394"><a href="#cb1-394"></a><span class="in">    \label{tbl-comptime}</span></span>
<span id="cb1-395"><a href="#cb1-395"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{2.5mm}</span></span>
<span id="cb1-396"><a href="#cb1-396"></a><span class="in">    \renewcommand{\arraystretch}{1.2}</span></span>
<span id="cb1-397"><a href="#cb1-397"></a><span class="in">    \begin{tabular}{cccccccc}</span></span>
<span id="cb1-398"><a href="#cb1-398"></a><span class="in">        \toprule</span></span>
<span id="cb1-399"><a href="#cb1-399"></a><span class="in">        方法 &amp; $k$ &amp; $p_k$ &amp; $\mu_k$ &amp; $\sigma_k^2$ &amp; $\lambda$ &amp; $\beta$ &amp; 耗时 \\</span></span>
<span id="cb1-400"><a href="#cb1-400"></a><span class="in">        \midrule</span></span>
<span id="cb1-401"><a href="#cb1-401"></a><span class="in">        \multirow{2}{*}{所提方法} </span></span>
<span id="cb1-402"><a href="#cb1-402"></a><span class="in">        &amp; $1$ &amp; 0.608 &amp; 0.263 &amp; 0.804 &amp; \multirow{2}{*}{390.85} &amp; \multirow{2}{*}{0.268} &amp; \multirow{2}{*}{\textbf{0.5秒}} \\</span></span>
<span id="cb1-403"><a href="#cb1-403"></a><span class="in">        &amp; $2$ &amp; 0.392 &amp; 0.471 &amp; 1.314 &amp; &amp; &amp; \\</span></span>
<span id="cb1-404"><a href="#cb1-404"></a><span class="in">        \midrule</span></span>
<span id="cb1-405"><a href="#cb1-405"></a><span class="in">        \multirow{2}{*}{Wang et al.} </span></span>
<span id="cb1-406"><a href="#cb1-406"></a><span class="in">        &amp; $1$ &amp; 0.596 &amp; 0.260 &amp; 0.792 &amp; \multirow{2}{*}{390.87} &amp; \multirow{2}{*}{0.268} &amp; \multirow{2}{*}{1.63秒} \\</span></span>
<span id="cb1-407"><a href="#cb1-407"></a><span class="in">        &amp; $2$ &amp; 0.404 &amp; 0.466 &amp; 1.326 &amp; &amp; &amp; \\</span></span>
<span id="cb1-408"><a href="#cb1-408"></a><span class="in">        \midrule</span></span>
<span id="cb1-409"><a href="#cb1-409"></a><span class="in">        \multirow{2}{*}{Marin et al.} </span></span>
<span id="cb1-410"><a href="#cb1-410"></a><span class="in">        &amp; $1$ &amp; 0.626 &amp; 0.270 &amp; 0.827 &amp; \multirow{2}{*}{390.98} &amp; \multirow{2}{*}{0.270} &amp; \multirow{2}{*}{23.15秒} \\</span></span>
<span id="cb1-411"><a href="#cb1-411"></a><span class="in">        &amp; $2$ &amp; 0.374 &amp; 0.483 &amp; 1.297 &amp; &amp; &amp; \\</span></span>
<span id="cb1-412"><a href="#cb1-412"></a><span class="in">        \bottomrule</span></span>
<span id="cb1-413"><a href="#cb1-413"></a><span class="in">    \end{tabular}</span></span>
<span id="cb1-414"><a href="#cb1-414"></a><span class="in">\end{table}</span></span>
<span id="cb1-415"><a href="#cb1-415"></a><span class="in">```</span></span>
<span id="cb1-416"><a href="#cb1-416"></a>::: {#fig-fig:cdede layout-ncol="2"}</span>
<span id="cb1-417"><a href="#cb1-417"></a><span class="al">![对数似然函数值](figures/IG/AMM2020/loglikeli.pdf)</span>{#fig-fig:logvalue}</span>
<span id="cb1-418"><a href="#cb1-418"></a></span>
<span id="cb1-419"><a href="#cb1-419"></a><span class="al">![每次迭代条件数](figures/IG/AMM2020/condnum.pdf)</span>{#fig-fig:fcond}</span>
<span id="cb1-420"><a href="#cb1-420"></a></span>
<span id="cb1-421"><a href="#cb1-421"></a>所提算法迭代效果.</span>
<span id="cb1-422"><a href="#cb1-422"></a>:::</span>
<span id="cb1-423"><a href="#cb1-423"></a></span>
<span id="cb1-424"><a href="#cb1-424"></a>通过监测对数似然函数\index{似然函数}值评估所提 EM 算法的收敛性, 容差设定为 $\epsilon=1 \times 10^{-5}$. 图 @fig-fig:logvalue 显示了每次迭代中对数似然函数\index{似然函数}的变化, 当 $|\sum_{i=1}^n<span class="co">[</span><span class="ot">\log L_i(\bm\Delta y_i|\bm\Theta^{(s+1)})-\log L_i(\bm\Delta y_i|\bm\Theta^{(s)})</span><span class="co">]</span>|&lt;\epsilon$ 时, 算法停止. 在本例中, 收敛在第 45 次迭代后实现.\</span>
<span id="cb1-425"><a href="#cb1-425"></a>图 @fig-fig:fcond 对比了所提 EM 算法与简单梯度上升算法每次迭代的条件数, 其中简单梯度上升算法基于矩阵 $H(\bm\Theta)$ 计算条件数. 从图中可以看出, 所提 EM 算法的条件数更小, 表明其收敛速度更快. 图 @fig-fig:parite 显示了每次迭代的模型参数估计值变化. 可以看到, 所提 EM 算法的参数估计值收敛非常迅速, 计算时间仅为 0.5 秒 (测试环境: Windows 7 系统, Intel Core 2 Duo 处理器, 2.4 GHz, 4 GB 内存). 相比之下, <span class="co">[</span><span class="ot">@wangschda2007</span><span class="co">]</span> 的 EM 算法也需 45 次迭代, 但计算时间为 1.63 秒; 而基于 MCMC\index{MCMC} 方法 (@matin2005 的第 4.3 节) 的算法需要 20,000 次迭代, 计算时间达 23.15 秒. 三种方法的参数估计结果列于表 \ref{tbl-comptime}. 图 @fig-fig:crackg2 展示了在假设存在两个子群体时, 30 个单元的聚类情况. 结果显示, 第 1 组样品的性能退化\index{性能退化}速度明显快于第 2 组.</span>
<span id="cb1-426"><a href="#cb1-426"></a></span>
<span id="cb1-429"><a href="#cb1-429"></a><span class="in">```{r}</span></span>
<span id="cb1-430"><a href="#cb1-430"></a><span class="co">#| label: fig-fig:parite</span></span>
<span id="cb1-431"><a href="#cb1-431"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-432"><a href="#cb1-432"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-433"><a href="#cb1-433"></a><span class="co">#| out.width: '95%'</span></span>
<span id="cb1-434"><a href="#cb1-434"></a><span class="co">#| fig.cap: '模型参数估迭代图.'</span></span>
<span id="cb1-435"><a href="#cb1-435"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/AMM2020/parites.pdf"</span>)</span>
<span id="cb1-436"><a href="#cb1-436"></a><span class="in">```</span></span>
<span id="cb1-437"><a href="#cb1-437"></a></span>
<span id="cb1-440"><a href="#cb1-440"></a><span class="in">```{r}</span></span>
<span id="cb1-441"><a href="#cb1-441"></a><span class="co">#| label: fig-fig:crackg2</span></span>
<span id="cb1-442"><a href="#cb1-442"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-443"><a href="#cb1-443"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-444"><a href="#cb1-444"></a><span class="co">#| out.width: '75%'</span></span>
<span id="cb1-445"><a href="#cb1-445"></a><span class="co">#| fig.cap: '当 $K=2$ 时, 疲劳裂纹数据的单元聚类.'</span></span>
<span id="cb1-446"><a href="#cb1-446"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/AMM2020/crackgroup2.pdf"</span>)</span>
<span id="cb1-447"><a href="#cb1-447"></a><span class="in">```</span></span>
<span id="cb1-448"><a href="#cb1-448"></a></span>
<span id="cb1-449"><a href="#cb1-449"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> 总结  {#sec-AMM2020-s6} --&gt;</span></span>
<span id="cb1-450"><a href="#cb1-450"></a></span>
<span id="cb1-451"><a href="#cb1-451"></a><span class="co">&lt;!-- 本研究针对具有子群体异质性的退化数据提出了一种新型随机效应模型. 具体而言, 提出了一个 IG 过程, 其参数之一服从混合高斯分布. 基于所提出的模型, 我们开发了一种计算效率高的 EM 算法来估计参数. 此外, 采用偏差校正百分位数引导法计算模型参数的置信区间\index{置信区间}. 通过模拟研究和具有子群体的真实数据集验证了所提模型的能力和有效性. 我们还将所提出的模型和相应的 EM 算法应用于经典数据集. 结果表明, 所提出的模型和 EM 算法在 AIC\index{AIC} 和收敛速度方面分别优于现有的模型和算法. 所提模型的优点是它灵活且能够适用于任意数量的子群体, 甚至适用于无子群体的情况 (即 $K=1$) . 值得一提的是, 当子种群数量很大时, 所需的样本量应该足够大, 以便确定精确的值 $K$. 所提模型中的随机效应由参数 $\alpha$ 反映. 然而, 分散参数 $\lambda$ 也可能是随机的, 并遵循混合分布, 例如混合伽马分布\index{伽马分布}. 此外, 这两个参数都服从混合分布. 这两种情况的统计推断也可以通过所提出的 EM 算法进行, 只需稍加修改.  --&gt;</span></span>
<span id="cb1-452"><a href="#cb1-452"></a></span>
<span id="cb1-453"><a href="#cb1-453"></a><span class="co">&lt;!-- 未来有一些可能的研究方向. 首先, 本研究通过基于 AIC\index{AIC} 的计数来确定子种群的数量. 一种更有效的确定适当数量的方法很重要, 值得研究, 例如可逆跳跃. 此外, 将所提出的模型集成到故障\index{故障}预测和预防性维护决策中具有重要意义, 需要付出大量努力.--&gt;</span></span>
<span id="cb1-454"><a href="#cb1-454"></a></span>
<span id="cb1-455"><a href="#cb1-455"></a>\newpage</span>
<span id="cb1-456"><a href="#cb1-456"></a></span>
<span id="cb1-457"><a href="#cb1-457"></a><span class="fu">### 附录 {#sec-Append-4B}</span></span>
<span id="cb1-458"><a href="#cb1-458"></a></span>
<span id="cb1-459"><a href="#cb1-459"></a><span class="fu">#### EM 算法技术细节 {.unnumbered}</span></span>
<span id="cb1-460"><a href="#cb1-460"></a></span>
<span id="cb1-461"><a href="#cb1-461"></a>M 步可以通过求解以下方程实现. \begin{align*}</span>
<span id="cb1-462"><a href="#cb1-462"></a>        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial p_k}&amp;=\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}}{p_k}=0,  <span class="sc">\\</span></span>
<span id="cb1-463"><a href="#cb1-463"></a>        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \mu_k}&amp;=</span>
<span id="cb1-464"><a href="#cb1-464"></a>        \sum\limits_{i=1}^n w_{ik}^{(s)}\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)/(1/y_{im_i}+\sigma_k^2)=0,<span class="sc">\\</span></span>
<span id="cb1-465"><a href="#cb1-465"></a>        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \sigma_k^2}&amp; =-\dfrac{1}{2} \sum\limits_{i=1}^n \left<span class="co">[</span><span class="ot">\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2} - \dfrac{w_{ik}^{(s)}\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{(1/y_{im_i}+\sigma_k^2)^2}\right</span><span class="co">]</span>=0, <span class="sc">\\</span></span>
<span id="cb1-466"><a href="#cb1-466"></a>        &amp; \qquad k=1,\dots,K,<span class="sc">\\</span></span>
<span id="cb1-467"><a href="#cb1-467"></a>        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \lambda}&amp;=</span>
<span id="cb1-468"><a href="#cb1-468"></a>        \dfrac{1}{2}\sum\limits_{i=1}^n\left[ m_i/\lambda- \sum\limits_{j=1}^{m_i} h_{ij}(\beta)^2/\Delta y_{ij}+\Lambda(t_{im_i},\beta)^2/y_{im_i} \right. <span class="sc">\\</span></span>
<span id="cb1-469"><a href="#cb1-469"></a>        &amp;\quad \left. - \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right]=0,<span class="sc">\\</span></span>
<span id="cb1-470"><a href="#cb1-470"></a>        \dfrac{\partial Q(\bm\Theta,\bm\Theta^{(s)})}{\partial \beta}&amp;=</span>
<span id="cb1-471"><a href="#cb1-471"></a>        \sum\limits_{i=1}^n \left[ \sum\limits_{j=1}^{m_i}\dfrac{h^{'}_{ij}(\beta)}{h_{ij}(\beta)}-</span>
<span id="cb1-472"><a href="#cb1-472"></a>        \lambda\left(\sum\limits_{i=1}^{m_i}h^{'}_{ij}(\beta)h_{ij}(\beta)/\Delta y_{ij}-\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)/y_{im_i}\right) \right]<span class="sc">\\</span></span>
<span id="cb1-473"><a href="#cb1-473"></a>        &amp;- \sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\lambda\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)/(1+y_{im_i}\sigma_k^2)=0. </span>
<span id="cb1-474"><a href="#cb1-474"></a>\end{align*} 通过求解上述方程, 可求得第 $(s+1)$ 次迭代的参数估计值 $\bm \Theta^{(s+1)}$, 如下所示 \begin{eqnarray}</span>
<span id="cb1-475"><a href="#cb1-475"></a>  p_k^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}}{n},\nonumber<span class="sc">\\</span></span>
<span id="cb1-476"><a href="#cb1-476"></a>  \mu_k^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nw_{ik}^{(s)}\Lambda(t_{im_i},\beta^{(s)})/(y_{im_i}/(\sigma_k^2)^{(s)}+1)}</span>
<span id="cb1-477"><a href="#cb1-477"></a>        {\sum\limits_{i=1}^nw_{ik}^{(s)}/(1/y_{im_i}+(\sigma_k^2)^{(s)})},\nonumber<span class="sc">\\</span></span>
<span id="cb1-478"><a href="#cb1-478"></a>        \lambda^{(s+1)}&amp;=&amp;\dfrac{\sum\limits_{i=1}^nm_i}{\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} h_{ij}(\beta^{(s)})^2/\Delta y_{ij}-\Lambda(t_{im_i},\beta^{(s)})^2/y_{im_i}+</span>
<span id="cb1-479"><a href="#cb1-479"></a>            \sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right] },\nonumber</span>
<span id="cb1-480"><a href="#cb1-480"></a>\end{eqnarray} \normalsize $(\sigma_k^2)^{(s+1)}$ 可以通过求解以下方程得到. \begin{equation}\label{sigmas}</span>
<span id="cb1-481"><a href="#cb1-481"></a>    \sum\limits_{i=1}^n \left<span class="co">[</span><span class="ot">\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2}- \dfrac{w_{ik}^{(s)}\lambda^{(s)}(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2}{(1/y_{im_i}+\sigma_k^2)^2}\right</span><span class="co">]</span>=0,</span>
<span id="cb1-482"><a href="#cb1-482"></a>\end{equation} $\beta^{(s+1)}$ 可以通过求解以下方程得到. \begin{align}\label{betas}</span>
<span id="cb1-483"><a href="#cb1-483"></a>    &amp;\sum\limits_{i=1}^n \left[\sum\limits_{j=1}^{m_i}\dfrac{h^{'}_{ij}(\beta)}{h_{ij}(\beta)}-</span>
<span id="cb1-484"><a href="#cb1-484"></a>    \lambda^{(s)}\left(\sum\limits_{i=1}^{m_i}h^{'}_{ij}(\beta)h_{ij}(\beta)/\Delta y_{ij}-\Lambda^{'}(t_{im_i},\beta)\Lambda(t_{im_i},\beta)/y_{im_i}\right) \right]\nonumber<span class="sc">\\</span></span>
<span id="cb1-485"><a href="#cb1-485"></a>    &amp;- \sum\limits_{i=1}^n\sum\limits_{k=1}^{K} w_{ik}^{(s)}\lambda^{(s)}\Lambda^{'}(t_{im_i},\beta)</span>
<span id="cb1-486"><a href="#cb1-486"></a>    \Lambda(t_{im_i},\beta)\dfrac{\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k^{(s)}}{1+y_{im_i}(\sigma_k^2)^{(s)}}=0.</span>
<span id="cb1-487"><a href="#cb1-487"></a>\end{align} 通过使用 *R* 软件中的 *uniroot()* 函数, 求解式 \eqref{sigmas} 和 \eqref{betas} 的零点.</span>
<span id="cb1-488"><a href="#cb1-488"></a></span>
<span id="cb1-489"><a href="#cb1-489"></a><span class="fu">#### 定理 @thm-AMM2020-2 的证明 {.unnumbered}</span></span>
<span id="cb1-490"><a href="#cb1-490"></a></span>
<span id="cb1-491"><a href="#cb1-491"></a>对数似然函数\index{似然函数}定义为 $l(\bm\Theta)=\sum_{i=1}^n \log L_i(\Delta \bm y_{i} \mid \bm \Theta)$, 其中 $L_i(\Delta \bm y_{i}|\bm \Theta)$ 的表达式如式 \eqref{margi} 所示. 定义 $$H_{ik}(\bm\Theta)=\dfrac{\sqrt{\lambda}}{\sqrt{2\pi(1/y_{im_i}+\sigma_k^2)}}</span>
<span id="cb1-492"><a href="#cb1-492"></a>    \exp\left<span class="sc">\{</span>-\dfrac{\lambda(\Lambda(t_{im_i},\beta)/y_{im_i}-\mu_k)^2}{2(1/y_{im_i}+\sigma_k^2)} \right<span class="sc">\}</span>.$$ 则对 $P$ 的一阶导数为 $$\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=</span>
<span id="cb1-493"><a href="#cb1-493"></a>\sum_{i=1}^{n}\dfrac{(H_{i1}(\bm\Theta^{(s)}),\dots,H_{iK}(\bm\Theta^{(s)}))^{'}}</span>
<span id="cb1-494"><a href="#cb1-494"></a>    {\sum_{k=1}^{K}p_k^{(s)}H_{ik}(\bm\Theta^{(s)})}, $$ 进一步计算得到:\</span>
<span id="cb1-495"><a href="#cb1-495"></a>\begin{equation*}</span>
<span id="cb1-496"><a href="#cb1-496"></a>    \begin{split}</span>
<span id="cb1-497"><a href="#cb1-497"></a>    G_P^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial P}\Big|_{\bm\Theta=\bm\Theta^{(s)}}&amp;=</span>
<span id="cb1-498"><a href="#cb1-498"></a>    \dfrac{1}{n}\sum_{i=1}^{n}\dfrac{(p_1^{(s)}H_{i1}(\bm\Theta^{(s)}),\dots,p_K^{(s)}H_{iK}(\bm\Theta^{(s)}))^{'}}</span>
<span id="cb1-499"><a href="#cb1-499"></a>    {\sum_{k=1}^{K}p_k^{(s)}H_{ik}(\bm\Theta^{(s)})}-P^{(s)}<span class="sc">\\</span></span>
<span id="cb1-500"><a href="#cb1-500"></a>    &amp;=\dfrac{1}{n}\sum_{i=1}^{n}\left(w_{i1}^{(s)},\dots,w_{iK}^{(s)}\right)^{'}-P^{(s)}<span class="sc">\\</span></span>
<span id="cb1-501"><a href="#cb1-501"></a>    &amp;=P^{(s+1)}-P^{(s)}.</span>
<span id="cb1-502"><a href="#cb1-502"></a>    \end{split}</span>
<span id="cb1-503"><a href="#cb1-503"></a>    \end{equation*} 类似地, 对 $\mu_k$ 的一阶导数为 $$\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=\sum_{i=1}^{n}\lambda^{(s)}w_{ik}^{(s)}\dfrac{\Lambda_{i}/y_{im_i}-\mu_k^{(s)}}{1/y_{im_i}+(\sigma_k^2)^{(s)}}</span>
<span id="cb1-504"><a href="#cb1-504"></a>.$$ 因此 \begin{equation*}</span>
<span id="cb1-505"><a href="#cb1-505"></a>    \begin{split}</span>
<span id="cb1-506"><a href="#cb1-506"></a>    G_{\mu_k}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \mu_k}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=</span>
<span id="cb1-507"><a href="#cb1-507"></a>    {\mu_k}^{(s+1)}-{\mu_k}^{(s)}.</span>
<span id="cb1-508"><a href="#cb1-508"></a>    \end{split}</span>
<span id="cb1-509"><a href="#cb1-509"></a>\end{equation*} 对 $\lambda$ 进行一阶导数, 并将 $\lambda=\lambda^{(s)}$ 代入, 得到 $$\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=</span>
<span id="cb1-510"><a href="#cb1-510"></a>\dfrac{\sum_{i=1}^{n}m_i}{2\lambda^{(s)}}-\dfrac{1}{2}</span>
<span id="cb1-511"><a href="#cb1-511"></a>\sum\limits_{i=1}^n\left[\sum\limits_{j=1}^{m_i} \dfrac{h_{ij}^2}{\Delta y_{ij}}-\dfrac{\Lambda_i^2}{y_{im_i}}+</span>
<span id="cb1-512"><a href="#cb1-512"></a>\sum\limits_{k=1}^{K} w_{ik}^{(s)}\dfrac{(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{2(1/y_{im_i}+(\sigma_k^2)^{(s)})}\right].</span>
<span id="cb1-513"><a href="#cb1-513"></a>$$ 因此 $$G_{\lambda}^{(s)}~\dfrac{\partial l(\bm\Theta)}{\partial \lambda}\Big|_{\bm\Theta=\bm\Theta^{(s)}}</span>
<span id="cb1-514"><a href="#cb1-514"></a>=\lambda^{(s+1)}-\lambda^{(s)}.$$ 令 $$g_k(\sigma_k)=-\dfrac{1}{2}\sum\limits_{i=1}^n \left<span class="co">[</span><span class="ot">\dfrac{w_{ik}^{(s)}}{1/y_{im_i}+\sigma_k^2}- \dfrac{w_{ik}^{(s)}\lambda^{(s)}(\Lambda(t_{im_i},\beta^{(s)})/y_{im_i}-\mu_k^{(s)})^2} {(1/y_{im_i}+\sigma_k^2)^2}\right</span><span class="co">]</span>,$$ 则 $$\dfrac{\partial l(\bm\Theta)}{\partial \sigma_k^2}\Big|_{\bm\Theta=\bm\Theta^{(s)}}=</span>
<span id="cb1-515"><a href="#cb1-515"></a>g_k(\sigma_k^{(s)}).$$ $\sigma_k^2$ 的 EM 更新通过牛顿法计算: $$  (\sigma_k^2)^{(s+1)}-(\sigma_k^2)^{(s)}=-\dfrac{g_k(\sigma_k^{(s)})}{g_k^{'}(\sigma_k^{(s)})},$$ 其中 $$g_k^{'}(\sigma_k^{(s)})=  \sum\limits_{i=1}^nw_{ik}^{(s)}\left<span class="co">[</span><span class="ot">\dfrac{\lambda^{(s)}(\Lambda_i/y_{im_i}-\mu_k^{(s)})^2}{\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^3}-\dfrac{1}{2\left(1/y_{im_i}+(\sigma_k^2)^{(s)}\right)^2}\right</span><span class="co">]</span>.$$ 设 $G_{\sigma_k}^{(s)} = -1 / g_k'(\sigma_k^{(s)})$, 则结果成立. 对 $\beta$ 的推导与 $\sigma_k^2$ 类似, 这里省略.</span>
<span id="cb1-516"><a href="#cb1-516"></a></span>
<span id="cb1-517"><a href="#cb1-517"></a><span class="fu">## 二阶段逆高斯过程 {#sec-tp-IG}</span></span>
<span id="cb1-518"><a href="#cb1-518"></a></span>
<span id="cb1-519"><a href="#cb1-519"></a><span class="fu">### 研究背景 {#sec-tp-s1}</span></span>
<span id="cb1-520"><a href="#cb1-520"></a></span>
<span id="cb1-521"><a href="#cb1-521"></a>在 @sec-Two-Phase-Wiener 节中，介绍了两阶段维纳过程\index{维纳过程}模型, 其用来描述产品性能呈现两个不同退化的规律. 由维纳过程\index{维纳过程}的性质可知, 这类模型对非单调退化数据的拟合有显著效果. 然而, 对于单调退化数据, 例如钢铝合金金属的疲劳裂纹扩展 <span class="co">[</span><span class="ot">@lawless2004covariates</span><span class="co">]</span>、碳膜电阻器的电阻变化 <span class="co">[</span><span class="ot">@park2006stochastic</span><span class="co">]</span> 以及LED的退化 <span class="co">[</span><span class="ot">@Zhai2018</span><span class="co">]</span>, 伽马过程\index{伽马过程}和IG过程可能会更合适. 这两类随机过程能够有效刻画单调退化模式, 并为系统剩余寿命\index{剩余寿命}的准确估计提供有力支持. 对于伽马过程\index{伽马过程}, @linngtsu2019 提出了一种两阶段伽马退化过程\index{退化过程}模型, 并使用ML方法和贝叶斯\index{贝叶斯}方法估计未知参数. 同样, @Lin2021b 提出了一个固定变点\index{变点}的两阶段伽马退化过程\index{退化过程}模型, 用于分析恒定电流下电池老化的电压-放电曲线. 而对于IG过程, @Duan2017 研究了一类两阶段 IG 退化过程\index{退化过程}模型, 但其工作存在以下局限:</span>
<span id="cb1-522"><a href="#cb1-522"></a></span>
<span id="cb1-523"><a href="#cb1-523"></a>1)  变点\index{变点}位置的约束: 在两阶段退化模型中 (如图 @fig-tp-fig:ig 所示), $Y(t)$在时间$\tau$之前服从IG过程$\mathcal{IG}(\alpha_1t, \lambda t^2)$, 在$\tau$之后则过渡到另一个IG过程$\mathcal{IG}(\alpha_2t, \lambda t^2)$. 假设$t_j &lt; \tau &lt; t_{j+1}$, 表示$Y_j$、$Y_\tau$和$Y_{j+1}$分别为时间$t_j$、$\tau$和$t_{j+1}$的退化值. 退化增量$Y_{j+1} - Y_j$可分解为$Y_{j+1} - Y_\tau$和$Y_\tau - Y_j$两个子增量, 且已知$Y_{j+1} - Y_\tau \sim IG(a, b)$和$Y_\tau - Y_j \sim IG(c, d)$, 其中: $a=\alpha_2(t_{j+1}-\tau)$, $b=\lambda(t_{j+1}-\tau)^2$, $c=\alpha_1(\tau-t_j)$, $d=\lambda(\tau-t_j)^2$. 然而, 由于 IG 分布的可加性在此问题中不适用, 即便$\alpha_1 = \alpha_2$, 推导$Y_{j+1} - Y_j$的分布仍具有挑战性. 为简化问题, @Duan2017 假设变点\index{变点}$\tau$与测量时间点重合, 即$\tau = t_j$或$\tau = t_{j+1}$. 尽管这种假设在理论上可行, 但实际情况下变点\index{变点}通常是随机的, 这一约束可能导致参数估计偏差、RUL预测\index{RUL预测}不准确, 进而影响维修决策.</span>
<span id="cb1-524"><a href="#cb1-524"></a></span>
<span id="cb1-525"><a href="#cb1-525"></a>2)  寿命\index{寿命}分布推导的局限: @Duan2017 假设变点\index{变点}对应的退化状态为固定值, 并在此基础上推导失效时间\index{失效时间}的分布. 然而, 变点\index{变点}位置的估计本质上依赖于样本信息, 其不确定性将直接影响退化状态的估计结果. 因此, 有必要进一步考虑变点\index{变点}的随机性, 并推导失效时间\index{失效时间}的边际分布. 此外, @Duan2017 仅聚焦于统计推断问题, 尚未充分探讨RUL估计及其对后续维修策略制定的潜在影响.</span>
<span id="cb1-526"><a href="#cb1-526"></a></span>
<span id="cb1-527"><a href="#cb1-527"></a>3)  **忽略估计中的不确定性**: @Duan2017 采用ML法对模型参数进行点估计, 未考虑参数估计的不确定性. 在中小样本情形下, 参数估计方差可能较大, 而MTTF、可靠性\index{可靠性}及分位寿命\index{寿命}等关键指标一般为参数的函数, 其估计方差也会较大, 从而影响对产品可靠性\index{可靠性}的准确评估. 因此, 引入区间估计方法以量化参数不确定性尤为关键. 这不仅有助于全面反映估计量的波动, 也为后续的维修决策提供更具参考价值的信息 <span class="co">[</span><span class="ot">@wu2022interval</span><span class="co">]</span>.</span>
<span id="cb1-528"><a href="#cb1-528"></a></span>
<span id="cb1-529"><a href="#cb1-529"></a>::: {#fig-tp-ig_rig layout-ncol="2"}</span>
<span id="cb1-530"><a href="#cb1-530"></a><span class="al">![IG过程](figures/IG/EJOR2024/IG.pdf)</span>{#fig-tp-fig:ig}</span>
<span id="cb1-531"><a href="#cb1-531"></a></span>
<span id="cb1-532"><a href="#cb1-532"></a><span class="al">![rIG过程](figures/IG/EJOR2024/rIG.pdf)</span>{#fig-tp-fig:rig}</span>
<span id="cb1-533"><a href="#cb1-533"></a></span>
<span id="cb1-534"><a href="#cb1-534"></a>两种类型的两阶段随机过程.</span>
<span id="cb1-535"><a href="#cb1-535"></a>:::</span>
<span id="cb1-536"><a href="#cb1-536"></a></span>
<span id="cb1-537"><a href="#cb1-537"></a>为更好地解决这些问题, 本节首先介绍一类新的两阶段重参数化IG (reparameterized IG, rIG) 过程模型, 并在此基础上考虑变点\index{变点}的异质性\index{异质性}以及基于RUL 的维修决策问题. 具体包括以下三个方面:</span>
<span id="cb1-538"><a href="#cb1-538"></a></span>
<span id="cb1-539"><a href="#cb1-539"></a>1)  **提出新的两阶段rIG退化模型**. 为克服传统两阶段IG退化模型中涉及的非可加问题, 引入一种新的两阶段rIG退化模型. 如图 @fig-tp-fig:rig 所示, 当变点\index{变点}位于时间间隔$(t_j, t_{j+1})$内时, 通过两个子增量$Y_{j+1} - Y_{\tau}$和$Y_{\tau} - Y_{j}$的分布, 推导出退化增量$Y_{j+1} - Y_{j}$的分布. 具体而言, 若$Y_{j+1} - Y_{\tau} \sim rIG(a, b)$且$Y_{\tau} - Y_{j} \sim rIG(c, b)$, 则$Y_{j+1} - Y_{j} \sim rIG(a+c, b)$. 该模型允许变点\index{变点}发生在任意时刻, 而不局限于特定的测量时间, 从而显著提升模型的灵活性和准确性, 使其能够更全面地刻画复杂退化模式.</span>
<span id="cb1-540"><a href="#cb1-540"></a></span>
<span id="cb1-541"><a href="#cb1-541"></a>2)  **引入系统特定的**变点\index{变点}和参数以刻画系统间的异质性\index{异质性}. 通过为每个系统设定独立的变点\index{变点}和模型参数, 反映设备之间的差异性, 并充分考虑变点\index{变点}处退化状态的不确定性. 在此基础上, 推导每个系统的故障\index{故障}时间分布及 RUL 分布. 为实现精准推断, 提供两种统计推断方法: i) 基于ML方法的参数估计, 通过自助法获得区间估计. ii) 采用自适应拒绝抽样 (Adaptive Rejection Metropolis Sampling, ARMS) 结合Gibbs抽样\index{Gibbs抽样}生成后验样本, 构建可信区间\index{可信区间}. 这些区间量化了参数估计和RUL预测\index{RUL预测}中的不确定性, 为工程应用提供全面的信息支持.</span>
<span id="cb1-542"><a href="#cb1-542"></a></span>
<span id="cb1-543"><a href="#cb1-543"></a>3)  **提出基于RUL分布的**自适应替换\index{自适应替换}策略. 针对两阶段或多阶段退化的维修策略, 尽管已有研究 <span class="co">[</span><span class="ot">@zhang2024condition; @yang2017condition; @zhang2016optimal</span><span class="co">]</span> 基于固定变点\index{变点}考虑了成本最优化决策, 但对未知参数和变点\index{变点}的动态检测关注较少. 文献 <span class="co">[</span><span class="ot">@fouladirad2011; @fouladirad2008use; @grall2008maintenance</span><span class="co">]</span> 考虑了已知模型参数情况下的变点\index{变点}检测问题. 相较之下, 本节假设参数和变点\index{变点}位置未知, 通过连续获取的观测数据动态更新参数估计, 并以此制定自适应 替换策略. 这种自适应策略更贴近实际应用, 可以显著提升系统动态演化背景下的维修决策效果.</span>
<span id="cb1-544"><a href="#cb1-544"></a></span>
<span id="cb1-545"><a href="#cb1-545"></a>本节内容安排如下: 第 @sec-tp-s2 节介绍两阶段rIG退化模型, 推导出相应的失效时间\index{失效时间}和剩余寿命\index{剩余寿命}分布, 并提出基于RUL的自适应替换\index{自适应替换}策略. 第 @sec-tp-s3 节描述用于估计模型未知参数的两种方法: EM方法和贝叶斯\index{贝叶斯}方法. 第 @sec-tp-s5 节通过模拟研究比较不同方法的统计推断性能. 第 @sec-tp-s6 节进行案例研究, 用于验证所提方法的适用性.</span>
<span id="cb1-546"><a href="#cb1-546"></a></span>
<span id="cb1-547"><a href="#cb1-547"></a><span class="fu">### 模型构建 {#sec-tp-s2}</span></span>
<span id="cb1-548"><a href="#cb1-548"></a></span>
<span id="cb1-549"><a href="#cb1-549"></a><span class="fu">#### rIG 过程 {#sec-EJOR2024-s2-1}</span></span>
<span id="cb1-550"><a href="#cb1-550"></a></span>
<span id="cb1-551"><a href="#cb1-551"></a>传统的 IG 过程广泛用于刻画产品性能的退化规律 <span class="co">[</span><span class="ot">@fan2023complete; @hao2019degradation; @pan2016remaining</span><span class="co">]</span>. 然而, 当性能退化\index{性能退化}呈现多个阶段时, 传统 IG 过程对不同阶段退化的可加性质将不满足, 这限制了其应用. 为解决这一问题, 本节首先引入 rIG 分布 $rIG(\delta, \gamma)$, 为相关的 rIG 过程提供数学基础. $rIG(\delta, \gamma)$ 与传统的 IG 分布 $IG(a, b)$ 之间的参数关系为 $a=\delta/\gamma$ 和 $b = \delta^2$ <span class="co">[</span><span class="ot">@Barndorff1998</span><span class="co">]</span>. $rIG(\delta, \gamma)$ 的 PDF 表达式为: \begin{equation}</span>
<span id="cb1-552"><a href="#cb1-552"></a>f_{rIG}(y| \delta, \gamma)=\frac{\delta}{\sqrt{2 \pi}} e^{\delta \gamma} y^{-3 / 2} e^{-\left(\delta^2 y^{-1}+\gamma^2 y\right) / 2}, ~ y&gt;0,\delta&gt;0,\gamma&gt;0.</span>
<span id="cb1-553"><a href="#cb1-553"></a>\end{equation} 对应的CDF 为: \begin{equation}\label{pdf}</span>
<span id="cb1-554"><a href="#cb1-554"></a>\begin{aligned}</span>
<span id="cb1-555"><a href="#cb1-555"></a>    F_{rIG}(y | \delta, \gamma)&amp;= \Phi\left<span class="co">[</span><span class="ot">\sqrt{y}\gamma - \frac{\delta}{\sqrt{y}}\right</span><span class="co">]</span>+e^{2 \delta \gamma} \Phi\left<span class="co">[</span><span class="ot">-\sqrt{y}\gamma - \frac{\delta}{\sqrt{y}} \right</span><span class="co">]</span>,</span>
<span id="cb1-556"><a href="#cb1-556"></a>\end{aligned}</span>
<span id="cb1-557"><a href="#cb1-557"></a>\end{equation} 其中 $\Phi(\cdot)$ 是标准正态分布\index{正态分布}的CDF. 若随机变量 $Y$ 服从 rIG 分布 $rIG(\delta,\gamma)$, 则其矩母函数 (moment-generating function, MGF) 为 \begin{equation}\label{mfg0}</span>
<span id="cb1-558"><a href="#cb1-558"></a>M_Y(t) = \mathbb{E}(e^{ty}) = e^{\delta \gamma \left( 1 - \sqrt{1-\frac{2t}{\gamma^2} } \right)}.</span>
<span id="cb1-559"><a href="#cb1-559"></a>\end{equation} 根据 \eqref{mfg0} 的表达式, 可知 rIG 分布具有可加性质, 即, 若两个独立随机变量 $Y_1\sim rIG\left(\delta_1, \gamma\right)$ 和 $Y_2\sim rIG\left(\delta_2, \gamma\right)$, 则有 $Y_1+Y_2\sim rIG\left(\delta_1+\delta_2, \gamma\right).$</span>
<span id="cb1-560"><a href="#cb1-560"></a></span>
<span id="cb1-561"><a href="#cb1-561"></a>由此, 可定义一类 rIG 过程. 若随机过程 ${Z(t), t\ge0}$ 满足以下条件, 则称其为 rIG 过程: i) $Z(0)=0$, 概率为1; ii) 对于 $t_2&gt;t_1 \geq s_2&gt;s_1 \geq 0$, $Z\left(t_2\right)-Z\left(t_1\right)$ 与 $Z\left(s_2\right)-Z\left(s_1\right)$ 相互独立; iii) 对于 $t&gt;s \geq 0$, 增量 $Z(t)-Z(s)$ 服从 rIG 分布 $rIG\left(\delta(\Lambda(t)-\Lambda(s)), \gamma\right)$, 其中 $\Lambda(t)$ 是单调增函数, 满足 $\Lambda(0)=0$. 称该 rIG 过程为 $r\mathcal{IG}\left(\delta\Lambda(t), \gamma\right)$, 其中 $\delta$ 是漂移参数, $\gamma$ 是扩散参数. 基于上述定义, 可以推导出 $Z(t)$ 的均值和方差分别为 $\delta \Lambda(t) / \gamma$ 和 $\delta \Lambda(t)/ \gamma^3$.</span>
<span id="cb1-562"><a href="#cb1-562"></a></span>
<span id="cb1-563"><a href="#cb1-563"></a><span class="fu">#### 两阶段rIG退化模型 {#sec-tp-s2-2}</span></span>
<span id="cb1-564"><a href="#cb1-564"></a></span>
<span id="cb1-565"><a href="#cb1-565"></a>假设系统的退化过程\index{退化过程}由两个不同阶段组成, 并通过一个变点\index{变点}进行区分. 在这两个阶段中, 假定退化模式符合rIG过程, 每个阶段使用不同的漂移参数来描述变点\index{变点}前后的退化行为. 由于测试系统来自相同的总体, 可以推断这些系统的故障\index{故障}机制是一致的. 由于扩散参数$\gamma$反映系统的故障\index{故障}机制, 进一步假定它在不同系统中保持一致. 令$\Lambda(t) = t$来描述退化速率随时间线性增加的情形 <span class="co">[</span><span class="ot">@Kong2017; @Wang2018itr</span><span class="co">]</span>. 此外, 不同系统的变点\index{变点}可能不同. 为了刻画这种变异性, 将变点\index{变点}$\tau$设为随机变量, 并假定其服从正态分布\index{正态分布}, 记其PDF为$g_\tau(\cdot|\mu_\tau, \sigma_\tau^2)$. 这种处理方式既能刻画系统间的异质性\index{异质性}, 又便于数学推导 (可以得到估计$\mu_\tau$和$\sigma_\tau^2$的解析形式), 因此在退化建模领域被广泛采用 <span class="co">[</span><span class="ot">@Lu2020; @shen2018degradation</span><span class="co">]</span>. 由此, 可考虑以下的两阶段rIG退化模型: \begin{equation}\label{tp-model}</span>
<span id="cb1-566"><a href="#cb1-566"></a>    \begin{aligned}</span>
<span id="cb1-567"><a href="#cb1-567"></a>        &amp;   Y(t)|\tau\sim r\mathcal{IG}\left(m(t;\delta_1 ,\delta_2 ,\tau),\gamma\right),~\tau\sim N\left(\mu_\tau, \sigma_\tau^2\right),<span class="sc">\\</span></span>
<span id="cb1-568"><a href="#cb1-568"></a>        &amp;   m(t;\delta_1 ,\delta_2 ,\tau) = \begin{cases} \delta_1t, &amp; t \leq \tau, <span class="sc">\\</span> \delta_2 \left(t-\tau\right)+\delta_1\tau, &amp; t&gt;\tau,\end{cases}</span>
<span id="cb1-569"><a href="#cb1-569"></a>    \end{aligned}</span>
<span id="cb1-570"><a href="#cb1-570"></a>\end{equation} 其中 $\delta_1$ 和 $\delta_2$ 分别是 $t \leq \tau$ 和 $t&gt;\tau$ 时的漂移参数.</span>
<span id="cb1-571"><a href="#cb1-571"></a></span>
<span id="cb1-572"><a href="#cb1-572"></a><span class="fu">#### 失效时间和 RUL分布 {#sec-tp-s2-3}</span></span>
<span id="cb1-573"><a href="#cb1-573"></a></span>
<span id="cb1-574"><a href="#cb1-574"></a>基于两阶段 rIG 退化模型 \ref{tp-model}, 接下来对系统的失效时间\index{失效时间}和RUL分布进行推导, 这对于维修决策和优化资源分配具有重要意义 <span class="co">[</span><span class="ot">@zhang2018degradation</span><span class="co">]</span>. 失效时间\index{失效时间} $T$ 定义为系统的退化值 $Y(t)$ 首次超过失效阈值 $\mathcal{D}$ 的时间, 即 $T=\inf \left<span class="sc">\{</span>t \mid Y(t) \geq \mathcal{D}\right<span class="sc">\}</span>$. $T$ 的可靠度函数\index{可靠度函数}和MTTF计算公式见定理 @thm-EJOR2024-thy-1.</span>
<span id="cb1-575"><a href="#cb1-575"></a></span>
<span id="cb1-576"><a href="#cb1-576"></a>::: {#thm-EJOR2024-thy-1}</span>
<span id="cb1-577"><a href="#cb1-577"></a>系统失效时间\index{失效时间} $T$ 的可靠度函数\index{可靠度函数}为 \begin{equation}</span>
<span id="cb1-578"><a href="#cb1-578"></a>            \begin{aligned}</span>
<span id="cb1-579"><a href="#cb1-579"></a>                R\left(t \right)    &amp; =P\left(Y(t)&lt;\mathcal{D}, \tau \geq t\right)+P\left(Y(t)&lt;\mathcal{D}, 0&lt;\tau&lt;t\right) <span class="sc">\\</span></span>
<span id="cb1-580"><a href="#cb1-580"></a>                &amp; =\bar{F}_1\left(t  \mid  \tau \right) \bar{G}_{\tau}(t)+\int_0^t g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_2\left(t  \mid  \tau\right) \mathrm{d} \tau, <span class="sc">\\</span></span>
<span id="cb1-581"><a href="#cb1-581"></a>            \end{aligned}</span>
<span id="cb1-582"><a href="#cb1-582"></a>        \end{equation} 其中 $\bar{G}_{\tau}(t)$ 是随机变量 $\tau$ 的生存函数, $\bar{F}_{1}(t|\tau)=P(T&gt;t \mid \tau \geq t)$, $\bar{F}_{2}(t|\tau)=P(T&gt;t \mid \tau &lt; t)$. 给定可靠性\index{可靠性}函数, MTTF 为 \begin{equation}\label{tp-mttf}</span>
<span id="cb1-583"><a href="#cb1-583"></a>            \text{MTTF} =  \mathbb{E}(T) = \int_{0}^{\infty} R(t) \mathrm{d} t.</span>
<span id="cb1-584"><a href="#cb1-584"></a>        \end{equation}</span>
<span id="cb1-585"><a href="#cb1-585"></a>:::</span>
<span id="cb1-586"><a href="#cb1-586"></a></span>
<span id="cb1-587"><a href="#cb1-587"></a>对于工程师来讲, 可能更关注系统在时刻 $t$未失效时, 还能继续正常工作多长时间. 令 $y_t$ 为时刻 $t$ 系统性能退化\index{性能退化}的观测值. 系统在 $t$时刻 的 RUL 定义为: $S_{t}=\inf \left<span class="sc">\{</span>x; Y\left(t+x\right) \geq \mathcal{D} \mid Y_t &lt; \mathcal{D}\right<span class="sc">\}</span>$.</span>
<span id="cb1-588"><a href="#cb1-588"></a></span>
<span id="cb1-589"><a href="#cb1-589"></a>::: {#thm-EJOR2024-thy-2}</span>
<span id="cb1-590"><a href="#cb1-590"></a>RUL 的可靠度函数\index{可靠度函数}为 \begin{equation}</span>
<span id="cb1-591"><a href="#cb1-591"></a>    \begin{aligned}</span>
<span id="cb1-592"><a href="#cb1-592"></a>      R_{S_t}(x) =&amp; \bar{F}_{S_t,1}\left(x \mid  \tau \right)    \bar{G}_{\tau}(x+t) + \int_{t}^{x+t} g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_{S_t,2}\left(x \mid  \tau\right) \mathrm{d} \tau <span class="sc">\\</span></span>
<span id="cb1-593"><a href="#cb1-593"></a>      &amp;+ \int_{0}^{t} g_{\tau}(\tau) \bar{F}_{S_t,3}\left(x \mid  \tau\right) \mathrm{d} \tau,</span>
<span id="cb1-594"><a href="#cb1-594"></a>    \end{aligned}</span>
<span id="cb1-595"><a href="#cb1-595"></a>\end{equation} 其中, $\bar{F}_{S_t,i}$ ($i=1,2,3$) 为 $S_t$ 的条件可靠度函数\index{可靠度函数}, 由时间 $t$、$t+x$ 和变点\index{变点} $\tau$ 的关系定义. RUL 的PDF为: \begin{equation}\label{tp-rul_pdf}</span>
<span id="cb1-596"><a href="#cb1-596"></a>  f_{S_t}(x) = -\frac{\partial R_{S_t}(x)}{\partial x}.</span>
<span id="cb1-597"><a href="#cb1-597"></a>\end{equation} 在时刻 $t$ 的平均剩余寿命\index{剩余寿命} (Mean Residual Life, MRL) 为: \begin{equation}</span>
<span id="cb1-598"><a href="#cb1-598"></a>  \text{MRL} =  \mathbb{E}(S_t) = \int_{0}^{\infty} R_{S_t}(x) \mathrm{d} x.</span>
<span id="cb1-599"><a href="#cb1-599"></a>\end{equation}</span>
<span id="cb1-600"><a href="#cb1-600"></a>:::</span>
<span id="cb1-601"><a href="#cb1-601"></a></span>
<span id="cb1-602"><a href="#cb1-602"></a>定理 @thm-EJOR2024-thy-1 和 @thm-EJOR2024-thy-2 的证明见本节附录A.</span>
<span id="cb1-603"><a href="#cb1-603"></a></span>
<span id="cb1-604"><a href="#cb1-604"></a><span class="fu">#### 自适应替换策略 {#sec-tp-s2-4}</span></span>
<span id="cb1-605"><a href="#cb1-605"></a></span>
<span id="cb1-606"><a href="#cb1-606"></a>本节将详细阐述自适应替换\index{自适应替换}策略, 并建立了一个基于单周期准则的维修成本模型 <span class="co">[</span><span class="ot">@Lu2022; @sheu2019optimal</span><span class="co">]</span>. 假设工程师在确定的检测时间点上对第 $i$ 个系统的性能退化\index{性能退化}进行观测. 令$0 = t_{i,0} &lt; t_{i,1} &lt; \dots &lt; t_{i,j} &lt; \dots &lt; t_{i,n_i}$表示检测时间点, 且 $y_{i,j}$ 表示在时间点$t_{i,j}$ 所观测到的退化值. 记$y_{i,1:j} = <span class="sc">\{</span>y_{i,1}, y_{i,2}, \dots, y_{i,j}<span class="sc">\}</span>$. 为了充分利用每次新增的观测数据, 可采用动态更新的方式, 通过更新模型参数的估计值 (将在第 @sec-tp-s3 节中详细介绍) 给出RUL分布预测, 并记在$t_{i,j}$时刻系统的RUL分布为 $f_{S_t}(x|y_{i,1:j})$. 在动态维修决策中, 需要在每个检测时间点重新评估候选维修操作, 并结合新收集的数据, 确定最优的预定备件方案和维修策略. 通过这种序贯更新过程, 企业可以实时获取系统状态信息, 动态优化维修决策, 从而实现主动预防系统失效.</span>
<span id="cb1-607"><a href="#cb1-607"></a></span>
<span id="cb1-608"><a href="#cb1-608"></a>假设系统的失效只能通过定期检测来发现, 每次检测的成本为 $c_i$. 当系统发生失效并进行维修时, 工程师会将其更换为全新的同型号备件. 这种维修方式称为完美维修, 即系统在维修后被完全恢复至初始状态. 为了保障系统的可靠运行, 通常需提前准备备件. 在实际维修开始前, 还需完成一系列维修前的准备工作, 以避免操作失误或不必要的延误. 这些准备工作包括但不限于: 工具与设备的配置、技术人员的调配以及系统的关闭等. 将准备所需的时间记为 $\varpi$.</span>
<span id="cb1-609"><a href="#cb1-609"></a></span>
<span id="cb1-610"><a href="#cb1-610"></a>在替换策略中, 决策者可选择纠正性替换或预防性替换两种策略. 设系统在$t_{i,j}$时刻正常运行, 当预测其即将发生故障\index{故障}时, 决策者可选择执行预防性替换, 以避免突发性故障\index{故障}带来的损失. 预防性替换的成本记为 $c_p$, 且替换操作需在指定的准备时间 $\varpi$ 后完成. 相反, 若在检测时发现系统已发生故障\index{故障}, 则必须执行纠正性替换, 对应的成本为 $c_c$. 此外, 在系统失效后, 维修准备期间的停机将会产生额外成本, 记停机成本为 $c_b$. 因此, 对于每个系统, 其在特定时刻 $t_{i,j}$ 的最优替换时间 $\mathcal{T}_{i,j}$ 可通过最小化期望成本来确定: \begin{equation}\label{tp-min}</span>
<span id="cb1-611"><a href="#cb1-611"></a>    \begin{aligned}</span>
<span id="cb1-612"><a href="#cb1-612"></a>        \mathcal{T}_{i,j} = \underset{T_{i,j}}{\inf} \left\lbrace \int_0^{T_{i,j}-t_{i,j}} \frac{c_c + c_i \lfloor x + t_{i,j} \rfloor + c_b}{x + t_{i,j} + \varpi} f_{S_{t}}(x|y_{i,1:j}) \mathrm{d} x \right. <span class="sc">\\</span> </span>
<span id="cb1-613"><a href="#cb1-613"></a><span class="ss">+ </span>\left. \int_{T_{i,j}-t_{i,j}}^{+\infty} f_{S_{t}}(x|y_{i,1:j}) \frac{c_p + c_i \lfloor T_{i,j}-\varpi \rfloor}{T_{i,j}} \mathrm{d} x  \right\rbrace,</span>
<span id="cb1-614"><a href="#cb1-614"></a>    \end{aligned}</span>
<span id="cb1-615"><a href="#cb1-615"></a>\end{equation} 其中, $\lfloor \psi \rfloor = \max <span class="sc">\{</span>h \in \mathbb{Z} \mid t_{i,h} \leq \psi \}$ 表示在时间 $\psi$ 之前已完成的检测次数. 这种决策过程在预防性替换的即时成本与等待下一次检测所可能带来的风险及相关成本之间实现了权衡. 需要注意的是, $\mathcal{T}_{i,j}$ 被视为候选的替换时间点. 这是因为在较长的时间跨度内, RUL的预测精度可能较低. 然而, 随着检测次数的增加和观测数据的累积, 基于RUL的自适应替换\index{自适应替换}策略将随着时间推移不断提升预测准确性. 由此, 能够实施更为可靠的维修策略, 从而优化系统的整体运行效率和安全性.</span>
<span id="cb1-616"><a href="#cb1-616"></a></span>
<span id="cb1-617"><a href="#cb1-617"></a>具体而言, 随着 $\mathcal{T}_{i,j}$ 的动态更新, 应在首次满足条件 $\mathcal{T}_{i,j} - t_{i,j} \leq \varpi$时, 确定最佳的准备时间点. 一旦该条件成立, 即可启动相应的准备工作, 并在准备工作完成后立即执行替换操作. 换言之, 最佳的准备时间和替换时间可通过以下公式来确定: \begin{equation}\label{tp-final}</span>
<span id="cb1-618"><a href="#cb1-618"></a>    \mathcal{T}^\prime_i =  \underset{t_{i,j}}{\inf} <span class="sc">\{</span>\mathcal{T}_{i,j}  - t_{i,j} \leq  \varpi<span class="sc">\}</span>, \quad  \text{和} \quad \mathcal{T}^*_i = \mathcal{T}^\prime_i + \varpi.</span>
<span id="cb1-619"><a href="#cb1-619"></a>\end{equation} 替换完成后, 新安装的部件将投入运行, 并开启新的维修决策周期.</span>
<span id="cb1-620"><a href="#cb1-620"></a></span>
<span id="cb1-621"><a href="#cb1-621"></a>上述内容描述了所提自适应替换\index{自适应替换}策略的基本原理, 接下来将重点评估该策略的实际性能. 设有 $I$ 个系统, 每个系统只运行一个维修周期. 定义 $\mathbb{X}_i = \min\{ \mathcal{T}^{*}_{i}, \mathcal{T}^{\text{f}}_{i} \}$, 其中 $\mathcal{T}^{*}_{i}$ 表示预测的最优替换时间, $\mathcal{T}^{\text{f}}_{i}$表示系统的实际失效时间\index{失效时间}. 此时, 第 $i$ 个系统的实际成本率可通过以下公式计算: \begin{equation}\label{cr} </span>
<span id="cb1-622"><a href="#cb1-622"></a>    \textit{CR}_{i}=\left<span class="sc">\{</span>\begin{array}{l}</span>
<span id="cb1-623"><a href="#cb1-623"></a>        \dfrac{c_{p} + c_i \lfloor \mathbb{X}_i -\varpi \rfloor}{\mathcal{T}^{*}_{i}},  ~\mathbb{X}_i = \mathcal{T}^{*}_{i}, <span class="sc">\\</span></span>
<span id="cb1-624"><a href="#cb1-624"></a>        \dfrac{c_{c} + c_i \lfloor \mathbb{X}_i \rfloor + c_b}{ \mathcal{T}^{\text{f}}_{i} + \varpi}, ~\mathbb{X}_i = \mathcal{T}^{\text{f}}_{i}. % + c_i \mathbb{X}_i</span>
<span id="cb1-625"><a href="#cb1-625"></a>    \end{array}\right.</span>
<span id="cb1-626"><a href="#cb1-626"></a>\end{equation} 因此, 可定义所有系统的平均成本率为: \begin{equation}\label{cr_everage}</span>
<span id="cb1-627"><a href="#cb1-627"></a>    \overline{\textit{CR}}= \frac{\sum_{i = 1}^{I}\textit{CR}_{i}}{I}.</span>
<span id="cb1-628"><a href="#cb1-628"></a>\end{equation} 算法 \ref{tp-alg4} 给出了所提出的动态自适应替换\index{自适应替换}决策过程. 在实际应用中可采用贝叶斯\index{贝叶斯}方法进行统计推断分析. 第 @sec-tp-s5 节的仿真结果表明, 相较于ML方法, 贝叶斯\index{贝叶斯}方法在预测准确性与不确定性量化方面表现更优. 为进一步验证基于RUL的自适应替换\index{自适应替换}策略的有效性, 本节将其与以下两种基准维修策略进行了对比: i). 经典替换策略 ( Classical Replacement Policy, CRP): 基于历史可靠性\index{可靠性}数据确定预防性维修时间，通常以系统的MTTF为准. 在该策略下, 第 $i$ 个系统的成本率形式与式 \eqref{cr} 类似，但将 $\mathcal{T}^{*}_{i}$ 替换为 $\bar{\mathcal{T}}^{F}$，且不计入检测成本. ii). 理想替换策略 (Ideal Replacement Policy, IRP): 假设可准确预测失效时间\index{失效时间}$\mathcal{T}^{P}_{i}$. 在这种策略下, 第 $i$ 个系统的成本率为 $c_p / \mathcal{T}^{P}_{i}$. 最终, 基于式 \eqref{cr_everage}, 计算三种策略下所有系统的平均成本率, 以评估所提方法的相对优势.</span>
<span id="cb1-629"><a href="#cb1-629"></a></span>
<span id="cb1-630"><a href="#cb1-630"></a><span class="in">```{=latex}</span></span>
<span id="cb1-631"><a href="#cb1-631"></a><span class="in">\begin{algorithm}[h!]</span></span>
<span id="cb1-632"><a href="#cb1-632"></a><span class="in">    \caption{基于RUL的自适应替换策略} \label{tp-alg4}</span></span>
<span id="cb1-633"><a href="#cb1-633"></a><span class="in">    \LinesNumbered</span></span>
<span id="cb1-634"><a href="#cb1-634"></a><span class="in">    \KwIn{$y, c_c, c_p, c_b, \varpi, \mathcal{D}$, $j$.\\}</span></span>
<span id="cb1-635"><a href="#cb1-635"></a><span class="in">    \KwOut{$\mathcal{T}_{i}^{*}$, $\textit{CR}_{i}, i = 1,\dots,I$, 和 $\overline{\textit{CR}}$.}</span></span>
<span id="cb1-636"><a href="#cb1-636"></a><span class="in">    </span></span>
<span id="cb1-637"><a href="#cb1-637"></a><span class="in">    \For{ $i=1$ \KwTo $I$}{</span></span>
<span id="cb1-638"><a href="#cb1-638"></a><span class="in">        </span></span>
<span id="cb1-639"><a href="#cb1-639"></a><span class="in">        \While{未执行维修}{</span></span>
<span id="cb1-640"><a href="#cb1-640"></a><span class="in">            \If{系统正在运行}{</span></span>
<span id="cb1-641"><a href="#cb1-641"></a><span class="in">                收集新的检测数据 $Y_{i,j}$\;</span></span>
<span id="cb1-642"><a href="#cb1-642"></a><span class="in">                使用第 \ref{sec-tp-s3} 节中的贝叶斯\index{贝叶斯}方法更新模型参数估计\;</span></span>
<span id="cb1-643"><a href="#cb1-643"></a><span class="in">                根据式 \eqref{tp-rul_pdf} 计算RUL分布 ${ f_{S_t}(x|y_{i,1:j}) }_{x = 0}^{+\infty}$\;</span></span>
<span id="cb1-644"><a href="#cb1-644"></a><span class="in">                利用式 \eqref{tp-min} 确定 $\mathcal{T}_{i,j}$, 并通过式 \eqref{tp-final} 找到 $\mathcal{T}_i^\prime$\;</span></span>
<span id="cb1-645"><a href="#cb1-645"></a><span class="in">                \If{$t_{i,j} = \mathcal{T}^\prime_i$}{检测完成, 预防性维修在 $\mathcal{T}_i^*$ 时执行.  }</span></span>
<span id="cb1-646"><a href="#cb1-646"></a><span class="in">            }</span></span>
<span id="cb1-647"><a href="#cb1-647"></a><span class="in">            \Else{纠正性维修;\\</span></span>
<span id="cb1-648"><a href="#cb1-648"></a><span class="in">                设置 $\mathcal{T}^{\text{f}}_{i} =  t_{i,j}$.</span></span>
<span id="cb1-649"><a href="#cb1-649"></a><span class="in">            }</span></span>
<span id="cb1-650"><a href="#cb1-650"></a><span class="in">            $j = j + 1$. </span></span>
<span id="cb1-651"><a href="#cb1-651"></a><span class="in">        }   </span></span>
<span id="cb1-652"><a href="#cb1-652"></a><span class="in">        通过式 \eqref{cr} 计算 $\textit{CR}_{i}$. </span></span>
<span id="cb1-653"><a href="#cb1-653"></a><span class="in">    }</span></span>
<span id="cb1-654"><a href="#cb1-654"></a><span class="in">    通过式 \eqref{cr_everage} 计算 $\overline{\textit{CR}}$. </span></span>
<span id="cb1-655"><a href="#cb1-655"></a><span class="in">\end{algorithm}</span></span>
<span id="cb1-656"><a href="#cb1-656"></a><span class="in">```</span></span>
<span id="cb1-657"><a href="#cb1-657"></a><span class="fu">### 统计推断 {#sec-tp-s3}</span></span>
<span id="cb1-658"><a href="#cb1-658"></a></span>
<span id="cb1-661"><a href="#cb1-661"></a><span class="in">```{r}</span></span>
<span id="cb1-662"><a href="#cb1-662"></a><span class="co">#| label: fig-tp-data_dis</span></span>
<span id="cb1-663"><a href="#cb1-663"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-664"><a href="#cb1-664"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-665"><a href="#cb1-665"></a><span class="co">#| out.width: '60%'</span></span>
<span id="cb1-666"><a href="#cb1-666"></a><span class="co">#| fig.cap: '变点与检测时间之间的三种关系.'</span></span>
<span id="cb1-667"><a href="#cb1-667"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/3frame.jpg"</span>)</span>
<span id="cb1-668"><a href="#cb1-668"></a><span class="in">```</span></span>
<span id="cb1-669"><a href="#cb1-669"></a></span>
<span id="cb1-670"><a href="#cb1-670"></a><span class="co">&lt;!-- ::: {#fig-tp-data_dis layout-ncol="2"} --&gt;</span></span>
<span id="cb1-671"><a href="#cb1-671"></a></span>
<span id="cb1-672"><a href="#cb1-672"></a><span class="co">&lt;!-- ![$\tau_i \geq t_{i, j}$](figures/IG/EJOR2024/dat1.pdf){#fig-tp-fig:data1} --&gt;</span></span>
<span id="cb1-673"><a href="#cb1-673"></a></span>
<span id="cb1-674"><a href="#cb1-674"></a><span class="co">&lt;!-- ![$t_{i, j-1} \leq \tau_i&lt;t_{i, j}$](figures/IG/EJOR2024/dat2.pdf){#fig-tp-fig:data2} --&gt;</span></span>
<span id="cb1-675"><a href="#cb1-675"></a></span>
<span id="cb1-676"><a href="#cb1-676"></a><span class="co">&lt;!-- ![$\tau_i&lt;t_{i, j-1}$](figures/IG/EJOR2024/dat3.pdf){#fig-tp-fig:data3} --&gt;</span></span>
<span id="cb1-677"><a href="#cb1-677"></a></span>
<span id="cb1-678"><a href="#cb1-678"></a><span class="co">&lt;!-- 两种类型的两阶段随机过程. --&gt;</span></span>
<span id="cb1-679"><a href="#cb1-679"></a></span>
<span id="cb1-680"><a href="#cb1-680"></a><span class="co">&lt;!-- ::: --&gt;</span></span>
<span id="cb1-681"><a href="#cb1-681"></a></span>
<span id="cb1-682"><a href="#cb1-682"></a>假设在退化试验中共有 $I$ 个系统. 每个系统的性能退化过程\index{退化过程}在某个特定时刻 $\tau_i$ 发生明显变化, 即, $\tau_i$为第 $i$ 个系统的性能退化\index{性能退化}变点\index{变点}. 假设系统的性能退化\index{性能退化}规律服从两阶段 rIG 退化模型 \ref{tp-model}. 记 $Y_{i, j}$ 表示在测量时间 $t_{i, j}$ 处观测到的退化值, 其中 $i=1, \dots, I$ 且 $j=1, \dots, n_i$, 满足 $0 &lt; t_{i, 1} &lt; \ldots &lt; t_{i, n_i}$. 定义退化增量 $\Delta y_{i, j}=Y_{i, j}-Y_{i, j-1}$, 其中 $Y_{i, 0}=0$. 进一步定义 $\boldsymbol{\Delta} \boldsymbol{Y}_i=\left(\Delta y_{i, 1}, \ldots, \Delta y_{i, n_i}\right)^{\top}$, $\boldsymbol{\Delta} \boldsymbol{Y}=\left(\boldsymbol{\Delta} \boldsymbol{Y}_1^{\top}, \cdots, \boldsymbol{\Delta} \boldsymbol{Y}_I^{\top}\right)^{\top}$. 变点\index{变点} $\tau_i$ 决定了各时刻下退化增量 $\Delta y_{i, j}$ 的分布形式. 如图 @fig-tp-data_dis 所示, 变点\index{变点} $\tau_i$ 与测量时间点存在三种潜在关系: $k=1$, 对应于 $\tau_i \geq t_{i, j}$; $k=2$, 对应于 $t_{i, j-1} \leq \tau_i &lt; t_{i, j}$; $k=3$, 对应于 $\tau_i &lt; t_{i, j-1}$. 因此, 对于每个观测点, 退化增量$\Delta y_{i, j}$ 的分布可统一表示为 $rIG\left(\Delta m_{i, j}^{(k)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right),\gamma\right)$, 其中 \begin{equation*}</span>
<span id="cb1-683"><a href="#cb1-683"></a>        \Delta m_{i, j}^{(k)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)= \begin{cases}\delta_{1,i} \Delta t_{i, j} &amp; k=1, <span class="sc">\\</span> \left(\delta_{1,i}-\delta_{2,i}\right)  \tau_i+\delta_{2,i} t_{i, j} -\delta_{1,i}  t_{i, j-1}, &amp; k=2, <span class="sc">\\</span> </span>
<span id="cb1-684"><a href="#cb1-684"></a>        \delta_{2,i}  \Delta t_{i, j}, &amp; k=3,\end{cases}</span>
<span id="cb1-685"><a href="#cb1-685"></a>\end{equation*} $\Delta t_{i, j}=t_{i, j} - t_{i, j-1}$ 且 $t_{i,0}=0$, $i=1\dots, I,~j=1, \dots, n_i$. 为简化表达, 令$\lambda_{i, j}^{(1)}=\mathcal{I}\left(\tau_i \geq t_{i, j}\right), \lambda_{i, j}^{(2)}=\mathcal{I}\left(t_{i, j-1} \leq \tau_i&lt;t_{i, j}\right)$, 和 $\lambda_{i, j}^{(3)}=\mathcal{I}\left(\tau_i&lt;t_{i, j-1}\right)$, 其中 $\mathcal{I}(\cdot)$ 为示性函数, 进一步可得: \begin{equation*}</span>
<span id="cb1-686"><a href="#cb1-686"></a>        \begin{aligned}</span>
<span id="cb1-687"><a href="#cb1-687"></a>            \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = &amp; \Delta m_{i, j}^{(1)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)^{\lambda_{i, j}^{(1)}} \times \Delta m_{i, j}^{(2)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) ^{\lambda_{i, j}^{(2)}} <span class="sc">\\</span></span>
<span id="cb1-688"><a href="#cb1-688"></a>            &amp; \times\Delta m_{i, j}^{(3)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)^{\lambda_{i, j}^{(3)}}.</span>
<span id="cb1-689"><a href="#cb1-689"></a>        \end{aligned}</span>
<span id="cb1-690"><a href="#cb1-690"></a>    \end{equation*} 因此, 给定变点\index{变点} $\tau_i$, $\Delta y_{i, j}$ 的条件PDF为: \begin{equation}\label{tp-pdf_1}</span>
<span id="cb1-691"><a href="#cb1-691"></a>        \begin{aligned}</span>
<span id="cb1-692"><a href="#cb1-692"></a>            \begin{aligned}</span>
<span id="cb1-693"><a href="#cb1-693"></a>                f_{i,j} \left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i}, \tau_i, \gamma\right) </span>
<span id="cb1-694"><a href="#cb1-694"></a>                &amp;= \frac{\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)}{\sqrt{2 \pi}} \exp\left\lbrace{ \gamma \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) }\right\rbrace  \Delta y_{i, j}^{-3 / 2} <span class="sc">\\</span> </span>
<span id="cb1-695"><a href="#cb1-695"></a>                &amp;~~~ \times \exp\left\lbrace {-\frac{\left<span class="co">[</span><span class="ot">\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\right</span><span class="co">]</span>^2 \Delta y_{i, j}^{-1}+\gamma^2 \Delta y_{i, j}}{2}}\right\rbrace.</span>
<span id="cb1-696"><a href="#cb1-696"></a>            \end{aligned}</span>
<span id="cb1-697"><a href="#cb1-697"></a>        \end{aligned}</span>
<span id="cb1-698"><a href="#cb1-698"></a>    \end{equation} 记 $\boldsymbol{\delta}_1=\left(\delta_{1,1}, \ldots, \delta_{1,I}\right)^{\top}$, $\boldsymbol{\delta}_2=\left(\delta_{2,1}, \ldots, \delta_{2,I}\right)^{\top}$ 和 $\boldsymbol{\tau}=\left(\tau_1, \ldots, \tau_I\right)^{\top}$. 定义 $\boldsymbol{\eta}=$ $\left(\boldsymbol{\delta}_1^{\top}, \boldsymbol{\delta}_2^{\top}, \gamma\right)^{\top}$, $\boldsymbol{\theta}_\tau=\left(\mu_\tau, \sigma_\tau^2\right)^{\top}$ 和 $\boldsymbol{\vartheta}=\left(\boldsymbol{\theta}_\tau^{\top}, \boldsymbol{\eta}^{\top}\right)^{\top}$. 给定观测数据 $\boldsymbol{\Delta} \boldsymbol{Y}$, 模型参数 $\boldsymbol{\vartheta}$ 的似然函数\index{似然函数}可表示为: \begin{equation}\label{tp-likelihood}</span>
<span id="cb1-699"><a href="#cb1-699"></a>        \begin{aligned}</span>
<span id="cb1-700"><a href="#cb1-700"></a>            L_{o b s}(\boldsymbol{\Delta} \boldsymbol{Y}|\boldsymbol{\vartheta}) &amp; = \prod_{i=1}^I \int_{-\infty}^{\infty} \prod_{j=1}^{n_i} f_{i,j}\left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i}, \tau_i, \gamma \right)g_\tau(\tau_i| \boldsymbol{\theta}_\tau)  \mathrm{d}  \tau_i.</span>
<span id="cb1-701"><a href="#cb1-701"></a>        \end{aligned}</span>
<span id="cb1-702"><a href="#cb1-702"></a>    \end{equation} 显然，该似然函数\index{似然函数}涉及对变点\index{变点} $\tau_i$ 的积分，难以获得参数 $\boldsymbol{\vartheta}$ 的MLE的解析形式. 为此，将引入一种基于EM算法\index{EM算法}的迭代优化方法来估计参数。EM算法\index{EM算法}是一种处理含有潜在变量问题的经典方法，广泛应用于可靠性\index{可靠性}建模与统计推断中 <span class="co">[</span><span class="ot">@xiao2023hybrid</span><span class="co">]</span>. 该算法通过在每次迭代中交替执行期望步 (E步) 和最大化步 (M步), 最终获得模型参数的估计值.</span>
<span id="cb1-703"><a href="#cb1-703"></a></span>
<span id="cb1-704"><a href="#cb1-704"></a><span class="fu">#### EM 算法与自助法 {#sec-tp-s3-1}</span></span>
<span id="cb1-705"><a href="#cb1-705"></a></span>
<span id="cb1-706"><a href="#cb1-706"></a>在 E 步中, 构建一个 Q 函数, 用于表示在当前参数估计值下, 完全数据 $(\boldsymbol{\Delta Y}, \boldsymbol{\tau})$ 的对数似然函数\index{似然函数}的条件期望. 该期望值基于当前参数向量 $\boldsymbol{\vartheta}$ 和 $\boldsymbol{\tau}$ 的条件分布进行计算. 随后, 在M 步中, 通过最大化该 Q 函数以更新模型参数 $\boldsymbol{\vartheta}$ 的估计值. 上述 E 步与 M 步的迭代过程将持续进行, 直至参数更新的幅度小于设定的收敛阈值, 从而获得稳定的参数估计. 在该框架下, 完全数据的对数似然函数\index{似然函数}可表示为: \begin{equation}\label{tp-com-log}</span>
<span id="cb1-707"><a href="#cb1-707"></a>    l_c(\boldsymbol{\Delta Y}, \boldsymbol{\tau}|\boldsymbol{\vartheta})=\sum_{i=1}^I l_i\left(\boldsymbol{\theta}_\tau\right)+\sum_{i=1}^I \sum_{j=1}^{n_i} l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}),</span>
<span id="cb1-708"><a href="#cb1-708"></a>\end{equation} 其中, \begin{equation*}</span>
<span id="cb1-709"><a href="#cb1-709"></a>    \begin{aligned}</span>
<span id="cb1-710"><a href="#cb1-710"></a>        l_i\left(\boldsymbol{\theta}_\tau\right)&amp;= \log g_\tau\left(\tau_i \mid \boldsymbol{\theta}_\tau\right) = -\log \sqrt{2\pi} \sigma_{\tau} - \frac{{(\tau_i - \mu_\tau)}^2}{2 \sigma_\tau^2},<span class="sc">\\</span></span>
<span id="cb1-711"><a href="#cb1-711"></a>        l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) &amp;=\log f_{i, j}\left(\Delta y_{i, j} \mid \boldsymbol{\eta}, \boldsymbol{\tau} \right) <span class="sc">\\</span></span>
<span id="cb1-712"><a href="#cb1-712"></a>        &amp; = - \log \sqrt{2\pi} + \log \Delta m_{i,j}  + \gamma \Delta m_{i,j} - \frac{3}{2} \log \Delta y_{i,j} - \frac{\Delta m_{i,j}^{2}}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},</span>
<span id="cb1-713"><a href="#cb1-713"></a>    \end{aligned}</span>
<span id="cb1-714"><a href="#cb1-714"></a>\end{equation*} $\Delta m_{i,j}= \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)$. 假设在第 $s$ 次迭代中, M 步得到了参数估计的最优解 $\boldsymbol{\vartheta}_{(s)}$, 则在第 $s+1$ 次迭代的 E 步中, 需计算如下形式的 Q 函数: \begin{equation}\label{tp-e-step}</span>
<span id="cb1-715"><a href="#cb1-715"></a>    \begin{aligned}</span>
<span id="cb1-716"><a href="#cb1-716"></a>        \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})&amp;=   \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left<span class="co">[</span><span class="ot">l_c(\boldsymbol{\Delta Y}, \boldsymbol{\tau}|\boldsymbol{\vartheta})\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-717"><a href="#cb1-717"></a>        &amp;=\sum_{i=1}^I  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]  +\sum_{i=1}^I \sum_{j=1}^{n_i}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[ l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right],</span>
<span id="cb1-718"><a href="#cb1-718"></a>    \end{aligned}</span>
<span id="cb1-719"><a href="#cb1-719"></a>\end{equation} 其中, 公式右侧的两项分别为 $\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]$ 和 $\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{Y}\right]$, 其详细推导见本节附录B. 一旦得到 Q 函数, 通过以下 M 步更新参数估计: \begin{equation}\label{tp-arg}</span>
<span id="cb1-720"><a href="#cb1-720"></a>    \boldsymbol{\vartheta}_{(s + 1)} =  \arg \max \boldsymbol{Q}_{(s)} (\boldsymbol{\vartheta}).</span>
<span id="cb1-721"><a href="#cb1-721"></a>\end{equation} 可利用数值优化算法 (如牛顿或拟牛顿算法) 获得$\boldsymbol{\vartheta}_{(s + 1)}$ [@jamshidian1997]. 在此基础上, 模型参数 $\boldsymbol{\vartheta}$ 的MLE可通过迭代计算直至收敛, 变点\index{变点} $\tau_i$ 可通过计算 $E_{\boldsymbol{\hat{\vartheta}}}\left<span class="sc">\{</span>\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right<span class="sc">\}</span>$, $i=1, \ldots, I$ 获得. EM 算法的详细技术细节可见本节附录B.</span>
<span id="cb1-722"><a href="#cb1-722"></a></span>
<span id="cb1-723"><a href="#cb1-723"></a>除了点估计 $\boldsymbol{\vartheta}$, 还需要为参数函数 $h(\boldsymbol{\vartheta})$ 构造置信区间\index{置信区间}. 通常的区间估计基于渐近理论. 然而, 考虑到所提出模型 Fisher 信息矩阵的复杂性, 采用参数化自助法 <span class="co">[</span><span class="ot">@efron2012bayesian; @Zhai2023multivariate</span><span class="co">]</span> 作为替代方法以量化参数的不确定性. 自助法的实施步骤可见算法 \ref{tp-alg1}. 在获得自助法估计 $\left\lbrace \hat{\boldsymbol{\vartheta}}_1^{\ast}, \ldots, \hat{\boldsymbol{\vartheta}}_{\mathcal{B}}^{\ast} \right\rbrace$ 后, 可为参数函数$h(\boldsymbol{\vartheta})$构造近似 $100 (1-\zeta)\%$ 的自助置信区间\index{置信区间}, 形式如下: $$\left[h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{(\zeta \mathcal{B} / 2)}, h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{((1-\zeta / 2) \mathcal{B})}\right],$$ 其中 $h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{(b)}$ 表示 $\left\lbrace h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_1, \ldots, h\left(\hat{\boldsymbol{\vartheta}}^\ast\right)_{\mathcal{B}}\right\rbrace$ 中的第 $b$ 个统计量.</span>
<span id="cb1-724"><a href="#cb1-724"></a></span>
<span id="cb1-725"><a href="#cb1-725"></a><span class="in">```{=latex}</span></span>
<span id="cb1-726"><a href="#cb1-726"></a><span class="in">\begin{algorithm}[h]</span></span>
<span id="cb1-727"><a href="#cb1-727"></a><span class="in">    \caption{参数化自助法} \label{tp-alg1}</span></span>
<span id="cb1-728"><a href="#cb1-728"></a><span class="in">    \LinesNumbered</span></span>
<span id="cb1-729"><a href="#cb1-729"></a><span class="in">%       \normalem</span></span>
<span id="cb1-730"><a href="#cb1-730"></a><span class="in">    \KwIn{点估计$\hat{\boldsymbol{\vartheta}}$.\\}</span></span>
<span id="cb1-731"><a href="#cb1-731"></a><span class="in">    \KwOut{$\mathcal{B}$个自助估计值 $\left\lbrace \hat{\boldsymbol{\vartheta}}_1^*, \ldots, \hat{\boldsymbol{\vartheta}}_{\mathcal{B}}^*\right\rbrace$.}</span></span>
<span id="cb1-732"><a href="#cb1-732"></a><span class="in">    </span></span>
<span id="cb1-733"><a href="#cb1-733"></a><span class="in">    \For{ $b=1$ \KwTo $\mathcal{\mathcal{B}}$}{</span></span>
<span id="cb1-734"><a href="#cb1-734"></a><span class="in">     从$\mathcal{N}(\hat{\mu}_\tau,\hat{\sigma}^2_\tau)$ 中产生$\boldsymbol{\tau}$;\\</span></span>
<span id="cb1-735"><a href="#cb1-735"></a><span class="in">        \For{ $i=1$ \KwTo $I$}{</span></span>
<span id="cb1-736"><a href="#cb1-736"></a><span class="in">            \For{ $j=1$ \KwTo $n_i$}{</span></span>
<span id="cb1-737"><a href="#cb1-737"></a><span class="in">                从 $rIG\left(\Delta m_{i, j}^{(k)}\left(\hat{\delta}_{1,i}, \hat{\delta}_{2,i}, \hat{\tau}_i\right),\hat{\gamma}\right), k = 1,2,3$ 中产生退化样本 $\Delta \tilde{Y}_{i,j}$.\\</span></span>
<span id="cb1-738"><a href="#cb1-738"></a><span class="in">            }</span></span>
<span id="cb1-739"><a href="#cb1-739"></a><span class="in">        }</span></span>
<span id="cb1-740"><a href="#cb1-740"></a><span class="in">        利用所提 EM 算法, 以 $\Delta\boldsymbol{\tilde{Y}}$ 为输入, 计算得到 $\hat{\boldsymbol{\vartheta}}_b^*$. </span></span>
<span id="cb1-741"><a href="#cb1-741"></a><span class="in">    }</span></span>
<span id="cb1-742"><a href="#cb1-742"></a><span class="in">\end{algorithm}</span></span>
<span id="cb1-743"><a href="#cb1-743"></a><span class="in">```</span></span>
<span id="cb1-744"><a href="#cb1-744"></a><span class="fu">#### 贝叶斯分析 {#sec-tp-s3-2}</span></span>
<span id="cb1-745"><a href="#cb1-745"></a></span>
<span id="cb1-746"><a href="#cb1-746"></a>贝叶斯\index{贝叶斯}分析在PHM领域中具有重要地位, 因其能够有效融合先验\index{先验}知识并量化模型参数的不确定性, 受到广泛关注 <span class="co">[</span><span class="ot">@zhou2023fast; @taylor2022bayesian; @zhu2022bayesian</span><span class="co">]</span>. 其显著优势之一在于通过先验\index{先验}分布整合已有信息, 这些先验\index{先验}分布体现了对参数的先验\index{先验}认知. 在结合观测数据后, 贝叶斯\index{贝叶斯}分析可提供更为稳健的参数估计与不确定性评估. 本节将采用贝叶斯\index{贝叶斯}方法对两阶段退化模型中的参数进行估计, 所考虑的模型框架如下: \begin{align}</span>
<span id="cb1-747"><a href="#cb1-747"></a>    &amp;Y_i(t|\tau_i) \sim r\mathcal{IG}\left(m(t;\delta_{1,i} ,\delta_{2,i} ,\tau_i),\gamma\right),~\tau_i\sim N\left(\mu_\tau, \sigma_\tau^2\right), ~i=1, \ldots, I, \label{tp-mod1} <span class="sc">\\</span></span>
<span id="cb1-748"><a href="#cb1-748"></a>    &amp;m(t;\delta_{1,i} ,\delta_{2,i} ,\tau_i) = \begin{cases} \delta_{1,i}t, &amp; t \leq \tau_i, <span class="sc">\\</span> \delta_{2,i} \left(t-\tau_i\right)+\delta_{1,i}\tau_i, &amp; t&gt;\tau_i,\end{cases} \label{tp-mod2}<span class="sc">\\</span></span>
<span id="cb1-749"><a href="#cb1-749"></a>    &amp;\left(\mu_\tau, \sigma_\tau^2\right) \sim NIGa\left(\beta_\tau, \eta_\tau, v_\tau, \xi_\tau\right), \gamma \sim N(\omega, \kappa^2), \label{tp-fiprior} <span class="sc">\\</span></span>
<span id="cb1-750"><a href="#cb1-750"></a>    &amp;\delta_{1,i} \sim N\left(\mu_1, \sigma_1^2\right), \delta_{2,i}  \sim N\left(\mu_2, \sigma_2^2\right), \label{tp-fiprior1} <span class="sc">\\</span></span>
<span id="cb1-751"><a href="#cb1-751"></a>    &amp;\left(\mu_1, \sigma_1^2\right)\sim NIGa\left(\beta_1, \eta_1, v_1, \xi_1\right), \left(\mu_2, \sigma_2^2\right) \sim NIGa\left(\beta_2, \eta_2, v_2, \xi_2\right), \label{tp-sedprior}</span>
<span id="cb1-752"><a href="#cb1-752"></a>\end{align} 其中, $NIGa(\cdot)$表示正态逆伽马分布. 式 \eqref{tp-mod1} 和式 \eqref{tp-mod2} 是与第 @sec-tp-s3-1 节的模型设定一致. 在式 \eqref{tp-fiprior} 中, 模型的共享参数 (如 $\tau_i$) 设定先验\index{先验}分布, 以整合样本间信息并提高 $\tau_i$ 的估计精度. 接下来, 为漂移参数设定先验\index{先验}分布. 由于不同系统的退化路径可能存在差异, 其漂移参数可能不同. 然而, 这些系统来自同一总体, 存在一定的共同特性. 因此, 引入分层先验\index{先验}方法, 在漂移参数中同时考虑总体层面的共同影响和个体层面的异质性\index{异质性}. 这种分层建模方法首先通过式 \eqref{tp-fiprior1} 描述漂移参数的个体特性, 然后在式 \eqref{tp-sedprior} 中进一步引入整体先验\index{先验}, 以捕捉系统间的整体相关性. 这种方法能够更全面地描述系统退化模式的复杂性.</span>
<span id="cb1-753"><a href="#cb1-753"></a></span>
<span id="cb1-754"><a href="#cb1-754"></a>**注1**: 在贝叶斯\index{贝叶斯}框架中, 本文为参数 $\gamma$、$\delta_{1,i}$ 和 $\delta_{2,i}$ 指定正态先验\index{先验}分布. 虽然这些参数可能出现负值, 但需要注意的是, 当先验\index{先验}分布的标准差与均值之比足够小时, 这种情况的发生概率会变得极低 <span class="co">[</span><span class="ot">@Chen2013; @Wang2018ress</span><span class="co">]</span>. 这一假设符合贝叶斯\index{贝叶斯}建模的标准做法, 即在精心构造的先验\index{先验}分布下, 罕见的极端值通常被赋予较低权重, 从而对后验推断的影响较小. 此外, 选择正态先验\index{先验}不仅具有数学上的便利性, 还适合为超参数构建分层结构. 正如 <span class="co">[</span><span class="ot">@bernardo2009bayesian</span><span class="co">]</span> 所述, 正态逆伽马分布是正态分布\index{正态分布}的均值和方差参数的共轭先验\index{先验}, 这一特性极大地简化了推断过程, 使分析更高效且易于处理.</span>
<span id="cb1-755"><a href="#cb1-755"></a></span>
<span id="cb1-756"><a href="#cb1-756"></a>定义$\boldsymbol{\theta}=\left(\boldsymbol{\vartheta}, \mu_1, \sigma_1^2, \mu_2, \sigma_2^2\right)^{\top}$ 为两阶段贝叶斯\index{贝叶斯}模型的参数向量. 根据贝叶斯\index{贝叶斯}定理, 参数 $\boldsymbol{\theta}$ 的联合后验分布可表示为: \begin{equation}\label{tp-posterior}</span>
<span id="cb1-757"><a href="#cb1-757"></a>    \begin{aligned}</span>
<span id="cb1-758"><a href="#cb1-758"></a>        \pi(\boldsymbol{\theta} \mid \boldsymbol{\Delta Y}) &amp;\propto \pi\left(\mu_\tau, \sigma_\tau^2\right) \pi\left(\mu_1, \sigma_1^2\right) \pi\left(\mu_2, \sigma_2^2\right) \pi\left(\gamma \mid \omega, \kappa\right) \pi\left(\tau \mid \mu_\tau, \sigma_\tau^2\right) <span class="sc">\\</span></span>
<span id="cb1-759"><a href="#cb1-759"></a>        &amp; \quad \times \pi\left(\boldsymbol{\delta}_1 \mid \mu_1, \sigma_1^2\right) \pi\left(\boldsymbol{\delta}_2 \mid \mu_1, \sigma_1^2\right) f_{\Delta Y}\left(\boldsymbol{\Delta Y} \mid \boldsymbol{\delta}_1, \boldsymbol{\delta}_2, \boldsymbol{\tau}, \gamma\right).<span class="sc">\\</span></span>
<span id="cb1-760"><a href="#cb1-760"></a>    \end{aligned}</span>
<span id="cb1-761"><a href="#cb1-761"></a>\end{equation} 由于 $\pi(\boldsymbol{\theta} \mid \boldsymbol{\Delta Y})$ 形式复杂, 难以直接解析求解其贝叶斯\index{贝叶斯}估计. 为此, 采用MCMC\index{MCMC}算法 (见算法 \ref{tp-alg}) 生成后验样本. 这里, $\boldsymbol{\theta}_{\backslash \eta}$ 表示从 $\boldsymbol{\theta}$ 中去除 $\boldsymbol{\eta}$ 后的剩余参数, 满条件后验分布的推导细节可以在本节附录C中找到. 需要注意的是, $\boldsymbol{\theta}$ 中除 $\tau_i$、$\delta_{1,i}$ 和 $\delta_{2,i}$ 外的参数, 其完整条件后验分布是已知的, 因此这些参数的后验样本可直接通过统计软件生成. 而对于 $\tau_i$、$\delta_{1,i}$ 和 $\delta_{2,i}$ ($i=1, \ldots, I$), 需要采用ARMS算法 <span class="co">[</span><span class="ot">@gilks1995</span><span class="co">]</span>.</span>
<span id="cb1-762"><a href="#cb1-762"></a></span>
<span id="cb1-763"><a href="#cb1-763"></a><span class="in">```{=latex}</span></span>
<span id="cb1-764"><a href="#cb1-764"></a><span class="in">\begin{algorithm}[!ht]</span></span>
<span id="cb1-765"><a href="#cb1-765"></a><span class="in">    \caption{ARMS-Gibbs采样算法.} \label{tp-alg}</span></span>
<span id="cb1-766"><a href="#cb1-766"></a><span class="in">    \LinesNumbered</span></span>
<span id="cb1-767"><a href="#cb1-767"></a><span class="in">    \KwIn{观测数据: ($\boldsymbol{\Delta} \boldsymbol{Y},\boldsymbol{\Delta} \boldsymbol{t})$.\\}</span></span>
<span id="cb1-768"><a href="#cb1-768"></a><span class="in">    \KwOut{$\boldsymbol{\theta}$的后验样本.}</span></span>
<span id="cb1-769"><a href="#cb1-769"></a><span class="in">    设置初始值 $\boldsymbol{\theta}^{(0)} = \left(\boldsymbol{\vartheta}^{(0)}, \sigma_\tau^{2(0)}, \mu_1^{(0)}, \sigma_1^{2(0)}, \mu_2^{(0)}, \sigma_2^{2(0)}\right)^{\top}.$</span></span>
<span id="cb1-770"><a href="#cb1-770"></a><span class="in">    </span></span>
<span id="cb1-771"><a href="#cb1-771"></a><span class="in">    \For{ $s=1$ \KwTo $\mathcal{S}$}{</span></span>
<span id="cb1-772"><a href="#cb1-772"></a><span class="in">        从 $NIG a\left(\beta_\tau^{\prime(s)}, \eta_\tau^{\prime(s)}, v_\tau^{\prime(s)}, \xi_\tau^{\prime(s)}\right)$, $NIG a\left(\beta_1^{\prime(s)}, \eta_1^{\prime(s)}, v_1^{\prime(s)}, \xi_1^{\prime(s)}\right)$ 和$NIG a\left(\beta_2^{\prime(s)}, \eta_2^{\prime(s)}, v_2^{\prime(s)}, \xi_2^{\prime(s)}\right)$ 分别产生后验样本 $\left(\mu_\tau^{(s)}, \sigma_\tau^{2(s)}\right)$, $\left(\mu_1^{(s)}, \sigma_1^{2(s)}\right)$ 和 $\left(\mu_2^{(s)}, \sigma_2^{2(s)}\right)$ 来自 $\left(\mu_\tau, \sigma_\tau^{2}\right)$, $\left(\mu_1, \sigma_1^{2}\right)$, $\left(\mu_2, \sigma_2^{2}\right)$; \\</span></span>
<span id="cb1-773"><a href="#cb1-773"></a><span class="in">        从 $N \left(\omega^\prime,  \kappa^\prime \right)$中产生$\gamma^{(s)}$ 的后验样本 $\gamma$ ;\\</span></span>
<span id="cb1-774"><a href="#cb1-774"></a><span class="in">        使用 ARMS 算法从 $\pi\left( \delta_{1,i} \mid \boldsymbol{\theta}_{\backslash \delta_{1,i}}^{(s)}, \boldsymbol{\Delta} \boldsymbol{Y} \right)$, $\pi\left( \delta_{2,i}  \mid \boldsymbol{\theta}_{\backslash \delta_{2,i}}^{(s)}, \boldsymbol{\Delta} \boldsymbol{Y} \right)$ 和 $\pi\left( \tau_i \mid \boldsymbol{\theta}_{\backslash \tau_i}^{(s)}, \boldsymbol{\Delta} \boldsymbol{Y} \right), i=1, \ldots, I$ 中生成参数 $\delta_{1,i}^{(s)}$, $\delta_{2,i}^{(s)}$ 和 $\tau_i^{(s)}$ 的后验样本.  </span></span>
<span id="cb1-775"><a href="#cb1-775"></a><span class="in">    }</span></span>
<span id="cb1-776"><a href="#cb1-776"></a><span class="in">    丢弃前 $\mathcal{L}$ 个预烧样本后, 保留每个参数的 $\mathcal{S} - \mathcal{L}$个后验样本. 基于这些后验样本, 可以计算参数的点估计 (例如后验均值或后验中位数) 以及构建区间估计 (例如最高密度区间或等尾置信区间\index{置信区间}), 以量化参数的不确定性. </span></span>
<span id="cb1-777"><a href="#cb1-777"></a><span class="in">\end{algorithm}</span></span>
<span id="cb1-778"><a href="#cb1-778"></a><span class="in">```</span></span>
<span id="cb1-779"><a href="#cb1-779"></a><span class="fu">### 模拟实验 {#sec-tp-s5}</span></span>
<span id="cb1-780"><a href="#cb1-780"></a></span>
<span id="cb1-781"><a href="#cb1-781"></a>本节通过模拟研究对所提出的模型与参数推断方法的性能进行评估. 为此, 考虑三种不同的系统数量 $I$ 和观测点数量 $n_i$: 情形 (I): $I = 5$, $n_i = 20$; 情形 (II): $I = 5$, $n_i = 40$; 情形 (III): $I = 8$, $n_i = 20$. 扩散参数$\gamma$设定为2. 为体现系统间的异质性\index{异质性}, 漂移参数和变点\index{变点}按照如下方式随机生成: 从$N(4, 1)$ 分布中生成 $\delta_{1,1}, \dots, \delta_{1,I}$; 从 $N(15, 1)$ 分布中生成 $\delta_{2,1}, \dots, \delta_{2,I}$; 从 $N(10, 1)$ 分布中生成变点\index{变点} $\tau_1, \dots, \tau_I$. 在给定变点\index{变点} $\tau_i$ 的条件下, 每个系统的退化增量根据式 \eqref{tp-pdf_1} 所定义的 rIG 分布模拟生成. 为降低随机抽样对结果的影响, 每种情形均重复模拟 500 组样本, 用于后续的统计分析与性能评估</span>
<span id="cb1-782"><a href="#cb1-782"></a></span>
<span id="cb1-783"><a href="#cb1-783"></a><span class="fu">#### 参数估计的性能评估 {#sec-tp-sec5-1}</span></span>
<span id="cb1-784"><a href="#cb1-784"></a></span>
<span id="cb1-785"><a href="#cb1-785"></a>首先, 使用所提出的模型和方法对模拟数据进行拟合. 对于贝叶斯\index{贝叶斯}方法, 先验\index{先验}分布设定为无信息先验\index{先验}, 具体如下: $(\mu_\tau,\sigma_\tau^2) \sim NIGa(8,100,0.01,0.01)$, $(\mu_1,\sigma_1^2) \sim NIGa(1,100,0.01,0.01)$, $(\mu_2,\sigma_2^2) \sim NIGa(2,100,0.01,0.01)$, $\gamma \sim N(5,100)$. 后验样本的生成采用第 @sec-tp-s3-2 节中介绍的 ARMS-Gibbs 算法. 设定烧蚀期样本长度为$\mathcal{L} = 5000$, 进行 $\mathcal{S} - \mathcal{L} = 5000$ 次迭代以获得后验样本. 所有参数的贝叶斯\index{贝叶斯}点估计均取对应后验样本的均值. 对于 ML 方法, 使用上述贝叶斯\index{贝叶斯}估计结果作为 EM 算法的初始值. 参数的点估计通过第 @sec-tp-s3-1 节中描述的 EM 算法获得, 参数的区间估计则通过参数化自助法实现, 自助样本数量设为 $\mathcal{B} = 500$. EM 算法的收敛标准为: $\left | \boldsymbol{\vartheta}_{(s+1)}-\boldsymbol{\vartheta}_{(s)}\right | &lt; 10^{-3}$, 其中 $|\cdot|$ 表示 $L_1$ 距离.</span>
<span id="cb1-786"><a href="#cb1-786"></a></span>
<span id="cb1-787"><a href="#cb1-787"></a><span class="in">```{=latex}</span></span>
<span id="cb1-788"><a href="#cb1-788"></a><span class="in">\begin{table}</span></span>
<span id="cb1-789"><a href="#cb1-789"></a><span class="in">\centering </span></span>
<span id="cb1-790"><a href="#cb1-790"></a><span class="in">\caption{三种情景下不同参数估计方法结果比较}</span></span>
<span id="cb1-791"><a href="#cb1-791"></a><span class="in">\label{tp-com}</span></span>
<span id="cb1-792"><a href="#cb1-792"></a><span class="in">\renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-793"><a href="#cb1-793"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{1.2mm}</span></span>
<span id="cb1-794"><a href="#cb1-794"></a><span class="in">    \scalebox{0.9}{</span></span>
<span id="cb1-795"><a href="#cb1-795"></a><span class="in">        \begin{tabular}{cccccccccccccc}</span></span>
<span id="cb1-796"><a href="#cb1-796"></a><span class="in">            \hline 场景 &amp; 方法 &amp;   &amp; $\delta_{1,1}$ &amp; $\delta_{1,2}$ &amp; $\delta_{1,3}$ &amp; $\delta_{1,4}$ &amp; $\delta_{1,5}$ &amp; $\delta_{2,1}$ &amp; $\delta_{2,2}$ &amp; $\delta_{2,3}$ &amp; $\delta_{2,4}$ &amp; $\delta_{2,5}$ &amp; $\gamma$\\</span></span>
<span id="cb1-797"><a href="#cb1-797"></a><span class="in">            \hline </span></span>
<span id="cb1-798"><a href="#cb1-798"></a><span class="in">            &amp;\multirow{3}{*}{HB}  &amp; RB   &amp; 0.024 &amp; 0.029 &amp; -0.007 &amp; 0.015 &amp; 0.012 &amp; -0.026 &amp; 0.019 &amp; 0.023 &amp; 0.056 &amp; 0.003 &amp; 0.011 \\</span></span>
<span id="cb1-799"><a href="#cb1-799"></a><span class="in">            &amp;&amp; RMSE &amp; 1.326 &amp; 1.363 &amp; 1.357  &amp; 1.332 &amp; 1.330 &amp; 0.422  &amp; 0.424 &amp; 0.476 &amp; 0.422 &amp; 0.431 &amp; 0.168 \\</span></span>
<span id="cb1-800"><a href="#cb1-800"></a><span class="in">            &amp;&amp; CP   &amp; 0.956 &amp; 0.953 &amp; 0.946  &amp; 0.953 &amp; 0.957 &amp; 0.941  &amp; 0.925 &amp; 0.900 &amp; 0.928 &amp; 0.926 &amp; 0.964 \\</span></span>
<span id="cb1-801"><a href="#cb1-801"></a><span class="in">            \cline{3-14}</span></span>
<span id="cb1-802"><a href="#cb1-802"></a><span class="in">            &amp;\multirow{3}{*}{ML} &amp; RB   &amp; 0.057 &amp; 0.039  &amp; 0.040 &amp; 0.057  &amp; 0.050  &amp; 0.065 &amp; 0.071  &amp; 0.057  &amp; 0.078  &amp; 0.060  &amp; 0.057  \\</span></span>
<span id="cb1-803"><a href="#cb1-803"></a><span class="in">            I&amp;&amp; RMSE &amp; 1.315 &amp; 1.381  &amp; 1.302 &amp; 1.401  &amp; 1.508  &amp; 0.641 &amp; 0.645  &amp; 0.576  &amp; 0.667  &amp; 0.739  &amp; 0.308  \\</span></span>
<span id="cb1-804"><a href="#cb1-804"></a><span class="in">            &amp;&amp; CP   &amp; 0.889 &amp; 0.922  &amp; 0.878 &amp; 0.900  &amp; 0.833  &amp; 0.922 &amp; 0.922  &amp; 0.900  &amp; 0.889  &amp; 0.867  &amp; 0.811  \\</span></span>
<span id="cb1-805"><a href="#cb1-805"></a><span class="in">            \cline{3-14}</span></span>
<span id="cb1-806"><a href="#cb1-806"></a><span class="in">            &amp;&amp; Stat.&amp; $\tau_1$ &amp; $\tau_2$ &amp; $\tau_3$ &amp; $\tau_4$ &amp; $\tau_5$&amp;&amp;&amp;&amp; \\</span></span>
<span id="cb1-807"><a href="#cb1-807"></a><span class="in">            &amp;\multirow{3}{*}{HB} &amp; RB   &amp; 0.002 &amp; 0.001 &amp; 0.002 &amp; 0.001 &amp; -0.009 \\</span></span>
<span id="cb1-808"><a href="#cb1-808"></a><span class="in">            &amp;&amp; RMSE &amp; 0.248 &amp; 0.224 &amp; 0.240 &amp; 0.191 &amp; 0.243  \\</span></span>
<span id="cb1-809"><a href="#cb1-809"></a><span class="in">            &amp;&amp; CP   &amp; 0.915 &amp; 0.937 &amp; 0.937 &amp; 0.961 &amp; 0.961 \\</span></span>
<span id="cb1-810"><a href="#cb1-810"></a><span class="in">            \hline</span></span>
<span id="cb1-811"><a href="#cb1-811"></a><span class="in">            场景 &amp; 方法 &amp;  &amp; $\delta_{1,1}$ &amp; $\delta_{1,2}$ &amp; $\delta_{1,3}$ &amp; $\delta_{1,4}$ &amp; $\delta_{1,5}$ &amp; $\delta_{2,1}$ &amp; $\delta_{2,2}$ &amp; $\delta_{2,3}$ &amp; $\delta_{2,4}$ &amp; $\delta_{2,5}$ &amp; $\gamma$\\</span></span>
<span id="cb1-812"><a href="#cb1-812"></a><span class="in">            \hline </span></span>
<span id="cb1-813"><a href="#cb1-813"></a><span class="in">            &amp;\multirow{3}{*}{HB}  &amp; RB   &amp; -0.005 &amp; 0.007 &amp; 0.023 &amp; 0.011 &amp; -0.005 &amp; -0.019 &amp; 0.000 &amp; 0.016 &amp; 0.000 &amp; 0.012 &amp; 0.001 \\</span></span>
<span id="cb1-814"><a href="#cb1-814"></a><span class="in">            &amp;&amp;  RMSE &amp; 1.068  &amp; 1.011 &amp; 1.065 &amp; 1.015 &amp; 1.044  &amp; 0.349  &amp; 0.283 &amp; 0.275 &amp; 0.355 &amp; 0.332 &amp; 0.124 \\</span></span>
<span id="cb1-815"><a href="#cb1-815"></a><span class="in">            &amp; &amp; CP   &amp; 0.930  &amp; 0.945 &amp; 0.950 &amp; 0.944 &amp; 0.927  &amp; 0.902  &amp; 0.925 &amp; 0.947 &amp; 0.885 &amp; 0.902 &amp; 0.914 \\  </span></span>
<span id="cb1-816"><a href="#cb1-816"></a><span class="in">            \cline{3-14}</span></span>
<span id="cb1-817"><a href="#cb1-817"></a><span class="in">            &amp;   \multirow{3}{*}{ML} &amp; RB   &amp; 0.036  &amp; 0.035  &amp; 0.017  &amp; 0.032 &amp; 0.039 &amp; 0.029  &amp; 0.041 &amp; 0.036 &amp; 0.025  &amp; 0.042  &amp; 0.039  \\</span></span>
<span id="cb1-818"><a href="#cb1-818"></a><span class="in">            II &amp;&amp; RMSE &amp; 0.944  &amp; 1.010  &amp; 0.880  &amp; 0.900 &amp; 0.985 &amp; 0.331  &amp; 0.358 &amp; 0.323 &amp; 0.328  &amp; 0.346  &amp; 0.150  \\</span></span>
<span id="cb1-819"><a href="#cb1-819"></a><span class="in">            &amp;&amp; CP   &amp; 0.905  &amp; 0.890  &amp; 0.905  &amp; 0.920 &amp; 0.900 &amp; 0.895  &amp; 0.890 &amp; 0.930 &amp; 0.930  &amp; 0.920  &amp; 0.865 \\</span></span>
<span id="cb1-820"><a href="#cb1-820"></a><span class="in">            \cline{3-14}</span></span>
<span id="cb1-821"><a href="#cb1-821"></a><span class="in">            &amp;&amp; Stat.&amp; $\tau_1$ &amp; $\tau_2$ &amp; $\tau_3$ &amp; $\tau_4$ &amp; $\tau_5$&amp;&amp; \\</span></span>
<span id="cb1-822"><a href="#cb1-822"></a><span class="in">            &amp;\multirow{3}{*}{HB} &amp; RB   &amp; 0.002 &amp; 0.000 &amp; -0.001 &amp; 0.003 &amp; -0.004 \\</span></span>
<span id="cb1-823"><a href="#cb1-823"></a><span class="in">            &amp;&amp; RMSE &amp; 0.225 &amp; 0.214 &amp; 0.218  &amp; 0.185 &amp; 0.189  \\</span></span>
<span id="cb1-824"><a href="#cb1-824"></a><span class="in">            &amp;&amp; CP   &amp; 0.951 &amp; 0.941 &amp; 0.929  &amp; 0.966 &amp; 0.942 \\</span></span>
<span id="cb1-825"><a href="#cb1-825"></a><span class="in">            \hline</span></span>
<span id="cb1-826"><a href="#cb1-826"></a><span class="in">            场景 &amp; 方法 &amp;  &amp;$\delta_{1,1}$ &amp; $\delta_{1,2}$ &amp; $\delta_{1,3}$ &amp; $\delta_{1,4}$ &amp; $\delta_{1,5}$ &amp; $\delta_{1,6}$ &amp; $\delta_{1,7}$ &amp; $\delta_{1,8}$ &amp; &amp; &amp; \\</span></span>
<span id="cb1-827"><a href="#cb1-827"></a><span class="in">            \hline </span></span>
<span id="cb1-828"><a href="#cb1-828"></a><span class="in">            &amp; \multirow{3}{*}{HB}  &amp; RB   &amp; -0.024 &amp; -0.010 &amp; -0.004 &amp; -0.010 &amp; 0.010 &amp; -0.002 &amp; 0.015 &amp; 0.029 \\</span></span>
<span id="cb1-829"><a href="#cb1-829"></a><span class="in">            &amp;&amp; RMSE &amp; 1.121  &amp; 1.096  &amp; 1.087  &amp; 1.083  &amp; 1.083 &amp; 1.221  &amp; 1.124 &amp; 1.155 \\</span></span>
<span id="cb1-830"><a href="#cb1-830"></a><span class="in">            &amp;&amp; CP   &amp; 0.946  &amp; 0.953  &amp; 0.942  &amp; 0.951  &amp; 0.947 &amp; 0.911  &amp; 0.943 &amp; 0.940 \\</span></span>
<span id="cb1-831"><a href="#cb1-831"></a><span class="in">            \cline{3-11}</span></span>
<span id="cb1-832"><a href="#cb1-832"></a><span class="in">            &amp;   \multirow{3}{*}{ML} &amp; RB   &amp; 0.089  &amp;0.073  &amp; 0.086  &amp; 0.079  &amp; 0.066 &amp; 0.076 &amp; 0.074 &amp; 0.073 \\</span></span>
<span id="cb1-833"><a href="#cb1-833"></a><span class="in">            &amp;&amp; RMSE &amp; 1.098  &amp; 1.095  &amp; 1.087  &amp; 1.179  &amp; 1.015 &amp; 1.028 &amp; 0.993 &amp; 1.018 \\</span></span>
<span id="cb1-834"><a href="#cb1-834"></a><span class="in">            &amp;&amp; CP   &amp; 0.887  &amp; 0.900  &amp; 0.913  &amp; 0.880  &amp; 0.887 &amp; 0.887 &amp; 0.867 &amp; 0.893 \\</span></span>
<span id="cb1-835"><a href="#cb1-835"></a><span class="in">            \cline{3-11}</span></span>
<span id="cb1-836"><a href="#cb1-836"></a><span class="in">            &amp;&amp;  &amp; $\delta_{2,1}$ &amp; $\delta_{2,2}$ &amp; $\delta_{2,3}$ &amp; $\delta_{2,4}$ &amp; $\delta_{2,5}$&amp;$\delta_{2,6}$&amp;$\delta_{2,7}$&amp;$\delta_{2,8}$&amp; $\gamma$ \\</span></span>
<span id="cb1-837"><a href="#cb1-837"></a><span class="in">            &amp;   \multirow{3}{*}{HB}  &amp; RB   &amp; 0.011 &amp; -0.060 &amp; 0.012 &amp; -0.073 &amp; 0.030 &amp; -0.022 &amp; 0.021 &amp; 0.107 &amp; -0.001 \\</span></span>
<span id="cb1-838"><a href="#cb1-838"></a><span class="in">            III&amp;&amp; RMSE &amp; 0.463 &amp; 0.432  &amp; 0.314 &amp; 0.485  &amp; 0.327 &amp; 0.356  &amp; 0.379 &amp; 0.494 &amp; 0.138  \\</span></span>
<span id="cb1-839"><a href="#cb1-839"></a><span class="in">            &amp;&amp; CP   &amp; 0.915 &amp; 0.909  &amp; 0.977 &amp; 0.916  &amp; 0.960 &amp; 0.931  &amp; 0.947 &amp; 0.918 &amp; 0.946  \\</span></span>
<span id="cb1-840"><a href="#cb1-840"></a><span class="in">            \cline{3-12}</span></span>
<span id="cb1-841"><a href="#cb1-841"></a><span class="in">            &amp;   \multirow{3}{*}{ML} &amp; RB   &amp; 0.087  &amp; 0.095 &amp; 0.087 &amp; 0.085  &amp; 0.102  &amp; 0.070  &amp; 0.087  &amp; 0.097  &amp; 0.091  \\</span></span>
<span id="cb1-842"><a href="#cb1-842"></a><span class="in">            &amp;&amp; RMSE &amp; 0.642  &amp; 0.629 &amp; 0.606 &amp; 0.604  &amp; 0.623  &amp; 0.604  &amp; 0.545  &amp; 0.569  &amp; 0.230  \\</span></span>
<span id="cb1-843"><a href="#cb1-843"></a><span class="in">            &amp;&amp; CP   &amp; 0.880  &amp; 0.887 &amp; 0.893 &amp; 0.887  &amp; 0.873  &amp; 0.900  &amp; 0.920  &amp; 0.900  &amp; 0.893  \\</span></span>
<span id="cb1-844"><a href="#cb1-844"></a><span class="in">            \cline{3-12}</span></span>
<span id="cb1-845"><a href="#cb1-845"></a><span class="in">            &amp;&amp; &amp;  $\tau_1$ &amp; $\tau_2$ &amp; $\tau_3$ &amp; $\tau_4$ &amp; $\tau_5$&amp;$\tau_6$&amp;$\tau_7$&amp;$\tau_8$&amp;&amp; \\</span></span>
<span id="cb1-846"><a href="#cb1-846"></a><span class="in">            &amp;\multirow{3}{*}{HB}  &amp; RB   &amp; 0.002 &amp; 0.003 &amp; -0.005 &amp; 0.004 &amp; 0.006 &amp; 0.003 &amp; -0.012 &amp; -0.001 \\</span></span>
<span id="cb1-847"><a href="#cb1-847"></a><span class="in">            &amp;&amp; RMSE &amp; 0.193 &amp; 0.230 &amp; 0.226  &amp; 0.208 &amp; 0.188 &amp; 0.183 &amp; 0.333  &amp; 0.174  \\</span></span>
<span id="cb1-848"><a href="#cb1-848"></a><span class="in">            &amp;&amp; CP   &amp; 0.957 &amp; 0.951 &amp; 0.917  &amp; 0.959 &amp; 0.960 &amp; 0.962 &amp; 0.912  &amp; 0.979 \\</span></span>
<span id="cb1-849"><a href="#cb1-849"></a><span class="in">            \hline</span></span>
<span id="cb1-850"><a href="#cb1-850"></a><span class="in">    \end{tabular}}</span></span>
<span id="cb1-851"><a href="#cb1-851"></a><span class="in">\end{table}</span></span>
<span id="cb1-852"><a href="#cb1-852"></a><span class="in">```</span></span>
<span id="cb1-853"><a href="#cb1-853"></a>表 \ref{tp-com} 展示了两种推断方法的评估结果, 包括RB、RMSE 和95%区间估计的CP. 从点估计的角度来看, 贝叶斯\index{贝叶斯}方法与ML方法均表现出较小的相对偏差和合理的 RMSE, 表明两种方法在参数点估计方面均具备较好的性能. 需要指出的是, 在情形 I 与情形 II 中, 随着单个系统观测次数 $n_i$ 的增加, 两种方法的 RMSE 均显著降低, 说明增加观测频率有助于提升参数估计的准确性. 而在情形 III 中，由于试验中包含更多的系统数量, RMSE 有一定程度的下降, 进一步表明系统间信息的融合对估计精度具有积极影响. 然而， 在区间估计方面， 贝叶斯\index{贝叶斯}方法在所有情形下均表现出更优性能, 其覆盖概率更接近 0.95 的名义水平, 显示出较强的区间置信性. 相比之下, ML 方法在所有情形中的 CP 均明显低于 0.95, 表明其在不确定性量化方面存在一定不足. 综上所述, 建议在两阶段退化模型的参数估计中优先采用贝叶斯\index{贝叶斯}方法, 以获得更为准确的点估计和更具可靠性\index{可靠性}的区间估计.</span>
<span id="cb1-854"><a href="#cb1-854"></a></span>
<span id="cb1-855"><a href="#cb1-855"></a><span class="fu">#### 可靠性估计的性能评估 {#sec-tp-sec5-2}</span></span>
<span id="cb1-856"><a href="#cb1-856"></a></span>
<span id="cb1-857"><a href="#cb1-857"></a>本小节进一步开展模拟研究, 以评估所提模型在可靠性\index{可靠性}估计中的优势. 选择情形 I 和情形 III, 假设系统故障\index{故障}均发生于第二阶段, 且失效阈值设定为 75. 为进行对比分析, 引入三种不考虑变点\index{变点}结构的基准模型, 包括: 1) 线性 rIG 模型, 退化路径设为$\Lambda(t) = t$; 2) 幂律模型: $\Lambda(t; \varsigma) = t^\varsigma$; 3) 指数模型: $\Lambda(t; \varsigma) = \exp(\varsigma t) - 1$. 对于所有基准模型, 均采用贝叶斯\index{贝叶斯}方法进行推断, 并设参数 $\varsigma$的先验\index{先验}为正态分布\index{正态分布} $N(5,100)$, 其中较大的方差表示参数 $\varsigma$的先验\index{先验}信息较弱. 其余模型参数的先验\index{先验}分布与第 @sec-tp-sec5-1 节的设定一致. 图 @fig-tp-mttf-rmse 给出了各模型对系统 MTTF估计上的RMSE对比结果. 从图中可以看出, 所提模型在贝叶斯\index{贝叶斯}方法下所得的RMSE显著低于其他基准模型. 这一结果表明, 所提模型在预测系统MTTF方面具有更高的精度, 从而验证了其在可靠性\index{可靠性}估计中的显著优势.</span>
<span id="cb1-858"><a href="#cb1-858"></a></span>
<span id="cb1-861"><a href="#cb1-861"></a><span class="in">```{r}</span></span>
<span id="cb1-862"><a href="#cb1-862"></a><span class="co">#| label: fig-tp-mttf-rmse</span></span>
<span id="cb1-863"><a href="#cb1-863"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-864"><a href="#cb1-864"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-865"><a href="#cb1-865"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-866"><a href="#cb1-866"></a><span class="co">#| fig.cap: '基于不同模型的MTTF估计结果比较.'</span></span>
<span id="cb1-867"><a href="#cb1-867"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/R_com2.pdf"</span>)</span>
<span id="cb1-868"><a href="#cb1-868"></a><span class="in">```</span></span>
<span id="cb1-869"><a href="#cb1-869"></a></span>
<span id="cb1-870"><a href="#cb1-870"></a><span class="fu">#### 变点估计的性能评估 {#sec-tp-sec5-3}</span></span>
<span id="cb1-871"><a href="#cb1-871"></a></span>
<span id="cb1-872"><a href="#cb1-872"></a>为进一步突出所提模型在实时环境下对变点\index{变点}检测的优势, 本研究基于情形 II ($n_i = 40$) 进行模拟实验. 设退化数据为动态获取, 在每个阶段使用当前观测数据 $y_{i,1:j}$ 对模型参数进行更新估计, 并据此判断变点\index{变点}位置. 图 @fig-tp-tau_com 展示了在 $j=20, 30, 40$三个时间点下, 变点\index{变点}估计的平均RMSE. 结果表明, 随着可用观测数据量的增加, 变点\index{变点}估计的 RMSE 持续下降, 且两种方法在各阶段均保持较小的RMSE, 说明所提模型能够有效识别变点\index{变点}位置. 值得注意的是, 贝叶斯\index{贝叶斯}方法在变点\index{变点}检测方面表现出更高的精度, 其在所有阶段下的平均 RMSE 均显著低于ML方法. 该结果进一步验证了贝叶斯\index{贝叶斯}方法在动态监测退化过程\index{退化过程}中的鲁棒性与优越性</span>
<span id="cb1-873"><a href="#cb1-873"></a></span>
<span id="cb1-876"><a href="#cb1-876"></a><span class="in">```{r}</span></span>
<span id="cb1-877"><a href="#cb1-877"></a><span class="co">#| label: fig-tp-tau_com</span></span>
<span id="cb1-878"><a href="#cb1-878"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-879"><a href="#cb1-879"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-880"><a href="#cb1-880"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-881"><a href="#cb1-881"></a><span class="co">#| fig.cap: '不同时间点下变点估计的平均 RMSE.'</span></span>
<span id="cb1-882"><a href="#cb1-882"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/tau_com.pdf"</span>)</span>
<span id="cb1-883"><a href="#cb1-883"></a><span class="in">```</span></span>
<span id="cb1-884"><a href="#cb1-884"></a></span>
<span id="cb1-885"><a href="#cb1-885"></a><span class="fu">### 实例分析 {#sec-tp-s6}</span></span>
<span id="cb1-886"><a href="#cb1-886"></a></span>
<span id="cb1-887"><a href="#cb1-887"></a>本小节采用锂离子电池退化数据集对所提方法的实际应用性能进行验证（见图 \ref{fig-tp-battery-data}）. 锂离子电池广泛应用于手机、电动汽车等各类商业产品中, 其性能退化\index{性能退化}或故障\index{故障}可能导致设备效能下降, 甚至完全失效. 因此, 准确预测电池的RUL分布，并据此制定科学的维修与更换策略，对于提升设备运行的可靠性\index{可靠性}和降低维护成本具有重要意义 <span class="co">[</span><span class="ot">@zhang2023joint; @peng2018joint</span><span class="co">]</span>.</span>
<span id="cb1-888"><a href="#cb1-888"></a></span>
<span id="cb1-889"><a href="#cb1-889"></a><span class="co">&lt;!-- 图 @fig-tp-battery-data 展示了六个电池容量随周期变化的退化数据. 从图中可以看出, 每个电池的容量退化呈现出两个阶段的特征: 初始阶段退化速率较低, 而后进入退化速率较高的阶段. 基于此数据集, 目标是利用所提模型拟合这些电池的退化路径, 并提供RUL的预测分布 (见第 @sec-tp-s6-1 节). 随后展示所提自适应替换\index{自适应替换}策略的维修决策效果 (见第 @sec-tp-s6-2 节). --&gt;</span></span>
<span id="cb1-890"><a href="#cb1-890"></a></span>
<span id="cb1-891"><a href="#cb1-891"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb1-892"><a href="#cb1-892"></a></span>
<span id="cb1-893"><a href="#cb1-893"></a><span class="co">&lt;!-- #| label: fig-tp-battery-data --&gt;</span></span>
<span id="cb1-894"><a href="#cb1-894"></a></span>
<span id="cb1-895"><a href="#cb1-895"></a><span class="co">&lt;!-- #| fig.align: 'center' --&gt;</span></span>
<span id="cb1-896"><a href="#cb1-896"></a></span>
<span id="cb1-897"><a href="#cb1-897"></a><span class="co">&lt;!-- #| echo: FALSE --&gt;</span></span>
<span id="cb1-898"><a href="#cb1-898"></a></span>
<span id="cb1-899"><a href="#cb1-899"></a><span class="co">&lt;!-- #| out.width: '70%' --&gt;</span></span>
<span id="cb1-900"><a href="#cb1-900"></a></span>
<span id="cb1-901"><a href="#cb1-901"></a><span class="co">&lt;!-- #| fig.cap: '6个锂电池的容量退化数据.' --&gt;</span></span>
<span id="cb1-902"><a href="#cb1-902"></a></span>
<span id="cb1-903"><a href="#cb1-903"></a><span class="co">&lt;!-- knitr::include_graphics("figures/IG/EJOR2024/battery-data.pdf") --&gt;</span></span>
<span id="cb1-904"><a href="#cb1-904"></a></span>
<span id="cb1-905"><a href="#cb1-905"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb1-906"><a href="#cb1-906"></a></span>
<span id="cb1-907"><a href="#cb1-907"></a><span class="fu">#### 模型拟合与可靠性分析 {#sec-tp-s6-1}</span></span>
<span id="cb1-908"><a href="#cb1-908"></a></span>
<span id="cb1-909"><a href="#cb1-909"></a>首先, 采用所提的两阶段 rIG 模型对退化数据进行拟合, 并分别通过贝叶斯\index{贝叶斯}方法和ML方法进行参数估计. 两种方法的设置与模拟实验中的保持一致. 为验证 EM 算法和 ARMS-Gibbs 采样算法的收敛性, 本节附录D展示了参数估计的迭代过程、后验样本的轨迹图以及遍历均值图. 结果表明, 两种算法均具有良好的收敛性, 表现出快速且稳定的收敛趋势. 表 \ref{tp-real-data-para} 给出了模型参数和变点\index{变点}的估计结果. 以扩散参数 $\gamma$ 为例, 贝叶斯\index{贝叶斯}方法和 ML 方法的点估计分别为 2.930 和 3.001, 对应的 95% 可信区间\index{可信区间}（贝叶斯\index{贝叶斯}方法）与置信区间\index{置信区间}（ML 方法）分别为 (2.615, 3.556) 和 (2.804, 3.165). 这些结果表明，两种方法均能够提供稳定且可靠的参数估计</span>
<span id="cb1-910"><a href="#cb1-910"></a></span>
<span id="cb1-911"><a href="#cb1-911"></a><span class="in">```{=latex}</span></span>
<span id="cb1-912"><a href="#cb1-912"></a><span class="in">\begin{table}</span></span>
<span id="cb1-913"><a href="#cb1-913"></a><span class="in">\centering</span></span>
<span id="cb1-914"><a href="#cb1-914"></a><span class="in">\caption{基于贝叶斯和ML方法的参数和变点估计}</span></span>
<span id="cb1-915"><a href="#cb1-915"></a><span class="in">\label{tp-real-data-para}</span></span>
<span id="cb1-916"><a href="#cb1-916"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-917"><a href="#cb1-917"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{4.5mm}</span></span>
<span id="cb1-918"><a href="#cb1-918"></a><span class="in">    \begin{tabular}{cccccccc}</span></span>
<span id="cb1-919"><a href="#cb1-919"></a><span class="in">        \toprule</span></span>
<span id="cb1-920"><a href="#cb1-920"></a><span class="in">        \multirow{2}{*}{电池}  &amp; &amp;\multicolumn{3}{c}{贝叶斯方法} &amp;  \multicolumn{2}{c}{极大似然方法} \\</span></span>
<span id="cb1-921"><a href="#cb1-921"></a><span class="in">        \cline {3 - 8} &amp; &amp;$\boldsymbol{\beta}_1$ &amp; $\boldsymbol{\beta}_2$ &amp; $\boldsymbol{\tau}$ &amp; $\boldsymbol{\beta}_1$ &amp; $\boldsymbol{\beta}_2$ &amp;$\boldsymbol{\tau}$ \\</span></span>
<span id="cb1-922"><a href="#cb1-922"></a><span class="in">        \midrule</span></span>
<span id="cb1-923"><a href="#cb1-923"></a><span class="in">        \multirow{3}{*}{$\#~1$} &amp; 2.5\%&amp; 0.422 &amp; 2.198 &amp; 22.257 &amp; 0.497 &amp; 2.511 &amp; 22.987 \\</span></span>
<span id="cb1-924"><a href="#cb1-924"></a><span class="in">        &amp; 均值 &amp; 0.536 &amp; 2.437 &amp; 23.187 &amp; 0.510  &amp; 2.632 &amp;23.011 \\</span></span>
<span id="cb1-925"><a href="#cb1-925"></a><span class="in">        &amp; 97.5\% &amp; 0.645 &amp; 2.851 &amp; 24.664 &amp; 0.518 &amp; 2.713 &amp;23.032 \\</span></span>
<span id="cb1-926"><a href="#cb1-926"></a><span class="in">        \midrule</span></span>
<span id="cb1-927"><a href="#cb1-927"></a><span class="in">        \multirow{3}{*}{$\#~2$} &amp; 2.5\%&amp;0.523 &amp; 2.013 &amp; 24.365 &amp;0.638 &amp; 2.113  &amp; 25.245\\</span></span>
<span id="cb1-928"><a href="#cb1-928"></a><span class="in">        &amp; 均值 &amp; 0.608 &amp; 2.356 &amp; 25.336 &amp; 0.658 &amp; 2.215 &amp; 25.321\\</span></span>
<span id="cb1-929"><a href="#cb1-929"></a><span class="in">        &amp; 97.5\% &amp;0.785 &amp; 2.615 &amp; 26.557 &amp; 0.670  &amp; 2.282 &amp; 25.398 \\</span></span>
<span id="cb1-930"><a href="#cb1-930"></a><span class="in">        \midrule</span></span>
<span id="cb1-931"><a href="#cb1-931"></a><span class="in">        \multirow{3}{*}{$\#~3$} &amp; 2.5\%&amp; 0.336 &amp; 2.161 &amp; 26.316 &amp; 0.405 &amp; 2.412 &amp; 26.773\\</span></span>
<span id="cb1-932"><a href="#cb1-932"></a><span class="in">        &amp; 均值 &amp; 0.468 &amp; 2.424 &amp; 26.761 &amp; 0.414 &amp; 2.531  &amp; 26.801\\</span></span>
<span id="cb1-933"><a href="#cb1-933"></a><span class="in">        &amp; 97.5\% &amp; 0.518 &amp; 2.831 &amp; 27.381 &amp; 0.420  &amp; 2.61  &amp; 26.821 \\</span></span>
<span id="cb1-934"><a href="#cb1-934"></a><span class="in">        \midrule</span></span>
<span id="cb1-935"><a href="#cb1-935"></a><span class="in">        \multirow{3}{*}{$\#~4$} &amp; 2.5\%&amp; 0.467 &amp; 1.993 &amp; 24.151 &amp; 0.561 &amp; 2.12 &amp; 24.923 \\</span></span>
<span id="cb1-936"><a href="#cb1-936"></a><span class="in">        &amp; 均值 &amp; 0.569 &amp; 2.345 &amp; 25.008 &amp; 0.576 &amp; 2.221 &amp;24.971 \\</span></span>
<span id="cb1-937"><a href="#cb1-937"></a><span class="in">        &amp; 97.5\% &amp; 0.703 &amp; 2.595 &amp; 26.060 &amp; 0.587 &amp; 2.288 &amp; 25.025\\</span></span>
<span id="cb1-938"><a href="#cb1-938"></a><span class="in">        \midrule</span></span>
<span id="cb1-939"><a href="#cb1-939"></a><span class="in">        \multirow{3}{*}{$\#~5$} &amp; 2.5\% &amp; 0.495 &amp; 2.162 &amp; 23.184 &amp;0.624 &amp; 2.382&amp; 23.932\\</span></span>
<span id="cb1-940"><a href="#cb1-940"></a><span class="in">        &amp; 均值 &amp; 0.588 &amp; 2.418 &amp; 23.893 &amp; 0.642 &amp; 2.496 &amp; 23.940\\</span></span>
<span id="cb1-941"><a href="#cb1-941"></a><span class="in">        &amp; 97.5\% &amp; 0.752 &amp; 2.809 &amp; 25.370  &amp; 0.654 &amp; 2.572 &amp; 23.944\\</span></span>
<span id="cb1-942"><a href="#cb1-942"></a><span class="in">        \midrule</span></span>
<span id="cb1-943"><a href="#cb1-943"></a><span class="in">        \multirow{3}{*}{$\#~6$} &amp; 2.5\% &amp; 0.464 &amp; 2.130  &amp; 24.722 &amp;0.559 &amp; 2.324&amp; 25.561\\</span></span>
<span id="cb1-944"><a href="#cb1-944"></a><span class="in">        &amp; 均值 &amp; 0.566 &amp; 2.408 &amp; 25.576 &amp;0.574 &amp; 2.440  &amp; 25.625\\</span></span>
<span id="cb1-945"><a href="#cb1-945"></a><span class="in">        &amp; 97.5\% &amp; 0.697 &amp; 2.769 &amp; 26.306 &amp; 0.585 &amp; 2.517 &amp; 25.667\\</span></span>
<span id="cb1-946"><a href="#cb1-946"></a><span class="in">        \bottomrule</span></span>
<span id="cb1-947"><a href="#cb1-947"></a><span class="in">    \end{tabular}</span></span>
<span id="cb1-948"><a href="#cb1-948"></a><span class="in">\end{table}</span></span>
<span id="cb1-949"><a href="#cb1-949"></a><span class="in">```</span></span>
<span id="cb1-950"><a href="#cb1-950"></a>此外, 为评估所提模型的预测能力, 选取前 30 个数据点用于模型拟合, 并预测后续19 个充放电循环后的电池容量变化. 作为对比, 本文引入 @Duan2017 提出的两阶段 IG 模型（以下简称 “Duan” 模型）, 该模型假设变点\index{变点}仅发生在观测时间点上. 模型中的未知参数通过ML方法估计，并借助 Schwarz 信息准则在拟合精度与模型复杂度之间进行权衡以确定变点\index{变点}位置. 需注意的是，“Duan” 模型的变点\index{变点}位置仅限定于离散的观测点上, 而所提模型则可在连续时间域中直接估计变点\index{变点}位置, 并允许其具备一定的不确定性.</span>
<span id="cb1-951"><a href="#cb1-951"></a></span>
<span id="cb1-952"><a href="#cb1-952"></a>表 \ref{tp-pre} 汇总了五种模型在训练阶段、预测阶段及整体性能方面的RB与RMSE, 其中 “Proposed” 表示采用贝叶斯\index{贝叶斯}方法进行参数估计的所提模型. 从表中可以看出, 三种不考虑变点\index{变点}的基准模型在预测精度方面表现较差, RMSE 与 RB 值均显著偏高. 例如, 图 @fig-tp-5method-path 展示了各模型对电池 #2 的拟合与预测路径. 可以观察到, 不包含变点\index{变点}机制的模型拟合能力不足, 导致其在未来退化路径的预测中存在较大误差. 相较之下, 两阶段模型能够有效识别退化过程\index{退化过程}中的变点\index{变点}, 从而生成与实际观测更为一致的预测结果. 与 “Duan” 模型相比, 所提模型在预测性能上表现更优, 体现为更低的 RMSE 与 RB 值. 这一优势主要得益于其对变点\index{变点}位置的更精准估计. 以电池 #2 为例, 图 @fig-tp-5method-path 进一步对比了两种模型在变点\index{变点}检测方面的差异. 可以明显看出, 变点\index{变点}估计结果的差异直接影响了第二阶段退化速率的判断, 进而对RUL预测\index{RUL预测}的准确性产生显著影响.</span>
<span id="cb1-953"><a href="#cb1-953"></a></span>
<span id="cb1-954"><a href="#cb1-954"></a><span class="in">```{=latex}</span></span>
<span id="cb1-955"><a href="#cb1-955"></a><span class="in">\begin{table}</span></span>
<span id="cb1-956"><a href="#cb1-956"></a><span class="in">\centering</span></span>
<span id="cb1-957"><a href="#cb1-957"></a><span class="in">\caption{不同模型的 RMSE 和 RB.}</span></span>
<span id="cb1-958"><a href="#cb1-958"></a><span class="in">\label{tp-pre}</span></span>
<span id="cb1-959"><a href="#cb1-959"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-960"><a href="#cb1-960"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{5mm}</span></span>
<span id="cb1-961"><a href="#cb1-961"></a><span class="in">    \begin{tabular}{ccccccc}</span></span>
<span id="cb1-962"><a href="#cb1-962"></a><span class="in">        \hline  </span></span>
<span id="cb1-963"><a href="#cb1-963"></a><span class="in">        \multirow{2}{*}{模型} &amp; \multicolumn{2}{c}{训练集} &amp; \multicolumn{2}{c}{预测集}&amp; \multicolumn{2}{c}{全部数据集}  \\</span></span>
<span id="cb1-964"><a href="#cb1-964"></a><span class="in">        \cmidrule{2-7}          &amp;      RMSE     &amp; RB    &amp; RMSE     &amp; RB     &amp; RMSE     &amp; RB      \\</span></span>
<span id="cb1-965"><a href="#cb1-965"></a><span class="in">        \hline  </span></span>
<span id="cb1-966"><a href="#cb1-966"></a><span class="in">        所提模型   &amp; 0.448 &amp; 0.248 &amp; 1.538 &amp; 0.060  &amp; 1.020  &amp; 0.175  \\</span></span>
<span id="cb1-967"><a href="#cb1-967"></a><span class="in">        线性模型   &amp;3.476 &amp; 1.442 &amp; 3.685 &amp; 0.156 &amp; 3.558 &amp; 0.943 \\</span></span>
<span id="cb1-968"><a href="#cb1-968"></a><span class="in">        逆幂模型   &amp;2.057 &amp; 0.568 &amp; 2.475 &amp; 0.113 &amp; 2.229 &amp; 0.391 \\</span></span>
<span id="cb1-969"><a href="#cb1-969"></a><span class="in">        指数模型   &amp; 0.908 &amp; 0.313 &amp; 1.611 &amp; 0.065 &amp; 1.230  &amp; 0.217 \\</span></span>
<span id="cb1-970"><a href="#cb1-970"></a><span class="in">        Duan模型 &amp;0.434 &amp; 0.239 &amp; 1.976 &amp; 0.075 &amp; 1.276 &amp; 0.175 \\</span></span>
<span id="cb1-971"><a href="#cb1-971"></a><span class="in">        \hline  </span></span>
<span id="cb1-972"><a href="#cb1-972"></a><span class="in">    \end{tabular}%</span></span>
<span id="cb1-973"><a href="#cb1-973"></a><span class="in">\end{table}</span></span>
<span id="cb1-974"><a href="#cb1-974"></a><span class="in">```</span></span>
<span id="cb1-977"><a href="#cb1-977"></a><span class="in">```{r}</span></span>
<span id="cb1-978"><a href="#cb1-978"></a><span class="co">#| label: fig-tp-5method-path</span></span>
<span id="cb1-979"><a href="#cb1-979"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-980"><a href="#cb1-980"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-981"><a href="#cb1-981"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-982"><a href="#cb1-982"></a><span class="co">#| fig.cap: '使用不同方法对电池\#2 进行退化路径训练和预测结果.'</span></span>
<span id="cb1-983"><a href="#cb1-983"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/5method-path5.pdf"</span>)</span>
<span id="cb1-984"><a href="#cb1-984"></a><span class="in">```</span></span>
<span id="cb1-985"><a href="#cb1-985"></a></span>
<span id="cb1-986"><a href="#cb1-986"></a>基于所提模型的估计结果, 可推导每个电池的失效时间\index{失效时间}和RUL分布, 方法如第 @sec-tp-s2-3 节所述. 以贝叶斯\index{贝叶斯}估计为例, 使用前30个循环数据, 图 @fig-tp-failure-time-plot 展示了每个电池失效时间\index{失效时间}的可靠度函数\index{可靠度函数}和PDF, 阈值为 $\mathcal{D} = 20\%$. 根据式 \eqref{tp-mttf}, 各电池的MTTF分别为 41.984、43.208、43.658、44.588、43.320 和 42.257. 图 @fig-tp-rul-plot 展示了第30个循环时RUL的可靠度函数\index{可靠度函数}和PDF, 各电池的MRL分别为 9.352、13.375、14.354、15.111、13.180 和 11.925.</span>
<span id="cb1-987"><a href="#cb1-987"></a></span>
<span id="cb1-988"><a href="#cb1-988"></a>::: {#fig-tp-failure-time-plot layout-ncol="2"}</span>
<span id="cb1-989"><a href="#cb1-989"></a><span class="al">![平均退化路径估计](figures/IG/EJOR2024/failure-time-R.pdf)</span>{#fig-failure-time-pdf}</span>
<span id="cb1-990"><a href="#cb1-990"></a></span>
<span id="cb1-991"><a href="#cb1-991"></a><span class="al">![寿命估计PDF](figures/IG/EJOR2024/failure-time-pdf.pdf)</span>{#fig-failure-time-R}</span>
<span id="cb1-992"><a href="#cb1-992"></a></span>
<span id="cb1-993"><a href="#cb1-993"></a>基于贝叶斯方法的可靠度和失效时间密度函数.</span>
<span id="cb1-994"><a href="#cb1-994"></a>:::</span>
<span id="cb1-995"><a href="#cb1-995"></a></span>
<span id="cb1-996"><a href="#cb1-996"></a>::: {#fig-tp-rul-plot layout-ncol="2"}</span>
<span id="cb1-997"><a href="#cb1-997"></a><span class="al">![平均退化路径估计](figures/IG/EJOR2024/rul_r.pdf)</span>{#fig-rul-R}</span>
<span id="cb1-998"><a href="#cb1-998"></a></span>
<span id="cb1-999"><a href="#cb1-999"></a><span class="al">![寿命估计PDF](figures/IG/EJOR2024/rul_pdf.pdf)</span>{#fig-rul-pdf}</span>
<span id="cb1-1000"><a href="#cb1-1000"></a></span>
<span id="cb1-1001"><a href="#cb1-1001"></a>基于贝叶斯方法的 RUL 在第 30 个周期的可靠度\index{可靠度}和密度函数.</span>
<span id="cb1-1002"><a href="#cb1-1002"></a>:::</span>
<span id="cb1-1003"><a href="#cb1-1003"></a></span>
<span id="cb1-1004"><a href="#cb1-1004"></a><span class="fu">#### 自适应替换策略 {#sec-tp-s6-2}</span></span>
<span id="cb1-1005"><a href="#cb1-1005"></a></span>
<span id="cb1-1006"><a href="#cb1-1006"></a>基于RUL预测\index{RUL预测}结果, 可利用所提自适应替换\index{自适应替换}策略确定每个电池的最佳替换时间. 为展示模型在实时场景中的适用性, 选取前30的数据点作为历史数据, 并随着时间推移逐步获取新数据. 在此过程中, 每当获取新的观测数据时, 模型参数和RUL分布的估计均会动态更新. 依据期望成本率式 \eqref{tp-min}, 可以确定持续数据收集期间每个电池的候选替换时间. 为说明效果, 表 \ref{tp-optimal-PR} 展示了电池 #2 和 #3 的候选替换时间, 其中各项成本设定为 $c_i = 2, c_c = 600, c_p = 200, c_b = 100$, 维修准备时间$\varpi = 1$. 此外, 表中还包括真实的RUL和预测的MRL. 从表中可以看出, 候选替换时间根据RUL预测\index{RUL预测}结果进行动态调整. 电池 #2 和 #3 的最佳准备时间分别为42和43. 一旦准备完成, 最佳替换时间分别为43和44, 均与电池实际失效时间\index{失效时间}高度一致, 表明应在失效发生前进行预防性维修. 这一结果进一步验证了所提自适应替换\index{自适应替换}策略在动态环境下的有效性与实用性.</span>
<span id="cb1-1007"><a href="#cb1-1007"></a></span>
<span id="cb1-1008"><a href="#cb1-1008"></a><span class="in">```{=latex}</span></span>
<span id="cb1-1009"><a href="#cb1-1009"></a><span class="in">\begin{table}</span></span>
<span id="cb1-1010"><a href="#cb1-1010"></a><span class="in">\centering</span></span>
<span id="cb1-1011"><a href="#cb1-1011"></a><span class="in">\caption{在连续数据采集周期中, 电池 \#2 和 \#3 的候选替换时间及最佳准备时间} </span></span>
<span id="cb1-1012"><a href="#cb1-1012"></a><span class="in">\label{tp-optimal-PR}</span></span>
<span id="cb1-1013"><a href="#cb1-1013"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{4mm}</span></span>
<span id="cb1-1014"><a href="#cb1-1014"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-1015"><a href="#cb1-1015"></a><span class="in">    %   \resizebox{\columnwidth}{!}{</span></span>
<span id="cb1-1016"><a href="#cb1-1016"></a><span class="in">        \begin{tabular}{cccc|ccc}</span></span>
<span id="cb1-1017"><a href="#cb1-1017"></a><span class="in">            \toprule</span></span>
<span id="cb1-1018"><a href="#cb1-1018"></a><span class="in">            \multirow{2}{*}{循环次数($\times 300$)}  &amp; \multicolumn{3}{c}{电池 \#2} &amp;  \multicolumn{3}{c}{电池 \#3} \\</span></span>
<span id="cb1-1019"><a href="#cb1-1019"></a><span class="in">            \cline{2-7}</span></span>
<span id="cb1-1020"><a href="#cb1-1020"></a><span class="in">            &amp; 真实RUL &amp; MRL &amp;  $  \mathcal{T}_{2,j} $ &amp; 真实RUL &amp; MRL&amp; $    \mathcal{T}_{3,j} $ \\</span></span>
<span id="cb1-1021"><a href="#cb1-1021"></a><span class="in">            \midrule</span></span>
<span id="cb1-1022"><a href="#cb1-1022"></a><span class="in">            %       30 &amp; 9  &amp; 9.156  &amp; 54.079 &amp;37.4 &amp; 12 &amp; 13.865 &amp; 49.122 &amp; 41.3\\</span></span>
<span id="cb1-1023"><a href="#cb1-1023"></a><span class="in">            31 &amp; 12 &amp; 13.865 &amp; 43 &amp; 13 &amp; 13.228 &amp; 46 \\</span></span>
<span id="cb1-1024"><a href="#cb1-1024"></a><span class="in">            33 &amp; 10 &amp; 11.219 &amp; 41  &amp; 11 &amp; 10.278 &amp; 43 \\</span></span>
<span id="cb1-1025"><a href="#cb1-1025"></a><span class="in">            35 &amp; 8  &amp; 7.624  &amp; 41 &amp; 9  &amp; 8.389  &amp; 42 \\</span></span>
<span id="cb1-1026"><a href="#cb1-1026"></a><span class="in">            37 &amp; 6  &amp; 5.986  &amp; 41 &amp; 7  &amp; 6.884  &amp; 42 \\</span></span>
<span id="cb1-1027"><a href="#cb1-1027"></a><span class="in">            39 &amp; 4  &amp; 4.040   &amp; 42 &amp; 5  &amp; 4.206  &amp; 43 \\</span></span>
<span id="cb1-1028"><a href="#cb1-1028"></a><span class="in">            41 &amp; 2  &amp; 2.764  &amp; 43 &amp; 3  &amp; 2.318  &amp; 44   \\</span></span>
<span id="cb1-1029"><a href="#cb1-1029"></a><span class="in">            \textbf{42} &amp; 1  &amp; 1.235  &amp; 43 &amp; 2  &amp; 1.556  &amp; 44   \\</span></span>
<span id="cb1-1030"><a href="#cb1-1030"></a><span class="in">            \textbf{43} &amp; -  &amp; -  &amp; - &amp; 1  &amp; 0.380   &amp; 44  \\</span></span>
<span id="cb1-1031"><a href="#cb1-1031"></a><span class="in">            % 31 &amp; 13 &amp; 20.712 &amp; 46 &amp; 14 &amp; 17.771 &amp; 44 \\</span></span>
<span id="cb1-1032"><a href="#cb1-1032"></a><span class="in">            %        33 &amp; 11 &amp; 13.875 &amp; 43 &amp; 12 &amp; 12.802 &amp; 42 \\</span></span>
<span id="cb1-1033"><a href="#cb1-1033"></a><span class="in">            %        35 &amp; 9  &amp; 11.429 &amp; 42 &amp; 10 &amp; 9.825  &amp; 41 \\</span></span>
<span id="cb1-1034"><a href="#cb1-1034"></a><span class="in">            %        37 &amp; 7  &amp; 8.781  &amp; 42 &amp; 8  &amp; 7.265  &amp; 41 \\</span></span>
<span id="cb1-1035"><a href="#cb1-1035"></a><span class="in">            %        39 &amp; 5  &amp; 6.953  &amp; 43 &amp; 6  &amp; 6.530   &amp; 43 \\</span></span>
<span id="cb1-1036"><a href="#cb1-1036"></a><span class="in">            %        41 &amp; 3  &amp; 5.948  &amp; 44 &amp; 4  &amp; 5.477  &amp; 44 \\</span></span>
<span id="cb1-1037"><a href="#cb1-1037"></a><span class="in">            % \textbf{43} &amp; 1  &amp; 2.524  &amp; \textbf{44} &amp; 2  &amp; 3.669  &amp; \textbf{44}\\</span></span>
<span id="cb1-1038"><a href="#cb1-1038"></a><span class="in">            \bottomrule  </span></span>
<span id="cb1-1039"><a href="#cb1-1039"></a><span class="in">        \end{tabular} %}</span></span>
<span id="cb1-1040"><a href="#cb1-1040"></a><span class="in">\end{table}</span></span>
<span id="cb1-1041"><a href="#cb1-1041"></a><span class="in">```</span></span>
<span id="cb1-1042"><a href="#cb1-1042"></a>为突出模型准确性对自适应维修策略的影响, 将所提两阶段模型的结果与其他模型进行比较. 需要注意, “Duan” 模型假设变点\index{变点}已知, 且未推导出 RUL 分布, 因此仅将所提模型与其他三个不考虑变点\index{变点}的模型 (线性、幂律和指数) 进行比较. 表 \ref{tp-6_battery} 展示了不同模型下 6 个电池的最佳替换时间, 其中“FC” 表示电池的真实失效时间\index{失效时间}, “P” 和 “C” 分别对应预防性维修和纠正性维修. 从表中可见, 在自适应替换\index{自适应替换}策略下, 除幂律模型对五个电池执行纠正性维修外, 其他模型中所有电池的最终确定的最佳替换时间均小于 FC, 即成功执行预防性维修.</span>
<span id="cb1-1043"><a href="#cb1-1043"></a></span>
<span id="cb1-1044"><a href="#cb1-1044"></a><span class="in">```{=latex}</span></span>
<span id="cb1-1045"><a href="#cb1-1045"></a><span class="in">\begin{table}</span></span>
<span id="cb1-1046"><a href="#cb1-1046"></a><span class="in">\centering</span></span>
<span id="cb1-1047"><a href="#cb1-1047"></a><span class="in">\caption{自适应更换政策下6块电池的维修成本率}</span></span>
<span id="cb1-1048"><a href="#cb1-1048"></a><span class="in">\label{tp-6_battery}</span></span>
<span id="cb1-1049"><a href="#cb1-1049"></a><span class="in">    \renewcommand{\arraystretch}{1.25}</span></span>
<span id="cb1-1050"><a href="#cb1-1050"></a><span class="in">    \vskip 0mm \setlength{\tabcolsep}{1.8mm}</span></span>
<span id="cb1-1051"><a href="#cb1-1051"></a><span class="in">    \begin{tabular}{cccccccccccccc}</span></span>
<span id="cb1-1052"><a href="#cb1-1052"></a><span class="in">        \toprule</span></span>
<span id="cb1-1053"><a href="#cb1-1053"></a><span class="in">        \multirow{2}{*}{电池} &amp; \multirow{2}{*}{FC} &amp; \multicolumn{3}{c}{所提模型} &amp; \multicolumn{3}{c}{线性模型} &amp; \multicolumn{3}{c}{逆幂模型}&amp; \multicolumn{3}{c}{指数模型}  \\ \cline{3-14}</span></span>
<span id="cb1-1054"><a href="#cb1-1054"></a><span class="in">        &amp; &amp; $\mathcal{T}_i^*$ &amp; 动作 &amp; CR &amp; $\mathcal{T}_i^*$ &amp; 动作 &amp; CR  &amp; $\mathcal{T}_i^*$ &amp;  动作 &amp; CR  &amp; $\mathcal{T}_i^*$ &amp;  动作 &amp; CR \\</span></span>
<span id="cb1-1055"><a href="#cb1-1055"></a><span class="in">        \midrule</span></span>
<span id="cb1-1056"><a href="#cb1-1056"></a><span class="in">        1 &amp; 40 &amp; 37 &amp; P &amp; 7.351 &amp; 37 &amp; P &amp; 7.351 &amp; 40 &amp; P &amp; 6.950  &amp; 35 &amp; P &amp;  7.657 \\</span></span>
<span id="cb1-1057"><a href="#cb1-1057"></a><span class="in">        2 &amp; 43 &amp; 43 &amp; P &amp; 6.605 &amp; 42 &amp; P &amp; 6.714 &amp; - &amp; C &amp; 17.909 &amp; 40 &amp; P &amp; 6.950 \\</span></span>
<span id="cb1-1058"><a href="#cb1-1058"></a><span class="in">        3 &amp; 44 &amp; 44 &amp; P &amp; 6.500 &amp; 44 &amp; P &amp; 6.500 &amp; - &amp; C &amp; 17.556 &amp; 42 &amp; P &amp; 6.714 \\</span></span>
<span id="cb1-1059"><a href="#cb1-1059"></a><span class="in">        4 &amp; 45 &amp; 44 &amp; P &amp; 6.500 &amp; 43 &amp; P &amp; 6.605 &amp; - &amp; C &amp; 17.217 &amp; 41 &amp; P &amp; 6.829 \\</span></span>
<span id="cb1-1060"><a href="#cb1-1060"></a><span class="in">        5 &amp; 41 &amp; 40 &amp; P &amp; 6.950 &amp; 39 &amp; P &amp; 7.077 &amp; - &amp; C &amp; 18.667  &amp; 38 &amp; P &amp; 7.211 \\</span></span>
<span id="cb1-1061"><a href="#cb1-1061"></a><span class="in">        6 &amp; 42 &amp; 42 &amp; P &amp; 6.714 &amp; 41 &amp; P &amp;  6.829 &amp; - &amp; C &amp; 18.326 &amp; 40 &amp; P &amp; 6.950 \\</span></span>
<span id="cb1-1062"><a href="#cb1-1062"></a><span class="in">        \bottomrule  </span></span>
<span id="cb1-1063"><a href="#cb1-1063"></a><span class="in">    \end{tabular}</span></span>
<span id="cb1-1064"><a href="#cb1-1064"></a><span class="in">\end{table}</span></span>
<span id="cb1-1065"><a href="#cb1-1065"></a><span class="in">```</span></span>
<span id="cb1-1066"><a href="#cb1-1066"></a>图 @fig-tp-arc 展示了每种策略的平均成本率, 其中 ARP 代表所提策略. 在 ARP 下, 使用两阶段 rIG 模型的策略称为 ARP-TP. 从图中可以看出, 除 ARP-Power 策略外, 其他基于 RUL 的 ARP 策略均明显优于 CRP. 此外, 值得注意的是, 与其他策略相比, ARP-TP 的表现最接近 IRP. 结合表 \ref{tp-6_battery}, ARP-TP 提供了接近系统实际故障\index{故障}时间的准确 $\mathcal{T}_i^*$ 值, 而不会超过其实际寿命\index{寿命}. ARP-TP 的平均成本率相对较低, 归因于所提两阶段模型的有效性, 该模型能够准确捕捉变更点的位置并拟合退化路径, 显著提升了预测和决策的精度.</span>
<span id="cb1-1067"><a href="#cb1-1067"></a></span>
<span id="cb1-1070"><a href="#cb1-1070"></a><span class="in">```{r}</span></span>
<span id="cb1-1071"><a href="#cb1-1071"></a><span class="co">#| label: fig-tp-arc</span></span>
<span id="cb1-1072"><a href="#cb1-1072"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1073"><a href="#cb1-1073"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1074"><a href="#cb1-1074"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-1075"><a href="#cb1-1075"></a><span class="co">#| fig.cap: '每个策略的平均成本率.'</span></span>
<span id="cb1-1076"><a href="#cb1-1076"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/ARC-prepare2.pdf"</span>)</span>
<span id="cb1-1077"><a href="#cb1-1077"></a><span class="in">```</span></span>
<span id="cb1-1078"><a href="#cb1-1078"></a></span>
<span id="cb1-1079"><a href="#cb1-1079"></a><span class="fu">### 附录</span></span>
<span id="cb1-1080"><a href="#cb1-1080"></a></span>
<span id="cb1-1081"><a href="#cb1-1081"></a><span class="fu">#### 附录A: 定理 @thm-EJOR2024-thy-1 和 @thm-EJOR2024-thy-2 证明</span></span>
<span id="cb1-1082"><a href="#cb1-1082"></a></span>
<span id="cb1-1083"><a href="#cb1-1083"></a>首先证明定理 @thm-EJOR2024-thy-1 的结果. 设$Y_1(t)$和$Y_2(t)$分别是变点\index{变点}$\tau$之前和之后的退化过程\index{退化过程}. 那么有 \begin{equation*}</span>
<span id="cb1-1084"><a href="#cb1-1084"></a>    Y(t)=\left<span class="sc">\{</span></span>
<span id="cb1-1085"><a href="#cb1-1085"></a>    \begin{array}{ll}</span>
<span id="cb1-1086"><a href="#cb1-1086"></a>        Y_1(t), &amp; t\le\tau, <span class="sc">\\</span></span>
<span id="cb1-1087"><a href="#cb1-1087"></a>        Y_1(\tau)+Y_2(t-\tau), &amp; t&gt;\tau.</span>
<span id="cb1-1088"><a href="#cb1-1088"></a>    \end{array}</span>
<span id="cb1-1089"><a href="#cb1-1089"></a>    \right.</span>
<span id="cb1-1090"><a href="#cb1-1090"></a>\end{equation*}\</span>
<span id="cb1-1091"><a href="#cb1-1091"></a>当$0 \leq t \leq \tau$时, 在给定$\tau$的条件下, $T$的可靠度函数\index{可靠度函数}, 记作$\bar{F}_{1}(t|\tau)$, 可以写为 \begin{equation}\label{r1}</span>
<span id="cb1-1092"><a href="#cb1-1092"></a>    \begin{aligned}</span>
<span id="cb1-1093"><a href="#cb1-1093"></a>        \bar{F}_{1}(t  \mid  \tau)&amp; = P(T&gt;t \mid \tau \geq t) = P(Y_1(t) &lt; \mathcal{D} \mid  \tau \geq t) = F_{rIG}(\mathcal{D}| \delta_1 t, \gamma).</span>
<span id="cb1-1094"><a href="#cb1-1094"></a>    \end{aligned}</span>
<span id="cb1-1095"><a href="#cb1-1095"></a>\end{equation} 当 $t &gt;\tau$ 时, 给定$\tau$的$T$的可靠度函数\index{可靠度函数}可以表示为 \begin{equation}\label{r2}</span>
<span id="cb1-1096"><a href="#cb1-1096"></a>    \begin{aligned}</span>
<span id="cb1-1097"><a href="#cb1-1097"></a>        \bar{F}_{2} (t \mid \tau)=&amp;P\left(Y(t)&lt;\mathcal{D} \mid \tau &lt; t \right) </span>
<span id="cb1-1098"><a href="#cb1-1098"></a>        =P\left(Y_{1}(\tau)+Y_{2}(t-\tau)&lt;\mathcal{D} \mid \tau &lt; t \right) <span class="sc">\\</span></span>
<span id="cb1-1099"><a href="#cb1-1099"></a>        =&amp;\int_0^{\mathcal{D}} P\left(Y_{2}(t-\tau)&lt; \mathcal{D} - y_{\tau} \mid  \tau&lt; t\right)  f_1(y_{\tau}\mid\tau)\mathrm{d} y_{\tau} <span class="sc">\\</span></span>
<span id="cb1-1100"><a href="#cb1-1100"></a>        =&amp;  \int_0^{\mathcal{D}} F_{rIG}(\mathcal{D} - y_{\tau}|  \delta_2  (t - \tau), \gamma)  f_1(y_{\tau}\mid\tau) \mathrm{d} y_{\tau},</span>
<span id="cb1-1101"><a href="#cb1-1101"></a>    \end{aligned}</span>
<span id="cb1-1102"><a href="#cb1-1102"></a>\end{equation} 其中$y_{\tau}$表示变点\index{变点}时间$\tau$处的退化值, $f_1(y<span class="sc">\_</span>{\tau}\mid\tau)$是$y_{\tau}$的PDF. 根据 rIG 过程的性质可知, $f_1(y_{\tau}\mid\tau) = f_{rIG}(y_\tau \mid \delta_1 \tau, \gamma)$. 由式 \eqref{r1} 和式 \eqref{r2} 得到$T$的无条件可靠度函数\index{可靠度函数}为 \begin{equation}</span>
<span id="cb1-1103"><a href="#cb1-1103"></a>    \begin{aligned}</span>
<span id="cb1-1104"><a href="#cb1-1104"></a>        R\left(t \right)   &amp; =P\left(Y(t)&lt;\mathcal{D}, \tau \geq t\right)+P\left(Y(t)&lt;\mathcal{D}, 0&lt;\tau&lt;t\right) <span class="sc">\\</span></span>
<span id="cb1-1105"><a href="#cb1-1105"></a>        &amp; =\bar{F}_1\left(t  \mid  \tau \right) \bar{G}_{\tau}(t)+\int_0^t g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_2\left(t  \mid  \tau\right) \mathrm{d} \tau, <span class="sc">\\</span></span>
<span id="cb1-1106"><a href="#cb1-1106"></a>    \end{aligned}</span>
<span id="cb1-1107"><a href="#cb1-1107"></a>\end{equation} 其中$\bar{G}_{\tau}(t)$是随机变量$\tau$的生存函数.</span>
<span id="cb1-1108"><a href="#cb1-1108"></a></span>
<span id="cb1-1109"><a href="#cb1-1109"></a>接下来, 证明定理 @thm-EJOR2024-thy-2 的结果. 设$y_t$是时间$t$处观测到的退化值. 在时间$t$处系统$S_{t}$的RUL定义为$S_{t}=\inf \left<span class="sc">\{</span>x; Y\left(t+x\right) \geq \mathcal{D} \mid y_t &lt; \mathcal{D}\right<span class="sc">\}</span>$, 表示在条件$y_t &lt; \mathcal{D}$下系统继续正常运行的最短时间. 为了计算系统在时间$t+x$处正常运行的概率, 需计算系统剩余使用寿命的可靠性\index{可靠性}. 考虑到时间$t$、$t+x$和$\tau$之间的不同关系, 首先根据$\tau$的条件得到了三种不同的可靠度\index{可靠度}.</span>
<span id="cb1-1110"><a href="#cb1-1110"></a></span>
<span id="cb1-1111"><a href="#cb1-1111"></a>(i) 当 $x+t  \leq \tau$ 时, $S_t$的条件可靠度函数\index{可靠度函数}为 \begin{equation}\label{rul1}</span>
<span id="cb1-1112"><a href="#cb1-1112"></a>        \begin{aligned}</span>
<span id="cb1-1113"><a href="#cb1-1113"></a>            \bar{F}_{S_{t},1}(x \mid  \tau)&amp;=  P(Y(t + x) &lt; \mathcal{D} \mid  y_t &lt; \mathcal{D}, x+t  \leq \tau)   <span class="sc">\\</span></span>
<span id="cb1-1114"><a href="#cb1-1114"></a>            &amp; =  P(Y(t + x) - y_t &lt; \mathcal{D} - y_t  \mid  y_t &lt; \mathcal{D}, x+t  \leq \tau)  <span class="sc">\\</span></span>
<span id="cb1-1115"><a href="#cb1-1115"></a>            &amp; = F_{r\mathcal{IG}}(\mathcal{D} - y_t| \delta_1 x, \gamma).</span>
<span id="cb1-1116"><a href="#cb1-1116"></a>        \end{aligned}</span>
<span id="cb1-1117"><a href="#cb1-1117"></a>    \end{equation}</span>
<span id="cb1-1118"><a href="#cb1-1118"></a>(ii) 当 $t &lt; \tau&lt;x+t$ 时, $S_t$的条件可靠度函数\index{可靠度函数}为 \begin{equation}\label{rul2}</span>
<span id="cb1-1119"><a href="#cb1-1119"></a>         \begin{aligned}</span>
<span id="cb1-1120"><a href="#cb1-1120"></a>        \bar{F}&amp;_{S_{t},2}(x  \mid  \tau)=  P(Y(t + x) &lt; \mathcal{D} \mid  y_t &lt; \mathcal{D}, t &lt; \tau&lt;x+t)   <span class="sc">\\</span></span>
<span id="cb1-1121"><a href="#cb1-1121"></a>        &amp; =  P(Y_{2}(t + x- \tau ) + Y_{1}(\tau) &lt; \mathcal{D}   \mid  y_t &lt; \mathcal{D}, t &lt; \tau&lt;x+t)  <span class="sc">\\</span></span>
<span id="cb1-1122"><a href="#cb1-1122"></a>        &amp; =  \int_0^{\mathcal{D}} F_{r\mathcal{IG}}(\mathcal{D} - y_\tau| \delta_2 (t+x-\tau), \gamma)   f_1(y_\tau\mid\tau) {\rm d} y_{\tau}.</span>
<span id="cb1-1123"><a href="#cb1-1123"></a>         \end{aligned}</span>
<span id="cb1-1124"><a href="#cb1-1124"></a>     \end{equation}</span>
<span id="cb1-1125"><a href="#cb1-1125"></a>(iii) 当 $\tau \leq t$ 时, $S_t$的条件可靠度函数\index{可靠度函数}为 \begin{equation}\label{rul3}</span>
<span id="cb1-1126"><a href="#cb1-1126"></a>          \bar{F}_{S_{t},3}(x  \mid  \tau)= F_{r\mathcal{IG}}(\mathcal{D} - y_t | \delta_2 x, \gamma).</span>
<span id="cb1-1127"><a href="#cb1-1127"></a>      \end{equation}</span>
<span id="cb1-1128"><a href="#cb1-1128"></a></span>
<span id="cb1-1129"><a href="#cb1-1129"></a>基于式 \eqref{rul1} - 式 \eqref{rul3}, RUL的无条件可靠度函数\index{可靠度函数}是 \begin{equation}</span>
<span id="cb1-1130"><a href="#cb1-1130"></a>  \begin{aligned}</span>
<span id="cb1-1131"><a href="#cb1-1131"></a>    R_{S_t}(x) =&amp; P(Y(t + x) &lt; \mathcal{D}, t &lt; x+t \leq \tau) <span class="sc">\\</span></span>
<span id="cb1-1132"><a href="#cb1-1132"></a>      &amp;+ P(Y(t + x) &lt; \mathcal{D}, t \leq \tau &lt; x+t)  + P(Y(t + x) &lt; \mathcal{D}, t &gt; \tau) <span class="sc">\\</span></span>
<span id="cb1-1133"><a href="#cb1-1133"></a>      =&amp; \bar{F}_{S_t,1}\left(x \mid  \tau \right) \bar{G}_{\tau}(x+t) + \int_{t}^{x+t} g_\tau(\tau| \mu_\tau, \sigma_\tau^2) \bar{F}_{S_t,2}\left(x \mid  \tau\right) {\rm d} \tau <span class="sc">\\</span></span>
<span id="cb1-1134"><a href="#cb1-1134"></a>      &amp; + \int_{0}^{t} g_{\tau}(\tau) \bar{F}_{S_t,3}\left(x \mid  \tau\right) {\rm d}\tau.<span class="sc">\\</span></span>
<span id="cb1-1135"><a href="#cb1-1135"></a>\end{aligned}</span>
<span id="cb1-1136"><a href="#cb1-1136"></a>\end{equation}</span>
<span id="cb1-1137"><a href="#cb1-1137"></a></span>
<span id="cb1-1138"><a href="#cb1-1138"></a><span class="fu">#### 附录B: EM算法技术细节</span></span>
<span id="cb1-1139"><a href="#cb1-1139"></a></span>
<span id="cb1-1140"><a href="#cb1-1140"></a>为了进一步解释EM算法\index{EM算法}的技术细节, 首先定义一组符号. 对数似然函数\index{似然函数} \eqref{tp-com-log} 可以根据 $\tau_i$ 分为两部分, 即 $$l_i(\boldsymbol{\theta_\tau})=\boldsymbol{v}_i^{\top}(\tau_i) \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right) \quad \text{和} \quad l_{i, j}(\boldsymbol{\eta},\tau_i) = \sum_{k=1}^{3}\lambda^{(k)}_{i,j} \boldsymbol{v}_{i, j}^{(k) \top}(\tau_i) \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta}),$$ 其中 $$</span>
<span id="cb1-1141"><a href="#cb1-1141"></a>\begin{aligned}</span>
<span id="cb1-1142"><a href="#cb1-1142"></a>    \boldsymbol{v}_i\left(\tau_i\right)=&amp;\left(1, \tau_i, \tau_i^2\right)^{\top}, v_{i, j}^{(1)}\left(\tau_i\right)=1,<span class="sc">\\</span></span>
<span id="cb1-1143"><a href="#cb1-1143"></a>    \boldsymbol{v}_{i, j}^{(2)}\left(\tau_i\right) =&amp;\left(1, \log(\Delta A_{i,j} + \Delta B_i \tau_i), \tau_i, \tau_i^2\right)^{\top}, <span class="sc">\\</span></span>
<span id="cb1-1144"><a href="#cb1-1144"></a>    v_{i, j}^{(3)}\left(\tau_i\right)=&amp;1, <span class="sc">\\</span></span>
<span id="cb1-1145"><a href="#cb1-1145"></a>    \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)=&amp;\left(-\log \sqrt{2 \pi} \sigma_\tau-\frac{\mu_\tau^2}{2 \sigma_\tau^2}, \frac{\mu_\tau}{\sigma_\tau^2}, -\frac{1}{2 \sigma_\tau^2}\right)^{\top}, <span class="sc">\\</span></span>
<span id="cb1-1146"><a href="#cb1-1146"></a>\end{aligned}</span>
<span id="cb1-1147"><a href="#cb1-1147"></a>$$ $$\begin{aligned}</span>
<span id="cb1-1148"><a href="#cb1-1148"></a>         w_{i, j}^{(1)}(\boldsymbol{\eta})=&amp;-\log \sqrt{2 \pi} + \log \delta_{1,i} \Delta t_{i,j}  + \gamma \delta_{1,i} \Delta t_{i,j} - \frac{3}{2} \log \Delta y_{i,j} <span class="sc">\\</span></span>
<span id="cb1-1149"><a href="#cb1-1149"></a>         &amp;- \frac{{\left( \delta_{1,i} \Delta t_{i,j}\right) }^2}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},<span class="sc">\\</span></span>
<span id="cb1-1150"><a href="#cb1-1150"></a>         \boldsymbol{w}_{i, j}^{(2)}(\boldsymbol{\eta}) =&amp; \left(</span>
<span id="cb1-1151"><a href="#cb1-1151"></a>        -\log \sqrt{2 \pi} -\frac{3}{2} \log \Delta y_{i,j} - \frac{\gamma^2 \Delta y_{i,j}}{2} \right. \nonumber <span class="sc">\\</span></span>
<span id="cb1-1152"><a href="#cb1-1152"></a>        &amp;\left. + \gamma \Delta A_{i,j} - \frac{\Delta A_{i,j}^2}{2 \Delta y_{i,j}}, 1, \Delta B_i \gamma - \frac{\Delta A_{i,j} \Delta B_i}{\Delta y_{i,j}}, - \frac{\Delta B_i^2}{2 \Delta y_{i,j}}</span>
<span id="cb1-1153"><a href="#cb1-1153"></a>        \right)^{\top},<span class="sc">\\</span></span>
<span id="cb1-1154"><a href="#cb1-1154"></a>        w_{i, j}^{(3)}(\boldsymbol{\eta})=&amp;-\log \sqrt{2 \pi} + \log \delta_{2,i}  \Delta t_{i,j}  + \gamma \delta_{2,i}  \Delta t_{i,j} - \frac{3}{2} \log \Delta y_{i,j} <span class="sc">\\</span></span>
<span id="cb1-1155"><a href="#cb1-1155"></a>        &amp; - \frac{{\left<span class="co">[</span><span class="ot"> \delta_{2,i}  \Delta t_{i,j}\right</span><span class="co">]</span> }^2}{2 \Delta y_{i,j}} - \frac{\gamma^2 \Delta y_{i,j}}{2},</span>
<span id="cb1-1156"><a href="#cb1-1156"></a>\end{aligned}</span>
<span id="cb1-1157"><a href="#cb1-1157"></a>$$ $\Delta A_{i,j} = \delta_{2,i}  t_{i,j} -  \delta_{1,i} t_{i,j-1}$ 和 $\Delta B_i  = \delta_{1,i} - \delta_{2,i}$.</span>
<span id="cb1-1158"><a href="#cb1-1158"></a></span>
<span id="cb1-1159"><a href="#cb1-1159"></a><span class="fu">##### 附录B-1: E步中条件期望的推导</span></span>
<span id="cb1-1160"><a href="#cb1-1160"></a></span>
<span id="cb1-1161"><a href="#cb1-1161"></a>在E步中, 需要计算关于 $p(\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i)$ 的期望. 为简化说明, 省略对参数$\boldsymbol{\vartheta}$的依赖. 根据退化增量的独立性, $\boldsymbol{\Delta} \boldsymbol{Y}_i$ 和 $\tau_i$ 的联合PDF为 \begin{equation}\label{joint}</span>
<span id="cb1-1162"><a href="#cb1-1162"></a>    \begin{aligned}</span>
<span id="cb1-1163"><a href="#cb1-1163"></a>        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i, \tau_i }\left(\boldsymbol{\Delta y}_i, \tau_i  \right) &amp; =</span>
<span id="cb1-1164"><a href="#cb1-1164"></a>        \prod_{j=1}^{n_i}  f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i\right) g_\tau\left(\tau_i \mid  \boldsymbol{\theta}_\tau\right). <span class="sc">\\</span></span>
<span id="cb1-1165"><a href="#cb1-1165"></a>    \end{aligned}</span>
<span id="cb1-1166"><a href="#cb1-1166"></a>\end{equation} 从式 \eqref{joint} 中积分掉 $\tau_i$ 后, $\boldsymbol{\Delta} \boldsymbol{Y}_i$ 的边际PDF为 \begin{equation}\label{e_y1}</span>
<span id="cb1-1167"><a href="#cb1-1167"></a>    \begin{aligned}</span>
<span id="cb1-1168"><a href="#cb1-1168"></a>        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i  }\left(\boldsymbol{\Delta y}_i  \right)= &amp; \int_{-\infty}^{+\infty}     \prod_{j=1}^{n_i}  </span>
<span id="cb1-1169"><a href="#cb1-1169"></a>        f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i. <span class="sc">\\</span></span>
<span id="cb1-1170"><a href="#cb1-1170"></a>        %       = &amp; \int_{-\infty}^{t_{i, 0}} L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_{\tau}\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i <span class="sc">\\</span></span>
<span id="cb1-1171"><a href="#cb1-1171"></a>        %       &amp; +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} M_{i, j}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_\tau\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i <span class="sc">\\</span></span>
<span id="cb1-1172"><a href="#cb1-1172"></a>        %       &amp; +\int_{t_{i, n_i}}^{+\infty} R_i\left(\boldsymbol{\Delta y}_i  \mid  \boldsymbol{\eta}, s_i\right) g_\tau\left(s_i  \mid  \boldsymbol{\theta}_\tau\right) d s_i,</span>
<span id="cb1-1173"><a href="#cb1-1173"></a>    \end{aligned}</span>
<span id="cb1-1174"><a href="#cb1-1174"></a>\end{equation} 在计算条件PDF时, 需考虑变点\index{变点} $\tau_i$、时间点 $t_{i,j}$ 以及 $t_{i,j-1}$ 之间的三种关系, 因为会得到不同形式的$\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)$. 为简化表示, 根据三种情形分别引入了不同的条件PDF. 具体来说, 当 $\tau_i &lt; t_{i, 0}$ 时, $\Delta y_{i,j}$ 的条件PDF为: \begin{equation}</span>
<span id="cb1-1175"><a href="#cb1-1175"></a>  \begin{aligned}</span>
<span id="cb1-1176"><a href="#cb1-1176"></a>    f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;  =  \frac{\Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)}{\sqrt{2 \pi}} \exp\left\lbrace{ \gamma \Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) }\right\rbrace  \Delta y_{i, j}^{-3 / 2} <span class="sc">\\</span> </span>
<span id="cb1-1177"><a href="#cb1-1177"></a>   &amp; \times \exp\left\lbrace {-\frac{\left<span class="co">[</span><span class="ot">\Delta m^{(3)}_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)\right</span><span class="co">]</span>^2 \Delta y_{i, j}^{-1}+\gamma^2 \Delta y_{i, j}}{2}}\right\rbrace,</span>
<span id="cb1-1178"><a href="#cb1-1178"></a>\end{aligned}</span>
<span id="cb1-1179"><a href="#cb1-1179"></a>\end{equation} 将 $\Delta y_{i,j}$ 的条件PDF记为 $f_{i, j \mid(3)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)$, 其中 $\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(3)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right)$. 类似地, 对于 $t_{i, j-1} \leqslant \tau_i&lt;t_{i, j}$ 和 $\tau_i \geqslant t_{i, n_i}$ 的情况, $\Delta y_{i,j}$ 的条件PDF分别记为 $f_{i, j \mid(2)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)$ 和 $f_{i, j \mid(1)}\left(\Delta y_{i, j} \mid \delta_{2,i} ,\gamma, \tau_i\right)$, 其中 $$\Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(2)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right), \text{以及} \Delta m_{i, j}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right) = \Delta m_{i, j}^{(1)}\left(\delta_{1,i}, \delta_{2,i}, \tau_i\right).$$</span>
<span id="cb1-1180"><a href="#cb1-1180"></a></span>
<span id="cb1-1181"><a href="#cb1-1181"></a>接下来, 将式 \eqref{e_y1} 中的 $\prod_{j=1}^{n_i} f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)$ 分解为以下三种情况:</span>
<span id="cb1-1182"><a href="#cb1-1182"></a></span>
<span id="cb1-1183"><a href="#cb1-1183"></a>(1) 当 $\tau_i&lt;t_{i, 0}$, \begin{equation}</span>
<span id="cb1-1184"><a href="#cb1-1184"></a>            \begin{aligned}</span>
<span id="cb1-1185"><a href="#cb1-1185"></a>                \prod_{j=1}^{n_i}  </span>
<span id="cb1-1186"><a href="#cb1-1186"></a>                f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;=\prod_{j=1}^{n_i} f_{i, j \mid(3)}\left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right), <span class="sc">\\</span></span>
<span id="cb1-1187"><a href="#cb1-1187"></a>                &amp;  \triangleq  L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid   \boldsymbol{\eta}, \tau_i \right).</span>
<span id="cb1-1188"><a href="#cb1-1188"></a>                %           \prod_{j=1}^{n_i} f_{i, j \mid(3)} \left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)</span>
<span id="cb1-1189"><a href="#cb1-1189"></a>            \end{aligned}</span>
<span id="cb1-1190"><a href="#cb1-1190"></a>    \end{equation}</span>
<span id="cb1-1191"><a href="#cb1-1191"></a>(2) 当 $t_{i, j-1} \leqslant \tau_i&lt;t_{i, j}, ~j = 1, \dots, n_i$, \begin{equation}</span>
<span id="cb1-1192"><a href="#cb1-1192"></a>            \begin{aligned}</span>
<span id="cb1-1193"><a href="#cb1-1193"></a>                \prod_{j=1}^{n_i}  </span>
<span id="cb1-1194"><a href="#cb1-1194"></a>                f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  &amp;=\left<span class="sc">\{</span>\prod_{j^{\prime}=1}^{j-1} f_{i, j^{\prime} \mid(1)}\left(\Delta y_{i, j^{\prime}}  \mid  \delta_{1,i},\gamma, \tau_i\right)\right<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb1-1195"><a href="#cb1-1195"></a>                &amp; ~~~\times f_{i, j\mid(2)}\left(\Delta y_{i, j}  \mid  \delta_{1,i}, \delta_{2,i} ,\gamma, \tau_i\right), <span class="sc">\\</span></span>
<span id="cb1-1196"><a href="#cb1-1196"></a>                &amp;~~~ \times\left<span class="sc">\{</span>\prod_{j^{\prime}=j+1}^{n_i} f_{i, j^{\prime} \mid(3)}\left(\Delta y_{i, j^{\prime}}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)\right<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb1-1197"><a href="#cb1-1197"></a>                &amp;  \triangleq  M_{ij}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i \right).</span>
<span id="cb1-1198"><a href="#cb1-1198"></a>                %           \prod_{j=1}^{n_i} f_{i, j \mid(3)} \left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right)</span>
<span id="cb1-1199"><a href="#cb1-1199"></a>            \end{aligned}</span>
<span id="cb1-1200"><a href="#cb1-1200"></a>    \end{equation}</span>
<span id="cb1-1201"><a href="#cb1-1201"></a>(3) 当 $\tau_i \geqslant t_{i, n_i}$, \begin{equation}</span>
<span id="cb1-1202"><a href="#cb1-1202"></a>            \begin{aligned}</span>
<span id="cb1-1203"><a href="#cb1-1203"></a>                \prod_{j=1}^{n_i}  </span>
<span id="cb1-1204"><a href="#cb1-1204"></a>                f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right) &amp;  =\prod_{j=1}^{n_i} f_{i, j \mid(1)}\left(\Delta y_{i, j}  \mid  \delta_{2,i} ,\gamma, \tau_i\right), <span class="sc">\\</span></span>
<span id="cb1-1205"><a href="#cb1-1205"></a>                &amp;  \triangleq  R_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i \right).</span>
<span id="cb1-1206"><a href="#cb1-1206"></a>            \end{aligned}</span>
<span id="cb1-1207"><a href="#cb1-1207"></a>    \end{equation}</span>
<span id="cb1-1208"><a href="#cb1-1208"></a></span>
<span id="cb1-1209"><a href="#cb1-1209"></a>因此, 式 \eqref{e_y1} 中的 $\boldsymbol{\Delta} \boldsymbol{Y}_i$ 的边际PDF可以重写为: \begin{equation}\label{e_y2}</span>
<span id="cb1-1210"><a href="#cb1-1210"></a>    \begin{aligned}</span>
<span id="cb1-1211"><a href="#cb1-1211"></a>        f_{\boldsymbol{\Delta} \boldsymbol{Y}_i } &amp;\left(\boldsymbol{\Delta y}_i  \right)=  \int_{-\infty}^{+\infty}     \prod_{j=1}^{n_i}  </span>
<span id="cb1-1212"><a href="#cb1-1212"></a>        f_{i, j}\left(\Delta y_{i, j} \mid \delta_{1,i}, \delta_{2,i}, \gamma, \tau_i \right)  g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i <span class="sc">\\</span></span>
<span id="cb1-1213"><a href="#cb1-1213"></a>        = &amp; \int_{-\infty}^{t_{i, 0}} L_i\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_{\tau}\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i </span>
<span id="cb1-1214"><a href="#cb1-1214"></a>        +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} M_{i, j}\left(\boldsymbol{\Delta} \boldsymbol{y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i <span class="sc">\\</span></span>
<span id="cb1-1215"><a href="#cb1-1215"></a>        &amp; +\int_{t_{i, n_i}}^{+\infty} R_i\left(\boldsymbol{\Delta y}_i  \mid  \boldsymbol{\eta}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_\tau\right) {\rm d} \tau_i,</span>
<span id="cb1-1216"><a href="#cb1-1216"></a>    \end{aligned}</span>
<span id="cb1-1217"><a href="#cb1-1217"></a>\end{equation} 根据贝叶斯\index{贝叶斯}定理, 可以计算条件PDF $p(\tau_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i)$ 为: \begin{equation}\label{con-1}</span>
<span id="cb1-1218"><a href="#cb1-1218"></a>    \begin{aligned}</span>
<span id="cb1-1219"><a href="#cb1-1219"></a>        p(\tau_i \mid  \boldsymbol{\Delta} \boldsymbol{y}_i) &amp;= \frac{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i, \tau_i }\left(\boldsymbol{\Delta} \boldsymbol{y}_i, \tau_i  \right)}{f_{\boldsymbol{\Delta}  \boldsymbol{Y}_i }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \right)}.</span>
<span id="cb1-1220"><a href="#cb1-1220"></a>    \end{aligned}</span>
<span id="cb1-1221"><a href="#cb1-1221"></a>\end{equation} 然后, 可以推导出条件期望 $\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[\boldsymbol{v}_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right]$ 和 $\mathbb{E}_{\boldsymbol{\vartheta}{(s)}}\left[\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right]$. 对于 $\boldsymbol{v}_i$ 的条件期望, $i=1, \ldots, I$, 可表示为: \begin{equation}\label{e_v}</span>
<span id="cb1-1222"><a href="#cb1-1222"></a>    \begin{aligned}</span>
<span id="cb1-1223"><a href="#cb1-1223"></a>         \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}} &amp;\left\{\boldsymbol{v}_i \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}=  \frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \right)}\left(\int_{-\infty}^{t_{i, 0}} \boldsymbol{v}_i(\tau_i) L_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right. <span class="sc">\\</span></span>
<span id="cb1-1224"><a href="#cb1-1224"></a>        &amp; +\sum_{j=1}^{n_i} \int_{t_{i, j-1}}^{t_{i, j}} \boldsymbol{v}_i(\tau_i) M_{i, j}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i <span class="sc">\\</span></span>
<span id="cb1-1225"><a href="#cb1-1225"></a>        &amp; \left.+\int_{t_{i, n_i}}^{\infty} \boldsymbol{v}_i(\tau_i) R_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid  \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid  \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right) .</span>
<span id="cb1-1226"><a href="#cb1-1226"></a>    \end{aligned}</span>
<span id="cb1-1227"><a href="#cb1-1227"></a>\end{equation} $\lambda_{i, j}^{(k)} v_{i, j}^{(k)}$ 的条件期望, 其中 $i=1, \ldots, I$, $j=1, \ldots, n_i$, $k=1,2,3$, 如下所示: 当 $k=1$时: \begin{equation}\label{e_k1}</span>
<span id="cb1-1228"><a href="#cb1-1228"></a>    \begin{aligned}</span>
<span id="cb1-1229"><a href="#cb1-1229"></a>        &amp; \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(1)} v_{i, j}^{(1)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb1-1230"><a href="#cb1-1230"></a>        &amp; = \frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)} \left(\sum_{j^{\prime}=j+1}^{n_i} \int_{t_{i, j^{\prime}-1}}^{t_{i, j^{\prime}}} v_{i, j^{\prime}}^{(1)}(\tau_i) M_{i, j^{\prime}}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right. <span class="sc">\\</span></span>
<span id="cb1-1231"><a href="#cb1-1231"></a>        &amp; \left.\quad+\int_{t_{i, n_i}}^{\infty} v_{i, j}^{(1)}(\tau_i) R_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i \mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right),</span>
<span id="cb1-1232"><a href="#cb1-1232"></a>    \end{aligned}</span>
<span id="cb1-1233"><a href="#cb1-1233"></a>\end{equation} 当 $k=2$时: \begin{equation}\label{e_k2}</span>
<span id="cb1-1234"><a href="#cb1-1234"></a>    \begin{aligned}</span>
<span id="cb1-1235"><a href="#cb1-1235"></a>        &amp;\boldsymbol{ \mathbb{E}}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(2)} \boldsymbol{v}_{i, j}^{(2)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right<span class="sc">\}\\</span></span>
<span id="cb1-1236"><a href="#cb1-1236"></a>        &amp;=\frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i  }\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)}  \left(\int_{t_{i, j-1}}^{t_{i, j}} \boldsymbol{v}_{i, j}^{(2)}(\tau_i) M_{i, j}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i  \mid \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i\right),</span>
<span id="cb1-1237"><a href="#cb1-1237"></a>    \end{aligned}</span>
<span id="cb1-1238"><a href="#cb1-1238"></a>\end{equation} 当 $k=3$时: \begin{equation}\label{e_k3}</span>
<span id="cb1-1239"><a href="#cb1-1239"></a>    \begin{aligned}</span>
<span id="cb1-1240"><a href="#cb1-1240"></a>        &amp; \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(3)} v_{i, j}^{(3)} \mid \boldsymbol{\Delta} \boldsymbol{y}_i\right\}\\ &amp;=\frac{1}{f_{\boldsymbol{\Delta} \boldsymbol{Y}_i}\left(\boldsymbol{\Delta}  \boldsymbol{y}_i  \right)}\left(\int_{-\infty}^{t_{i, 0}} v_{i, j}^{(3)}(\tau_i) L_i\left(\boldsymbol{\Delta}  \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)}, \tau_i\right) g_\tau\left(\tau_i \mid \boldsymbol{\theta}_{\tau(s)}\right) {\rm d} \tau_i\right. <span class="sc">\\</span></span>
<span id="cb1-1241"><a href="#cb1-1241"></a>        &amp; \left.\quad+\sum_{j^{\prime}=1}^{j-1} \int_{t_{i, j^{\prime}-1}}^{t_{i, j^{\prime}}} v_{i, j^{\prime}}^{(3)}(\tau_i) M_{i, j^{\prime}}\left(\boldsymbol{\Delta} \boldsymbol{y}_i \mid \boldsymbol{\eta}_{(s)},\tau_i\right) g_\tau\left(\tau_i\mid \boldsymbol{\theta}_{\tau(s)} \right) {\rm d} \tau_i\right).</span>
<span id="cb1-1242"><a href="#cb1-1242"></a>    \end{aligned}</span>
<span id="cb1-1243"><a href="#cb1-1243"></a>\end{equation} 因此, E 步中的 Q 函数为: \begin{equation}\label{e-step2}</span>
<span id="cb1-1244"><a href="#cb1-1244"></a>    \begin{aligned}</span>
<span id="cb1-1245"><a href="#cb1-1245"></a>        \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})</span>
<span id="cb1-1246"><a href="#cb1-1246"></a>        =&amp; \sum_{i=1}^I  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\boldsymbol{v}_i \mid \boldsymbol{\Delta} y\right\}^{\top}  \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)<span class="sc">\\</span></span>
<span id="cb1-1247"><a href="#cb1-1247"></a>        &amp; +  \sum_{i=1}^I \sum_{j=1}^{n_i} \sum_{k=1}^3  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right\}^{\top}  \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta}).</span>
<span id="cb1-1248"><a href="#cb1-1248"></a>    \end{aligned}</span>
<span id="cb1-1249"><a href="#cb1-1249"></a>\end{equation}</span>
<span id="cb1-1250"><a href="#cb1-1250"></a></span>
<span id="cb1-1251"><a href="#cb1-1251"></a><span class="fu">##### 附录B-2: M步中关于$\boldsymbol{\vartheta}$的一阶偏导数</span></span>
<span id="cb1-1252"><a href="#cb1-1252"></a></span>
<span id="cb1-1253"><a href="#cb1-1253"></a>对式 \eqref{e-step2} 中的 Q 函数关于 $\boldsymbol{\vartheta}$ 求一阶偏导数, 并将导数设为零, 从而得到 $\boldsymbol{\vartheta}_{(s+1)}$ 的估计. \begin{equation}\label{derivation}</span>
<span id="cb1-1254"><a href="#cb1-1254"></a>    \begin{aligned}</span>
<span id="cb1-1255"><a href="#cb1-1255"></a>        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial \boldsymbol{\theta}_\tau}= &amp; \sum_{i=1}^I \left[\frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}\right]^{\top}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left<span class="sc">\{</span>\boldsymbol{v}_i \mid \boldsymbol{\Delta} y\right<span class="sc">\}</span> = \boldsymbol{0},<span class="sc">\\</span></span>
<span id="cb1-1256"><a href="#cb1-1256"></a>        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top }= &amp;  \sum_{j=1}^{n_i} \sum_{k=1}^3  \left[\frac{\partial \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top }\right]^{\top}</span>
<span id="cb1-1257"><a href="#cb1-1257"></a>         \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right<span class="sc">\}</span> = \boldsymbol{0}, ~ i = 1,\dots,I, <span class="sc">\\</span></span>
<span id="cb1-1258"><a href="#cb1-1258"></a>        \frac{\partial \boldsymbol{Q}_{(s)}(\boldsymbol{\vartheta})}{\partial \gamma}= &amp; \sum_{i=1}^{I}  \sum_{j=1}^{n_i} \sum_{k=1}^3 \left[ \frac{\partial \boldsymbol{w}_{i, j}^{(k)}(\boldsymbol{\eta})}{\partial \gamma  }\right]^{\top}  \mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left\{\lambda_{i, j}^{(k)} v_{i, j}^{(k)} \mid \boldsymbol{\Delta} \boldsymbol{y}\right<span class="sc">\}</span> = 0,</span>
<span id="cb1-1259"><a href="#cb1-1259"></a>    \end{aligned}</span>
<span id="cb1-1260"><a href="#cb1-1260"></a>\end{equation} 其中 \begin{equation*}</span>
<span id="cb1-1261"><a href="#cb1-1261"></a>    \begin{aligned}</span>
<span id="cb1-1262"><a href="#cb1-1262"></a>        \frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}  &amp; = </span>
<span id="cb1-1263"><a href="#cb1-1263"></a>        \left(\begin{array}{ccc}-\frac{\mu_\tau}{\sigma_\tau^2}, &amp; -\frac{1}{2 \sigma_\tau^2}+\frac{\mu_\tau^2}{2 \sigma_\tau^4}<span class="sc">\\</span> </span>
<span id="cb1-1264"><a href="#cb1-1264"></a>            \frac{1}{\sigma_\tau^2}, &amp; \frac{-\mu_\tau}{\sigma^4_\tau}<span class="sc">\\</span> 0, &amp; \frac{1}{2 \sigma_\tau^4} \end{array}\right),<span class="sc">\\</span></span>
<span id="cb1-1265"><a href="#cb1-1265"></a>        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right)}^\top } &amp; = \left(\begin{array}{ccc} \left( \frac{1}{\delta_{1,i}}+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{1,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}},&amp; 0\end{array}\right),<span class="sc">\\</span></span>
<span id="cb1-1266"><a href="#cb1-1266"></a>                \frac{\partial \boldsymbol{w}_i\left(\boldsymbol{\theta}_\tau\right)}{\partial \boldsymbol{\theta}_\tau}  &amp; = </span>
<span id="cb1-1267"><a href="#cb1-1267"></a>        \left(\begin{array}{ccc}-\frac{\mu_\tau}{\sigma_\tau^2}, &amp; -\frac{1}{2 \sigma_\tau^2}+\frac{\mu_\tau^2}{2 \sigma_\tau^4}<span class="sc">\\</span> </span>
<span id="cb1-1268"><a href="#cb1-1268"></a>            \frac{1}{\sigma_\tau^2}, &amp; \frac{-\mu_\tau}{\sigma^4_\tau}<span class="sc">\\</span> 0, &amp; \frac{1}{2 \sigma_\tau^4} \end{array}\right),<span class="sc">\\</span></span>
<span id="cb1-1269"><a href="#cb1-1269"></a>        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right)}^\top } &amp; = \left(\begin{array}{ccc} \left( \frac{1}{\delta_{1,i}}+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{1,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}},&amp; 0\end{array}\right),<span class="sc">\\</span></span>
<span id="cb1-1270"><a href="#cb1-1270"></a>    \end{aligned}</span>
<span id="cb1-1271"><a href="#cb1-1271"></a>\end{equation*} \begin{equation*}</span>
<span id="cb1-1272"><a href="#cb1-1272"></a>    \begin{aligned}</span>
<span id="cb1-1273"><a href="#cb1-1273"></a>        \frac{\partial \boldsymbol{w}_{i,j}^{(2)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i} \right)}^\top  } &amp; = </span>
<span id="cb1-1274"><a href="#cb1-1274"></a>        \left(</span>
<span id="cb1-1275"><a href="#cb1-1275"></a>        \begin{array}{ccc} -\gamma t_{i,j-1} + \frac{\Delta A_{i,j} t_{i,j-1}}{\Delta y_{i,j}},&amp; \gamma t_{i,j} -\frac{\Delta A_{i,j} t_{i,j}}{\Delta y_{i,j}}<span class="sc">\\</span></span>
<span id="cb1-1276"><a href="#cb1-1276"></a>            0, &amp;0<span class="sc">\\</span></span>
<span id="cb1-1277"><a href="#cb1-1277"></a>            \gamma+\frac{\Delta  B_i t_{i,j-1} - \Delta A_{i,j}}{\Delta y_{i,j}}, &amp;     - \gamma+\frac{\Delta A_{i,j}- \Delta B_i t_{i,j}}{\Delta y_{i,j}}<span class="sc">\\</span></span>
<span id="cb1-1278"><a href="#cb1-1278"></a>            \frac{\delta_{2,i} -\delta_{1,i} }{\Delta y_{i,j}}, &amp;  \frac{\delta_{1,i} -\delta_{2,i} }{\Delta y_{i,j}}</span>
<span id="cb1-1279"><a href="#cb1-1279"></a>        \end{array}\right),<span class="sc">\\</span></span>
<span id="cb1-1280"><a href="#cb1-1280"></a>        \frac{\partial {w}_{i, j}^{(3)}(\boldsymbol{\eta})}{\partial {\left( \delta_{1,i}, \delta_{2,i}\right) }^\top } &amp; = \left(\begin{array}{ccc} </span>
<span id="cb1-1281"><a href="#cb1-1281"></a>            0, &amp; \left( \frac{1}{\delta_{2,i} }+ \gamma\right)  \Delta t_{i,j}-\frac{\delta_{2,i}  \Delta t_{i,j}^2}{\Delta y_{i,j}}</span>
<span id="cb1-1282"><a href="#cb1-1282"></a>        \end{array}\right), <span class="sc">\\</span></span>
<span id="cb1-1283"><a href="#cb1-1283"></a>        \frac{\partial {w}_{i, j}^{(1)}(\boldsymbol{\eta})}{\partial \gamma} &amp; =  \delta_{1,i}  \Delta t_{i,j}-\gamma \Delta y_{i,j},<span class="sc">\\</span></span>
<span id="cb1-1284"><a href="#cb1-1284"></a>    \end{aligned}</span>
<span id="cb1-1285"><a href="#cb1-1285"></a>\end{equation*}</span>
<span id="cb1-1286"><a href="#cb1-1286"></a></span>
<span id="cb1-1287"><a href="#cb1-1287"></a><span class="in">```{=latex}</span></span>
<span id="cb1-1288"><a href="#cb1-1288"></a><span class="in">\begin{equation*}</span></span>
<span id="cb1-1289"><a href="#cb1-1289"></a><span class="in">    \begin{aligned}</span></span>
<span id="cb1-1290"><a href="#cb1-1290"></a><span class="in">        \frac{\partial \boldsymbol{w}_{i,j}^{(2)}(\boldsymbol{\eta})}{\partial \gamma } &amp; = </span></span>
<span id="cb1-1291"><a href="#cb1-1291"></a><span class="in">        {\left(</span></span>
<span id="cb1-1292"><a href="#cb1-1292"></a><span class="in">            \begin{array}{ccc} -\gamma \Delta y_{i,j}+\Delta A_{i,j},~0,~\Delta B_i,~0\\</span></span>
<span id="cb1-1293"><a href="#cb1-1293"></a><span class="in">            \end{array}\right)}^\top,\\</span></span>
<span id="cb1-1294"><a href="#cb1-1294"></a><span class="in">        \frac{\partial {w}_{i, j}^{(3)}(\boldsymbol{\eta})}{\partial \gamma } &amp;= \delta_{2,i}  \Delta t_{i,j} - \gamma \Delta y_{i,j}.</span></span>
<span id="cb1-1295"><a href="#cb1-1295"></a><span class="in">    \end{aligned}</span></span>
<span id="cb1-1296"><a href="#cb1-1296"></a><span class="in">\end{equation*}</span></span>
<span id="cb1-1297"><a href="#cb1-1297"></a><span class="in">```</span></span>
<span id="cb1-1298"><a href="#cb1-1298"></a><span class="fu">##### 附录B-3: EM 算法的步骤</span></span>
<span id="cb1-1299"><a href="#cb1-1299"></a></span>
<span id="cb1-1300"><a href="#cb1-1300"></a>EM 算法可以通过以下步骤实现:</span>
<span id="cb1-1301"><a href="#cb1-1301"></a></span>
<span id="cb1-1302"><a href="#cb1-1302"></a><span class="ss">-   </span>**步骤 1**. 设定参数 $\boldsymbol{\vartheta}$的初始值 $\boldsymbol{\vartheta}_{(\mathbf{0})}$, 并设置容差误差 $\epsilon$.</span>
<span id="cb1-1303"><a href="#cb1-1303"></a></span>
<span id="cb1-1304"><a href="#cb1-1304"></a><span class="ss">-   </span>**步骤 2**. 基于第 $s$ 次迭代的解 $\boldsymbol{\vartheta}_{(s)}$, 计算 $\mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[l_i\left(\boldsymbol{\theta}_\tau\right) \mid \boldsymbol{\Delta} \boldsymbol{y}\right]$ 和 $\mathbb{E}_{\boldsymbol{\vartheta}_{(s)}}\left[ l_{i, j}(\boldsymbol{\eta}, \boldsymbol{\tau}) \mid \boldsymbol{\Delta} \boldsymbol{y}\right]$.</span>
<span id="cb1-1305"><a href="#cb1-1305"></a></span>
<span id="cb1-1306"><a href="#cb1-1306"></a><span class="ss">-   </span>**步骤 3**. 根据式 \eqref{tp-arg} 计算第 $(s+1)$ 次迭代的解 $\boldsymbol{\vartheta}_{(s+1)}$.</span>
<span id="cb1-1307"><a href="#cb1-1307"></a></span>
<span id="cb1-1308"><a href="#cb1-1308"></a><span class="ss">-   </span>**步骤 4**. 重复步骤 2 和步骤 3, 直到 $\left | \boldsymbol{\vartheta}_{(s+1)}-\boldsymbol{\vartheta}_{(s)}\right | &lt;\epsilon$, 其中 $|\cdot|$ 是 $L_1$ 距离.</span>
<span id="cb1-1309"><a href="#cb1-1309"></a></span>
<span id="cb1-1310"><a href="#cb1-1310"></a><span class="ss">-   </span>**步骤 5**. 参数 $\boldsymbol{\vartheta}$ 的MLE可以通过 $\hat{\boldsymbol{\vartheta}}=\boldsymbol{\vartheta}_{(s+1)}$ 获得.</span>
<span id="cb1-1311"><a href="#cb1-1311"></a></span>
<span id="cb1-1312"><a href="#cb1-1312"></a><span class="fu">#### 附录C: 贝叶斯分析技术细节</span></span>
<span id="cb1-1313"><a href="#cb1-1313"></a></span>
<span id="cb1-1314"><a href="#cb1-1314"></a>每个参数的满条件后验分布计算如下</span>
<span id="cb1-1315"><a href="#cb1-1315"></a></span>
<span id="cb1-1316"><a href="#cb1-1316"></a><span class="ss">-   </span>给定 $\boldsymbol{\theta}_{\backslash\left(\mu_\tau, \sigma_\tau^2\right)}$ 和 $\boldsymbol{\Delta Y}$, $\left(\mu_\tau, \sigma_\tau^2\right)$ 的满条件后验分布是 $$</span>
<span id="cb1-1317"><a href="#cb1-1317"></a>      \begin{aligned}</span>
<span id="cb1-1318"><a href="#cb1-1318"></a>          &amp; \left(\mu_\tau, \sigma_\tau^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_\tau, \sigma_\tau^2\right)}, \boldsymbol{\Delta Y} \sim NIG a\left(\beta_\tau^{\prime}, \eta_\tau^{\prime}, v_\tau^{\prime}, \xi_\tau^{\prime}\right), </span>
<span id="cb1-1319"><a href="#cb1-1319"></a>      \end{aligned}</span>
<span id="cb1-1320"><a href="#cb1-1320"></a>      $$ 其中 $\beta_\tau^{\prime}=\beta_\tau+I, \eta_\tau^{\prime}=\left(\beta_\tau \eta_\tau+\sum_{i=1}^I \tau_i\right) /\left(\beta_\tau+I\right), v_\tau^{\prime}=I / 2+v_\tau$, 和 $\xi_\tau^{\prime}=\xi_\tau+\beta_\tau \eta_\tau^2 / 2+\sum_{i=1}^I \tau_i^2 / 2-\left(\beta_\tau \eta_\tau+\sum_{i=1}^I \tau_i\right)^2 /\left(2\left(\beta_\tau+I\right)\right).$</span>
<span id="cb1-1321"><a href="#cb1-1321"></a></span>
<span id="cb1-1322"><a href="#cb1-1322"></a><span class="ss">-   </span>给定 $\boldsymbol{\theta}_{\backslash\left(\mu_1, \sigma_1^2\right)}$ 和 $\boldsymbol{\Delta Y}$, $\left(\mu_1, \sigma_1^2\right)$ 的满条件后验分布是 $$</span>
<span id="cb1-1323"><a href="#cb1-1323"></a>      \begin{aligned}</span>
<span id="cb1-1324"><a href="#cb1-1324"></a>          &amp; \left(\mu_1, \sigma_1^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_1, \sigma_1^2\right)}, \boldsymbol{\Delta Y} \sim NIGa\left(\beta_1^{\prime}, \eta_1^{\prime}, v_1^{\prime}, \xi_1^{\prime}\right), </span>
<span id="cb1-1325"><a href="#cb1-1325"></a>      \end{aligned}</span>
<span id="cb1-1326"><a href="#cb1-1326"></a>      $$ 其中$\beta_1^{\prime}=\beta_1+I, \quad \eta_1^{\prime}=\left(\beta_1 \eta_1+\sum_{i=1}^I \delta_i^1\right) /\left(\beta_1+I\right)$, $v_1^{\prime}=I / 2+v_1$ 和 $\xi_1^{\prime}=\xi_1+\beta_1 \eta_1^2 / 2+\sum_{i=1}^I \delta_{1,i}^{2} / 2- \left(\beta_1 \eta_1+\sum_{i=1}^I \delta_i^1\right)^2 /\left(2\left(\beta_1+I\right)\right)$.</span>
<span id="cb1-1327"><a href="#cb1-1327"></a></span>
<span id="cb1-1328"><a href="#cb1-1328"></a><span class="ss">-   </span>给定 $\boldsymbol{\theta}_{\backslash\left(\mu_2, \sigma_2^2\right)}$ 和 $\boldsymbol{\Delta Y}$, $\left(\mu_2, \sigma_2^2\right)$ 的满条件后验分布是 $$\begin{aligned}</span>
<span id="cb1-1329"><a href="#cb1-1329"></a>    &amp; \left(\mu_2, \sigma_2^2\right) \mid \boldsymbol{\theta}_{\backslash\left(\mu_2, \sigma_2^2\right)}, \boldsymbol{\Delta Y} \sim NIGa\left(\beta_2^{\prime}, \eta_2^{\prime}, v_2^{\prime}, \xi_2^{\prime}\right), </span>
<span id="cb1-1330"><a href="#cb1-1330"></a>      \end{aligned}$$ 其中 $\beta_2^{\prime}=\beta_2+I$, $\eta_2^{\prime}=\left(\beta_2 \eta_2+\sum_{i=1}^I \delta_{2,i} \right) /\left(\beta_2+I\right)$, $v_2^{\prime}=I / 2+v_2$ 和 $\xi_2^{\prime}=\xi_2+\beta_2 \eta_2^2 / 2+\sum_{i=1}^I \delta_{2,i}^{2} / 2- \left(\beta_2 \eta_2+\sum_{i=1}^I \delta_{2,i} \right)^2 /\left(2\left(\beta_2+I\right)\right)$.</span>
<span id="cb1-1331"><a href="#cb1-1331"></a></span>
<span id="cb1-1332"><a href="#cb1-1332"></a><span class="ss">-   </span>给定 $\boldsymbol{\theta}_{\backslash\gamma}$ 和 $\boldsymbol{\Delta Y}$, $\gamma$ 的满条件后验分布是 $$\gamma \mid \boldsymbol{\theta}_{\backslash \gamma}, \boldsymbol{\Delta Y} \sim </span>
<span id="cb1-1333"><a href="#cb1-1333"></a>      N\left(\omega^\prime, \kappa^\prime \right).$$ 其中 $\omega^\prime = \left( \omega + \kappa N \right) / \left(1 + \kappa N\right), \kappa^\prime = \kappa^2 / \left( 1 + \kappa^2 N\right)$和 $N = \sum_{i=1}^{I}\sum_{j=1}^{n_i} \Delta y_{i,j}$.</span>
<span id="cb1-1334"><a href="#cb1-1334"></a></span>
<span id="cb1-1335"><a href="#cb1-1335"></a><span class="ss">-   </span>$\delta_{1,i}, i=1, \ldots, I$的满条件后验分布为: $$\begin{aligned}</span>
<span id="cb1-1336"><a href="#cb1-1336"></a>          \pi &amp;\left( \delta_{1,i} \mid \boldsymbol{\theta}_{\backslash \delta_{1,i}}, \boldsymbol{\Delta Y} \right)  \propto <span class="sc">\\</span></span>
<span id="cb1-1337"><a href="#cb1-1337"></a>          &amp;   \exp \left\lbrace  \frac{ 2 \mu_1 \delta_{1,i} - \delta_{1,i}^2}{ 2 \sigma_1^2 } + \gamma     \sum_{j=1}^{n_i} \Delta \mathcal{M}_{1,i,j} - </span>
<span id="cb1-1338"><a href="#cb1-1338"></a>          \sum_{i=1}^{I}\sum_{j=1}^{n_i}  \frac{  \Delta\mathcal{M}_{1,i,j}^2 }{2 \Delta y_{i,j}} \right\rbrace  \prod_{j=1}^{n_i} \Delta \mathcal{M}_{1,i,j},</span>
<span id="cb1-1339"><a href="#cb1-1339"></a>      \end{aligned}$$ 其中$\Delta \mathcal{M}_{1,i,j} = \delta_{1,i} t_{i,j}\lambda^{(1)}_{i,j} + \left[\left( \delta_{1,i} -  \delta_{2,i}  \right) \tau_i + \delta_{2,i}   t_{i,j+1}  - \delta_{1,i} t_{i,j} \right] \lambda^{(2)}_{i,j}$.</span>
<span id="cb1-1340"><a href="#cb1-1340"></a></span>
<span id="cb1-1341"><a href="#cb1-1341"></a><span class="ss">-   </span>$\delta_{2,i}, i=1, \ldots, I$ 的满条件后验分布为: $$\begin{aligned}</span>
<span id="cb1-1342"><a href="#cb1-1342"></a>              \pi &amp;\left(\delta_{2,i}  \mid \boldsymbol{\theta}_{\backslash \delta_{2,i} }, \boldsymbol{\Delta Y} \right)  \propto <span class="sc">\\</span></span>
<span id="cb1-1343"><a href="#cb1-1343"></a>              &amp; \exp \left\lbrace    \frac{2 \mu_2 \delta_{2,i}   -   \delta^2_{2,i} }{ 2 \sigma_2^2 } + \gamma      \sum_{j=1}^{n_i} \Delta \mathcal{M}_{2,i,j} - </span>
<span id="cb1-1344"><a href="#cb1-1344"></a>              \sum_{i=1}^{I}  \sum_{j=1}^{n_i}    \frac{  {\Delta \mathcal{M}^2_{2,i,j}} }{2 \Delta y_{i,j}} \right\rbrace \prod_{j=1}^{n_i} \Delta \mathcal{M}_{2,i,j},</span>
<span id="cb1-1345"><a href="#cb1-1345"></a>          \end{aligned}$$ 其中 $\Delta \mathcal{M}_{2,i,j} =\left[\left(\delta_{1,i} - \delta_{2,i}  \right) \tau_i +\delta_{2,i} t_{i,j+1}  -\delta_{1,i}  t_{i,j} \right] \lambda^{(2)}_{i,j} + \delta_{2,i}  t_{i,j}\lambda^{(3)}_{i,j}$.</span>
<span id="cb1-1346"><a href="#cb1-1346"></a></span>
<span id="cb1-1347"><a href="#cb1-1347"></a><span class="ss">-   </span>对于 $\tau_i, i=1, \ldots, I$, 满条件后验分布如下: $$ \begin{aligned}</span>
<span id="cb1-1348"><a href="#cb1-1348"></a>              \pi  &amp; \left( \tau_i \mid \boldsymbol{\theta}_{\backslash \tau_i}, \boldsymbol{\Delta Y} \right)  \propto <span class="sc">\\</span></span>
<span id="cb1-1349"><a href="#cb1-1349"></a>              &amp;   \exp \left\lbrace \frac{ 2 \mu_\tau \tau_i - \tau_i^2}{ 2 \sigma_\tau^2 } + \gamma   \sum_{j=1}^{n_i} \Delta \mathcal{M}_{3,i,j} - </span>
<span id="cb1-1350"><a href="#cb1-1350"></a>              \sum_{i=1}^{I}\sum_{j=1}^{n_i}  \frac{ \Delta \mathcal{M}_{3,i,j}^2 }{2 \Delta y_{i,j}} \right\rbrace   \prod_{j=1}^{n_i} \Delta \mathcal{M}_{3,i,j},</span>
<span id="cb1-1351"><a href="#cb1-1351"></a>          \end{aligned}$$ 其中$\Delta \mathcal{M}_{3,i,j} =  \left[\left(\delta_{1,i} - \delta_{2,i}  \right) \tau_i +\delta_{2,i}  t_{i,j+1}  -\delta_{1,i}  t_{i,j} \right] \lambda^{(2)}_{i,j}$.</span>
<span id="cb1-1352"><a href="#cb1-1352"></a></span>
<span id="cb1-1353"><a href="#cb1-1353"></a><span class="fu">#### 附录D: 案例研究附加结果</span></span>
<span id="cb1-1354"><a href="#cb1-1354"></a></span>
<span id="cb1-1355"><a href="#cb1-1355"></a>对于贝叶斯\index{贝叶斯}方法, 通过轨迹图和遍历均值图来监控ARMS-Gibbs算法的收敛性, 见图 @fig-tp-fig:trace 和图 @fig-tp-fig:erg_mean . 通过这些图可以确认马尔科夫链已经收敛. 图 @fig-tp-fig:em 则展示了基于EM算法\index{EM算法}的模型参数估计迭代过程. 从图中可以看出, 经过100次迭代后, 参数估计值已经收敛到一个相对稳定的状态.</span>
<span id="cb1-1356"><a href="#cb1-1356"></a></span>
<span id="cb1-1359"><a href="#cb1-1359"></a><span class="in">```{r}</span></span>
<span id="cb1-1360"><a href="#cb1-1360"></a><span class="co">#| label: fig-tp-fig:trace</span></span>
<span id="cb1-1361"><a href="#cb1-1361"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1362"><a href="#cb1-1362"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1363"><a href="#cb1-1363"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-1364"><a href="#cb1-1364"></a><span class="co">#| fig.cap: '模型参数后验样本轨迹图.'</span></span>
<span id="cb1-1365"><a href="#cb1-1365"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/trace_plot.pdf"</span>)</span>
<span id="cb1-1366"><a href="#cb1-1366"></a><span class="in">```</span></span>
<span id="cb1-1367"><a href="#cb1-1367"></a></span>
<span id="cb1-1370"><a href="#cb1-1370"></a><span class="in">```{r}</span></span>
<span id="cb1-1371"><a href="#cb1-1371"></a><span class="co">#| label: fig-tp-fig:erg_mean</span></span>
<span id="cb1-1372"><a href="#cb1-1372"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1373"><a href="#cb1-1373"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1374"><a href="#cb1-1374"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-1375"><a href="#cb1-1375"></a><span class="co">#| fig.cap: '模型参数后验样本遍历平均图.'</span></span>
<span id="cb1-1376"><a href="#cb1-1376"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/erg_mean.pdf"</span>)</span>
<span id="cb1-1377"><a href="#cb1-1377"></a><span class="in">```</span></span>
<span id="cb1-1378"><a href="#cb1-1378"></a></span>
<span id="cb1-1381"><a href="#cb1-1381"></a><span class="in">```{r}</span></span>
<span id="cb1-1382"><a href="#cb1-1382"></a><span class="co">#| label: fig-tp-fig:em</span></span>
<span id="cb1-1383"><a href="#cb1-1383"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1384"><a href="#cb1-1384"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1385"><a href="#cb1-1385"></a><span class="co">#| out.width: '70%'</span></span>
<span id="cb1-1386"><a href="#cb1-1386"></a><span class="co">#| fig.cap: 'EM算法中各参数迭代过程.'</span></span>
<span id="cb1-1387"><a href="#cb1-1387"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/EJOR2024/EM-iter.pdf"</span>)</span>
<span id="cb1-1388"><a href="#cb1-1388"></a><span class="in">```</span></span>
<span id="cb1-1389"><a href="#cb1-1389"></a></span>
<span id="cb1-1390"><a href="#cb1-1390"></a><span class="fu">## 在线估计与RUL预测 {#sec-Online-IG}</span></span>
<span id="cb1-1391"><a href="#cb1-1391"></a></span>
<span id="cb1-1392"><a href="#cb1-1392"></a><span class="co">&lt;!-- 快速且可靠的RUL预测在工业资产的预测与健康管理中起着至关重要的作用. 随着数据采集技术的进步, 基于退化数据的RUL预测在过去十年中引起了广泛关注. 在文献中, 大多数研究集中于使用Wiener过程作为基础退化模型的RUL预测. 另一方面, 当退化路径是单调时, IG过程已被证明是Wiener过程的一个流行替代方案. 尽管IG过程在退化建模中具有重要性, 但基于IG过程的RUL预测研究仍然较为匮乏. 因此, 本研究的主要目的是对基于IG过程的RUL预测进行系统分析. 我们首先提出了一系列新的在线估计算法, 以便在每次获得新的退化测量数据时高效地更新模型参数. 随后推导出RUL的分布, 并且该分布也可以递归更新. 鉴于不同系统之间可能存在的异质性, 我们进一步将提出的在线算法扩展到IG随机效应模型. 数值研究和渐近分析表明, 所提出的算法能够高效且可靠地估计参数和RUL. 最后, 我们使用了两个实际退化数据集进行说明.--&gt;</span></span>
<span id="cb1-1393"><a href="#cb1-1393"></a></span>
<span id="cb1-1394"><a href="#cb1-1394"></a><span class="co">&lt;!-- 关键词: 退化; IG过程; 一步估计器; 随机效应.--&gt;</span></span>
<span id="cb1-1395"><a href="#cb1-1395"></a></span>
<span id="cb1-1396"><a href="#cb1-1396"></a><span class="co">&lt;!-- RUL 是指一个组件或系统在其预定用途下能够正常运行的剩余时间, 直到需要维修或更换. RUL在工业系统的预测与健康管理中起着关键作用, 它是维护活动规划、备件准备、缺陷识别以及运行效率优化的关键因素之一. 由于RUL预测对运营成本具有巨大的影响, 它在诸如导航系统[@si2013degradation]、电池工业[@hu2020joint]、航空应用[@lorton2013methodology]和高分子材料[@peng2019transformed]等多个领域得到了广泛关注. 传统的RUL估计方法基于寿命数据, RUL也被称为平均剩余寿命[@mercier2019stochastic; @liu2020steady; @xu2024ob]. 然而, 由于现代系统和产品的高可靠性, 失效时间数据通常难以获取, 甚至几乎不可能. 另一方面, 退化是另一个重要的可靠性信息来源, 失效通常被定义为退化水平首次达到预设阈值的时间. 在过去的几十年中, 基于退化数据的RUL预测引起了广泛的兴趣.  --&gt;</span></span>
<span id="cb1-1397"><a href="#cb1-1397"></a></span>
<span id="cb1-1398"><a href="#cb1-1398"></a><span class="co">&lt;!-- 为了进行基于退化的RUL预测, 一个重要的任务是为退化数据开发适当的模型. 在文献中, Wiener过程、伽马过程\index{伽马过程}和IG过程是退化数据的三种常见随机模型, 因为它们具有良好的数学性质和明确的物理解释. Wiener过程适用于非单调的退化数据, 如LED光强度, 而伽马过程\index{伽马过程}和IG过程则更适用于需要单调性的情形. 在文献中, 有大量研究集中在基于这三种随机退化过程对参数和可靠性特征进行统计推断, 例如[@peng2015inverse; @hong2018interval; @hu2020joint; @chen2018uncertainty; @hong2020nonparametric; @hajiha2021degradation; @zhai2023multivariate]. 在RUL预测方面, 基于Wiener过程的研究引起了显著关注, 这主要是因为其数学性质和与传统统计方法的兼容性, 使得处理和分析变得更为简单; 相关示例可见[@si2013degradation; @zhai2017rul; @wang2019improved; @hu2020joint], 以及综述论文[@zhang2018degradation]中的参考文献. 另一方面, 尽管在过去十年中许多研究验证了伽马过程\index{伽马过程}和IG过程在退化建模中的重要性和实用性, 但它们在RUL预测中的关注度相对较低[@ye2014inverse; @chen2019pairwise; @fang2022inverse; @tung2023optimizing].  --&gt;</span></span>
<span id="cb1-1399"><a href="#cb1-1399"></a></span>
<span id="cb1-1400"><a href="#cb1-1400"></a><span class="co">&lt;!-- 本研究的重点是基于IG过程的RUL预测. 目前关于IG过程的大多数研究假设所有退化数据均可获得 (例如, 通过退化试验获取) , 并且主要关注如何估计一些与总体相关的可靠性特征, 如寿命分布和寿命分位数[@wang2010inverse; @ye2014inverse; @peng2015inverse; @chen2018uncertainty]. 然而, 在实际操作中, 退化数据通常只可获得至当前时刻, 因此在每次数据到达时需要进行RUL预测, 以便为后续的预测与健康管理提供支持. [@pan2016remaining]的研究是一个出色的例外, 该研究讨论了基于IG过程的RUL预测. 在该文中, 研究考虑了一个平稳的IG过程, 假设平均退化水平是时间的线性函数. 此外, 通过假设IG过程中的一个参数是特定于个体并在不同个体之间变化, 考虑了单元之间的异质性. 在模型设置的基础上, 推导了在获得新的退化测量时RUL的概率分布, 并使用期望最大化 EM 算法估计未知参数. --&gt;</span></span>
<span id="cb1-1401"><a href="#cb1-1401"></a></span>
<span id="cb1-1402"><a href="#cb1-1402"></a><span class="co">&lt;!-- @pan2016remaining 的开创性工作提出了一种可行的方法, 并突显了基于IG过程进行RUL预测的重要性. 然而, 其模型设置和估计方法存在一些局限性. 首先, 平稳性假设并非总是成立. 在大多数应用中, 退化是非平稳的, 并且退化水平随时间呈现非线性趋势. 如果退化数据被错误地建模为平稳的IG过程, 所预测的RUL可能会不准确, 从而误导操作人员. 其次, RUL预测仅基于一个系统的退化数据. 然而, 在实践中, 通常是同时监测多个系统, 其他系统的退化数据也包含了对目标系统RUL有价值的信息. 实际上, 如果只考虑一个系统, 随机效应模型的动机并不充分. 最后, 在估计RUL分布函数中的未知参数时, 所有历史退化数据都需要作为EM算法的输入. 这种非递归的过程在历史退化测量数据量巨大的情况下计算负担沉重, 而快速RUL预测在许多决策过程中至关重要.  --&gt;</span></span>
<span id="cb1-1403"><a href="#cb1-1403"></a></span>
<span id="cb1-1404"><a href="#cb1-1404"></a><span class="co">&lt;!-- 本研究旨在通过关注IG过程, 尤其是结合非线性和随机效应, 填补上述RUL预测中的空白. 首先, 我们考虑基于时间尺度变换$\Lambda(t)$的非平稳IG过程的在线RUL预测, 这是退化建模中广泛采用的技术 [@hu2020predictive; @zhou2021generalized; @wang2021degradation]. $\Lambda(t)$的一些常见参数化形式包括幂变换, 即$\Lambda_\beta(t) = t^\beta$, 以及指数变换, 即$\Lambda_\beta(t) = 1-e^{-\beta t}$. 引入附加参数$\beta$使得RUL的在线预测更加复杂. 此外, 未知参数的离线估计和在线更新是基于来自多个具有异质性的系统的历史退化数据, 这使得估计变得更具挑战性. 这些挑战将在本研究中通过对$\beta$和其他参数的迭代估计来解决.  --&gt;</span></span>
<span id="cb1-1405"><a href="#cb1-1405"></a></span>
<span id="cb1-1406"><a href="#cb1-1406"></a><span class="co">&lt;!-- 另一方面, 文献中常通过一些滤波技术来缓解计算需求, 从而使参数估计可以随着新观测数据的到来进行序贯更新. 例如, Wiener过程通常结合不同变体的粒子滤波器, 也称为序贯蒙特卡罗方法, 以实现在线RUL预测 [@si2013wiener; @zhai2017rul; @hu2020joint]. 因此, 将粒子滤波器引入IG过程以进行在线RUL预测可能是一个自然的想法. 然而, 众所周知, 粒子滤波器存在退化问题, 即粒子权重逐渐被少数粒子主导, 这显然会影响后验分布的近似精度. 尽管基于重采样的补救措施被提出以应对权重退化问题, 但其采样效率无法得到保证, 且可能会出现样本退化问题 [@givens2012computational]. 在本研究中, 我们提出了一种新的在线算法, 当获得新的退化测量数据时, 该算法能够高效地更新估计值. 其基本思想是为$\beta$的估计值开发一步近似方法, 并在此基础上构建其他未知参数的闭式递归公式. 我们将建立递归估计量的渐近性质. RUL的分布进一步被推导为未知参数的函数, 并且可以通过序贯方式高效地进行估计.  --&gt;</span></span>
<span id="cb1-1407"><a href="#cb1-1407"></a></span>
<span id="cb1-1408"><a href="#cb1-1408"></a><span class="co">&lt;!-- 本文余下部分的安排如下: 第 @sec-igintro 节介绍非平稳IG过程及问题设定. 第 @sec-igsimple 节开发了用于估计参数和RUL的在线算法, 并建立了渐近性质. 第 @sec-igre 节进一步将算法扩展至IG随机效应模型. 第 @sec-simulation 节通过模拟验证所提出的在线算法的性能. 第 @sec-case 节通过两个实际应用来说明所提方法.  --&gt;</span></span>
<span id="cb1-1409"><a href="#cb1-1409"></a></span>
<span id="cb1-1410"><a href="#cb1-1410"></a>现有大多关于IG过程的研究主要集中于离线退化数据分析, 侧重于评估分位寿命\index{寿命}、 平均寿命\index{寿命}和可靠度\index{可靠度}等总体特征<span class="co">[</span><span class="ot">@wang2010inverse; @ye2014inverse; @peng2015inverse; @chen2018uncertainty</span><span class="co">]</span>. 然而, 随着实际应用中实时获取的退化数据日益增多, 对RUL预测\index{RUL预测}的动态更新需求日益迫切. 在此背景下, @pan2016remaining 基于 IG 过程探讨了 RUL 预测问题. 然而, 其模型假设和估计方法存在以下局限性:</span>
<span id="cb1-1411"><a href="#cb1-1411"></a></span>
<span id="cb1-1412"><a href="#cb1-1412"></a><span class="ss">-   </span>平稳性假设: 在大多数应用中, 性能退化\index{性能退化}通常呈现非线性趋势, 平稳性假设可能导致RUL预测\index{RUL预测}结果产生较大偏差.</span>
<span id="cb1-1413"><a href="#cb1-1413"></a></span>
<span id="cb1-1414"><a href="#cb1-1414"></a><span class="ss">-   </span>单一系统数据: 当前方法仅基于单个系统的退化数据进行 RUL 预测, 而实际中往往需同时监测多个系统, 其他系统的退化数据同样蕴含对目标系统 RUL 有价值的信息. 合理利用这些信息有助于提升预测精度.</span>
<span id="cb1-1415"><a href="#cb1-1415"></a></span>
<span id="cb1-1416"><a href="#cb1-1416"></a><span class="ss">-   </span>计算负担: 在估计 RUL 分布函数中未知参数时, 当前方法要求将所有历史退化数据作为 EM 算法的输入. 这种非递归估计方法在处理海量数据时会显著增加计算负担, 从而难以满足决策过程中对快速 RUL 预测的需求.</span>
<span id="cb1-1417"><a href="#cb1-1417"></a></span>
<span id="cb1-1418"><a href="#cb1-1418"></a>为克服上述局限性, 实现对实时退化数据的动态处理和 RUL 的快速预测, 本节介绍一种适用于非平稳IG过程的在线RUL预测\index{RUL预测}方法. 本节结构如下: 第 @sec-igintro 节介绍模型设定及相关问题; 第 @sec-igsimple 节提出参数估计与RUL预测\index{RUL预测}的在线算法; 第 @sec-igre 节将方法扩展至随机效应\index{随机效应}模型; 第 @sec-simulation 节通过模拟验证方法性能; 第 @sec-case 节展示实际应用.</span>
<span id="cb1-1419"><a href="#cb1-1419"></a></span>
<span id="cb1-1420"><a href="#cb1-1420"></a><span class="in">```{=html}</span></span>
<span id="cb1-1421"><a href="#cb1-1421"></a><span class="in">&lt;!--@pan2016remaining 采用平稳IG过程进行RUL预测, </span></span>
<span id="cb1-1422"><a href="#cb1-1422"></a><span class="in">假设性能退化\index{性能退化}随时间线性变化, 并通过引入个体随机效应\index{随机效应}处理系统间异质性. 这项工作虽然奠定了基础, 但在模型假设和估计方法上存在局限: i). 平稳性假设不适用于许多非线性退化情形;  ii). 单一系统数据的建模忽略了多系统间的共性特征, 这些特征能用来提供参数估计的效率;  iii). 需输入全部历史数据的EM算法\index{EM算法}计算效率较低. --&gt;</span></span>
<span id="cb1-1423"><a href="#cb1-1423"></a><span class="in">```</span></span>
<span id="cb1-1424"><a href="#cb1-1424"></a><span class="fu">### 模型设定 {#sec-igintro}</span></span>
<span id="cb1-1425"><a href="#cb1-1425"></a></span>
<span id="cb1-1426"><a href="#cb1-1426"></a>假设系统的性能退化\index{性能退化}指标$Y(t) \sim \textrm{\textrm{IG}}(\Lambda_\beta(t)/\nu , \lambda \Lambda^2_\beta(t))$, 其中$\Lambda_\beta(t)$是时间$t$的单调递增函数, 且满足$\Lambda_\beta(0) = 0$, $\beta$为待估未知参数. 则退化增量$\Delta Y_{ts} = Y(t) - Y(s)$服从逆高斯分布\index{逆高斯分布}$IG(\Delta \Lambda_{ts}/\nu, \lambda \Delta \Lambda_{ts}^2)$, 其中$\Delta \Lambda_{ts} = \Lambda_\beta(t) - \Lambda_\beta(s)$. 假设当前有 $n$ 个系统, 在时间点 $0 = t_0 &lt; t_1 &lt; t_2 &lt; \cdots &lt; t_m &lt; \cdots$, 对所有系统的性能退化\index{性能退化}值进行测量. 令 $y_{i,j}$ 表示第 $i$ 个系统在时间 $t_j$ 的退化值, $\bm Y^{(i)}_{0:m} = (y_{i,0}, \dots, y_{i,m})$ 表示第 $i$ 个系统在 $t_m$ 之前收集的退化观测数据. 所有系统的观测数据集合表示为 $\bm Y_{0:m} = (\bm Y^{(1)}_{0:m}, \dots, \bm Y^{(n)}_{0:m})$. 不失一般性, 假设所有系统在相同的时间点进行检测, 本节方法同样适用于系统检测时间点不同的情形. 假设当前时间点为$t_m$, 在线RUL预测\index{RUL预测}需要解决以下两个问题:</span>
<span id="cb1-1427"><a href="#cb1-1427"></a></span>
<span id="cb1-1428"><a href="#cb1-1428"></a><span class="ss">-   </span>**离线训练**: 基于历史数据$\bm Y_{0:m}$, 估计未知参数$\bm\theta = (\nu, \lambda, \beta)$. 假设某个特定系统的历史退化观测值为$(y_1, \dots, y_m)$, 且失效阈值为$\omega$. 在$t_m$时刻该系统的RUL定义为$\mathcal{X}_m = \inf\{x: Y(x+t_m) \geq \omega \mid y_{m} &lt; \omega<span class="sc">\}</span>$, 其分布可以利用当前参数估计值$\hat{\boldsymbol{\theta}}^{(m)} = (\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})$进行估计.</span>
<span id="cb1-1429"><a href="#cb1-1429"></a></span>
<span id="cb1-1430"><a href="#cb1-1430"></a><span class="ss">-   </span>**在线更新**: 记$(y_{1,m+1}, \dots, y_{n,m+1})$为下一个时间点$t_{m+1}$所收集到的系统退化值. 基于新数据以及之前的估计值$\hat{\boldsymbol{\theta}}^{(m)}$, 如何高效更新参数估计$\hat{\boldsymbol{\theta}}^{(m+1)}$. 该在线算法应通过递归方式更新参数, 避免直接使用完整历史数据$\bm Y_{0:m}$进行重新计算, 以降低计算复杂度.</span>
<span id="cb1-1431"><a href="#cb1-1431"></a></span>
<span id="cb1-1432"><a href="#cb1-1432"></a>由于RUL分布是参数$\bm\theta$的函数, 在每次参数更新后, 可根据新的参数估计值实时预测RUL. 这种方法不仅适用于单一系统, 还能高效整合多系统间的信息, 提升预测的精度与时效性.</span>
<span id="cb1-1433"><a href="#cb1-1433"></a></span>
<span id="cb1-1434"><a href="#cb1-1434"></a><span class="co">&lt;!-- 假设当前的时间点为$t_m$, 我们的任务有两部分. 首先, 我们基于历史数据$\bm Y_{0}$估计未知参数$\bm\theta = (\nu, \lambda, \beta)$, 这在RUL研究中也被称为离线训练. 假设我们关注一个历史退化水平为$(y_1, \dots, y_m)$的系统, 软失效时间定义为退化水平达到由领域知识或专家经验确定的失效阈值$\omega$的时刻. 系统在$t_m$时刻的RUL定义为$\mathcal{X}_m = \inf\{x: Y(x+t_m) \geq \omega  \mid  y_{m} &lt; \omega\}$, 其分布可以使用当前估计值$\hat{\boldsymbol{\theta}}^{(m)} = (\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})$进行估计. 在下一个检测时间点$t_{m+1}$, 来自$n$个系统的新观测值$(y_{1,m+1}, \dots, y_{n,m+1})$变得可用. 我们的下一个目标是利用这些新观测值、之前的估计值$\hat{\boldsymbol{\theta}}^{(m)}$以及可能仅基于历史数据$\bm Y_{0}$的一些统计量, 高效地获得$\hat{\boldsymbol{\theta}}^{(m+1)}$. 换句话说, 所提出的在线算法不需要使用$\bm Y_{0}$中的所有数据点, 估计值以递归方式进行更新. 随后, 由于RUL的分布是$\boldsymbol{\theta}$的函数, 因此可以基于当前估计参数进行实时RUL预测.  --&gt;</span></span>
<span id="cb1-1435"><a href="#cb1-1435"></a></span>
<span id="cb1-1436"><a href="#cb1-1436"></a><span class="fu">### 在线估计 {#sec-igsimple}</span></span>
<span id="cb1-1437"><a href="#cb1-1437"></a></span>
<span id="cb1-1438"><a href="#cb1-1438"></a><span class="fu">#### 当 $\beta$ 已知时, 递归更新 $\hat \nu$ 和 $\hat \lambda$</span></span>
<span id="cb1-1439"><a href="#cb1-1439"></a></span>
<span id="cb1-1440"><a href="#cb1-1440"></a>高效的在线RUL估计需要快速的递归算法来更新参数$\bm\theta=(\nu, \lambda, \beta)$的估计值. 为此, 可先基于历史数据 $\bm Y_{0:m}=(\bm Y^{(1)}_{0:m},\dots,\bm Y^{(n)}_{0:m})$考察参数估计量. 设$\Delta\Lambda_j=\Lambda_\beta(t_j)-\Lambda_\beta(t_{j-1})$ 和 $\Delta y_{i,j}=y_{i,j}-y_{i,j-1}$, 其中 $i=1,\dots,n$ $j=1,\dots,m$. 根据IG过程的性质, 给定$\bm Y_{0:m}$时, $\bm\theta$的似然函数\index{似然函数}为 \begin{align} </span>
<span id="cb1-1441"><a href="#cb1-1441"></a>    L(\bm\theta \mid \bm Y_{0:m}) &amp;=\prod_{i=1}^{n}\prod_{j=1}^{m} \sqrt{\frac{\lambda \Delta\Lambda_{j}^{2}}{2 \pi \Delta y_{i,j}^{3}}} \exp \left<span class="sc">\{</span>-\frac{\lambda}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_{j}\right)^{2}\right<span class="sc">\}</span> \nonumber<span class="sc">\\</span> </span>
<span id="cb1-1442"><a href="#cb1-1442"></a>    &amp;=C_0\lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j}  \exp \left<span class="sc">\{</span>-\lambda  \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{1}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_j\right)^{2}\right<span class="sc">\}</span>, \label{iglike}</span>
<span id="cb1-1443"><a href="#cb1-1443"></a>\end{align} 其中常数$C_0=\prod_{i=1}^{n}\prod_{j=1}^{m}\sqrt{\frac{1}{2 \pi \Delta y_{i,j}^{3}}}$. 假设$\beta$已知, 则$\nu$和$\lambda$的MLE为 (推导见本节附录 @sec-Append-4C) \begin{equation}\label{eq:mle}</span>
<span id="cb1-1444"><a href="#cb1-1444"></a>    \hat{\nu}^{(m)}=\dfrac{n\Lambda_\beta(t_m)}{\sum_{i=1}^{n}y_{i,m}},\quad \hat{\lambda}^{(m)}=\dfrac{nm}{ \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{n^2\Lambda^2_\beta(t_m)}{\sum_{i=1}^{n}y_{i,m}}}.</span>
<span id="cb1-1445"><a href="#cb1-1445"></a>\end{equation} 上述公式表明 $\nu$ 和 $\lambda$ 的估计可通过递归公式更新. 当收集到新的退化测量值$\mathcal{y}_{m+1} = (y{1,m+1}, \dots, y_{n,m+1})$时:\</span>
<span id="cb1-1446"><a href="#cb1-1446"></a>\begin{equation}\label{eq:aupdate}</span>
<span id="cb1-1447"><a href="#cb1-1447"></a>  \hat{\nu}^{(m+1)}=\dfrac{n\Lambda_\beta(t_{m+1})}{\sum_{i=1}^{n}y_{i,m+1}}.</span>
<span id="cb1-1448"><a href="#cb1-1448"></a>\end{equation} 这不需要使用$\bm Y_{0:m}$中的任何信息. 对于$\hat{\lambda}^{(m+1)}$, 其分母包含两部分: $\sum_{i=1}^{n}\sum_{j=1}^{m+1} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}$和$\frac{n^2\Lambda^2_\beta(t_{m+1})}{\sum_{i=1}^{n}y_{i,m+1}}$. 前者可分解为$\sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}+\sum_{i=1}^{n}\frac{\Delta\Lambda_{m+1}^2}{\Delta y_{i,m+1}}$, 后者等于$\left<span class="co">[</span><span class="ot">\hat{\nu}^{(m+1)}\right</span><span class="co">]</span>^2\sum_{i=1}^{n}y_{i,m+1}$. 基于此, $\hat{\lambda}^{(m+1)}$的递归公式为\</span>
<span id="cb1-1449"><a href="#cb1-1449"></a>\begin{align}</span>
<span id="cb1-1450"><a href="#cb1-1450"></a>  \label{eq:bupdate}</span>
<span id="cb1-1451"><a href="#cb1-1451"></a>  \hat{\lambda}^{(m+1)}&amp;=n(m+1)\Bigg<span class="co">[</span><span class="ot">\frac{nm}{\hat \lambda^{(m)}}+\left[\hat{\nu}^{(m)}\right</span><span class="co">]</span>^2\sum_{i=1}^{n}y_{i,m}\nonumber<span class="sc">\\</span></span>
<span id="cb1-1452"><a href="#cb1-1452"></a>  &amp;\quad -\left<span class="co">[</span><span class="ot">\hat{\nu}^{(m+1)}\right</span><span class="co">]</span>^2\sum_{i=1}^{n}y_{i,m+1}+ \sum_{i=1}^{n}\frac{\Delta\Lambda_{m+1}^2}{\Delta y_{i,m+1}}\Bigg]^{-1}.</span>
<span id="cb1-1453"><a href="#cb1-1453"></a>\end{align} 因此, 只需存储历史数据 $\bm Y_{0:m}$ 中的最后一次退化观测量$\mathcal{y}_m =(y_{1,m}, \dots, y_{n,m})$, 以及$\hat\nu^{(m)}$和$\hat\lambda^{(m)}$, 即可实现参数估计的更新.</span>
<span id="cb1-1454"><a href="#cb1-1454"></a></span>
<span id="cb1-1455"><a href="#cb1-1455"></a>**注6**: @pan2016remaining 考虑的单个系统情形, 即$n=1$ (单个系统). 根据\eqref{eq:aupdate}, 可知 $$\hat{\nu}^{(m+1)}=\dfrac{\Lambda_\beta(t_{m+1})}{y_{1,m+1}}.$$ 令 $$\psi_m= \sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{1,j}}-\frac{\Lambda^2_\beta(t_m)} {y_{1,m}},$$ 则有 $$ \psi_{m+1}=\psi_{m}+\dfrac{\Delta y_{1,m+1}y_{1,m+1}}{y_{1,m}}</span>
<span id="cb1-1456"><a href="#cb1-1456"></a>\left<span class="co">[</span><span class="ot">\hat{\nu}^{(m+1)}-\dfrac{\Delta \Lambda_{m+1}}{\Delta y_{1,m+1}}\right</span><span class="co">]</span>^2.$$ 根据和\eqref{eq:bupdate}, 则可得 $\hat{\lambda}^{(m+1)}$ 的更新公式 $$</span>
<span id="cb1-1457"><a href="#cb1-1457"></a>\begin{aligned}</span>
<span id="cb1-1458"><a href="#cb1-1458"></a>\hat{\lambda}^{(m+1)}&amp;=\dfrac{m+1}{\psi_{m+1}}</span>
<span id="cb1-1459"><a href="#cb1-1459"></a>=\hat{\lambda}^{(m)}\dfrac{m+1}{m}\dfrac{\psi_{m}}{\psi_{m+1}}<span class="sc">\\</span></span>
<span id="cb1-1460"><a href="#cb1-1460"></a>&amp;=\hat{\lambda}^{(m)}\dfrac{m+1}{m}</span>
<span id="cb1-1461"><a href="#cb1-1461"></a>\left[1+\dfrac{\Delta y_{1,m+1}y_{1,m+1}}{\psi_{m}y_{1,m}}</span>
<span id="cb1-1462"><a href="#cb1-1462"></a>\left<span class="co">[</span><span class="ot">\hat{\nu}^{(m+1)}-\dfrac{\Delta \Lambda_{m+1}}{\Delta y_{1,m+1}}\right</span><span class="co">]</span>^2\right]^{-1}.</span>
<span id="cb1-1463"><a href="#cb1-1463"></a>\end{aligned}</span>
<span id="cb1-1464"><a href="#cb1-1464"></a>$$</span>
<span id="cb1-1465"><a href="#cb1-1465"></a></span>
<span id="cb1-1466"><a href="#cb1-1466"></a><span class="fu">#### 基于一步近似的 $\hat{\beta}$ 递归更新</span></span>
<span id="cb1-1467"><a href="#cb1-1467"></a></span>
<span id="cb1-1468"><a href="#cb1-1468"></a>在上一小节中, 给定参数 $\beta$时, 得到参数估计$\hat{\nu}$ 和 $\hat{\lambda}$ 的递归公式. 当 $\beta$ 未知时, 可通过历史数据 $\bm Y_{0:m}$ 推导 $\beta$ 的轮廓似然函数\index{似然函数}(Profile likelihood function), 并利用 $\hat{\beta}^{(m)}$ 的MLE更新 $\hat{\nu}^{(m+1)}$ 和 $\hat{\lambda}^{(m+1)}$. 另一方面, $\hat{\beta}^{(m+1)}$ 也可通过更新后的 $\hat{\nu}^{(m+1)}$ 和 $\hat{\lambda}^{(m+1)}$ 进一步优化. 然而, 由于 $\hat{\beta}$ 的 MLE 缺乏解析表达式, 直接更新算法较为复杂. 因此, 本小节介绍了一种基于一步近似(one-step approximation)的高效递归算法来更新 $\hat{\beta}$. 其基本思想是借用一步估计(one-step estimator)的方法: 给定一个初始估计$\tilde{\theta}$, 一步估计量 $\hat{\theta}$ 表示为 \begin{equation}\label{eq:onestep}</span>
<span id="cb1-1469"><a href="#cb1-1469"></a>  \hat \theta = \tilde \theta + <span class="co">[</span><span class="ot">I(\tilde \theta)</span><span class="co">]</span>^{-1} \dot{L}(\tilde \theta),</span>
<span id="cb1-1470"><a href="#cb1-1470"></a>\end{equation} 其中$I(\cdot)$是Fisher信息矩阵, $\dot{L}(\cdot)$是得分函数, 定义为$\dot{L}(\theta) = \frac{\partial \log L(\theta)}{\partial \theta}$, $L(\cdot)$为似然函数\index{似然函数}. 如果$\tilde{\theta}$是$\sqrt{n}$一致的, 并且$\theta\mapsto \dot{L}(\theta)$满足一定的可微性条件, 则一步估计量$\hat{\theta}$也是$\sqrt{n}$一致的, 且其渐近方差可达到Cramér-Rao下界 <span class="co">[</span><span class="ot">@van2000asymptotic</span><span class="co">]</span>.</span>
<span id="cb1-1471"><a href="#cb1-1471"></a></span>
<span id="cb1-1472"><a href="#cb1-1472"></a><span class="in">```{=html}</span></span>
<span id="cb1-1473"><a href="#cb1-1473"></a><span class="in">&lt;!--按照上述循环迭代过程, 依次更新 ($\hat{\nu}, \hat{\lambda}$) 和 $\hat{\beta}$. 在推导 $\hat{\beta}$ 的递归公式时, 假设 $\nu$ 和 $\lambda$ 是已知的. </span></span>
<span id="cb1-1474"><a href="#cb1-1474"></a><span class="in">$\hat{\beta}$ 的更新方法是基一步估计(one-step estimator)方法, 这是一种计算高效的 MLE 替代方案.--&gt;</span></span>
<span id="cb1-1475"><a href="#cb1-1475"></a><span class="in">```</span></span>
<span id="cb1-1476"><a href="#cb1-1476"></a>这里假设$\nu$ 和 $\lambda$已知来说明更新$\hat{\beta}$的方法, 具体实施时可通过循环迭代依次更新 ($\hat{\nu}, \hat{\lambda}$) 和 $\hat{\beta}$. 设$\hat{\beta}^{(m)}$为基于观测数据$\bm Y_{0:m}$得到的参数$\beta$的一致估计. 若初始估计为MLE估计, 则该估计的一致性可以得到保障. 将$\hat{\beta}^{(m)}$作为式 \eqref{eq:onestep} 中的初始估计, 可以得到一步估计量$\hat{\beta}^{(m+1)}$的表达式为 \begin{align}\label{eq:os1}</span>
<span id="cb1-1477"><a href="#cb1-1477"></a>  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + V_{m+1} (\hat{\beta}^{(m)}) \frac{1}{n} \dot{L}(\nu, \lambda, \hat{\beta}^{(m)} \mid \bm Y_{0:m+1}),</span>
<span id="cb1-1478"><a href="#cb1-1478"></a>\end{align} 其中$V_{m+1}(\beta)$是由$\bm Y_{0:m+1}$贡献的Fisher信息矩阵的逆, $L(\cdot)$为式 \eqref{iglike} 中的似然函数\index{似然函数}. 给定时刻$t_j$测量的增量$\Delta \bm{y}_j=(\Delta y_{1,j}, \dots, \Delta y_{n,j})$, $1\le j\le m$, $\beta$ 的对数似然函数\index{似然函数}为 \begin{equation*}</span>
<span id="cb1-1479"><a href="#cb1-1479"></a>\begin{split}</span>
<span id="cb1-1480"><a href="#cb1-1480"></a>  l_j(\beta \mid \Delta \bm{y}_j,\nu,\lambda)=&amp;\frac{n}{2}\log\left(\frac{\lambda}{2\pi}\right)+n\log( \Delta\Lambda_{j})-\frac{3}{2}\sum_{i=1}^{n}\log(\Delta y_{i,j})<span class="sc">\\</span></span>
<span id="cb1-1481"><a href="#cb1-1481"></a>  &amp;-\sum_{i=1}^{n}\frac{\lambda}{2 \Delta y_{i,j}}\left(\nu \Delta y_{i,j}-\Delta\Lambda_{j}\right)^{2}.</span>
<span id="cb1-1482"><a href="#cb1-1482"></a>\end{split}</span>
<span id="cb1-1483"><a href="#cb1-1483"></a>\end{equation*} 由第$j$个增量贡献的$\beta$的Fisher信息为 \begin{align}\label{fij}</span>
<span id="cb1-1484"><a href="#cb1-1484"></a>  I_j(\beta \mid \nu,\lambda)&amp;=-\mathbb{E}\left<span class="co">[</span><span class="ot">\dfrac{\partial^2 l_j(\beta \mid \Delta \bm{y}_j,\nu,\lambda)  }{\partial \beta^2}\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-1485"><a href="#cb1-1485"></a>  &amp; =n\left<span class="co">[</span><span class="ot">\dfrac{\nu\lambda(\Delta\Lambda_{j}^{'})^2}{\Delta\Lambda_{j}}+2\left(\dfrac{\Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2\right</span><span class="co">]</span>,</span>
<span id="cb1-1486"><a href="#cb1-1486"></a>\end{align} 其中$\Delta\Lambda_{j}^{'}$是 $\Delta\Lambda_{j}$ 关于 $\beta$ 的导数（详见本节附录 @sec-Append-4B）. 根据IG过程的性质, 增量$\Delta y_{i,j}$, $i=1, \dots, n$, $j=1, \dots, m$, 是独立的但非同分布. 历史数据$\bm Y_{0:m}$对$\beta$的Fisher信息贡献为$\sum_{j=1}^{m} I_j(\beta \mid \nu,\lambda)$, 因此式 \eqref{eq:os1} 中的$V_{m+1} (\hat{\beta}^{(m)})$可以表示为$\left<span class="co">[</span><span class="ot">\sum_{j=1}^{m+1} I_j(\hat{\beta}^{(m)} \mid \nu,\lambda)\right</span><span class="co">]</span>^{-1}$. 由于$I_j$需要针对不同时刻下的$\beta$估计值进行重新计算, $V_{m+1} (\hat{\beta}^{(m)})$无法通过$V_{m} (\hat{\beta}^{(m-1)})$迭代更新. 为解决这一问题, 需考虑一个高效递归公式来近似$V_{m+1}(\hat{\beta}^{(m)})$: 结合每个时间点上$\nu$和$\lambda$的估计, 可用$\tilde V_{m+1} = \left<span class="co">[</span><span class="ot"> \sum_{j=1}^{m+1} I_j(\beta^{(j-1)} \mid \nu^{(j-1)},\lambda^{(j-1)}) \right</span><span class="co">]</span>^{-1}$近似$V_{m+1}(\hat{\beta}^{(m)})$.\</span>
<span id="cb1-1487"><a href="#cb1-1487"></a>可发现这种处理方式会有以下的迭代关系 \begin{equation}</span>
<span id="cb1-1488"><a href="#cb1-1488"></a>\label{eq:vupdate}</span>
<span id="cb1-1489"><a href="#cb1-1489"></a>\widetilde{V}_{m+1}^{-1}=\widetilde{V}_{m}^{-1}+I_{m+1}(\hat{\beta}^{(m)} \mid \hat{\nu}^{(m)},\hat{\lambda}^{(m)}).</span>
<span id="cb1-1490"><a href="#cb1-1490"></a>\end{equation} <span class="co">&lt;!--该递归公式在 $m \geq 3$ 时表现良好, 初始 $\widetilde{V}m$ 可通过MLE估计获得.--&gt;</span> 基于式 \eqref{eq:vupdate}, $\beta$估计的递归公式\eqref{eq:os1}可近似为\</span>
<span id="cb1-1491"><a href="#cb1-1491"></a>\begin{equation}</span>
<span id="cb1-1492"><a href="#cb1-1492"></a>\begin{aligned}</span>
<span id="cb1-1493"><a href="#cb1-1493"></a>  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + \frac{1}{n}\widetilde V_{m+1}  \dot{L}(\nu, \lambda, \hat{\beta}_n^{(m)}  \mid  \bm Y_{0:m+1}),</span>
<span id="cb1-1494"><a href="#cb1-1494"></a>\end{aligned} \label{eq:os2}</span>
<span id="cb1-1495"><a href="#cb1-1495"></a>\end{equation} 另一方面, 基于$Y_{0:m}$所得的$\hat{\beta}^{(m)}$具有$\sqrt{n}$一致性, 则有\</span>
<span id="cb1-1496"><a href="#cb1-1496"></a>$$\dot{L}(\nu, \lambda, \hat{\beta}_n^{(m)}  \mid  \bm Y_{0:m}) = o_P(n^{-1/2}),$$ 这表明可以忽略与历史数据相关的部分, 仅需考虑新增观测 $\Delta \bm{y}_{m+1}$ 对似然函数\index{似然函数}的贡献. 因此, 式 \eqref{eq:os2} 可进一步简化为\</span>
<span id="cb1-1497"><a href="#cb1-1497"></a>\begin{equation}</span>
<span id="cb1-1498"><a href="#cb1-1498"></a>  \begin{aligned}</span>
<span id="cb1-1499"><a href="#cb1-1499"></a>  \hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} +  \frac{1}{n}\widetilde V_{m+1}S_{m+1}(\Delta \bm y_{m+1},\hat{\beta}^{(m)}), </span>
<span id="cb1-1500"><a href="#cb1-1500"></a>  \end{aligned} \label{eq:lambdaupdate}</span>
<span id="cb1-1501"><a href="#cb1-1501"></a>\end{equation} 其中 $S_j(\bm y,\beta)=\dfrac{\partial l_j(\beta \mid \bm y,\nu,\lambda) }{\partial\beta}$. 显然, $S_{m+1}(\Delta \bm y_{m+1},\hat{\beta}^{(m)})$ 仅依赖于新增观测 $\Delta \bm y_{m+1}$.</span>
<span id="cb1-1502"><a href="#cb1-1502"></a></span>
<span id="cb1-1503"><a href="#cb1-1503"></a>**注7**: 对于非线性和非高斯模型, 粒子滤波器常用来处理在线估计问题<span class="co">[</span><span class="ot">@ma2019pf</span><span class="co">]</span>. 然而, 随着粒子数量的增加, 其计算复杂度显著提高, 这对实时应用构成挑战. 此外, 粒子退化可能导致估计偏差, 而重采样过程中的噪声可能进一步降低性能 <span class="co">[</span><span class="ot">@peng2024coll</span><span class="co">]</span>. 相比之下, 上述提出的一步更新方法具有更高的计算效率, 通过递归计算, 仅利用新增观测和上一步的估计即可实现估计的更新, 显著减少了存储需求和计算负担.</span>
<span id="cb1-1504"><a href="#cb1-1504"></a></span>
<span id="cb1-1505"><a href="#cb1-1505"></a><span class="fu">#### 在线算法和RUL估计</span></span>
<span id="cb1-1506"><a href="#cb1-1506"></a></span>
<span id="cb1-1507"><a href="#cb1-1507"></a>本小节介绍估计参数 $\boldsymbol{\theta}=(\nu,\lambda,\beta)$的整体在线算法. 首先需要初始化参数值. 正如本节附录 @sec-Append-4C 所示, 当系统的性能退化\index{性能退化}仅被测量一次 (即 $m=1$) 时, 参数 $\beta$ 是不可识别的. 同时数值实验也表明, 基于前三个检测时间点的观测数据进行离线训练比 $m=2$ 的情况更稳健. 因此将基于前三次观测数据得到的MLE $\hat{\boldsymbol{\theta}}^{(3)} = (\hat{\nu}^{(3)}, \hat{\lambda}^{(3)},\hat{\beta}^{(3)})$作为算法的初始值, 其具体计算步骤详见本节附录 @sec-Append-4C. 之后, 当新的退化测量数据到来时, 可通过式 \eqref{eq:aupdate}, \eqref{eq:bupdate} 和 \eqref{eq:lambdaupdate} 依次更新 $\hat{\nu}$、$\hat{\lambda}$ 和 $\hat{\beta}$. 以下给出了整体在线估计算法的流程:</span>
<span id="cb1-1508"><a href="#cb1-1508"></a></span>
<span id="cb1-1509"><a href="#cb1-1509"></a><span class="in">```{=latex}</span></span>
<span id="cb1-1510"><a href="#cb1-1510"></a><span class="in">\begin{framed}</span></span>
<span id="cb1-1511"><a href="#cb1-1511"></a><span class="in">\label{alm:onlineig}</span></span>
<span id="cb1-1512"><a href="#cb1-1512"></a><span class="in">    {\bf IG过程的在线算法}</span></span>
<span id="cb1-1513"><a href="#cb1-1513"></a><span class="in">    \begin{enumerate}</span></span>
<span id="cb1-1514"><a href="#cb1-1514"></a><span class="in">        \item 在收集至少三次测量的退化数据后, 执行离线估计以获得参数的初始值 $\hat{\nu}^{(3)}$、$\hat{\lambda}^{(3)}$和$\hat{\beta}^{(3)}$. 同时计算$\tilde V_3 = \left[ \sum_{j=1}^3 I_j(\beta^{(3)} \mid \hat{\nu}^{(3)},\hat{\lambda}^{(3)}) \right]^{-1}$. </span></span>
<span id="cb1-1515"><a href="#cb1-1515"></a><span class="in">        \item 在第 $m$ 次迭代 ($m \geq 3$) 后, 当收到新的观测值 $\bm{y}_{m+1}$ 时, 使用式 \eqref{eq:aupdate} 和 \eqref{eq:bupdate} 更新 $\nu$ 和 $\lambda$ 的估计值, 其中 $\beta$ 替换为 $\hat{\beta}^{(m)}$, 记更新后的估计值为 $\hat{\nu}^{(m+1)}$ 和 $\hat{\lambda}^{(m+1)}$. </span></span>
<span id="cb1-1516"><a href="#cb1-1516"></a><span class="in">        \item 使用式 \eqref{eq:vupdate} 更新$\widetilde{V}_{m+1}$. 然后将$\hat{\nu}^{(m+1)}$和$\hat{\lambda}^{(m+1)}$代入式 \eqref{eq:lambdaupdate}, 计算$\hat{\beta}^{(m+1)}$. </span></span>
<span id="cb1-1517"><a href="#cb1-1517"></a><span class="in">        \item 重复步骤 2 和 3, 直到没有新的观测值为止. </span></span>
<span id="cb1-1518"><a href="#cb1-1518"></a><span class="in">    \end{enumerate}</span></span>
<span id="cb1-1519"><a href="#cb1-1519"></a><span class="in">\end{framed}</span></span>
<span id="cb1-1520"><a href="#cb1-1520"></a><span class="in">```</span></span>
<span id="cb1-1521"><a href="#cb1-1521"></a>定理 @thm-NRL2024-th1 给出了估计量$\hat{\bm\theta}^{(m)}$的一致性和渐近正态性结论, 为提出的迭代过程提供了理论支撑. 相比经典估计理论 (如 M 估计和一步估计) , 该算法由于增加近似和迭代特性使得证明渐近性质时有一定区别, 基本思路是通过将MLE$\hat{\bm\theta}^{(3)}$作为算法初始值, 逐步建立$(\hat{\nu}^{(m)}, \hat{\lambda}^{(m)})$ 和 $\hat{\beta}^{(m)}$ 的收敛性; 进一步, 基于 Donsker 类性质 (见本节附录 @sec-Append-4C), 证明了估计量的渐近正态性.</span>
<span id="cb1-1522"><a href="#cb1-1522"></a></span>
<span id="cb1-1523"><a href="#cb1-1523"></a>::: {#thm-NRL2024-th1}</span>
<span id="cb1-1524"><a href="#cb1-1524"></a>对于每个$m \geq 3$, 当$n \to \infty$时, $(\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})$依概率收敛于$(\nu_0, \lambda_0, \beta_0)$. 此外, 估计量序列$\sqrt{n}<span class="sc">\{</span>(\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)}) - (\nu_0, \lambda_0, \beta_0)<span class="sc">\}</span>$依分布收敛于均值为零且协方差矩阵为$\Sigma_m$的三维正态随机向量, 其中矩阵$\Sigma_m$可用递归公式更新, 其具体形式见本节附录 @sec-Append-4C.</span>
<span id="cb1-1525"><a href="#cb1-1525"></a>:::</span>
<span id="cb1-1526"><a href="#cb1-1526"></a></span>
<span id="cb1-1527"><a href="#cb1-1527"></a>在确定不同检测时间点的估计量后, 可对RUL进行实时更新. 定义系统在时间 $t_m$ 的 RUL 为$\mathcal{X}_m=\inf\{x: Y(x+t_m)\ge \omega \mid y_{m}&lt;\omega<span class="sc">\}</span>$, 其中 $\omega$ 为失效阈值. 若$t_m$时刻的退化值 $y_m$ 已达到 $\omega$, 则 RUL 为零. 由于IG过程是单调递增的, 事件 $<span class="sc">\{</span>\mathcal{X}_m &lt; x<span class="sc">\}</span>$ 等价于 $<span class="sc">\{</span>Y(x+t_m)\ge \omega<span class="sc">\}</span>$, 因此 RUL 的CDF 可表示为 \begin{align}\label{cdfrul}</span>
<span id="cb1-1528"><a href="#cb1-1528"></a>  F_{\mathcal{X}_m}\left(x \mid y_m \right)</span>
<span id="cb1-1529"><a href="#cb1-1529"></a>  &amp;=P<span class="sc">\{</span>Y(x+t_m)\ge \omega<span class="sc">\}</span></span>
<span id="cb1-1530"><a href="#cb1-1530"></a>  =P<span class="sc">\{</span>Y(x+t_m)-y_{m}\ge \omega-y_{m}<span class="sc">\}</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-1531"><a href="#cb1-1531"></a>  &amp;=\Phi\left({\frac{\sqrt{\lambda}\left<span class="co">[</span><span class="ot">\Delta\Lambda_x-\nu(\omega-y_m)\right</span><span class="co">]</span>}{\sqrt{\omega-y_m}}}\right) \nonumber<span class="sc">\\</span></span>
<span id="cb1-1532"><a href="#cb1-1532"></a>  &amp;\quad -\exp\left(2\nu\lambda \Delta \Lambda_x\right)</span>
<span id="cb1-1533"><a href="#cb1-1533"></a>  \Phi\left(-{\frac{\sqrt{\lambda}\left<span class="co">[</span><span class="ot">\Delta\Lambda_x+\nu(\omega-y_m)\right</span><span class="co">]</span>}{\sqrt{\omega-y_m}}}\right),</span>
<span id="cb1-1534"><a href="#cb1-1534"></a>\end{align} 其中$\Delta \Lambda_x=\Lambda_\beta(x+t_m)-\Lambda_\beta(t_m)$, $\Phi(\cdot)$是标准正态分布\index{正态分布}的CDF. 使用估计量$(\hat{\nu}^{(m)}, \hat{\lambda}^{(m)}, \hat{\beta}^{(m)})$可对$F_{\mathcal{X}_m}(\cdot)$进行 实时更新. 此外, 还可推导系统的其他可靠性\index{可靠性}特征. 例如, RUL 的均值可表示为 $$\mathbb{E}(\mathcal{X}_m \mid y_m) = \int_0^\infty \left[1-F_{\mathcal{X}_m}\left(x \mid y_m \right)\right]\diff x.$$ 然而, 由于$\mathbb{E}(\mathcal{X}_m \mid y_m)$涉及到非线性时间尺度变换$\Lambda_{\beta}(\cdot)$, 其解析表达式难以获得, 需要借助数值方法计算 <span class="co">[</span><span class="ot">@huynh2021adaptive</span><span class="co">]</span>.</span>
<span id="cb1-1535"><a href="#cb1-1535"></a></span>
<span id="cb1-1536"><a href="#cb1-1536"></a><span class="fu">### 考虑随机效应的在线估计 {#sec-igre}</span></span>
<span id="cb1-1537"><a href="#cb1-1537"></a></span>
<span id="cb1-1538"><a href="#cb1-1538"></a>本小节研究带随机效应\index{随机效应}IG过程的在线RUL估计. 由于原材料差异、生产过程波动和运行环境变化等因素, 不同系统之间可能存在异质性\index{异质性}. 随机效应\index{随机效应}模型常被用来刻画这类异质特征 <span class="co">[</span><span class="ot">@zhai2018random; @wang2021degradation; @fang2022inverse; @wu2020maintenance</span><span class="co">]</span>. 在 IG 过程中, 可将漂移参数 $\nu$ 设为正态分布\index{正态分布}随机变量 $\nu \sim N(\mu, \sigma^2)$, 并假定 $\mu \gg \sigma$, 以忽略 $\nu$ 取负值的概率 <span class="co">[</span><span class="ot">@ye2014inverse; @pan2016remaining</span><span class="co">]</span>.</span>
<span id="cb1-1539"><a href="#cb1-1539"></a></span>
<span id="cb1-1540"><a href="#cb1-1540"></a><span class="fu">#### 估计量</span></span>
<span id="cb1-1541"><a href="#cb1-1541"></a></span>
<span id="cb1-1542"><a href="#cb1-1542"></a>在带随机效应\index{随机效应}IG过程的模型中, 参数为 $\boldsymbol{\theta} = (\lambda, \beta, \mu, \sigma)$. 基于退化数据$Y_{0:m}$, 似然函数\index{似然函数}的形式较为复杂, 无法得到参数$\boldsymbol{\theta}$的估计量的解析表达式.\</span>
<span id="cb1-1543"><a href="#cb1-1543"></a>本小节将介绍一个两阶段的离线估计方法, 并为模型参数提供结合偏差校正的解析形式估计量.</span>
<span id="cb1-1544"><a href="#cb1-1544"></a></span>
<span id="cb1-1545"><a href="#cb1-1545"></a>由于$\beta$可通过上一节中的一步估计方法获得, 这里先假设其已知. 两阶段估计方法的基本策略是 先估计缺失参数$\nu_1,\dots,\nu_n$, 然后利用基于这些估计量获取$\mu$和$\sigma$的估计. 第一步中, 在给定$\beta$和观测退化增量$\Delta \bm y_{1}$, $\dots$, $\Delta \bm y_{m}$的条件下, $\lambda$和$\nu_i$的MLE分别为 \begin{equation}</span>
<span id="cb1-1546"><a href="#cb1-1546"></a>\label{eq:remle}</span>
<span id="cb1-1547"><a href="#cb1-1547"></a>\hat{\lambda}^{(m)}=\dfrac{nm}{\sum_{i=1}^{n}\phi_{i,m}}, ~</span>
<span id="cb1-1548"><a href="#cb1-1548"></a>\hat{\nu}_i^{(m)}=</span>
<span id="cb1-1549"><a href="#cb1-1549"></a>\dfrac{\Lambda_\beta(t_{m})}{y_{i,m}},~i=1,\dots,n,</span>
<span id="cb1-1550"><a href="#cb1-1550"></a>\end{equation} 其中$\phi_{i,m}= \sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_m)} {y_{i,m}}$. 鉴于参数数量较多而单个系统的样本量有限, 当 $m$ 较小时, 这些估计量可能存在较大偏差. 因此, 引入以下方法 来减少估计的偏差. 首先, 对$\hat{\lambda}^{(m)}$进行校正. 注意到 $$\Delta y_{i,j}\sim \textrm{\textrm{IG}}(\Delta \Lambda_{j}/\nu_i,\lambda\Delta \Lambda_{j}^2), \quad \quad y_{i,m}\sim \textrm{\textrm{IG}}(\Lambda_{\beta}(t_m)/\nu_i,\lambda\Lambda_{\beta}^2(t_m)).$$ 同时有 $$\mathbb{E}\left<span class="co">[</span><span class="ot">\frac{1}{\Delta y_{i,j}}\right</span><span class="co">]</span>=\frac{\nu_i}{\Delta \Lambda_{j}}+ \frac{1}{\lambda\Delta \Lambda_{j}^2}, \quad  \quad \mathbb{E}\left<span class="co">[</span><span class="ot">y_{i,m}\right</span><span class="co">]</span>=\frac{\nu_i}{\Lambda_{\beta}(t_m)}+ \frac{1}{\lambda\Lambda_{\beta}^2(t_m)}.</span>
<span id="cb1-1551"><a href="#cb1-1551"></a>$$ 由此可得 $$</span>
<span id="cb1-1552"><a href="#cb1-1552"></a>\begin{aligned}</span>
<span id="cb1-1553"><a href="#cb1-1553"></a>    \mathbb{E}\left<span class="co">[</span><span class="ot">\phi_{i,m}\right</span><span class="co">]</span>&amp;=\sum_{j=1}^{m} \mathbb{E}\left<span class="co">[</span><span class="ot">\frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}\right</span><span class="co">]</span>-\mathbb{E}\left[\frac{\Lambda^2_\beta(t_m)}</span>
<span id="cb1-1554"><a href="#cb1-1554"></a>    {y_{i,m}}\right]<span class="sc">\\</span></span>
<span id="cb1-1555"><a href="#cb1-1555"></a>    &amp;=\sum_{j=1}^{m}\left(\nu_i\Delta \Lambda_{j}+\frac{1}{\lambda}\right)-</span>
<span id="cb1-1556"><a href="#cb1-1556"></a>    \left(\nu_i\Lambda_{\beta}(t_m)+\frac{1}{\lambda}\right)=\frac{m-1}{\lambda}.</span>
<span id="cb1-1557"><a href="#cb1-1557"></a>\end{aligned}</span>
<span id="cb1-1558"><a href="#cb1-1558"></a>$$ $\sum_{i=1}^{n}\phi_{i,m}$的期望为 $$\mathbb{E}\left<span class="co">[</span><span class="ot">\sum_{i=1}^{n}\phi_{i,m}\right</span><span class="co">]</span>=\frac{n(m-1)}{\lambda},$$ 从而可得 $1/\lambda$的无偏估计量: $T_m = \sum_{i=1}^{n}\phi_{im}/<span class="co">[</span><span class="ot">n(m-1)</span><span class="co">]</span>$. 对于任何可微函数$h(\cdot)$, $h(T_m)$都可以作为$h(1/\lambda)$的估计量, 但通常会有偏差. 通过泰勒展开近似可得 \begin{equation*}</span>
<span id="cb1-1559"><a href="#cb1-1559"></a>\begin{aligned}</span>
<span id="cb1-1560"><a href="#cb1-1560"></a>\mathbb{E}\left<span class="co">[</span><span class="ot">h(T_m)\right</span><span class="co">]</span>&amp;\approx </span>
<span id="cb1-1561"><a href="#cb1-1561"></a>\mathbb{E}\left[h(1/\lambda)+h^{'}(1/\lambda)(T_m-1/\lambda)</span>
<span id="cb1-1562"><a href="#cb1-1562"></a>+h^{''}(1/\lambda)(T_m-1/\lambda)^2/2\right]<span class="sc">\\</span></span>
<span id="cb1-1563"><a href="#cb1-1563"></a>&amp;=h(1/\lambda)+\mathbb{Var}(T_m)h^{''}(1/\lambda)/2.</span>
<span id="cb1-1564"><a href="#cb1-1564"></a>\end{aligned}</span>
<span id="cb1-1565"><a href="#cb1-1565"></a>\end{equation*} 当$h(x) = 1/x$时, $1/T_m$的期望可近似为 \begin{equation}\label{bias1}</span>
<span id="cb1-1566"><a href="#cb1-1566"></a>\mathbb{E}\left<span class="co">[</span><span class="ot">1/T_m\right</span><span class="co">]</span>\approx </span>
<span id="cb1-1567"><a href="#cb1-1567"></a>\lambda+\mathbb{Var}(T_m)\lambda^3.</span>
<span id="cb1-1568"><a href="#cb1-1568"></a>\end{equation} 为了找到$\lambda$的渐近无偏估计量, 需要找到$\mathbb{Var}(T_m)$的近似. 由于$\phi_{im}, i=1, \dots, n$独立同分布, 因此$\mathbb{Var}(T_m) = \dfrac{\mathbb{Var}(\phi_{im})}{n(m-1)^2}$. 给定$\beta$, $\mathbb{Var}(\phi_{im})$可以通过$\frac{1}{n-1}\sum_{i=1}^{n}(\phi_{im} - \bar{\phi}_{m})^2$进行估计, 其中$\bar{\phi}_{m} = \frac{1}{n}\sum_{i=1}^{n}\phi_{im}$. 因此, 方差的渐近估计量为 \begin{equation}\label{varest}</span>
<span id="cb1-1569"><a href="#cb1-1569"></a>\widehat{\mathbb{Var}(T_m)}=\dfrac{\frac{1}{n-1}\sum_{i=1}^{n}(\phi_{im}-\bar{\phi}_{m})^2}{n(m-1)^2}.</span>
<span id="cb1-1570"><a href="#cb1-1570"></a>\end{equation} 结合式 \eqref{eq:remle}和 \eqref{bias1}, 可得带偏差校正的$\lambda$的解析形式估计量为\</span>
<span id="cb1-1571"><a href="#cb1-1571"></a>\begin{equation}</span>
<span id="cb1-1572"><a href="#cb1-1572"></a>\label{eq:betaest}</span>
<span id="cb1-1573"><a href="#cb1-1573"></a>\tilde{\lambda}^{(m)}=\dfrac{n(m-1)}{\sum_{i=1}^{n}\phi_{im}}-\dfrac{\sum_{i=1}^{n}(\phi_{im}-\bar{\phi}_{m})^2}{n(n-1)(m-1)^2}</span>
<span id="cb1-1574"><a href="#cb1-1574"></a>\left(\dfrac{nm}{\sum_{i=1}^{n}\phi_{i,m}}\right)^3.</span>
<span id="cb1-1575"><a href="#cb1-1575"></a>\end{equation} 对于$\hat{\nu}_i^{(m)}$的偏差校正, 有 \begin{equation}\label{bias2}</span>
<span id="cb1-1576"><a href="#cb1-1576"></a>\begin{aligned}</span>
<span id="cb1-1577"><a href="#cb1-1577"></a>\mathbb{E}\left<span class="co">[</span><span class="ot">\hat{\nu}_i^{(m)}\right</span><span class="co">]</span>&amp;=</span>
<span id="cb1-1578"><a href="#cb1-1578"></a>\mathbb{E}\left<span class="co">[</span><span class="ot">\mathbb{E}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right</span><span class="co">]</span></span>
<span id="cb1-1579"><a href="#cb1-1579"></a>=\mathbb{E}\left<span class="co">[</span><span class="ot">\nu_i+\frac{1}{\lambda\Lambda_\beta(t_{m})}\right</span><span class="co">]</span></span>
<span id="cb1-1580"><a href="#cb1-1580"></a>=\mu+\frac{1}{\lambda\Lambda_\beta(t_{m})},</span>
<span id="cb1-1581"><a href="#cb1-1581"></a>\end{aligned}</span>
<span id="cb1-1582"><a href="#cb1-1582"></a>\end{equation} 这意味着偏差为${1}/{(\lambda\Lambda_\beta(t_{m}))}$. 因此, 带有偏差校正的$\nu$的解析形式估计量为 \begin{equation}</span>
<span id="cb1-1583"><a href="#cb1-1583"></a>\label{alphaest}</span>
<span id="cb1-1584"><a href="#cb1-1584"></a>\tilde{\nu}_i^{(m)} =\hat{\nu}_i^{(m)} -</span>
<span id="cb1-1585"><a href="#cb1-1585"></a>\frac{1}{\tilde{\lambda}^{(m)}\Lambda_\beta(t_{m})} =\dfrac{\Lambda_\beta(t_{m})}{y_{i,m}}-</span>
<span id="cb1-1586"><a href="#cb1-1586"></a>\frac{1}{\tilde{\lambda}^{(m)}\Lambda_\beta(t_{m})},~i=1,\dots,n.</span>
<span id="cb1-1587"><a href="#cb1-1587"></a>\end{equation}</span>
<span id="cb1-1588"><a href="#cb1-1588"></a></span>
<span id="cb1-1589"><a href="#cb1-1589"></a>在第二阶段, 通过估计量 $\boldsymbol{\tilde{\nu}}^{(m)} = \left(\tilde{\nu}_1^{(m)}, \dots, \tilde{\nu}_n^{(m)} \right)$ 来估计随机效应\index{随机效应}参数 $\mu$ 和 $\sigma$, 这些参数可被视为 来自 $N(\mu, \sigma^2)$ 的伪样本. $\mu$的估计量可以直接通过 $\boldsymbol{\tilde{\nu}}^{(m)}$ 的均值计算, 具体为 \begin{equation}\label{muest}</span>
<span id="cb1-1590"><a href="#cb1-1590"></a>\tilde{\mu}^{(m)}=\frac{1}{n}\sum_{i=1}^{n}\tilde{\nu}_i^{(m)}.</span>
<span id="cb1-1591"><a href="#cb1-1591"></a>\end{equation} 同时, $\tilde{\nu}_i^{(m)}$的方差近似为 \begin{align}</span>
<span id="cb1-1592"><a href="#cb1-1592"></a>\label{eq:alphavar}</span>
<span id="cb1-1593"><a href="#cb1-1593"></a>\mathbb{Var}\left<span class="co">[</span><span class="ot">\tilde{\nu}_i^{(m)}\right</span><span class="co">]</span> &amp; \approx \mathbb{Var}\left<span class="co">[</span><span class="ot">\hat{\nu}_i^{(m)}\right</span><span class="co">]</span> =</span>
<span id="cb1-1594"><a href="#cb1-1594"></a>\mathbb{Var}\left<span class="co">[</span><span class="ot">\mathbb{E}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right</span><span class="co">]</span>+</span>
<span id="cb1-1595"><a href="#cb1-1595"></a>\mathbb{E}\left<span class="co">[</span><span class="ot">\mathbb{Var}\left[\hat{\nu}_i^{(m)} \mid \nu_i\right]\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-1596"><a href="#cb1-1596"></a>&amp;=\mathbb{Var}\left<span class="co">[</span><span class="ot">\nu_i+\frac{1}{\lambda\Lambda_\beta(t_{m})}\right</span><span class="co">]</span>+\mathbb{E}\left[\dfrac{2}{\lambda^2\Lambda^4_\beta(t_{m})}+</span>
<span id="cb1-1597"><a href="#cb1-1597"></a>\dfrac{\nu_i}{\lambda\Lambda^3_\beta(t_{m})}\right]\nonumber<span class="sc">\\</span></span>
<span id="cb1-1598"><a href="#cb1-1598"></a>&amp;=\sigma^2+\dfrac{2}{\lambda^2\left<span class="co">[</span><span class="ot">\Lambda_\beta(t_{m})\right</span><span class="co">]</span>^4}+</span>
<span id="cb1-1599"><a href="#cb1-1599"></a>\dfrac{\mu}{\lambda\left<span class="co">[</span><span class="ot">\Lambda_\beta(t_{m})\right</span><span class="co">]</span>^3}. </span>
<span id="cb1-1600"><a href="#cb1-1600"></a>\end{align} 基于此, $\sigma$可用以下估计量来估计 \begin{align}</span>
<span id="cb1-1601"><a href="#cb1-1601"></a>\label{sigest}</span>
<span id="cb1-1602"><a href="#cb1-1602"></a>\tilde{\sigma}^{(m)}&amp; = \Bigg<span class="sc">\{</span></span>
<span id="cb1-1603"><a href="#cb1-1603"></a>\dfrac{1}{n-1}\sum_{i=1}^{n}\left(\tilde{\nu}_i^{(m)}-\tilde{\mu}^{(m)}\right)^2 \nonumber<span class="sc">\\</span> </span>
<span id="cb1-1604"><a href="#cb1-1604"></a>&amp;\quad -\frac{2}{<span class="co">[</span><span class="ot">\tilde{\lambda}^{(m)}</span><span class="co">]</span>^2\left<span class="co">[</span><span class="ot">\Lambda_\beta(t_{m})\right</span><span class="co">]</span>^4}-</span>
<span id="cb1-1605"><a href="#cb1-1605"></a>\frac{\tilde{\mu}^{(m)}}{\tilde{\lambda}^{(m)}\left<span class="co">[</span><span class="ot">\Lambda_\beta(t_{m})\right</span><span class="co">]</span>^3}\Bigg<span class="sc">\}</span>^{-1/2}.</span>
<span id="cb1-1606"><a href="#cb1-1606"></a>\end{align}</span>
<span id="cb1-1607"><a href="#cb1-1607"></a></span>
<span id="cb1-1608"><a href="#cb1-1608"></a><span class="fu">#### 递归更新</span></span>
<span id="cb1-1609"><a href="#cb1-1609"></a></span>
<span id="cb1-1610"><a href="#cb1-1610"></a>上节推导的解析形式估计量的一大优势在于: 它们能够利用历史退化数据的汇总(summary)统计量进行高效更新. 为说明这一点, 本小节首先给出了 $\phi_{i,m}$ 的递归表达式. 对于 $i = 1, \dots, n$, 有 \begin{align}\label{eq:phiupdate}</span>
<span id="cb1-1611"><a href="#cb1-1611"></a>\phi_{i,m+1} &amp;= \sum_{j=1}^{m+1} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_{m+1})}</span>
<span id="cb1-1612"><a href="#cb1-1612"></a>{y_{i,m+1}}\nonumber<span class="sc">\\</span></span>
<span id="cb1-1613"><a href="#cb1-1613"></a>&amp;=\phi_{i,m}+\dfrac{y_{i,m+1} \Delta y_{i,m+1}}{y_{i,m}}</span>
<span id="cb1-1614"><a href="#cb1-1614"></a>\left[\frac{\Lambda_{\beta}(t_{m+1})}</span>
<span id="cb1-1615"><a href="#cb1-1615"></a>{y_{i,m+1}}-\frac{\Delta \Lambda_{m+1}}{\Delta y_{i,m+1}}\right]^2,</span>
<span id="cb1-1616"><a href="#cb1-1616"></a>\end{align} 其中 $y_{i,m+1}$和$\Delta y_{i,m+1}$分别为第$i$个系统的新退化测量值和退化增量. 基于递归公式, $\tilde{\lambda}^{(m+1)}$ 可以直接通过式 \eqref{eq:betaest} 更新, 而只需存储 $n$ 个系统的汇总统计量 $\phi_{i,m}$ 和最后一次退化测量值 $y_{i,m}$, 这些统计量可由历史退化数据 $Y_{0:m}$ 计算.\</span>
<span id="cb1-1617"><a href="#cb1-1617"></a>更新后的 $\tilde{\lambda}^{(m+1)}$ 可用于递归更新 $\boldsymbol{\tilde{\nu}}^{(m+1)}$ (参见式 \eqref{alphaest}) . 随后, 利用式 \eqref{muest} 和 \eqref{sigest} 可分别得到 $\tilde{\mu}^{(m+1)}$ 和 $\tilde{\sigma}^{(m+1)}$. 上述的递归过程需要输入 $\beta$. 为了进一步优化, 采用一步估计法得到 $\beta$ 的递推公式, 从而实现 $(\tilde{\lambda}, \tilde{\mu}, \tilde{\sigma}, \tilde{\beta})$ 的高效迭代更新. 类似于在不考虑随机效应\index{随机效应}时的递推公式 \eqref{eq:lambdaupdate}, 在存在随机效应\index{随机效应}时可用以下递推公式. \begin{equation}</span>
<span id="cb1-1618"><a href="#cb1-1618"></a>\label{eq:relambdaupdate}</span>
<span id="cb1-1619"><a href="#cb1-1619"></a>\tilde{\beta}^{(m+1)}=\tilde{\beta}^{(m)}+</span>
<span id="cb1-1620"><a href="#cb1-1620"></a>\frac{1}{n}\widetilde{RV}_{m+1} RS_{m+1}(\Delta \bm y_{m+1},\tilde{\beta}^{(m)}), </span>
<span id="cb1-1621"><a href="#cb1-1621"></a>\end{equation} 其中 $\widetilde{RV}_{m+1}=\left[\sum_{j=1}^{m+1} RI_j(\tilde{\beta}^{(j-1)} \mid \boldsymbol{\tilde{\nu}}^{(j-1)}, \tilde{\lambda}^{(j-1)})\right]^{-1}$ 是Fisher信息逆矩阵的近似, 且 $$RI_j(\tilde{\beta}^{(j)} \mid \boldsymbol{\tilde{\nu}}^{(j)},\tilde{\lambda}^{(j)})=\sum_{i=1}^{n}\left[2\left(\dfrac{ \Delta\tilde{\Lambda}_{j}^{'}}{ \Delta\tilde{\Lambda}_{j}}\right)^2+\dfrac{ \tilde{\nu}_i^{(j)}\tilde{\lambda}^{(j)} (\Delta\tilde{\Lambda}_{j}^{'})^2}{\Delta\tilde{\Lambda}_{j}}\right],$$ 其中$\Delta\tilde{\Lambda}_{j}$和$\Delta\tilde{\Lambda}_{j}^{'}$分别是$\Delta{\Lambda}_{j}$和$\Delta{\Lambda}_{j}^{'}$, 只需将$\beta$替换为$\tilde{\beta}^{(j)}$. 另一方面, $RS_{j}(\Delta \bm y_{j}, \beta)$表示第 $j$ 个退化增量的对数似然函数\index{似然函数}关于 $\beta$ 的导数, 其表达式为 $$RS_{j}(\Delta \bm y_{j},\tilde{\beta}^{(j-1)})=\dfrac{ n\Delta\tilde{\Lambda}_{j}^{'}}{ \Delta\tilde{\Lambda}_{j}}</span>
<span id="cb1-1622"><a href="#cb1-1622"></a> +\sum_{i=1}^{n}\left[\tilde{\nu}_i^{(j)}\tilde{\lambda}^{(j)}\Delta\tilde{\Lambda}_{j}^{'}-\dfrac{\tilde{\lambda}^{(j)}</span>
<span id="cb1-1623"><a href="#cb1-1623"></a> \Delta\tilde{\Lambda}_{j}^{'}\Delta\tilde{\Lambda}_{j}}{y_{ij}}\right]. $$ 容易验证, Fisher 信息逆矩阵的近似 $\widetilde{RV}_m$ 可通过以下公式递归更新. \begin{equation}</span>
<span id="cb1-1624"><a href="#cb1-1624"></a>\label{eq:rvupdate}</span>
<span id="cb1-1625"><a href="#cb1-1625"></a>\widetilde{RV}_{m+1}^{-1}= \widetilde{RV}_{m}^{-1}+RI_{m+1}(\tilde{\beta}^{(m)} \mid \boldsymbol{\tilde{\nu}}^{(m)},</span>
<span id="cb1-1626"><a href="#cb1-1626"></a>          \tilde{\lambda}^{(m)})</span>
<span id="cb1-1627"><a href="#cb1-1627"></a>\end{equation} 并且$RS_{m+1}(\Delta \bm y_{m+1}, \tilde{\beta}^{(m)})$仅依赖于新退化增量$\Delta \bm y_{m+1}$. 因此, 式 \eqref{eq:relambdaupdate} 中的$\tilde{\beta}$具有递归结构, 可实现高效更新.</span>
<span id="cb1-1628"><a href="#cb1-1628"></a></span>
<span id="cb1-1629"><a href="#cb1-1629"></a><span class="fu">#### 在线算法和RUL估计</span></span>
<span id="cb1-1630"><a href="#cb1-1630"></a></span>
<span id="cb1-1631"><a href="#cb1-1631"></a>基于上述递推公式的推导, 可构建一个全面的在线算法. 类似于不考虑随机效应\index{随机效应}的情形, 建议采用至少 $m=3$ 次退化测量来获取参数的初始估计. 算法的具体步骤如下:</span>
<span id="cb1-1632"><a href="#cb1-1632"></a></span>
<span id="cb1-1633"><a href="#cb1-1633"></a><span class="in">```{=latex}</span></span>
<span id="cb1-1634"><a href="#cb1-1634"></a><span class="in">\begin{framed}</span></span>
<span id="cb1-1635"><a href="#cb1-1635"></a><span class="in">{\bf 含随机效应的IG过程在线算法}</span></span>
<span id="cb1-1636"><a href="#cb1-1636"></a><span class="in">    \begin{enumerate}</span></span>
<span id="cb1-1637"><a href="#cb1-1637"></a><span class="in">        \item 使用前三次退化测量进行离线估计. 根据式  \eqref{eq:betaest}、\eqref{alphaest}和 \eqref{inilams},  计算初始参数 $\left(\tilde{\lambda}^{(3)}, \tilde{\nu}_1^{(3)}, \dots, \tilde{\nu}_n^{(3)}, \tilde{\beta}^{(3)}\right)$, 并基于伪样本$\boldsymbol{\tilde{\nu}}^{(3)}$通过式 \eqref{muest} 和 \eqref{sigest} 获得 $\tilde{\mu}^{(3)}$和$\tilde{\sigma}^{(3)}$. 同时计算 Fisher 信息逆矩阵的初始值: $\widetilde{RV}_3=\left[\sum_{j=1}^3 RI_j(\tilde{\beta}^{(3)} \mid \boldsymbol{\tilde{\nu}}^{(3)}, \tilde{\lambda}^{(3)})\right]^{-1}$. </span></span>
<span id="cb1-1638"><a href="#cb1-1638"></a><span class="in">        </span></span>
<span id="cb1-1639"><a href="#cb1-1639"></a><span class="in">  \item 对于第$m$次迭代后 ($m \geq 3$) , 在获得新的观测值 $\bm{y}_{m+1}$ 后, 按照以下步骤更新: a) 利用式 \eqref{eq:phiupdate} 更新 $\phi_{i,m+1}$. b) 根据式 \eqref{eq:betaest}、\eqref{alphaest}、\eqref{muest} 和 \eqref{sigest}, 依次更新 $\tilde{\lambda}^{(m+1)}$、$\boldsymbol{\tilde{\nu}}^{(m+1)}$、$\tilde{\mu}^{(m+1)}$ 和 $\tilde{\sigma}^{(m+1)}$, 其中 $\beta$ 替换为 $\tilde{\beta}^{(m)}$. </span></span>
<span id="cb1-1640"><a href="#cb1-1640"></a><span class="in">        </span></span>
<span id="cb1-1641"><a href="#cb1-1641"></a><span class="in">  \item 使用式 \eqref{eq:rvupdate} 更新$\widetilde{RV}_{m+1}$, 并将$\tilde{\lambda}^{(m+1)}$和$\boldsymbol{\tilde{\nu}}^{(m+1)}$代入式 \eqref{eq:relambdaupdate}, 更新$\beta^{(m+1)}$. </span></span>
<span id="cb1-1642"><a href="#cb1-1642"></a><span class="in">  </span></span>
<span id="cb1-1643"><a href="#cb1-1643"></a><span class="in">  \item 重复步骤 2 和 3, 直到不再有新的观测值被收集. </span></span>
<span id="cb1-1644"><a href="#cb1-1644"></a><span class="in">        </span></span>
<span id="cb1-1645"><a href="#cb1-1645"></a><span class="in">    \end{enumerate}</span></span>
<span id="cb1-1646"><a href="#cb1-1646"></a><span class="in">\end{framed}</span></span>
<span id="cb1-1647"><a href="#cb1-1647"></a><span class="in">```</span></span>
<span id="cb1-1648"><a href="#cb1-1648"></a>在推导$t_m$时刻的RUL分布 $\mathcal{X}_m=\inf\{x: Y(x+t_m)\ge \omega \mid y_{m}&lt;\omega<span class="sc">\}</span>$ 时, 需要在式 \eqref{cdfrul} 中对未知的$\nu$进行积分, 这增加了计算的复杂性. 具体来说, 给定$\nu$和$y_m$的情况下, $\mathcal{X}_m$的CDF为 \begin{equation*}</span>
<span id="cb1-1649"><a href="#cb1-1649"></a>\begin{aligned}</span>
<span id="cb1-1650"><a href="#cb1-1650"></a>F_{\mathcal{X}_m}\left(x \mid \nu, y_m \right)=&amp;</span>
<span id="cb1-1651"><a href="#cb1-1651"></a>\Phi\left({\frac{\sqrt{\lambda}\left<span class="co">[</span><span class="ot">\Delta \Lambda_x-\nu(\omega-y_m)\right</span><span class="co">]</span>}{\sqrt{\omega-y_m}}}\right)<span class="sc">\\</span></span>
<span id="cb1-1652"><a href="#cb1-1652"></a>&amp;-\exp \left(2\nu\lambda \Delta \Lambda_x\right)</span>
<span id="cb1-1653"><a href="#cb1-1653"></a>\Phi\left(-{\frac{\sqrt{\lambda}\left<span class="co">[</span><span class="ot">\Delta \Lambda_x+\nu(\omega-y_m)\right</span><span class="co">]</span>}{\sqrt{\omega-y_m}}}\right),</span>
<span id="cb1-1654"><a href="#cb1-1654"></a>\end{aligned}</span>
<span id="cb1-1655"><a href="#cb1-1655"></a>\end{equation*} 其中 $\Delta \Lambda_x = \Lambda_\beta(x+t_m) - \Lambda_\beta(t_m)$. 通过对$F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)$关于$\nu$的条件分布取期望, 可以得到$\mathcal{X}_m$的边际CDF:\</span>
<span id="cb1-1656"><a href="#cb1-1656"></a>\begin{equation}</span>
<span id="cb1-1657"><a href="#cb1-1657"></a>\label{eq:rerul}</span>
<span id="cb1-1658"><a href="#cb1-1658"></a>F_{\mathcal{X}_m}\left(x \mid  y_m \right) = \int_\nu F_{\mathcal{X}_m}\left(x \mid \nu, y_m \right) \pi(\nu  \mid  y_m) \diff \nu,</span>
<span id="cb1-1659"><a href="#cb1-1659"></a>\end{equation} 其中$\pi(\nu \mid y_m)$表示$\nu$的后验PDF. 利用本节附录 @sec-Append-4C 中$n=1$的似然函数\index{似然函数}和贝叶斯\index{贝叶斯}公式, $\pi(\nu \mid y_m)$ 为 \begin{equation*}</span>
<span id="cb1-1660"><a href="#cb1-1660"></a>\begin{split}</span>
<span id="cb1-1661"><a href="#cb1-1661"></a>\pi(\nu \mid y_m)</span>
<span id="cb1-1662"><a href="#cb1-1662"></a>&amp; \propto \exp \left<span class="sc">\{</span>-\frac{\lambda y_{m}\left(\nu-\Lambda_\beta(t_{m}) / y_{m}\right)^{2}}{2}\right<span class="sc">\}</span></span>
<span id="cb1-1663"><a href="#cb1-1663"></a>\exp\left<span class="sc">\{</span>-\dfrac{\left(\nu-\mu\right)^{2}}{2\sigma^2}\right<span class="sc">\}\\</span></span>
<span id="cb1-1664"><a href="#cb1-1664"></a>&amp;\propto </span>
<span id="cb1-1665"><a href="#cb1-1665"></a>\exp\left<span class="sc">\{</span>-\dfrac{\left(\nu-\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}\right)^{2}}{2\left(\lambda y_m+\sigma^{-2}\right)^{-1}}\right<span class="sc">\}</span>,</span>
<span id="cb1-1666"><a href="#cb1-1666"></a>\end{split}</span>
<span id="cb1-1667"><a href="#cb1-1667"></a>\end{equation*} 化简后可得 $\pi(\nu \mid y_m)$ 为正态分布\index{正态分布} $\mathcal{N}(\mu_m, \tau_m)$, 其中 $$\mu_m=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}, \quad \quad \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1}.$$ 因此, 边际CDF有显式表达式, 如定理 @thm-th2 所示, 其证明见本节附录 @sec-Append-4C.</span>
<span id="cb1-1668"><a href="#cb1-1668"></a></span>
<span id="cb1-1669"><a href="#cb1-1669"></a>::: {#thm-th2}</span>
<span id="cb1-1670"><a href="#cb1-1670"></a>假设当前$t_m$时刻的观测退化测量值为 $0&lt;y_1&lt;\cdots&lt;y_m&lt;\omega$, 且这些值服从带随机效应\index{随机效应}$\nu \sim N(\mu,\sigma\^2)$的IG过程. 则$\mathcal{X}_m$的CDF为 \begin{align}\label{recdfrul}</span>
<span id="cb1-1671"><a href="#cb1-1671"></a>    F_{\mathcal{X}_{m}}(x \mid y_m) &amp; = \Phi\left(\frac{-K_1\mu_m+K_2}{\sqrt{1+K_1^2\tau_m}}\right)-\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber<span class="sc">\\</span></span>
<span id="cb1-1672"><a href="#cb1-1672"></a>    &amp;\ \ \  \times</span>
<span id="cb1-1673"><a href="#cb1-1673"></a>  \Phi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right),</span>
<span id="cb1-1674"><a href="#cb1-1674"></a>\end{align} 其中 \begin{align*}</span>
<span id="cb1-1675"><a href="#cb1-1675"></a>\mu_m&amp;=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}}, \ \ \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1},<span class="sc">\\</span></span>
<span id="cb1-1676"><a href="#cb1-1676"></a>K_1&amp; =\sqrt{\lambda(\omega-y_m)}, K_2=\frac{\sqrt{\lambda}\Delta \Lambda_x}{\sqrt{(\omega-y_m)}},\ \  K_3=2\lambda\Delta \Lambda_x.</span>
<span id="cb1-1677"><a href="#cb1-1677"></a>\end{align*} 此外, $\mathcal{X}_{m}$的PDF为 \begin{align}</span>
<span id="cb1-1678"><a href="#cb1-1678"></a>    \label{pdfrul}</span>
<span id="cb1-1679"><a href="#cb1-1679"></a>    f_{\mathcal{X}_{m}}(x \mid y_m)</span>
<span id="cb1-1680"><a href="#cb1-1680"></a>    &amp;=\varphi\left(\frac{-K_1\mu_m+K_2}{\sqrt{1+K_1^2\tau_m}}\right)\frac{K_2^{'}}{\sqrt{1+K_1^2\tau_m}}\nonumber<span class="sc">\\</span></span>
<span id="cb1-1681"><a href="#cb1-1681"></a>    &amp;\quad -(K_3^{'}\mu_m+K_3^{'}K_3\tau_m)\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber<span class="sc">\\</span></span>
<span id="cb1-1682"><a href="#cb1-1682"></a>    &amp;\quad \times\Phi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right)\nonumber<span class="sc">\\</span></span>
<span id="cb1-1683"><a href="#cb1-1683"></a>    &amp;\quad +\frac{K_2^{'}+K_1K_3^{'}\tau_m}{\sqrt{1+K_1^2\tau_m}}\exp\left(K_3\mu_m+\frac{K_3^2\tau_m}{2}\right)\nonumber<span class="sc">\\</span></span>
<span id="cb1-1684"><a href="#cb1-1684"></a>    &amp;\quad \times \varphi\left(\frac{-K_1\mu_m-K_2-K_1K_3\tau_m}{\sqrt{1+K_1^2\tau_m}}\right),</span>
<span id="cb1-1685"><a href="#cb1-1685"></a>\end{align} 其中$\varphi(\cdot)$为标准正态分布\index{正态分布}的PDF, $K_2^{'}=\frac{\sqrt{\lambda}\Delta \Lambda_x^{'}}{\sqrt{(\omega-y_m)}}$,$K_3^{'}=2\lambda\Delta \Lambda_x^{'}$, $\Delta \Lambda_{x}^{'}$ 为 $\Delta \Lambda_{x}$关于$x$的一阶导数.</span>
<span id="cb1-1686"><a href="#cb1-1686"></a>:::</span>
<span id="cb1-1687"><a href="#cb1-1687"></a></span>
<span id="cb1-1688"><a href="#cb1-1688"></a><span class="fu">### 模拟实验 {#sec-simulation}</span></span>
<span id="cb1-1689"><a href="#cb1-1689"></a></span>
<span id="cb1-1692"><a href="#cb1-1692"></a><span class="in">```{r}</span></span>
<span id="cb1-1693"><a href="#cb1-1693"></a><span class="co">#| label: fig-fig:olialp1</span></span>
<span id="cb1-1694"><a href="#cb1-1694"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1695"><a href="#cb1-1695"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1696"><a href="#cb1-1696"></a><span class="co">#| out.width: '100%'</span></span>
<span id="cb1-1697"><a href="#cb1-1697"></a><span class="co">#| fig.cap: '$\nu$、$\lambda$ 和 $\beta$ 参数的估计性能. '</span></span>
<span id="cb1-1698"><a href="#cb1-1698"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/olipars.pdf"</span>)</span>
<span id="cb1-1699"><a href="#cb1-1699"></a><span class="in">```</span></span>
<span id="cb1-1700"><a href="#cb1-1700"></a></span>
<span id="cb1-1701"><a href="#cb1-1701"></a>本节通过模拟研究评估所提出在线算法的性能. 参数设置: $$\nu = 3、\lambda = 10, \Lambda_{\beta}(t) = t^2 (\beta = 2).$$ 试验中随机选取 $n = 15$ 个系统, 采用等间隔测量, 测量时间在区间$<span class="co">[</span><span class="ot">0.1, 10</span><span class="co">]</span>$内, 测量间隔为 0.1. 因此, 每个系统的测量次数 $m = 100$.\</span>
<span id="cb1-1702"><a href="#cb1-1702"></a>采用第 @sec-igsimple 节提出的在线算法分析数据, 并记录每个时间点的估计值. 该过程重复 10000 次, 总计算耗时 3.27 分钟 (运行环境: 2.7 GHz Intel Core i5, 8 GB RAM) . 通过10000次重复实验, 计算每个测量时间点 $t_j$ 处不同参数的RB和RMSE. 图 @fig-fig:olialp1 展示参数 $\nu$、$\lambda$ 和 $\beta$ 的估计结果. 结果表明, 估计值在几次迭代后迅速稳定, 并最终收敛于真实值.</span>
<span id="cb1-1703"><a href="#cb1-1703"></a></span>
<span id="cb1-1704"><a href="#cb1-1704"></a>接下来, 进一步考虑带随机效应\index{随机效应}的 IG 过程, 假设 $\nu \sim N(3, 0.8^2)$, 即 $\mu = 3$ 且 $\sigma = 0.8$. 为说明偏差校正估计量的效果, 本小节对比了带偏差校正和不带偏差校正的在线算法. 本次模拟重复进行 10000 次, 总计算时间为 5.45 分钟. 图 @fig-fig:rmsecomp 展示了不同参数在不同测量时间点的RMSE, 其中黑色曲线代表带偏差校正的在线算法, 红色曲线代表不带偏差校正的算法. 结果表明, 采用偏差校正后, 估计精度显著提升. 此外, 即使在收集到少量退化测量后, 基于偏差校正的在线算法的估计值也能快速收敛至真实值.</span>
<span id="cb1-1705"><a href="#cb1-1705"></a></span>
<span id="cb1-1706"><a href="#cb1-1706"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb1-1707"><a href="#cb1-1707"></a></span>
<span id="cb1-1708"><a href="#cb1-1708"></a><span class="co">&lt;!-- #| label: fig-fig:rbcomp --&gt;</span></span>
<span id="cb1-1709"><a href="#cb1-1709"></a></span>
<span id="cb1-1710"><a href="#cb1-1710"></a><span class="co">&lt;!-- #| fig.align: 'center' --&gt;</span></span>
<span id="cb1-1711"><a href="#cb1-1711"></a></span>
<span id="cb1-1712"><a href="#cb1-1712"></a><span class="co">&lt;!-- #| echo: FALSE --&gt;</span></span>
<span id="cb1-1713"><a href="#cb1-1713"></a></span>
<span id="cb1-1714"><a href="#cb1-1714"></a><span class="co">&lt;!-- #| out.width: '90%' --&gt;</span></span>
<span id="cb1-1715"><a href="#cb1-1715"></a></span>
<span id="cb1-1716"><a href="#cb1-1716"></a><span class="co">&lt;!-- #| fig.cap: '基于含随机效应的 IG 模型, 不同方法下参数估计的RB.' --&gt;</span></span>
<span id="cb1-1717"><a href="#cb1-1717"></a></span>
<span id="cb1-1718"><a href="#cb1-1718"></a><span class="co">&lt;!-- knitr::include_graphics("figures/IG/NRL2024/rbcomp.pdf") --&gt;</span></span>
<span id="cb1-1719"><a href="#cb1-1719"></a></span>
<span id="cb1-1720"><a href="#cb1-1720"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb1-1721"><a href="#cb1-1721"></a></span>
<span id="cb1-1724"><a href="#cb1-1724"></a><span class="in">```{r}</span></span>
<span id="cb1-1725"><a href="#cb1-1725"></a><span class="co">#| label: fig-fig:rmsecomp</span></span>
<span id="cb1-1726"><a href="#cb1-1726"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1727"><a href="#cb1-1727"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1728"><a href="#cb1-1728"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1729"><a href="#cb1-1729"></a><span class="co">#| fig.cap: '基于含随机效应的 IG 模型, 不同方法下参数估计的RMSE.'</span></span>
<span id="cb1-1730"><a href="#cb1-1730"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/msecomp.pdf"</span>)</span>
<span id="cb1-1731"><a href="#cb1-1731"></a><span class="in">```</span></span>
<span id="cb1-1732"><a href="#cb1-1732"></a></span>
<span id="cb1-1733"><a href="#cb1-1733"></a>本节还评估了基于含随机效应\index{随机效应}的 IG 过程的RUL预测\index{RUL预测}性能. 不失一般性, 选取第一个系统的 RUL 作为研究对象, 并将失效阈值设定为 $\omega = 60$. 在每次模拟中, 持续监测系统的退化水平直至达到失效阈值, 从而在每个检测时间点获得真实的 RUL. 基于 10000 次重复实验, 图 @fig-fig:rmsrul 展示了第一个系统 RUL 预测的RB和RMSE. 结果表明, 所提出的 RUL 预测方法在仅收集到少量测量值后就能达到较高的预测精度. 后续章节将结合真实数据集进一步分析 RUL 预测性能.</span>
<span id="cb1-1734"><a href="#cb1-1734"></a></span>
<span id="cb1-1737"><a href="#cb1-1737"></a><span class="in">```{r}</span></span>
<span id="cb1-1738"><a href="#cb1-1738"></a><span class="co">#| label: fig-fig:rmsrul</span></span>
<span id="cb1-1739"><a href="#cb1-1739"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1740"><a href="#cb1-1740"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1741"><a href="#cb1-1741"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1742"><a href="#cb1-1742"></a><span class="co">#| fig.cap: '第一个系统RUL预测的RB和RMSE. '</span></span>
<span id="cb1-1743"><a href="#cb1-1743"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/rulsimu.pdf"</span>)</span>
<span id="cb1-1744"><a href="#cb1-1744"></a><span class="in">```</span></span>
<span id="cb1-1745"><a href="#cb1-1745"></a></span>
<span id="cb1-1746"><a href="#cb1-1746"></a><span class="fu">### 实例分析 {#sec-case}</span></span>
<span id="cb1-1747"><a href="#cb1-1747"></a></span>
<span id="cb1-1748"><a href="#cb1-1748"></a>本节通过两个真实的退化数据集, 验证了所提出方法的有效性. 这些数据表明, IG 过程是一个合适的模型, 且在线算法可以高效地估计模型参数并预测 RUL.</span>
<span id="cb1-1749"><a href="#cb1-1749"></a></span>
<span id="cb1-1750"><a href="#cb1-1750"></a><span class="fu">#### 集成电路器件退化数据</span></span>
<span id="cb1-1751"><a href="#cb1-1751"></a></span>
<span id="cb1-1752"><a href="#cb1-1752"></a>本研究选取了在 $195^\circ$C 下收集的集成电路器件退化数据作为分析对象 (详见图 @fig-fig:deviceB). 在该温度下, 共测试了 $n=12$ 个器件, 测量次数 $m=16$, 测量时间点均匀分布在 0 至 2000 小时的区间内. 选取非线性时间函数为 $\Lambda_\beta(t) = t^\beta$. 图 @fig-fig:d1fit 展示了退化数据以及拟合的带随机效应\index{随机效应}和无随机效应\index{随机效应}的 IG 过程模型. 从图中可以看出, 这两种模型均能够较好地刻画退化路径特征.</span>
<span id="cb1-1753"><a href="#cb1-1753"></a></span>
<span id="cb1-1756"><a href="#cb1-1756"></a><span class="in">```{r}</span></span>
<span id="cb1-1757"><a href="#cb1-1757"></a><span class="co">#| label: fig-fig:d1fit</span></span>
<span id="cb1-1758"><a href="#cb1-1758"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1759"><a href="#cb1-1759"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1760"><a href="#cb1-1760"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1761"><a href="#cb1-1761"></a><span class="co">#| fig.cap: '基于集成电路器件的退化数据的不同模型拟合情况. '</span></span>
<span id="cb1-1762"><a href="#cb1-1762"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/d1fit.pdf"</span>)</span>
<span id="cb1-1763"><a href="#cb1-1763"></a><span class="in">```</span></span>
<span id="cb1-1764"><a href="#cb1-1764"></a></span>
<span id="cb1-1765"><a href="#cb1-1765"></a>随后, 运用所提出的在线算法计算参数估计值. 图 @fig-fig:d1evol1 和图 @fig-fig:d1evol2 展示了在两种 IG 模型下参数的递归更新估计值. 可看出, 参数估计普遍在0.75 千小时左右后达到稳定. 为了对比两种 IG 模型, 计算了每个时间点下模型的 AIC\index{AIC} 值, 其中 AIC\index{AIC} 值较低的模型更优. 此外, 将无随机效应\index{随机效应}的 IG 模型作为原假设, 含随机效应\index{随机效应}的 IG 模型作为备择假设, 运用似然比检验, 同时计算每个时间下的检验 $p$ 值. 图 @fig-fig:d1aic 展示每个时间点的 AIC\index{AIC} 值和 $p$ 值.\</span>
<span id="cb1-1766"><a href="#cb1-1766"></a>结果显示, 在所有测量时间点, 含随机效应\index{随机效应}的 IG 模型具有更低的 AIC\index{AIC} 值, 表明其拟合效果更佳. 同时, $p$ 值均小于设定的显著性水平 0.05, 说明拒绝原假设. 这些发现表明, 带随机效应\index{随机效应}的 IG 模型更适用于分析该退化数据集.</span>
<span id="cb1-1767"><a href="#cb1-1767"></a></span>
<span id="cb1-1770"><a href="#cb1-1770"></a><span class="in">```{r}</span></span>
<span id="cb1-1771"><a href="#cb1-1771"></a><span class="co">#| label: fig-fig:d1evol1</span></span>
<span id="cb1-1772"><a href="#cb1-1772"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1773"><a href="#cb1-1773"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1774"><a href="#cb1-1774"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1775"><a href="#cb1-1775"></a><span class="co">#| fig.cap: '基于集成电路器件退化数据, 无随机效应的 IG 过程的参数估计演变轨迹. '</span></span>
<span id="cb1-1776"><a href="#cb1-1776"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/d1evol1.pdf"</span>)</span>
<span id="cb1-1777"><a href="#cb1-1777"></a><span class="in">```</span></span>
<span id="cb1-1778"><a href="#cb1-1778"></a></span>
<span id="cb1-1781"><a href="#cb1-1781"></a><span class="in">```{r}</span></span>
<span id="cb1-1782"><a href="#cb1-1782"></a><span class="co">#| label: fig-fig:d1evol2</span></span>
<span id="cb1-1783"><a href="#cb1-1783"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1784"><a href="#cb1-1784"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1785"><a href="#cb1-1785"></a><span class="co">#| out.width: '95%'</span></span>
<span id="cb1-1786"><a href="#cb1-1786"></a><span class="co">#| fig.cap: '基于集成电路器件退化数据, 含随机效应的IG过程的参数估计值演变轨迹. '</span></span>
<span id="cb1-1787"><a href="#cb1-1787"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/d1evol2.pdf"</span>)</span>
<span id="cb1-1788"><a href="#cb1-1788"></a><span class="in">```</span></span>
<span id="cb1-1789"><a href="#cb1-1789"></a></span>
<span id="cb1-1792"><a href="#cb1-1792"></a><span class="in">```{r}</span></span>
<span id="cb1-1793"><a href="#cb1-1793"></a><span class="co">#| label: fig-fig:d1aic</span></span>
<span id="cb1-1794"><a href="#cb1-1794"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1795"><a href="#cb1-1795"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1796"><a href="#cb1-1796"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1797"><a href="#cb1-1797"></a><span class="co">#| fig.cap: '基于集成电路器件退化数据, 两个IG模型的AIC值和$p$值.'</span></span>
<span id="cb1-1798"><a href="#cb1-1798"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/d1aic.pdf"</span>)</span>
<span id="cb1-1799"><a href="#cb1-1799"></a><span class="in">```</span></span>
<span id="cb1-1800"><a href="#cb1-1800"></a></span>
<span id="cb1-1801"><a href="#cb1-1801"></a><span class="fu">#### 锂离子电池容量退化数据</span></span>
<span id="cb1-1802"><a href="#cb1-1802"></a></span>
<span id="cb1-1803"><a href="#cb1-1803"></a><span class="co">&lt;!-- 锂离子电池已广泛应用于电动汽车、电网储能和手机等商业产品中. 锂离子电池的RUL预测在技术发展加速、制造过程优化以及预测与健康管理中发挥着至关重要的作用. 在过去的十年中, 有关锂离子电池的大量研究文献集中于RUL预测; 有关一些最近的研究, 请参见[@ma2019remaining; @xue2020remaining; @cheng2021remaining; @xu2021remaining; @li2022end]. RUL预测通常基于充放电实验中获得的容量退化数据. 图 @fig-fig:capdeg1 展示了17个电池的退化数据, 容量每500次充放电循环进行一次测量. 该数据提取自一个包含多种实验设置下的锂离子电池退化数据的大型数据集[@severson2019data].  --&gt;</span></span>
<span id="cb1-1804"><a href="#cb1-1804"></a></span>
<span id="cb1-1805"><a href="#cb1-1805"></a>以图 @fig-fig:capdeg1 中的 17 个电池退化数据为例, 首先使用所提出的两种 IG 模型对数据进行拟合. 设定 $\Lambda_\beta(t) = t^\beta$, 使用所提出的算法获得参数的在线估计, 结果如图 @fig-fig:evol1 和图 @fig-fig:evol2 所示. 可发现参数估计在 100 次循环后趋于稳定. 图 @fig-fig:aicpval 显示了 AIC\index{AIC} 值和似然比检验的 $p$ 值. 结果表明, 在显著性水平 0.05 下, 带随机效应\index{随机效应}的 IG 过程更适合描述该数据. 随后, 通过 Shapiro-Wilk 检验评估了随机效应\index{随机效应}服从正态分布\index{正态分布}的假设. 如图 @fig-fig:normality 所示, 除前几个时间点外, 几乎所有正态性检验的 $p$ 值均大于 0.05, 这表明随机效应\index{随机效应} $\nu$ 的正态性假设是合理的.</span>
<span id="cb1-1806"><a href="#cb1-1806"></a></span>
<span id="cb1-1809"><a href="#cb1-1809"></a><span class="in">```{r}</span></span>
<span id="cb1-1810"><a href="#cb1-1810"></a><span class="co">#| label: fig-fig:evol1</span></span>
<span id="cb1-1811"><a href="#cb1-1811"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1812"><a href="#cb1-1812"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1813"><a href="#cb1-1813"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1814"><a href="#cb1-1814"></a><span class="co">#| fig.cap: '基于锂离子电池退化数据, 无随机效应的IG过程的参数估计演变轨迹. '</span></span>
<span id="cb1-1815"><a href="#cb1-1815"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/evol1.pdf"</span>)</span>
<span id="cb1-1816"><a href="#cb1-1816"></a><span class="in">```</span></span>
<span id="cb1-1817"><a href="#cb1-1817"></a></span>
<span id="cb1-1820"><a href="#cb1-1820"></a><span class="in">```{r}</span></span>
<span id="cb1-1821"><a href="#cb1-1821"></a><span class="co">#| label: fig-fig:evol2</span></span>
<span id="cb1-1822"><a href="#cb1-1822"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1823"><a href="#cb1-1823"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1824"><a href="#cb1-1824"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1825"><a href="#cb1-1825"></a><span class="co">#| fig.cap: '基于锂离子电池退化数据, 带有随机效应的IG过程的参数估计值演变轨迹. '</span></span>
<span id="cb1-1826"><a href="#cb1-1826"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/evol2.pdf"</span>)</span>
<span id="cb1-1827"><a href="#cb1-1827"></a><span class="in">```</span></span>
<span id="cb1-1828"><a href="#cb1-1828"></a></span>
<span id="cb1-1831"><a href="#cb1-1831"></a><span class="in">```{r}</span></span>
<span id="cb1-1832"><a href="#cb1-1832"></a><span class="co">#| label: fig-fig:aicpval</span></span>
<span id="cb1-1833"><a href="#cb1-1833"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1834"><a href="#cb1-1834"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1835"><a href="#cb1-1835"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1836"><a href="#cb1-1836"></a><span class="co">#| fig.cap: '基于锂离子电池退化数据, 两个IG模型的AIC值和$p$值. '</span></span>
<span id="cb1-1837"><a href="#cb1-1837"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/aicpval.pdf"</span>)</span>
<span id="cb1-1838"><a href="#cb1-1838"></a><span class="in">```</span></span>
<span id="cb1-1839"><a href="#cb1-1839"></a></span>
<span id="cb1-1842"><a href="#cb1-1842"></a><span class="in">```{r}</span></span>
<span id="cb1-1843"><a href="#cb1-1843"></a><span class="co">#| label: fig-fig:normality</span></span>
<span id="cb1-1844"><a href="#cb1-1844"></a><span class="co">#| fig.align: 'center'</span></span>
<span id="cb1-1845"><a href="#cb1-1845"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb1-1846"><a href="#cb1-1846"></a><span class="co">#| out.width: '90%'</span></span>
<span id="cb1-1847"><a href="#cb1-1847"></a><span class="co">#| fig.cap: '基于锂离子电池退化数据的随机效应正态性检验 $p$ 值. '</span></span>
<span id="cb1-1848"><a href="#cb1-1848"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figures/IG/NRL2024/normality.pdf"</span>)</span>
<span id="cb1-1849"><a href="#cb1-1849"></a><span class="in">```</span></span>
<span id="cb1-1850"><a href="#cb1-1850"></a></span>
<span id="cb1-1851"><a href="#cb1-1851"></a>为了进一步展示随机效应\index{随机效应}模型在 RUL 预测中的优势, 本小节以#6锂离子电池 为例, 设定失效阈值为 $\omega = 17$. 基于此阈值, #6 电池 的寿命\index{寿命}为 731 个充放电循环, 因此在每个循环中都可以获得其真实 RUL. 采用第 @sec-igre 节提出的算法, 在 251、326、401、476 和 551 个循环时对#6 电池 的 RUL 进行预测. 图 @fig-rulpred 展示了基于两种 IG 模型的 RUL 预测均值和 PDF. 结果表明, 带随机效应\index{随机效应}的IG 模型提供了更准确的预测, 且随着退化数据量的增加, 预测精度不断提高. 图 @fig-rulall 展示了所有 125 个测量时间点的 RUL 预测均值及近似 95% 置信区间\index{置信区间}. 这些置信区间\index{置信区间}利用 $F_{\mathcal{X}_{m}}(x \mid y_m)$ 的 2.5% 和 97.5% 分位数和参数的估计值来构造, 见公式 \eqref{recdfrul}. 结果显示, 基于随机效应\index{随机效应}模型的置信区间\index{置信区间}中, 125 个真实 RUL 点中有 7 个超出置信区间\index{置信区间}, 对应的频率覆盖概率为 $(125-7)/125 = 94.4\%$, 接近名义水平 95%. 相比之下,基于无随机效应\index{随机效应}的 IG 模型所构造的置信区间\index{置信区间}明显更宽, 仅有 2 个真实 RUL 点超出区间, 对应覆盖概率为 98.4%. 尽管覆盖概率较高, 但较宽的置信区间\index{置信区间}反映了更大的预测不确定性. 综合来看, 随机效应\index{随机效应}模型能更有效地利用退化数据, 为 RUL 预测提供更高的精度和更具解释性的信息.</span>
<span id="cb1-1852"><a href="#cb1-1852"></a></span>
<span id="cb1-1853"><a href="#cb1-1853"></a>::: {#fig-fig:rulpred2 layout-ncol="2"}</span>
<span id="cb1-1854"><a href="#cb1-1854"></a><span class="al">![RUL 预测均值和 PDF](figures/IG/NRL2024/rulpred.pdf)</span>{#fig-rulpred width="95%"}</span>
<span id="cb1-1855"><a href="#cb1-1855"></a></span>
<span id="cb1-1856"><a href="#cb1-1856"></a><span class="al">![RUL 近似 95% 置信区间](figures/IG/NRL2024/rulall.pdf)</span>{#fig-rulall width="95%"}</span>
<span id="cb1-1857"><a href="#cb1-1857"></a></span>
<span id="cb1-1858"><a href="#cb1-1858"></a>基于锂离子电池退化数据, 两种IG模型的锂离子电池#6的RUL预测结果.</span>
<span id="cb1-1859"><a href="#cb1-1859"></a>:::</span>
<span id="cb1-1860"><a href="#cb1-1860"></a></span>
<span id="cb1-1861"><a href="#cb1-1861"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> 总结 {#sec-conclusion} --&gt;</span></span>
<span id="cb1-1862"><a href="#cb1-1862"></a></span>
<span id="cb1-1863"><a href="#cb1-1863"></a><span class="co">&lt;!-- 本节系统研究了基于非线性IG过程的在线RUL预测. 我们开发了一种复合算法, 通过迭代估计时间尺度变换参数$\beta$及其他参数. 具体而言, 在假设$\beta$已知的情况下, 我们基于闭式估计量推导出其他模型参数的递归公式, 并将其作为使用单步近似法来递归估计$\beta$的输入. 利用递归更新的参数估计, 我们推导出RUL的公式, 并且该公式也可以通过递归方式获得. 此外, 我们将所提出的在线算法扩展至IG随机效应模型. 特别地, 我们提出了带偏差校正的闭式估计量, 从而能够准确且递归地估计IG随机效应模型中的参数. 模拟研究和实际应用表明, 我们提出的算法非常高效, 模型参数的估计值通常在几次迭代内就能收敛到真实值. 更重要的是, RUL也能得到高效且可靠的预测, 从而为后续的在线决策提供支持.  --&gt;</span></span>
<span id="cb1-1864"><a href="#cb1-1864"></a></span>
<span id="cb1-1865"><a href="#cb1-1865"></a><span class="co">&lt;!-- 有几个潜在的研究主题值得进一步探讨. 首先, 在本研究中, 漂移参数$\nu$假设为每个系统的常数. 然而, 当系统在动态环境中运行时, 随着退化的进展, 漂移参数可能是时间依赖的[@zhai2017rul]. 因此, 研究如何将提出的框架扩展到自适应IG过程模型是一个有趣的问题. 此外, 通过考虑不同的实际场景, IG过程在退化建模中还有其他变体. 本研究应为研究这些更复杂模型提供基础. 最后, 伽马过程\index{伽马过程}作为IG过程的替代, 也被广泛用于建模单调退化数据, 但基于伽马过程\index{伽马过程}的RUL预测在文献中尚未得到充分研究. 将所提出的方法扩展到伽马过程\index{伽马过程}并非易事, 因为伽马过程\index{伽马过程}的闭式ML估计量 (ML估计量) 不存在, 这使得推导递归公式变得困难. 虽然[@paroissin2017online]为平稳伽马过程\index{伽马过程}提出了矩估计量, 但已知这些估计量在有限样本和大样本中均效率不高. 同时, [@ye2017closed]提出了伽马分布的类似闭式ML估计量, 可能可以扩展到平稳伽马过程\index{伽马过程}. 然而, 当考虑时间尺度变换和随机效应时, 扩展这些估计量的过程将极为艰难. 因此, 我们认为需要付出相当大的努力来开发针对伽马过程\index{伽马过程}的有效在线算法.  --&gt;</span></span>
<span id="cb1-1866"><a href="#cb1-1866"></a></span>
<span id="cb1-1867"><a href="#cb1-1867"></a><span class="fu">### 附录 {#sec-Append-4C}</span></span>
<span id="cb1-1868"><a href="#cb1-1868"></a></span>
<span id="cb1-1869"><a href="#cb1-1869"></a><span class="co">&lt;!-- {.unnumbered} --&gt;</span></span>
<span id="cb1-1870"><a href="#cb1-1870"></a></span>
<span id="cb1-1871"><a href="#cb1-1871"></a><span class="fu">#### 当 $\beta$ 已知时, $\nu$ 和 $\lambda$ 的 MLE {.unnumbered}</span></span>
<span id="cb1-1872"><a href="#cb1-1872"></a></span>
<span id="cb1-1873"><a href="#cb1-1873"></a>在式 \eqref{iglike} 中, 似然函数\index{似然函数}可写为 \begin{align}\label{nlk}</span>
<span id="cb1-1874"><a href="#cb1-1874"></a> L(\bm\theta \mid \bm Y_{0:m}) &amp;=C_0 \lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j} \exp \left<span class="sc">\{</span>-\frac{\lambda}{2}\left<span class="co">[</span><span class="ot">\sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_{j}^{2}}{\Delta y_{ij}}-\frac{n^2\Lambda_\beta(t_{m})^{2}}{\sum_{i=1}^{n}y_{im}}\right</span><span class="co">]</span>\right<span class="sc">\}</span> \nonumber<span class="sc">\\</span></span>
<span id="cb1-1875"><a href="#cb1-1875"></a> &amp;\quad\times\exp \left<span class="sc">\{</span>-\dfrac{\lambda\sum_{i=1}^{n}y_{im}}{2}</span>
<span id="cb1-1876"><a href="#cb1-1876"></a> \left(\nu-\dfrac{n\Lambda_\beta(t_{m})}{ \sum_{i=1}^{n}y_{im}}\right)^{2}</span>
<span id="cb1-1877"><a href="#cb1-1877"></a>\right<span class="sc">\}</span>. </span>
<span id="cb1-1878"><a href="#cb1-1878"></a>\end{align} 在 \eqref{nlk} 中, 第一行是 $\lambda$ 的函数 (记为 $G(\lambda)$) , 而第二行是一个指数函数, 当 $\nu=n\Lambda_\beta(t_{m})/\sum_{i=1}^{n}y_{im}$ 时达到最大值. 另一方面, 当 $$\lambda=\dfrac{nm}{ \sum_{i=1}^{n}\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{ij}}-\frac{n^2\Lambda^2_\beta(t_m)} {\sum_{i=1}^{n}y_{im}}}$$ 时, $G(\lambda)$ 达到最大值. 此时, $\nu$ 和 $\lambda$ 的MLE如 \eqref{eq:mle} 所示.</span>
<span id="cb1-1879"><a href="#cb1-1879"></a></span>
<span id="cb1-1880"><a href="#cb1-1880"></a><span class="fu">#### $\beta$ 的 Fisher 信息的推导 {.unnumbered}</span></span>
<span id="cb1-1881"><a href="#cb1-1881"></a></span>
<span id="cb1-1882"><a href="#cb1-1882"></a>给定第 $j$ 个增量 $\Delta \mathcal{y}_j = (\Delta y_{i,j},\dots,\Delta y_{n,j})$ 时, $\beta$ 的对数似然函数\index{似然函数}为$l_j(\beta)$. 对 $l_j(\beta)$关于$\beta$求一阶导数, 可得 \begin{equation*}</span>
<span id="cb1-1883"><a href="#cb1-1883"></a>\dfrac{\partial  l_j(\beta \mid \Delta\bm y_j) }{\partial \beta}</span>
<span id="cb1-1884"><a href="#cb1-1884"></a>=\dfrac{ n\Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}+n\nu\lambda \Delta\Lambda_{j}^{'}-\sum_{i=1}^{n}\dfrac{\lambda  \Delta\Lambda_{j}^{'} \Delta\Lambda_{j}}{\Delta y_{i,j}}, </span>
<span id="cb1-1885"><a href="#cb1-1885"></a>\end{equation*} 对 $l_j(\beta)$关于$\beta$求二阶导数, 可得 \begin{align*}</span>
<span id="cb1-1886"><a href="#cb1-1886"></a>\dfrac{\partial^2 l_j(\beta \mid \Delta \bm y_j) }{\partial \beta^2}</span>
<span id="cb1-1887"><a href="#cb1-1887"></a>&amp;=n\left[\dfrac{ \Delta\Lambda_{j}^{''}}{ \Delta\Lambda_{j}}-</span>
<span id="cb1-1888"><a href="#cb1-1888"></a>\left(\dfrac{ \Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2</span>
<span id="cb1-1889"><a href="#cb1-1889"></a>+\nu\lambda \Delta\Lambda_{j}^{''}\right]<span class="sc">\\</span></span>
<span id="cb1-1890"><a href="#cb1-1890"></a>&amp;\quad -\sum_{i=1}^{n}\left<span class="co">[</span><span class="ot">\dfrac{\lambda  \Delta\Lambda_{j}^{''} \Delta\Lambda_{j}}{\Delta y_{i,j}}+\dfrac{\lambda  (\Delta\Lambda_{j}^{'})^2}{\Delta y_{i,j}}\right</span><span class="co">]</span>,</span>
<span id="cb1-1891"><a href="#cb1-1891"></a>\end{align*} 其中 $\Delta\Lambda_{j}^{'}$ 和 $\Delta\Lambda_{j}^{''}$ 分别是 $\Delta\Lambda_{j}$ 关于 $\beta$ 的一阶和二阶导数. 由于 $\Delta y_{i,j}\sim \textrm{\textrm{IG}}(\Delta\Lambda_j/\nu,\lambda\Delta\Lambda_j^2)$, 可以计算出 $1/\Delta y_{i,j}$ 的期望为 $$E\left<span class="co">[</span><span class="ot">\dfrac{1}{\Delta y_{i,j}}\right</span><span class="co">]</span>=\dfrac{\nu}{\Delta\Lambda_j}+</span>
<span id="cb1-1892"><a href="#cb1-1892"></a>\dfrac{1}{\lambda\Delta\Lambda_j^2}.$$ 因此, 给定观测值 $\Delta y_{i,j}$, $\beta$ 的 Fisher 信息为\</span>
<span id="cb1-1893"><a href="#cb1-1893"></a>\begin{equation*}</span>
<span id="cb1-1894"><a href="#cb1-1894"></a>I_j(\beta \mid \nu,\lambda)=-E\left<span class="co">[</span><span class="ot">\dfrac{\partial^2  l_j(\beta \mid \Delta \bm y_j) }{\partial \beta^2}\right</span><span class="co">]</span>=n\left[</span>
<span id="cb1-1895"><a href="#cb1-1895"></a>\dfrac{\nu\lambda (\Delta\Lambda_{j}^{'})^2}{\Delta\Lambda_{j}}+</span>
<span id="cb1-1896"><a href="#cb1-1896"></a>2\left(\dfrac{ \Delta\Lambda_{j}^{'}}{ \Delta\Lambda_{j}}\right)^2\right]. </span>
<span id="cb1-1897"><a href="#cb1-1897"></a>\end{equation*}</span>
<span id="cb1-1898"><a href="#cb1-1898"></a></span>
<span id="cb1-1899"><a href="#cb1-1899"></a><span class="fu">#### 参数的可识别性和离线估计 {.unnumbered}</span></span>
<span id="cb1-1900"><a href="#cb1-1900"></a></span>
<span id="cb1-1901"><a href="#cb1-1901"></a>需要证明当 $n$ 个系统仅被测量一次时, 参数是不可识别的. 给定 $\mathcal{y}_1 = (y_{1,1},\dots,y_{n,1})$, $\bm\theta$ 的对数似然函数\index{似然函数}为\</span>
<span id="cb1-1902"><a href="#cb1-1902"></a>$$l(\boldsymbol{\theta}  \mid  \mathcal{y}_1)=C+\dfrac{n}{2}\log\lambda+n\log\Lambda_\beta(t_1)-\lambda\sum_{i=1}^{n}\dfrac{1}{2y_{i,1}}(\nu y_{i,1}-\Lambda_\beta(t_1))^2. $$ 根据式 \eqref{eq:mle}, 在给定 $\beta$ 的情况下, $\nu$ 和 $\lambda$ 的MLE分别为 $$\dfrac{n\Lambda_\beta(t_1)}{\sum_{i=1}^{n}y_{i1}} \quad \text{和} \quad</span>
<span id="cb1-1903"><a href="#cb1-1903"></a>\dfrac{n}{\sum_{i=1}^{n}\frac{1}{y_{i1}}(\nu y_{i1}-\Lambda_\beta(t_1))^2}. $$ 将这两个估计量代入 $l(\boldsymbol{\theta} \mid \mathcal{y}_1)$ 中, 得到 $\beta$ 的轮廓似然函数\index{似然函数}为 $$pl_1(\beta)=C_1-n\log\Lambda_\beta(t_1)+n\log\Lambda_\beta(t_1)-n/2=C_1-n/2,$$ 其中 $C_1$ 是一个与 $\beta$ 无关的常数. 因此, $\beta$ 是不可识别的, 因为 $pl_1(\beta)$ 对于任意的 $\beta$ 值均为常数. 这个结果是比较直观的, 因为一条曲线的形状仅通过两个点无法确定. 因此, 为了获得参数的MLE并运用在线算法, 至少需要两次测量. 在实际应用中, 通过前三个测量时间点 $t_1$、$t_2$ 和 $t_3$ 收集的观测数据, $\nu$ 和 $\lambda$ 的MLE分别为 $$\hat{\nu}^{(3)}=\dfrac{n\Lambda_{\hat{\beta}^{(3)}}(t_3)}</span>
<span id="cb1-1904"><a href="#cb1-1904"></a>{\sum_{i=1}^{n}y_{i,3}}, ~\quad</span>
<span id="cb1-1905"><a href="#cb1-1905"></a>\hat{\lambda}^{(3)}=\dfrac{3n}{ \sum_{i=1}^{n}\sum_{j=1}^{3} \dfrac{\Delta\tilde{\Lambda}_j^2}{\Delta y_{i,j}}-\dfrac{n^2\Lambda^2_{\hat{\beta}^{(3)}}(t_3)}</span>
<span id="cb1-1906"><a href="#cb1-1906"></a>    {\sum_{i=1}^{n}y_{i,3}}},$$ 其中 $\Delta \tilde{\Lambda}_j$ 是$\Delta \Lambda_j$ 的估计, $\beta$ 被替换为$\hat{\beta}^{(3)}$, 而 $\hat{\beta}^{(3)}$ 可通过最大化以下轮廓似然函数\index{似然函数}得到. $$pl_3(\beta)=C_3-\frac{3n}{2}\log\left[\sum_{i=1}^{n}\sum_{j=1}^{3} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{n^2\Lambda^2_\beta(t_3)}</span>
<span id="cb1-1907"><a href="#cb1-1907"></a>{\sum_{i=1}^{n}y_{i,3}}\right]+</span>
<span id="cb1-1908"><a href="#cb1-1908"></a>n\sum_{j=1}^{3}\log\Delta\Lambda_j,$$ 其中 $C_3$ 是与 $\beta$ 无关的常数.</span>
<span id="cb1-1909"><a href="#cb1-1909"></a></span>
<span id="cb1-1910"><a href="#cb1-1910"></a>对于含随机效应\index{随机效应}的 IG 模型, $\bm\Theta=(\lambda,\nu_1,\dots,\nu_n,\beta)$ 的似然函数\index{似然函数}为 \begin{align}\label{nlkre}</span>
<span id="cb1-1911"><a href="#cb1-1911"></a>    L(\bm\Theta \mid \bm Y_{0:m}) &amp;=C_0 \lambda^{nm/2}\prod_{j=1}^{m}\Delta\Lambda^n_{j} \exp \left<span class="sc">\{</span>-\frac{\lambda}{2}\sum_{i=1}^{n}\left<span class="co">[</span><span class="ot">\sum_{j=1}^{m} \frac{\Delta\Lambda_{j}^{2}}{\Delta y_{ij}}-\frac{n^2\Lambda_\beta(t_{m})^{2}}{\sum_{i=1}^{n}y_{im}}\right</span><span class="co">]</span>\right<span class="sc">\}</span> \nonumber<span class="sc">\\</span></span>
<span id="cb1-1912"><a href="#cb1-1912"></a>    &amp;\quad\times\exp\left<span class="sc">\{</span>-\dfrac{\lambda}{2}\sum_{i=1}^{n}y_{im}\left(\nu_i-\dfrac{\Lambda_\beta(t_{m})}{ y_{im}}\right)^{2} \right<span class="sc">\}</span>. </span>
<span id="cb1-1913"><a href="#cb1-1913"></a>  \end{align} 此时可以得到\eqref{eq:remle} 中的 $\lambda$ 和 $\nu_i$ 的MLE. 再将 $\lambda$ 和 $\nu_i$ 替换为MLE, 可得 $\beta$ 的轮廓似然函数\index{似然函数}, 即, \begin{equation}\label{inilams}</span>
<span id="cb1-1914"><a href="#cb1-1914"></a>    pl^\ast_m(\beta)=C_4-\frac{mn}{2}\log\sum_{i=1}^{n}\left[\sum_{j=1}^{m} \frac{\Delta\Lambda_j^2}{\Delta y_{i,j}}-\frac{\Lambda^2_\beta(t_m)}</span>
<span id="cb1-1915"><a href="#cb1-1915"></a>    {y_{i,m}}\right]+</span>
<span id="cb1-1916"><a href="#cb1-1916"></a>    n\sum_{j=1}^{m}\log\Delta\Lambda_j,</span>
<span id="cb1-1917"><a href="#cb1-1917"></a>\end{equation} 其中 $C_4$ 是与 $\beta$ 无关的常数. $\beta$ (即 $m=3$) 的初始估计量可通过最大化轮廓似然函数\index{似然函数} $pl^\ast_m(\beta)$ 进行数值求解.</span>
<span id="cb1-1918"><a href="#cb1-1918"></a></span>
<span id="cb1-1919"><a href="#cb1-1919"></a><span class="fu">#### 理论 @thm-NRL2024-th1 证明 {.unnumbered}</span></span>
<span id="cb1-1920"><a href="#cb1-1920"></a></span>
<span id="cb1-1921"><a href="#cb1-1921"></a>为了方便表示, 做以下定义. \begin{align*}</span>
<span id="cb1-1922"><a href="#cb1-1922"></a>\ell^{(j)}(\boldsymbol{\theta}; \Delta y_j)\equiv \frac{1}{2}\log\left(\frac{\lambda}{2\pi}\right) + \log(\Delta\Lambda_j) - \frac{3}{2}\log(\Delta y_{j}) - \frac{\lambda}{2\Delta y_j}(\nu \Delta y_j - \Delta \Lambda_j)^2,</span>
<span id="cb1-1923"><a href="#cb1-1923"></a>\end{align*} 并且$\ell^m(\boldsymbol{\theta}; \Delta Y) \equiv \sum_{j=1}^m \ell^{(j)}(\boldsymbol{\theta}; \Delta y_j)$ 表示单系统的对数似然函数\index{似然函数}.</span>
<span id="cb1-1924"><a href="#cb1-1924"></a></span>
<span id="cb1-1925"><a href="#cb1-1925"></a>令 $\mathcal{I}^{(j)} = P\ddot{\ell}^{(j)}(\nu_0, \lambda_0, \beta_0)$ 表示基于第$j$次检测时间点的Fisher信息矩阵, 它可以表示为矩阵块的形式 \begin{align*}</span>
<span id="cb1-1926"><a href="#cb1-1926"></a>\mathcal{I}^{(j)} \equiv \left(\begin{array}{ccccc}</span>
<span id="cb1-1927"><a href="#cb1-1927"></a>\mathcal{I}_{(\nu, \lambda)}^{(j)} &amp;\mathcal{I}_{(\nu, \lambda),\beta}^{(j)}<span class="sc">\\</span></span>
<span id="cb1-1928"><a href="#cb1-1928"></a>\mathcal{I}_{\beta, (\nu, \lambda)}^{(j)} &amp;\mathcal{I}_{\beta}^{(j)}</span>
<span id="cb1-1929"><a href="#cb1-1929"></a>\end{array}\right),\quad \mathcal{I}_{(\nu, \lambda)}^{(j)}\in\mathbb{R}^{2\times 2}, \quad \mathcal{I}_{(\nu, \lambda),\beta}^{(j)} = \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)} \in\mathbb{R}^{2\times 1},</span>
<span id="cb1-1930"><a href="#cb1-1930"></a>\end{align*} 其中下标 $(\nu, \lambda)$ 对应于 $(\nu, \lambda)$ 的维度, 而下标 $\beta$ 对应于 $\beta$ 的维度. 令 $\mathcal{I}^{m} = \sum_{j=1}^m \mathcal{I}^{(j)}$, 并以类似的方式定义 $\mathcal{I}{(\nu, \lambda)}^{m}$、$\mathcal{I}{(\nu, \lambda),\beta}^{m}$ 和 $\mathcal{I}_{\beta}^{m}$.</span>
<span id="cb1-1931"><a href="#cb1-1931"></a></span>
<span id="cb1-1932"><a href="#cb1-1932"></a>首先, 通过经典的大样本理论, 可以确立初始MLE $\nu^{(3)}$、$\lambda^{(3)}$ 和 $\beta^{(3)}$ 的一致性. 目标是在 $\nu^{(m)}$、$\lambda^{(m)}$ 和 $\beta^{(m)}$ 的一致性基础上, 证明对于每个 $m\geq 3$, $\nu^{(m+1)}$、$\lambda^{(m+1)}$ 和 $\beta^{(m+1)}$ 也具有一致性. 利用大数定律, 可以得到以下结论. \begin{align*}</span>
<span id="cb1-1933"><a href="#cb1-1933"></a>n^{-1}\sum_{i=1}^n y_{i, m} &amp;\to_P \frac{\Lambda_{\beta_0}(t_{m})}{\nu},<span class="sc">\\</span></span>
<span id="cb1-1934"><a href="#cb1-1934"></a>\quad n^{-1}\sum_{i=1}^n \frac{1}{\Delta y_{i, m+1}} &amp; \to_P \frac{\nu_0}{\Delta\Lambda_{\beta_0}(t_{m+1})} + \frac{1}{\lambda_0 \Delta\Lambda_{\beta_0}(t_{m+1})^2}.</span>
<span id="cb1-1935"><a href="#cb1-1935"></a>\end{align*} 如果 $\beta^{(m)}\to_P \beta_0$, 由于 $\Lambda_\beta(t)$ 关于 $\beta$ 的可微性, 利用连续映射定理可以得到 \begin{align*}</span>
<span id="cb1-1936"><a href="#cb1-1936"></a>\Lambda_{\beta^{(m)}}(t_m) &amp; \to_P \Lambda_{\beta_0}(t_m),<span class="sc">\\</span></span>
<span id="cb1-1937"><a href="#cb1-1937"></a>\Delta\Lambda_{\beta^{(m)}}(t_{m+1}) &amp;\to_P \Delta\Lambda_{\beta_0}(t_{m+1}).</span>
<span id="cb1-1938"><a href="#cb1-1938"></a>\end{align*} 再次使用连续映射定理, 得到 $$\nu^{(m+1)} = \Lambda_{\beta^{(m)}}(t_m)/(n^{-1}\sum_{i=1}^n y_{i, m}) \to_P \nu_0$$ \begin{align*}</span>
<span id="cb1-1939"><a href="#cb1-1939"></a>\lambda^{(m+1)} &amp;= (m+1)\Bigg<span class="sc">\{</span>m/\hat{\lambda}^{(m)} + \left<span class="co">[</span><span class="ot">\hat{\nu}^{(m)}\right</span><span class="co">]</span>^2 n^{-1}\sum_{i=1}^n y_{i, m}<span class="sc">\\</span></span>
<span id="cb1-1940"><a href="#cb1-1940"></a>&amp; \quad - \left<span class="co">[</span><span class="ot">\hat{\nu}^{(m+1)}\right</span><span class="co">]</span>^2 n^{-1}\sum_{i=1}^n y_{i, m+1} + \Delta\Lambda^2_{\hat{\beta}^{(m)}}(t_{m+1}) n^{-1}\sum_{i=1}^n/\Delta y_{i, m+1}\Bigg<span class="sc">\}</span>^{-1}<span class="sc">\\</span></span>
<span id="cb1-1941"><a href="#cb1-1941"></a>&amp;\to_P (m+1)\Big<span class="sc">\{</span>m/\lambda_0 - \nu n^{-1}\Delta\Lambda_{\beta_0}(t_{m+1}) <span class="sc">\\</span></span>
<span id="cb1-1942"><a href="#cb1-1942"></a>&amp; \quad + \Delta\Lambda^2_{\beta_0}(t_{m+1}) \left<span class="co">[</span><span class="ot">\nu_0/\Delta\Lambda^2_{\beta_0}(t_{m+1}) + (\lambda_0\Delta\Lambda^2_{\beta_0}(t_{m+1}))^{-1}\right</span><span class="co">]</span>\Big<span class="sc">\}</span>^{-1} = \lambda_0,</span>
<span id="cb1-1943"><a href="#cb1-1943"></a>\end{align*} 其中, 后一项的弱收敛依赖于 $\nu^{(m+1)}$ 的一致性. 要利用一致的 $\nu^{(m+1)}$ 和 $\lambda^{(m+1)}$ 去证明 $\beta^{(m+1)}$ 的一致性, 需要以下引理.</span>
<span id="cb1-1944"><a href="#cb1-1944"></a></span>
<span id="cb1-1945"><a href="#cb1-1945"></a>::: {#lem-Donsker-class}</span>
<span id="cb1-1946"><a href="#cb1-1946"></a>若 $\Delta \Lambda_j$ 关于 $\beta$ 在 $\beta_0$ 的邻域内是二阶连续可微的, 存在 $\delta &gt; 0$ 使得函数类 $\mathcal{F}_\delta$ 是 Donsker 类, 其中 \begin{align*}</span>
<span id="cb1-1947"><a href="#cb1-1947"></a>\mathcal{F}_\delta &amp;\equiv \left<span class="sc">\{</span>\dot{\ell}^m(\boldsymbol{\theta}; \Delta Y) - \dot{\ell}^m(\boldsymbol{\theta}_0; \Delta Y): \Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert \leq \delta\right<span class="sc">\}</span>,</span>
<span id="cb1-1948"><a href="#cb1-1948"></a>\end{align*} 且 $\dot{\ell}^m(\boldsymbol{\theta}; \Delta Y)$ 是 $\ell^m(\boldsymbol{\theta};\Delta Y)$ 关于 $(\nu, \lambda, \beta)$ 的导数. 对于每一个满足 $\tilde{\boldsymbol{\theta}}_n\to_P \boldsymbol{\theta}_0$ 的序列 ${\tilde{\boldsymbol{\theta}}n}{n=1}^\infty$ 有 \begin{align*}</span>
<span id="cb1-1949"><a href="#cb1-1949"></a>\mathbb{G}_n \left<span class="co">[</span><span class="ot">\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right</span><span class="co">]</span> \equiv \sqrt{n}(\mathbb{P}_n - P)\left<span class="co">[</span><span class="ot">\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right</span><span class="co">]</span> = o_P(1).</span>
<span id="cb1-1950"><a href="#cb1-1950"></a>\end{align*}</span>
<span id="cb1-1951"><a href="#cb1-1951"></a>:::</span>
<span id="cb1-1952"><a href="#cb1-1952"></a></span>
<span id="cb1-1953"><a href="#cb1-1953"></a>::: proof</span>
<span id="cb1-1954"><a href="#cb1-1954"></a>对于任意 $M &gt; 0$, 存在 $\delta &gt; 0$, 使得当 $\Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta$ 时, $\Delta\Lambda_j$、$\Delta\Lambda_j'$ 和 $\Delta\Lambda_j''$ 都是上有界且远离零的. 因此可以得到 \begin{align*}</span>
<span id="cb1-1955"><a href="#cb1-1955"></a>\left\Vert\ddot{\ell}^m(\boldsymbol{\theta}; \Delta Y)\right\Vert \lesssim (\sum_{j=1}^m \Delta y_j)\bigvee (\sum_{j=1}^m \Delta 1/y_j),</span>
<span id="cb1-1956"><a href="#cb1-1956"></a>\end{align*} 其中右侧是可积函数. 由于二阶导数在 $\Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta$ 上一致有界, 存在一个函数 $h(y)$ 使得以下的 Lipschitz 条件成立. \begin{align*}</span>
<span id="cb1-1957"><a href="#cb1-1957"></a>\Vert \dot{\ell}^m(\boldsymbol{\theta}_1; \Delta Y) - \dot{\ell}^m(\boldsymbol{\theta}_2; \Delta Y)\Vert \leq h(y)\Vert \boldsymbol{\theta}_1 - \boldsymbol{\theta}_2\Vert, \ \text{任意}\ \boldsymbol{\theta}_1, \boldsymbol{\theta}_2.</span>
<span id="cb1-1958"><a href="#cb1-1958"></a>\end{align*} 因此, 类似于 [@van2000asymptotic] 中的例子 19.7, $\mathcal{F}_\delta$ 的包围数满足 \begin{align*}</span>
<span id="cb1-1959"><a href="#cb1-1959"></a>N_{<span class="co">[</span><span class="ot">\ </span><span class="co">]</span>}(\epsilon\Vert h\Vert_{L_2(P_0)}, \mathcal{F}_{\delta}, L_2(P_0)) \lesssim (\delta/\epsilon)^3, \ \forall  0&lt;\epsilon&lt;\delta.</span>
<span id="cb1-1960"><a href="#cb1-1960"></a>\end{align*} 因此, 包围积分是有限的, 这意味着 $\mathcal{F}_\delta$ 是 Donsker 类.</span>
<span id="cb1-1961"><a href="#cb1-1961"></a></span>
<span id="cb1-1962"><a href="#cb1-1962"></a>接下来证明 $\mathbb{G}_n \left[\dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right] = o_{P}(1)$. 类似于 $\ddot{\ell}^m(\boldsymbol{\theta}; \Delta Y)$ 的构造, 可以证明函数类 $\mathcal{F}_\delta$ 被平方可积函数所界定. 因此, 通过对 $\tilde{\boldsymbol{\theta}}_n$ 的几乎处处收敛子序列进行讨论, 使用支配收敛定理, 得到 \begin{align*}</span>
<span id="cb1-1963"><a href="#cb1-1963"></a>P_0 \left<span class="co">[</span><span class="ot"> \dot{\ell}^m(\tilde{\boldsymbol{\theta}}_n) - \dot{\ell}^m(\boldsymbol{\theta}_0)\right</span><span class="co">]</span>^2 \to_P 0.</span>
<span id="cb1-1964"><a href="#cb1-1964"></a>\end{align*} 因此, @lem-Donsker-class 引理的第二部分可以通过 <span class="sc">\[</span>@van2000asymptotic<span class="sc">\]</span> 中的定理 19.24 推导得出.</span>
<span id="cb1-1965"><a href="#cb1-1965"></a>:::</span>
<span id="cb1-1966"><a href="#cb1-1966"></a></span>
<span id="cb1-1967"><a href="#cb1-1967"></a>此时可利用 $(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})$ 依概率收敛于 $(\nu_0, \lambda_0)$ 来证明 $\hat{\beta}^{(m+1)}$ 的一致性. 根据在线算法, 估计量 $\hat{\beta}^{(m+1)}$ 表达式如下. \begin{align*}</span>
<span id="cb1-1968"><a href="#cb1-1968"></a>\hat{\beta}^{(m+1)} = \hat{\beta}_n^{(m)} + \widetilde{V}_{m+1}^{-1} n\mathbb{P}_n \dot{\ell}^{(m+1)}(\hat{\nu}_n^{(m+1)}, \hat{\lambda}_n^{(m+1)}, \hat{\beta}_n^{(m)}).</span>
<span id="cb1-1969"><a href="#cb1-1969"></a>\end{align*} 根据假设, 第一项 $\hat{\beta}^{(m)}$ 以概率收敛到 $\beta_0$. 类似于引理 @lem-Donsker-class 的证明, 序列 $${\ell^{(m+1)}(\boldsymbol{\theta}) - \ell^{(m+1)}(\boldsymbol{\theta}_0): \Vert\boldsymbol{\theta} - \boldsymbol{\theta}_0\Vert\leq \delta}$$ 形成一个 Donsker 类, 这意味着: \begin{align*}</span>
<span id="cb1-1970"><a href="#cb1-1970"></a>\mathbb{P}_n \dot{\ell}^{(m+1)}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) = o_P(n^{-1/2}).</span>
<span id="cb1-1971"><a href="#cb1-1971"></a>\end{align*} 由于每个 $I_j$ 都是关于 $\boldsymbol{\theta}$ 的连续函数, 利用连续映射定理得到 $$n\widetilde{V}_{m+1}(\hat{\nu}_n^{(m+1)}, \hat{\lambda}_n^{(m+1)}, \hat{\beta}_n^{(m)}) = O_P(1).</span>
<span id="cb1-1972"><a href="#cb1-1972"></a>$$ 因此, 第二项是 $O_P(n^{-1/2}) = o_P(1)$. 综上所述, $\hat{\beta}_n^{(m+1)} \to_P \beta_0$.</span>
<span id="cb1-1973"><a href="#cb1-1973"></a></span>
<span id="cb1-1974"><a href="#cb1-1974"></a>接下来, 通过利用 $(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(j)})$ 在 $j = 3, \cdots, m$ 时的收敛速度, 建立 $(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)})$ 的渐近正态性. 为此, 提供一个关于 $(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)})$ 渐近分布的递推关系, 并建立 $$\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m+1)}) - (\nu_0, \lambda_0, \beta_0)\right</span><span class="co">]</span></span>
<span id="cb1-1975"><a href="#cb1-1975"></a>$$ 的弱收敛结果. $(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(3)})$ 的 $\sqrt{n}$-一致性可通过 MLE 估计的 $\sqrt{n}$-一致性来保证, 后者可通过经典统计方法得到验证. 在此基础上, 通过数学归纳法假设, 对于每个 $j = 3, \cdots, m$, 估计量 $(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(j)})$ 均满足 $\sqrt{n}$-一致性. 对于 $(\nu, \lambda)$ 的估计量, 因为 $(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})$最大化了 $\mathbb{P}_n \dot{\ell}^{m+1}(\nu, \lambda, \hat{\beta}^{(m)})$, 对于固定的 $\hat{\beta}^{(m)}$ 的值有 \begin{align*}</span>
<span id="cb1-1976"><a href="#cb1-1976"></a>\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, &amp; \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})<span class="sc">\\</span></span>
<span id="cb1-1977"><a href="#cb1-1977"></a>&amp; \equiv \mathbb{P}_n \left.\frac{\partial}{\partial(\nu, \lambda)}\right|_{(\nu, \lambda)=(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)})}\ell^{m+1}(\nu, \lambda, \hat{\beta}^{(m)}) = 0.</span>
<span id="cb1-1978"><a href="#cb1-1978"></a>\end{align*} 通过向量 $(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})$的一致性, 并使用引理 @lem-Donsker-class 得到 \begin{align*}</span>
<span id="cb1-1979"><a href="#cb1-1979"></a>\mathbb{G}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) = \mathbb{G}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0) + o_P(1).</span>
<span id="cb1-1980"><a href="#cb1-1980"></a>\end{align*} 由 $P\dot{\ell}^{m+1}(\nu_0, \lambda_0, \beta_0) = 0$ 得 \begin{align*}</span>
<span id="cb1-1981"><a href="#cb1-1981"></a>\sqrt{n}\Big[P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, &amp;\hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)})</span>
<span id="cb1-1982"><a href="#cb1-1982"></a><span class="ss">- </span>P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)\Big]<span class="sc">\\</span> </span>
<span id="cb1-1983"><a href="#cb1-1983"></a>&amp; = -\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0) + o_P(1)</span>
<span id="cb1-1984"><a href="#cb1-1984"></a>\end{align*} 对于每一个 $j$, 得分函数的期望可以写为 \begin{align*}</span>
<span id="cb1-1985"><a href="#cb1-1985"></a>P\dot{\ell}_{(\nu, \lambda)}^{(j)}(\boldsymbol{\theta})</span>
<span id="cb1-1986"><a href="#cb1-1986"></a>=\left(\begin{array}{cccc}- \lambda( \Delta \Lambda_{j;0} - \Delta \Lambda_j)<span class="sc">\\</span></span>
<span id="cb1-1987"><a href="#cb1-1987"></a>\frac{\Delta \Lambda_{j;0}^2 - \Delta \Lambda_{j}^2 - \nu\lambda(\Delta \Lambda_{j;0} - \Delta \Lambda_{j})^2}{2\lambda\Delta \Lambda_{j;0}^2}</span>
<span id="cb1-1988"><a href="#cb1-1988"></a>\end{array}\right),</span>
<span id="cb1-1989"><a href="#cb1-1989"></a>\end{align*} 函数 $\boldsymbol{\theta}\mapsto P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\boldsymbol{\theta})$是连续可微的. 因此有 \begin{align*}</span>
<span id="cb1-1990"><a href="#cb1-1990"></a>&amp;\sqrt{n}\left<span class="co">[</span><span class="ot">P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}) - P\dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-1991"><a href="#cb1-1991"></a>&amp;= -\mathcal{I}_{(\nu, \lambda)}^{m+1}\sqrt{n}\left[(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right] - \mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)} - \beta_0) <span class="sc">\\</span></span>
<span id="cb1-1992"><a href="#cb1-1992"></a>&amp;\quad + O_P\left(\sqrt{n}\Vert(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\Vert^2 + \sqrt{n}\Vert \hat{\beta}^{(m)} - \beta_0\Vert^2\right).</span>
<span id="cb1-1993"><a href="#cb1-1993"></a>\end{align*} 使用 $\hat{\beta}^{(m)}$ 的 $\sqrt{n}$ 一致性和 $\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)$, 得到 $$</span>
<span id="cb1-1994"><a href="#cb1-1994"></a>(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0) = O_p(n^{-1/2}),</span>
<span id="cb1-1995"><a href="#cb1-1995"></a>$$ 这进一步意味着如下近似关系. \begin{align}</span>
<span id="cb1-1996"><a href="#cb1-1996"></a>&amp;\mathcal{I}_{(\nu, \lambda)}^{m+1}\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-1997"><a href="#cb1-1997"></a>&amp;= \sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{m+1}(\nu_0, \lambda_0, \beta_0)</span>
<span id="cb1-1998"><a href="#cb1-1998"></a><span class="ss">- </span>\mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)} - \beta_0) + o_P(1).\label{eq: iteration for alpha+beta}</span>
<span id="cb1-1999"><a href="#cb1-1999"></a>\end{align} 对于 $\beta$ 的估计, 迭代算法由以下公式给出 \begin{align*}</span>
<span id="cb1-2000"><a href="#cb1-2000"></a>\hat{\beta}^{(m+1)} = \hat{\beta}^{(m)} + \widetilde{V}_{m+1} n\mathbb{P}_n \dot{\ell}_\beta^{(m+1)}(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}, \hat{\beta}^{(m)}).</span>
<span id="cb1-2001"><a href="#cb1-2001"></a>\end{align*} 假设以下方程对 $m\geq 4$ 都成立 \begin{align}\label{eq: iteration assymption for lambda_(m+1)}</span>
<span id="cb1-2002"><a href="#cb1-2002"></a>\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m)}) + \sum_{j=4}^m \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)}) = o_P(n^{-1/2}).</span>
<span id="cb1-2003"><a href="#cb1-2003"></a>\end{align} 实际上, 根据MLE估计的定义, 有 $\mathbb{P}n \dot{\ell}\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(3)}) = o_P(n^{-1/2})$. 接着, 将通过递归关系证明该等式在 $m=4$ 时成立, 并假设当方程 \eqref{eq: iteration assymption for lambda_(m+1)} 对 $m$ 成立时, 它对 $m+1$ 也成立. 再将利用递推关系证明该等式在 $m=4$ 的情况下成立, 并在此基础上, 假设方程 \eqref{eq: iteration assymption for lambda_(m+1)} 对 $m$ 成立, 则其对 $m+1$ 也成立. 若方程 \eqref{eq: iteration assymption for lambda_(m+1)} 成立, 可以推导出以下结论. \begin{align}</span>
<span id="cb1-2004"><a href="#cb1-2004"></a>&amp;n\widetilde{V}_{m+1}^{-1}(\hat{\beta}^{(m+1)}-\beta_0) - n\widetilde{V}_{m+1}^{-1}(\hat{\beta}^{(m)} - \beta_0)\nonumber<span class="sc">\\</span></span>
<span id="cb1-2005"><a href="#cb1-2005"></a>&amp;= \mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)}) + o_P(n^{-1/2}).\label{eq: expansion for lambda_(m+1)}</span>
<span id="cb1-2006"><a href="#cb1-2006"></a>\end{align} 根据 $(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})$ 的一致性以及引理 @lem-Donsker-class , 可得以下结论. \begin{align*}</span>
<span id="cb1-2007"><a href="#cb1-2007"></a>\mathbb{G}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})</span>
<span id="cb1-2008"><a href="#cb1-2008"></a><span class="ss">- </span>\mathbb{G}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0) = o_P(1),\ \text{任意}\ 1\leq j\leq m+1,</span>
<span id="cb1-2009"><a href="#cb1-2009"></a>\end{align*} 这意味着$\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})$ 可以表示为 \begin{align*}</span>
<span id="cb1-2010"><a href="#cb1-2010"></a>\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m)})</span>
<span id="cb1-2011"><a href="#cb1-2011"></a>&amp;= \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0)</span>
<span id="cb1-2012"><a href="#cb1-2012"></a>-\mathcal{I}_{\beta}^{(j)}(\hat{\beta}^{(m)} - \beta_0)<span class="sc">\\</span></span>
<span id="cb1-2013"><a href="#cb1-2013"></a>&amp; \quad - \mathcal{I}_{(\nu,\lambda),\beta}^{(j)}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> + O_P(n^{-1/2}).</span>
<span id="cb1-2014"><a href="#cb1-2014"></a>\end{align*} 因此, \eqref{eq: expansion for lambda_(m+1)} 的右侧可以表示为 \begin{align*}</span>
<span id="cb1-2015"><a href="#cb1-2015"></a>&amp;\mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0)</span>
<span id="cb1-2016"><a href="#cb1-2016"></a><span class="ss">- </span>\mathcal{I}_{\beta}^{m+1}(\hat{\beta}^{(m)} - \beta_0) + \sum_{j=4}^{m+1} \mathcal{I}_{\beta,(\nu, \lambda)}^{(j)}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-2017"><a href="#cb1-2017"></a>&amp;+ \mathcal{I}_{\beta, (\nu, \lambda)}^{3}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> + o_P(n^{-1/2}).</span>
<span id="cb1-2018"><a href="#cb1-2018"></a>\end{align*} \normalsize</span>
<span id="cb1-2019"><a href="#cb1-2019"></a></span>
<span id="cb1-2020"><a href="#cb1-2020"></a>借助 $n\widetilde{V}{m+1}^{-1}\to_P \mathcal{I}{\beta}^{m+1}$ 这一事实, 可以得到以下近似关系. \begin{align}</span>
<span id="cb1-2021"><a href="#cb1-2021"></a>\mathcal{I}_{\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m+1)}-\beta_0)</span>
<span id="cb1-2022"><a href="#cb1-2022"></a>&amp;= \sqrt{n}\mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0)</span>
<span id="cb1-2023"><a href="#cb1-2023"></a><span class="ss">- </span>\mathcal{I}_{\beta, (\nu, \lambda)}^{3}\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span>\nonumber<span class="sc">\\</span></span>
<span id="cb1-2024"><a href="#cb1-2024"></a>&amp;\quad - \sum_{j=4}^{m+1} \mathcal{I}_{\beta,(\nu, \lambda)}^{(j)}\sqrt{n}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right] + o_P(1).\label{eq: asymptotic form for lambda_(m+1)}</span>
<span id="cb1-2025"><a href="#cb1-2025"></a>\end{align} 因此证得 $\hat{\beta}^{(m+1)}-\beta_0 = O_P(n^{-1/2})$.</span>
<span id="cb1-2026"><a href="#cb1-2026"></a></span>
<span id="cb1-2027"><a href="#cb1-2027"></a>接下来证明渐近性质可以从 $m$ 传递到 $m+1$, 即 \begin{align*}</span>
<span id="cb1-2028"><a href="#cb1-2028"></a>\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m+1)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)}) = o_P(n^{-1/2}).</span>
<span id="cb1-2029"><a href="#cb1-2029"></a>\end{align*} 再次使用引理 @lem-Donsker-class , 对于每一个 $j$ 有 \begin{align*}</span>
<span id="cb1-2030"><a href="#cb1-2030"></a>&amp;\mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)}) <span class="sc">\\</span></span>
<span id="cb1-2031"><a href="#cb1-2031"></a>&amp;= \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\boldsymbol{\theta}_0) - \mathcal{I}_{\beta}^{(j)}\left[\hat{\beta}^{(m+1)} - \beta_0\right] - \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> + o_P(n^{-1/2}).<span class="sc">\\</span></span>
<span id="cb1-2032"><a href="#cb1-2032"></a>&amp;\mathbb{P}_n \dot{\ell}_\beta^3(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}, \hat{\beta}^{(m+1)}) + \sum_{j=4}^{m+1} \mathbb{P}_n \dot{\ell}_\beta^{(j)}(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}, \hat{\beta}^{(m+1)})<span class="sc">\\</span></span>
<span id="cb1-2033"><a href="#cb1-2033"></a>&amp;= \mathbb{P}_n \dot{\ell}_\beta^{m+1}(\boldsymbol{\theta}_0) -\mathcal{I}_{\beta}^{m+1}\left(\hat{\beta}^{(m+1)} - \beta_0\right) -\mathcal{I}_{\beta, (\nu, \lambda)}^{3}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-2034"><a href="#cb1-2034"></a>&amp;- \sum_{j=4}^{m+1}\mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> + o_P(n^{-1/2}).</span>
<span id="cb1-2035"><a href="#cb1-2035"></a>\end{align*} \normalsize 再利用式 \eqref{eq: asymptotic form for lambda_(m+1)} 将 $\hat{\beta}n^{(m+1)} - \beta_0$ 进行替换, 可以得到右侧等于 $o_P(n^{-1/2})$, 从而证明了式 \eqref{eq: iteration assymption for lambda_(m+1)} 对于 $m+1$ 成立. 因此, 公式 \eqref{eq: iteration assymption for lambda_(m+1)} 对于每个 $m \geq 4$ 都成立.</span>
<span id="cb1-2036"><a href="#cb1-2036"></a></span>
<span id="cb1-2037"><a href="#cb1-2037"></a>最后, 需推导 $\Sigma_{m+1}$ 的渐近协方差. 对于 $m=3$, 利用MLE的渐近性质, 可以得到 \begin{align*}</span>
<span id="cb1-2038"><a href="#cb1-2038"></a>\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span></span>
<span id="cb1-2039"><a href="#cb1-2039"></a>&amp;= (\tilde{\mathcal{I}}_{(\nu, \lambda)}^3)^{-1} \left(I_2, -\mathcal{I}_{(\nu, \lambda), \beta}^3\left(\mathcal{I}_{\beta}^3\right)^{-1} \right)\sqrt{n}\mathbb{P}\dot{\ell}^3(\boldsymbol{\theta}_0) + o_P(1),<span class="sc">\\</span></span>
<span id="cb1-2040"><a href="#cb1-2040"></a>\sqrt{n}\left(\hat{\beta}^{(3)} - \beta_0\right)</span>
<span id="cb1-2041"><a href="#cb1-2041"></a>&amp;=  \left(-(\tilde{\mathcal{I}}_\beta^3)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}, (\tilde{\mathcal{I}}_\beta^3)^{-1} \right)\sqrt{n}\mathbb{P}\dot{\ell}^3(\boldsymbol{\theta}_0) + o_P(1),</span>
<span id="cb1-2042"><a href="#cb1-2042"></a>\end{align*} 其中$I_2$ 是 2×2 的单位矩阵, $\tilde{\mathcal{I}}_{(\nu, \lambda)}^3$和 $\tilde{\mathcal{I}}_{\beta}^3$ 分别表示有效信息矩阵, 其定义如下. \begin{align*}</span>
<span id="cb1-2043"><a href="#cb1-2043"></a>\tilde{\mathcal{I}}_{(\nu, \lambda)}^3 &amp;= \mathcal{I}_{(\nu, \lambda)}^3 - \mathcal{I}_{(\nu, \lambda), \beta}^3\left(\mathcal{I}_{\beta}^3\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3,<span class="sc">\\</span></span>
<span id="cb1-2044"><a href="#cb1-2044"></a>\tilde{\mathcal{I}}_{\beta}^3 &amp;= \mathcal{I}_{\beta}^3 - \mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}\mathcal{I}_{(\nu, \lambda), \beta}^3.</span>
<span id="cb1-2045"><a href="#cb1-2045"></a>\end{align*} 对于 $m=4$, 根据递推关系有 \begin{align*}</span>
<span id="cb1-2046"><a href="#cb1-2046"></a>\sqrt{n}&amp;\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(4)}, \hat{\lambda}^{(4)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-2047"><a href="#cb1-2047"></a>&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left[\sqrt{n}\mathbb{P}_n \dot{\ell}_{(\nu, \lambda)}^{4}(\boldsymbol{\theta}_0)</span>
<span id="cb1-2048"><a href="#cb1-2048"></a><span class="ss">- </span>\mathcal{I}_{(\nu, \lambda),\beta}^{4}\sqrt{n}(\hat{\beta}^{(3)} - \beta_0)\right]+ o_P(1) <span class="sc">\\</span></span>
<span id="cb1-2049"><a href="#cb1-2049"></a>&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left(I_2 + \mathcal{I}_{(\nu, \lambda),\beta}^{4}\left(\tilde{\mathcal{I}}_{\beta}^3\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3\left(\mathcal{I}_{(\nu, \lambda)}^3\right)^{-1}, \mathcal{I}_{(\nu, \lambda),\beta}^{4}\left(\tilde{\mathcal{I}}_{\beta}^3\right)^{-1}\right)\sqrt{n}\mathbb{P}_n\dot{\ell}^3(\boldsymbol{\theta}_0) <span class="sc">\\</span></span>
<span id="cb1-2050"><a href="#cb1-2050"></a>&amp;\quad + \left(\mathcal{I}_{(\nu, \lambda)}^{4}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n\dot{\ell}^{(4)}(\boldsymbol{\theta}_0) + o_P(1),<span class="sc">\\</span></span>
<span id="cb1-2051"><a href="#cb1-2051"></a>\sqrt{n}&amp;(\hat{\beta}^{(4)}-\beta_0)<span class="sc">\\</span></span>
<span id="cb1-2052"><a href="#cb1-2052"></a>&amp;= \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\left\{\sqrt{n}\mathbb{P}_n \dot{\ell}_\beta^{4}(\boldsymbol{\theta}_0)</span>
<span id="cb1-2053"><a href="#cb1-2053"></a><span class="ss">- </span>\mathcal{I}_{\beta, (\nu, \lambda)}^{3}\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(3)}, \hat{\lambda}^{(3)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span> \right. <span class="sc">\\</span></span>
<span id="cb1-2054"><a href="#cb1-2054"></a>&amp;\quad \left. - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)}\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(4)}, \hat{\lambda}^{(4)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span>\right<span class="sc">\}</span> + o_P(1)<span class="sc">\\</span></span>
<span id="cb1-2055"><a href="#cb1-2055"></a>&amp;= \left(\begin{array}{cccc}</span>
<span id="cb1-2056"><a href="#cb1-2056"></a>-\left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3(\tilde{\mathcal{I}}_{\beta}^3)^{-1} - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)} - \mathcal{I}_{\beta, (\nu, \lambda)}^{(4)}\mathcal{I}_{(\nu, \lambda), \beta}^4 (\tilde{\mathcal{I}}_{\beta}^3)^{-1} \mathcal{I}_{\beta, (\nu, \lambda)}^3 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}<span class="sc">\\</span></span>
<span id="cb1-2057"><a href="#cb1-2057"></a>\left(\mathcal{I}_{\beta}^{4}\right)^{-1} + \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta, (\nu, \lambda)}^3(\tilde{\mathcal{I}}_{\beta}^3)^{-1} \mathcal{I}_{(\nu, \lambda), \beta}^3 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}</span>
<span id="cb1-2058"><a href="#cb1-2058"></a>-\mathcal{I}_{\beta,(\nu, \lambda)}^{(4)}\mathcal{I}_{(\nu, \lambda), \beta}^4 (\tilde{\mathcal{I}}_{\beta}^3)^{-1}</span>
<span id="cb1-2059"><a href="#cb1-2059"></a>\end{array}\right)^\top<span class="sc">\\</span></span>
<span id="cb1-2060"><a href="#cb1-2060"></a>&amp;\quad \times \sqrt{n}\mathbb{P}_n \dot{\ell}^3(\boldsymbol{\theta}_0) + \left(-\left(\mathcal{I}_{\beta}^{4}\right)^{-1}\mathcal{I}_{\beta,(\nu, \lambda)}^{(4)}(\mathcal{I}_{(\nu, \lambda)}^4)^{-1}, \left(\mathcal{I}_{\beta}^{4}\right)^{-1}\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{(4)}(\boldsymbol{\theta}_0) + o_P(1),</span>
<span id="cb1-2061"><a href="#cb1-2061"></a>\end{align*} 其中$\sqrt{n}\mathbb{P}_n \ell^3(\boldsymbol{\theta}_0)\leadsto N(0, \mathcal{I}^{3})$ 和 $\sqrt{n}\mathbb{P}_n \ell^{(4)}(\boldsymbol{\theta}_0)\leadsto N(0, \mathcal{I}^{(4)})$是独立的. 结合这两个近似结果, 可以得到 $\Sigma_4$ 的表达式.</span>
<span id="cb1-2062"><a href="#cb1-2062"></a></span>
<span id="cb1-2063"><a href="#cb1-2063"></a>要建立对于每个 $m \geq 4$ 的渐近协方差 $\Sigma_{m+1}$, 注意 $\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)$ 可以表示为 \begin{align*}</span>
<span id="cb1-2064"><a href="#cb1-2064"></a>\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)</span>
<span id="cb1-2065"><a href="#cb1-2065"></a>&amp;= A_{m,3}\sqrt{n}\mathbb{P}_n \dot{\ell}^3(\boldsymbol{\theta}_0) + A_{m,4}\sqrt{n}\mathbb{P}_n \dot{\ell}^{(4)}(\boldsymbol{\theta}_0)<span class="sc">\\</span></span>
<span id="cb1-2066"><a href="#cb1-2066"></a>&amp; \quad + \cdots + A_{m,m}\sqrt{n}\mathbb{P}_n \dot{\ell}^{(m)}(\boldsymbol{\theta}_0),</span>
<span id="cb1-2067"><a href="#cb1-2067"></a>\end{align*} 其中$A_{m, 3}, \cdots, A_{m, m}$ 是 $3 \times 1$ 的矩阵. 接下来为这些系数矩阵建立一个递推关系. 根据 $\sqrt{n}(\hat{\beta}^{(m)} - \beta_0)$ 的近似式, 得到 \begin{align*}</span>
<span id="cb1-2068"><a href="#cb1-2068"></a>&amp;\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-2069"><a href="#cb1-2069"></a>&amp; = \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{m+1}(\boldsymbol{\theta}_0) - \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\mathcal{I}_{(\nu, \lambda),\beta}^{m+1}\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)<span class="sc">\\</span></span>
<span id="cb1-2070"><a href="#cb1-2070"></a>&amp;= \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left\{\left[\left(I_2, 0\right) - A_{m, 3}\right]\sqrt{n}\mathbb{P}_n \dot{\ell}^{3}(\boldsymbol{\theta}_0) + \sum_{j=4}^{m} \left[\left(I_2, 0\right) - A_{m, j}\right]\sqrt{n}\mathbb{P}_n \dot{\ell}^{(j)}(\boldsymbol{\theta}_0)\right<span class="sc">\}\\</span></span>
<span id="cb1-2071"><a href="#cb1-2071"></a>&amp;\quad + \sum_{j=4}^{m} \left(\mathcal{I}_{(\nu, \lambda)}^{m+1}\right)^{-1}\left(I_2, 0\right)\sqrt{n}\mathbb{P}_n \dot{\ell}^{(m+1)}(\boldsymbol{\theta}_0).</span>
<span id="cb1-2072"><a href="#cb1-2072"></a>\end{align*} 再利用式 \eqref{eq: iteration assymption for lambda_(m+1)} 中关于$\sqrt{n}\left[(\hat{\nu}^{(j)}, \hat{\lambda}^{(j)}) - (\nu_0, \lambda_0)\right]$ 的近似, 可以得到 \begin{align*}</span>
<span id="cb1-2073"><a href="#cb1-2073"></a>A_{m+1, 3} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}\left\{(0,0,1) - \mathcal{I}_{\beta, (\nu, \lambda)}^3 A_{3,3}\vphantom{\sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}}\right.<span class="sc">\\</span></span>
<span id="cb1-2074"><a href="#cb1-2074"></a>&amp; \quad \left. - \sum_{j=4}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left(\mathcal{I}_{(\nu, \lambda</span>
<span id="cb1-2075"><a href="#cb1-2075"></a>)}^{j}\right)^{-1}\left<span class="co">[</span><span class="ot">(I_2, 0) - A_{m, 3}\right</span><span class="co">]</span>\right<span class="sc">\}</span>,<span class="sc">\\</span></span>
<span id="cb1-2076"><a href="#cb1-2076"></a>A_{m+1, j} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}\left\{(0,0,1) - \mathcal{I}_{\beta, (\nu, \lambda)}^{(j)}\left(\mathcal{I}_{(\nu, \lambda)}^{j}\right)^{-1}(I_2, 0) \vphantom{\sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}} \right.<span class="sc">\\</span></span>
<span id="cb1-2077"><a href="#cb1-2077"></a>&amp;\quad \left. - \sum_{l=j+1}^m \mathcal{I}_{\beta, (\nu, \lambda)}^{(l)}\left(\mathcal{I}_{(\nu, \lambda)}^{(l)}\right)^{-1}\left[(I_2, 0) - A_{m, l}\right]\right<span class="sc">\}</span>,<span class="sc">\\</span></span>
<span id="cb1-2078"><a href="#cb1-2078"></a>A_{m+1, m+1} &amp;= \left(\mathcal{I}_\beta^{m+1}\right)^{-1}(0,0,1),</span>
<span id="cb1-2079"><a href="#cb1-2079"></a>\end{align*} \normalsize 其中 $j = 4, \cdots, m$. 结合 $\sqrt{n}\left<span class="co">[</span><span class="ot">(\hat{\nu}^{(m+1)}, \hat{\lambda}^{(m+1)}) - (\nu_0, \lambda_0)\right</span><span class="co">]</span>$ 和 $\sqrt{n}(\hat{\beta}^{(m)}-\beta_0)$ 的近似, 可以得到协方差矩阵 $\Sigma_{m+1}$.</span>
<span id="cb1-2080"><a href="#cb1-2080"></a></span>
<span id="cb1-2081"><a href="#cb1-2081"></a><span class="fu">#### 定理 @thm-th2 证明 {.unnumbered}</span></span>
<span id="cb1-2082"><a href="#cb1-2082"></a></span>
<span id="cb1-2083"><a href="#cb1-2083"></a>基于 \eqref{eq:rerul}, $\mathcal{X}_m$ 的 CDF 可以表示为 $\mathbb{E}_{\pi(\nu \mid y_m)}[F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)]$, 并且已知 $\pi(\nu \mid y_m)$ 是一个正态分布\index{正态分布}, 其均值和方差分别为 $$\mu_m=\dfrac{\lambda \Lambda_\beta(t_m)+\mu\sigma^{-2}}{\lambda y_m+\sigma^{-2}},\quad \tau_m=\left(\lambda y_m+\sigma^{-2}\right)^{-1}.$$ 另一方面, $F_{\mathcal{X}_m}\left(x \mid \nu,y_m\right)$ 在 \eqref{cdfrul} 中给出, 由两个部分组成, 其形式为 $\Phi(aX+b)$ 和 $\exp(cX)\Phi(aX+b)$, 其中 $a$、$b$ 和 $c$ 为实数. 因此, $F_{\mathcal{X}_m}\left(x \mid \nu\right)$可以根据以下结果推导 <span class="co">[</span><span class="ot">@si2013generalized</span><span class="co">]</span>:</span>
<span id="cb1-2084"><a href="#cb1-2084"></a></span>
<span id="cb1-2085"><a href="#cb1-2085"></a>(i) 如果 $X\sim \mathcal{N}(w,\delta^2)$, 且 $a,b\in \mathbb{R}$, 则有 $\mathbb{E}<span class="co">[</span><span class="ot">\Phi(aX+b)</span><span class="co">]</span>=\Phi\left(\frac{aw+b}{\sqrt{1+a^2\delta^2}}\right)$.</span>
<span id="cb1-2086"><a href="#cb1-2086"></a></span>
<span id="cb1-2087"><a href="#cb1-2087"></a>(ii) 如果 $X\sim \mathcal{N}(w,\delta^2)$, 且 $a,b, c\in \mathbb{R}$, 则 $$\mathbb{E}<span class="co">[</span><span class="ot">\exp(cX)\Phi(aX+b)</span><span class="co">]</span>=\exp\left(cw+c^2\delta^2/2\right)\Phi\left(\frac{aw+b+ac\delta^2}{\sqrt{1+a^2\delta^2}}\right).$$</span>
</code><button title="复制到剪贴板" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>